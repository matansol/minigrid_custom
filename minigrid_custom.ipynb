{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.5, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\gym\\envs\\registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from gym.wrappers.record_video import RecordVideo\n",
    "from gym_minigrid.wrappers import *\n",
    "from gym import spaces\n",
    "from gym_minigrid.minigrid import OBJECT_TO_IDX, COLOR_TO_IDX\n",
    "from minigrid.wrappers import FullyObsWrapper\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from custom_env import *\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# enable manual control for testing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m manual_control \u001b[38;5;241m=\u001b[39m ManualControl(env, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmanual_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\minigrid\\manual_control.py:29\u001b[0m, in \u001b[0;36mManualControl.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "from custom_env import SimpleEnv\n",
    "# from base_env import SimpleEnv \n",
    "from minigrid.manual_control import ManualControl\n",
    "\n",
    "env = SimpleEnv(render_mode=\"human\")\n",
    "\n",
    "# enable manual control for testing\n",
    "manual_control = ManualControl(env, seed=42)\n",
    "manual_control.start()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '__version__' from 'tensorflow.keras' (c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent  \u001b[38;5;66;03m# pip install keras-rl2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BoltzmannQPolicy  \u001b[38;5;66;03m# important to have gym==0.25.2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialMemory\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\agents\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent, NAFAgent, ContinuousDQNAgent\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mddpg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPGAgent\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CEMAgent\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\agents\\dqn.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lambda, Input, Layer, Dense\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EpsGreedyQPolicy, GreedyQPolicy\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\core.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m History\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     CallbackList,\n\u001b[0;32m      9\u001b[0m     TestLogger,\n\u001b[0;32m     10\u001b[0m     TrainEpisodeLogger,\n\u001b[0;32m     11\u001b[0m     TrainIntervalLogger,\n\u001b[0;32m     12\u001b[0m     Visualizer\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAgent\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class for all implemented agents.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Each agent interacts with the environment (as defined by the `Env` class) by first observing the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        processor (`Processor` instance): See [Processor](#processor) for details.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\callbacks.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m KERAS_VERSION\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback \u001b[38;5;28;01mas\u001b[39;00m KerasCallback, CallbackList \u001b[38;5;28;01mas\u001b[39;00m KerasCallbackList\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Progbar\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '__version__' from 'tensorflow.keras' (c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from rl.agents import DQNAgent  # pip install keras-rl2\n",
    "from rl.policy import BoltzmannQPolicy  # important to have gym==0.25.2\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(states)\n",
    "print(actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1, states)))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(actions, activation=\"linear\"))\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    memory=SequentialMemory(limit=50000, window_length=1),\n",
    "    policy=BoltzmannQPolicy(),\n",
    "    nb_actions=actions,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=0.01\n",
    ")\n",
    "agent.compile(Adam(lr=0.001), metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fit(env, nb_steps=100000, visualize=False, verbose=1)\n",
    "\n",
    "results = agent.test(env, nb_episodes=10, visualize=True)\n",
    "print(np.mean(results.history[\"episode_reward\"]))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 39.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016745023 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -6.56e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 56          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012996806 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 439         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 67          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813505 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 70.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017063232 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 373      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 83.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00724918 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013514 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066653113 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016817097 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 82       |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050967913 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 4.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700294 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051882556 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 4.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064221974 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 93.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040440275 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    value_loss           | 4.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027300868 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 93.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322477 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 79.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001761134 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.000244    |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006904303 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045830947 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000986033 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016759988 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000147   |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 96.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 342      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074285967 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 5.2e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 108           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089353387 |\n",
      "|    clip_fraction        | 0.0162        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 4.58e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007995691 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109256245 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074775834 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.864       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 4.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065346584 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.84        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000203    |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005958454 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035281728 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 5.38e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 95.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036199484 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072609335 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 4.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008907542 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000301   |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012195694 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 83968    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837668 |\n",
      "|    clip_fraction        | 0.00122    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.71e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 5.51e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042872117 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 4.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003127471 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757554 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 347      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806638 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469336 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000132   |\n",
      "|    value_loss           | 4.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 94          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544237 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 87.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027082602 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 937          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 3.79e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 346      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 104448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699876 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 5.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021670484 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -7.28e-05    |\n",
      "|    value_loss           | 3.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 200          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318239 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.766       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.00225      |\n",
      "|    value_loss           | 4.52e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 114           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 195           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069240853 |\n",
      "|    clip_fraction        | 0.0885        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.695        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04e+03      |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | 0.00744       |\n",
      "|    value_loss           | 5.34e+03      |\n",
      "-------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    fps             | 340      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132288 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    value_loss           | 3.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962042 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014535714 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915886 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.99     |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 111           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090316555 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.876        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+03      |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 4.56e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005358369 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000219    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027590515 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00389      |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129278 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.000136    |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 97          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009328622 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827135 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000193   |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802983 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.58e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 4.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038080818 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 4.33e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 81.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334834 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884477 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027027782 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000953     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148533825 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 4.61e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 87.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 359      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057178666 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 122          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033629797 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00051      |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007892546 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.000648    |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019677244 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03e+03    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.000685    |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 79       |\n",
      "| time/              |          |\n",
      "|    fps             | 370      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060133724 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.839       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.00149      |\n",
      "|    value_loss           | 3.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 96.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005331138 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033965213 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.841       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000696    |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012086405 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 3.68e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 85.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011505147 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 87.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186378 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 118          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025656747 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.857       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 116          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028238147 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 4.55e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 326      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007451922 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.000854   |\n",
      "|    value_loss           | 5.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165756 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013255063 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091443565 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91       |\n",
      "| time/              |          |\n",
      "|    fps             | 355      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044491906 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.83        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    value_loss           | 3.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058027483 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -6.83e-05    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048686834 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.769       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 3.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648111 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 4.26e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 83.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005274161 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815546 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070802174 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 5.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 188          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054791663 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 3.88e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 321      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 76           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011077174 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.000274     |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046208925 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015564067 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074326093 |\n",
      "|    clip_fraction        | 0.0871       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 3.81e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 98.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 227328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876669 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063385884 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264943 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016652509 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 107           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034711955 |\n",
      "|    clip_fraction        | 0.0244        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.69e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.00085       |\n",
      "|    value_loss           | 4.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016328925 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000263    |\n",
      "|    value_loss           | 4.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003549381 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.000475    |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663654 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.8e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86       |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 92            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 230           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029237106 |\n",
      "|    clip_fraction        | 0.0285        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.787        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+03      |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | 0.000375      |\n",
      "|    value_loss           | 3.43e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059726173 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.792       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    value_loss           | 3.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005957151 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.000321   |\n",
      "|    value_loss           | 4.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033260798 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 4.31e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 99       |\n",
      "| time/              |          |\n",
      "|    fps             | 354      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 258048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006194873 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 92.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021582353 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | 0.00137      |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976463 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037286112 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | 0.000389     |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 268288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017541461 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 0.000427     |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149781 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068907375 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.812       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047259 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00012    |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 100      |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006399434 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008038925 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.000327   |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015558364 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+03    |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016617142 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.856       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 4.99e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 84       |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186628 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+03     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.99       |\n",
      "|    ep_rew_mean          | 102        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01078388 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.895     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    value_loss           | 3.78e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022918442 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 8.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012425364 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 4.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from custom_env import *\n",
    "\n",
    "from custom_env import SimpleEnv \n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "TIMSTEMPS = 10000\n",
    "for i in range(1, 15):\n",
    "    model.learn(total_timesteps=TIMSTEMPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/model_{i}\")\n",
    "# model.learn(2e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{models_dir}/model_13.zip\"\n",
    "load_model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('image': Box(0, 255, (7, 7, 3), uint8))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (5 x 1). Kernel size: (2 x 2). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mobservation_space)\n\u001b[1;32m---> 12\u001b[0m extractor \u001b[38;5;241m=\u001b[39m \u001b[43mMinigridFeaturesExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Use the model to predict the next action\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# obs = torch.from_numpy(obs[0]).float().unsqueeze(0)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# obs = extractor.forward(obs)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\technion\\master\\experiment\\my_project\\minigrid\\custom_env.py:132\u001b[0m, in \u001b[0;36mMinigridFeaturesExtractor.__init__\u001b[1;34m(self, observation_space, features_dim, normalized_image)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Compute shape by doing one forward pass\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 132\u001b[0m     n_flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(n_flatten, features_dim), nn\u001b[38;5;241m.\u001b[39mReLU())\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (5 x 1). Kernel size: (2 x 2). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# extractor = MinigridFeaturesExtractor(env.observation_space, features_dim=128)\n",
    "test_env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10, change_reward=True)\n",
    "test_env = ImgObsWrapper(test_env)  # Wrap the environment if needed\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ObjObsWrapper(env)\n",
    "# Reset the environment to get the initial observation\n",
    "obs = env.reset()\n",
    "print(env.observation_space)\n",
    "extractor = MinigridFeaturesExtractor(env.observation_space['image'], features_dim=128)\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "# Use the model to predict the next action\n",
    "    # obs = torch.from_numpy(obs[0]).float().unsqueeze(0)\n",
    "    # obs = extractor.forward(obs)\n",
    "    obs = extractor.forward(obs)\n",
    "    print(obs.shape)\n",
    "\n",
    "    action, _states = model.predict(obs[0], deterministic=True)\n",
    "    \n",
    "    # You can then take the action in the environment to move to the next state\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "\n",
    "    # If you want to visualize the action taken, you can render the environment\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoToObject base code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train] [--load_model LOAD_MODEL]\n",
      "                             [--render]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\matan\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-12600ExN17fKT334V.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from minigrid_gotoobj_train import *\n",
    "from custom_env import SimpleEnv\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--train\", action=\"store_true\", help=\"train the model\")\n",
    "parser.add_argument(\n",
    "    \"--load_model\",\n",
    "    default=\"minigrid_gotoobj/iter_2000000_steps.zip\",\n",
    ")\n",
    "parser.add_argument(\"--render\", action=\"store_true\", help=\"render trained models\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "policy_kwargs = dict(features_extractor_class=ObjEnvExtractor)\n",
    "\n",
    "# Create time stamp of experiment\n",
    "stamp = datetime.fromtimestamp(time()).strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if args.train:\n",
    "    env = SimpleEnv()\n",
    "    env = ObjObsWrapper(env)\n",
    "\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=1e5,\n",
    "        save_path=f\"./models/ppo/minigrid_gotoobj_{stamp}/\",\n",
    "        name_prefix=\"iter\",\n",
    "    )\n",
    "\n",
    "    model = PPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./logs/ppo/minigrid_gotoobj_tensorboard/\",\n",
    "    )\n",
    "    model.learn(\n",
    "        2e4, # epochs to train\n",
    "        tb_log_name=f\"{stamp}\",\n",
    "        callback=checkpoint_callback,\n",
    "    )\n",
    "else:\n",
    "    if args.render:\n",
    "        env = SimpleEnv(render_mode=\"human\")\n",
    "    else:\n",
    "        env = SimpleEnv()\n",
    "    env = ObjObsWrapper(env)\n",
    "\n",
    "    ppo = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "    # add the experiment time stamp\n",
    "    ppo = ppo.load(f\"models/ppo/{args.load_model}\", env=env)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    rewards = 0\n",
    "\n",
    "    for i in range(2000):\n",
    "        action, _state = ppo.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            print(f\"Test reward: {rewards}\")\n",
    "            obs, info = env.reset()\n",
    "            rewards = 0\n",
    "            continue\n",
    "\n",
    "    print(f\"Test reward: {rewards}\")\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 2, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 1.5, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2,  Reward: -110.69, Done: True, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0: score: -107.19\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 1, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2,  Reward: -31.580000000000005, Done: True, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1: score: -30.580000000000005\n"
     ]
    }
   ],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "num_episodes = 2\n",
    "for i in range(num_episodes):\n",
    "# Reset the environment to get the initial state\n",
    "    state, info = env.reset()\n",
    "    # plot_state(env)\n",
    "    score = 0\n",
    "    # Run the simulation\n",
    "    done = False\n",
    "    plot_state(env)\n",
    "    while not done:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take the action in the environment\n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        if reward != 0:\n",
    "            print(f\"Action: {action},  Reward: {reward}, Done: {done}, Truncated: {truncated}, Info: {info}\")\n",
    "            plot_state(env)\n",
    "            \n",
    "    plot_state(env)\n",
    "    print(f\"episode {i}: score: {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Player(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "from app_db import *\n",
    "from datetime import datetime\n",
    "\n",
    "with app.app_context():\n",
    "    db.create_all()\n",
    "    players = Player.query.all()\n",
    "\n",
    "    print(players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
