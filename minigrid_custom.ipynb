{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# from IPython import display\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# from gym.wrappers.record_video import RecordVideo\n",
    "from minigrid.wrappers import *\n",
    "\n",
    "from minigrid.wrappers import FullyObsWrapper, ImgObsWrapper, NoDeath\n",
    "from minigrid.core.actions import Actions\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from minigrid_custom_train import UpgradedObjEnvExtractor\n",
    "\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from minigrid_custom_env import *\n",
    "from minigrid_custom_train import *\n",
    "from dpu_clf import *\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_env_from_model_name(model_name):\n",
    "    env_info = model_name.split('S')[0].split(',')\n",
    "    grid_size = 8\n",
    "    max_steps = 200\n",
    "    agent_view_size = 7\n",
    "    lava_cost = float(env_info[3])\n",
    "    step_cost = float(env_info[4])\n",
    "    colors_rewards = {'red':float(env_info[0]), 'green': float(env_info[1]), 'blue': float(env_info[2])}\n",
    "    step_count = True if 'Step_Count' in model_name else False\n",
    "    env = CustomEnv(grid_size=grid_size, render_mode='rgb_array', max_steps=max_steps, highlight=True, unique_env=0, step_cost=step_cost, step_count_observation=step_count,\n",
    "                        num_objects=4, lava_cells=4, train_env=True, image_full_view=False, agent_view_size=agent_view_size, colors_rewards=colors_rewards)\n",
    "    env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=lava_cost)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new env with balls: [(5, 6, 'blue', 2), (4, 1, 'blue', 2), (4, 2, 'green', 2)]\n",
      "observation size: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "#test the environment\n",
    "\n",
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "# env = CustomEnv(size = 8, render_mode='rgb_array', difficult_grid=False, agent_pov=True, step_count_observation=False)\n",
    "# env = ImgObsWrapper(ObjObsWrapper(env))\n",
    "grid_size = 8\n",
    "max_steps = 300\n",
    "agent_view_size = 7\n",
    "lava_cost = -5\n",
    "colors_rewards = {'red':3, 'green': 1, 'blue': 0}\n",
    "kwargs = {\n",
    "    \"initial_balls\": initial_balls,\n",
    "    \"other_lava_cells\": other_lava_cells,\n",
    "    \"grid_size\": grid_size,\n",
    "    \"render_mode\": 'rgb_array',\n",
    "    \"max_steps\": max_steps,\n",
    "    \"highlight\": True,\n",
    "    \"unique_env\": 0,\n",
    "    \"step_count_observation\": False,\n",
    "    \"num_objects\": 4,\n",
    "    \"train_env\": True,\n",
    "    \"image_full_view\": False,\n",
    "    \"agent_view_size\": agent_view_size,\n",
    "    \"colors_rewards\": colors_rewards,\n",
    "    \"simillarity_level\": 3,\n",
    "    \"num_lava_cells\": 4,\n",
    "}\n",
    "\n",
    "env = CustomEnv(**kwargs)\n",
    "        \n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=lava_cost)\n",
    "# env = ObjObsWrapper(env)\n",
    "\n",
    "\n",
    "current_obs = env.reset()\n",
    "current_obs = current_obs[0]\n",
    "plot_state(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset new env with balls: [(4, 4, 'green', 2), (4, 5, 'red', 2), (4, 2, 'red', 2), (5, 6, 'blue', 2)]\n",
      "lava cells: [(2, 1), (3, 4), (3, 5), (3, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\AppData\\Local\\Temp\\ipykernel_6316\\3311627992.py:18: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "current_obs = env.reset()\n",
    "current_obs = current_obs[0]\n",
    "plot_state(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 5), (2, 4), (4, 3)]\n",
      "[(5, 6, 'blue', 2), (4, 1, 'red', 2), (4, 2, 'red', 2)]\n"
     ]
    }
   ],
   "source": [
    "initial_balls = env.get_wrapper_attr('initial_balls')\n",
    "other_lava_cells = env.get_wrapper_attr('lava_cells')\n",
    "print(other_lava_cells)\n",
    "print(initial_balls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "models_names = [\n",
    "                # 'models/0,5,0,-3,0.2Steps100Grid8_20241231',\n",
    "                'models/1,1,1,-3.0,0.01Steps200Grid8_20250416',\n",
    "                'models/1,1,1,0.0,0.01Steps200Grid8_20250416',\n",
    "                'models/2,-0.1,2,0,0.01Steps200Grid8_20250416',\n",
    "                'models/2,0,2,-3,0.01Steps200Grid8_20250416',\n",
    "                'models/2,0,2,-3,0.01Steps200Grid8_20250416',\n",
    "                # 'models/2,2,2,-1,0.2Steps200Grid8_20250324',\n",
    "                # 'models/2,2,2,-3,0.2Steps100Grid8_20241230',\n",
    "                # 'models/2,2,2,-3,0.2Steps100Grid8_20241231',\n",
    "                # 'models/2,2,2,0,0.1Steps250Grid8_20241225',\n",
    "                # 'models/3,0,0,-4,0.2Steps300Grid8_20250106',\n",
    "                # 'models/3,1,0,-4,0.2Steps300Grid8_20250106',\n",
    "                # 'models/3,1,0,-4,0.2Steps300Grid8_20250109',\n",
    "                # 'models/3,3,3,-0.1,0.2Steps300Grid8_20250406',\n",
    "                'models/3,3,3,-5,0.1Steps100Grid8_20250417',\n",
    "                # 'models/3,3,3,0,0.1Steps100Grid8_Step_Count_20250327',\n",
    "                # 'models/4,-0.1,-0.1,-4,0.2Steps300Grid8_20250129',\n",
    "                # 'models/5,5,5,-4,0.2Steps200Grid8_Step_Count_20250325',\n",
    "                ]\n",
    "\n",
    "models_names = [path.split(\"/\")[1] for path in models_names]\n",
    "\n",
    "\n",
    "# model_name = models_names[0]\n",
    "# model_path = os.path.join(\"models\", model_name, \"best_model\")\n",
    "# env = create_env_from_model_name(model_name)\n",
    "# agent = load_agent(env, model_path)\n",
    "# print(evaluate_agent(env, agent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation size: 7\n"
     ]
    }
   ],
   "source": [
    "def create_env(model_name, grid_size, agent_view_size, max_steps, highlight, num_objects, lava_cells, train_env=True, image_full_view=False):\n",
    "    env_info = model_name.split('S')[0].split(',')\n",
    "    lava_cost = float(env_info[3])\n",
    "    step_cost = float(env_info[4])\n",
    "    colors_rewards = {'red':float(env_info[0]), 'green': float(env_info[1]), 'blue': float(env_info[2])}\n",
    "    step_count = True if 'Step_Count' in model_name else False\n",
    "    base_env =  CustomEnv(\n",
    "            grid_size=grid_size,\n",
    "            render_mode='rgb_array',\n",
    "            max_steps=max_steps,\n",
    "            highlight=highlight,\n",
    "            step_cost=step_cost,\n",
    "            num_objects=num_objects,\n",
    "            lava_cells=lava_cells,\n",
    "            train_env=train_env,\n",
    "            image_full_view=image_full_view,\n",
    "            agent_view_size=agent_view_size,\n",
    "            color_rewards=colors_rewards,\n",
    "            step_count_observation=step_count\n",
    "        )\n",
    "    base_env = NoDeath(ObjObsWrapper(base_env), no_death_types=('lava',), death_cost=lava_cost)\n",
    "    env = Monitor(base_env)  # Add Monitor for logging\n",
    "    \n",
    "    # env = DummyVecEnv([lambda: env])\n",
    "    # env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "\n",
    "model_name = '1,1,1,-1,0.01Steps200Grid8_20250409' #'1,1,1,-1,0.01Steps200Grid8_20250409'\n",
    "grid_size = 8\n",
    "max_steps = 200\n",
    "agent_view_size = 7\n",
    "num_balls = 4\n",
    "num_lava_cell = 4\n",
    "env = create_env(\n",
    "        model_name=model_name,\n",
    "        grid_size=grid_size,\n",
    "        agent_view_size=agent_view_size,\n",
    "        max_steps=max_steps,\n",
    "        highlight=True,\n",
    "        num_objects=num_balls,\n",
    "        lava_cells=num_lava_cell,\n",
    "        train_env=True,\n",
    "        image_full_view=False,\n",
    "        )\n",
    "# env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=10.0)\n",
    "# env_instance = CustomEnv(\n",
    "#         grid_szie=8, render_mode=\"rgb_array\", image_full_view=False,\n",
    "#         highlight=True, max_steps=100, num_objects=5, lava_cells=3, partial_obs=True,\n",
    "#         unique_env=0\n",
    "#     )\n",
    "# env = NoDeath(ObjObsWrapper(env_instance), no_death_types=(\"lava\",), death_cost=-3)\n",
    "model_path = os.path.join(\"models\", model_name, \"best_model\")\n",
    "# agent = load_agent(env, model_path, update=True)\n",
    "# eval_res = evaluate_agent(env, agent, 10)\n",
    "# print(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=200\n",
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "observation size: 7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n",
      "reached max steps=200\n"
     ]
    }
   ],
   "source": [
    "models_evaluations = []\n",
    "for model_name in models_names:\n",
    "    env = create_env_from_model_name(model_name)\n",
    "    model_path = os.path.join(\"models\", model_name, \"best_model\")\n",
    "    agent = load_agent(env, model_path)\n",
    "    eval_res = evaluate_agent(env, agent)\n",
    "    models_evaluations.append({\"model name\": model_name, \"model mean score\": eval_res[0], \"model mean illegal moves\": eval_res[1], \"model mean steps\": eval_res[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model name': '1,1,1,-3.0,0.01Steps200Grid8_20250416', 'model mean score': 4.829935000000016, 'model mean illegal moves': 2, 'model mean steps': 21}\n",
      "{'model name': '1,1,1,0.0,0.01Steps200Grid8_20250416', 'model mean score': 3.7995800000000104, 'model mean illegal moves': 0, 'model mean steps': 11}\n",
      "{'model name': '2,-0.1,2,0,0.01Steps200Grid8_20250416', 'model mean score': 3.5698900000000124, 'model mean illegal moves': 0, 'model mean steps': 11}\n",
      "{'model name': '2,0,2,-3,0.01Steps200Grid8_20250416', 'model mean score': 2.1565799999999387, 'model mean illegal moves': 6, 'model mean steps': 49}\n",
      "{'model name': '2,0,2,-3,0.01Steps200Grid8_20250416', 'model mean score': 1.972284999999955, 'model mean illegal moves': 6, 'model mean steps': 52}\n",
      "{'model name': '3,3,3,-5,0.1Steps100Grid8_20250417', 'model mean score': -22.79042999999735, 'model mean illegal moves': 66, 'model mean steps': 151}\n"
     ]
    }
   ],
   "source": [
    "for model_eval in models_evaluations:\n",
    "    print(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation size: 7\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "Environment Observation Space: Dict('image': Box(0, 255, (7, 7, 3), uint8))\n",
      "PPO Model Observation Space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "index - i: 0, action: 2, reward: -0.09, done: False\n",
      "index - i: 1, action: 2, reward: -0.08, done: False\n",
      "index - i: 2, action: 2, reward: -0.07, done: False\n",
      "index - i: 3, action: 2, reward: -0.06, done: False\n",
      "index - i: 4, action: 2, reward: -0.05, done: False\n",
      "index - i: 5, action: 1, reward: -0.05, done: False\n",
      "index - i: 6, action: 3, reward: 0.95, done: False\n",
      "index - i: 7, action: 2, reward: -0.04, done: False\n",
      "index - i: 8, action: 2, reward: -0.03, done: False\n",
      "index - i: 9, action: 2, reward: -0.02, done: False\n",
      "index - i: 10, action: 2, reward: -0.01, done: False\n",
      "index - i: 11, action: 2, reward: 3.892, done: True\n",
      "index - i: 0, action: 2, reward: -0.09, done: False\n",
      "index - i: 1, action: 2, reward: -0.08, done: False\n",
      "index - i: 2, action: 2, reward: -0.07, done: False\n",
      "index - i: 3, action: 2, reward: -0.06, done: False\n",
      "index - i: 4, action: 2, reward: -0.05, done: False\n",
      "index - i: 5, action: 1, reward: -0.05, done: False\n",
      "index - i: 6, action: 2, reward: -0.04, done: False\n",
      "index - i: 7, action: 2, reward: -0.03, done: False\n",
      "index - i: 8, action: 2, reward: -0.02, done: False\n",
      "index - i: 9, action: 2, reward: -0.01, done: False\n",
      "index - i: 10, action: 2, reward: 3.901, done: True\n",
      "Video saved to videos/episode_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def create_video_from_images(imgs_action_list, output_path='episode_video.mp4', fps=1):\n",
    "    \"\"\"Save images to a video file.\"\"\"\n",
    "    # Write images to a video file\n",
    "    imageio.mimsave(output_path, imgs_action_list, fps=fps)\n",
    "    print(f\"Video saved to {output_path}\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "video_path = 'videos/episode_video.mp4'\n",
    "os.makedirs(os.path.dirname(video_path), exist_ok=True)\n",
    "\n",
    "random_seed = np.random.randint(0, 10000)\n",
    "\n",
    "# model_name = models_names[-1]\n",
    "model_name = \"1,1,1,0.0,0.01Steps200Grid8_20250416\"\n",
    "model_path = os.path.join(\"models\", model_name, \"best_model\")\n",
    "env = create_env(model_name,\n",
    "                grid_size=8,\n",
    "                 agent_view_size=7,\n",
    "                 max_steps=100,\n",
    "                 highlight=True,\n",
    "                 num_objects=4,\n",
    "                 lava_cells=6,\n",
    "                 train_env=True,\n",
    "                 seed=random_seed,)\n",
    "agent = load_agent(env, model_path, False) # false = use regular ObjExtractor, true = use upgraded ObjExtractor\n",
    "images_list = []\n",
    "\n",
    "\n",
    "# for i in range(num_episodes):\n",
    "#         # kwargs = {'simillarity_level': 3}\n",
    "#         state = env.unwrapped.reset()\n",
    "#         state = {'image': state['image']}\n",
    "#         done = False\n",
    "#         while not (done):\n",
    "#             last_obs = state\n",
    "#             agent_pos_before = env.envs[0].unwrapped.agent_pos\n",
    "#             # print(state)\n",
    "#             action, _ = agent.predict(state)\n",
    "#             state, reward, done, truncle = env.unwrapped.step(action)\n",
    "#             total_reward += reward\n",
    "#             total_moves += 1\n",
    "#             if is_illegal_move(action, last_obs, state, agent_pos_before, env.envs[0].unwrapped.agent_pos):\n",
    "#                 total_illegal_moves += 1\n",
    "\n",
    "for i in range(2):  # Two episodes\n",
    "    done = False\n",
    "    current_obs = env.unwrapped.reset()\n",
    "    current_obs = current_obs[0]\n",
    " \n",
    "    current_obs = {'image': current_obs['image']}\n",
    "\n",
    "    j = 0\n",
    "    while not done:\n",
    "        action, _ = agent.predict(current_obs)\n",
    "        current_obs, reward, done, _, _ = env.unwrapped.step(action)\n",
    "        current_obs = {'image': current_obs['image']}\n",
    "        print(f\"index - i: {j}, action: {action}, reward: {reward}, done: {done}\")\n",
    "        img = env.unwrapped.render()  # Get the rendered frame\n",
    "        images_list.append(img)\n",
    "        time.sleep(0.3)  # Slow down for visualization\n",
    "        j+=1\n",
    "\n",
    "# Ensure images_list is not empty\n",
    "if images_list:\n",
    "    create_video_from_images(images_list, output_path=video_path, fps=4)\n",
    "\n",
    "    # Display the video inline in Jupyter\n",
    "    display(Video(video_path, embed=True))\n",
    "else:\n",
    "    print(\"No images to create video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n"
     ]
    }
   ],
   "source": [
    "# save in CSV preference vector and evaluation\n",
    "\n",
    "name = 'LavaLaverNR_Grid8_20241113'\n",
    "model_path = 'models\\LavaLaverRedN8_20241113\\iter_500000_steps' \n",
    "pref_vector = [-2,2,2,0,-0.1] # (red ball, green ball, blue ball, lava, step penalty)\n",
    "evaluation = evaluate_agent(env, load_agent(env, model_path), num_episodes=100)\n",
    "add_path_to_csv(name, model_path, pref_vector, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'direction', 'mission'])\n",
      "observation size: 7\n",
      "dict_keys(['image'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points {0: (1, 1, 0), 1: (2, 5, 2), 2: (2, 3, 2), 3: (2, 5, 2), 4: (5, 5, 2)}\n",
      "Total reward: 6.0, Total steps: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.find_optimal_path to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.find_optimal_path` for environment variables or `env.get_wrapper_attr('find_optimal_path')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#test the environment\n",
    "\n",
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = CustomEnv(grid_size=8, render_mode='rgb_array', difficult_grid=False, max_steps=300, highlight=True, unique_env=0,\n",
    "                        num_objects=5, lava_cells=2, train_env=True, image_full_view=False, agent_view_size=7, partial_obs=False)\n",
    "state, _ = env.reset()\n",
    "print(state.keys())\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-1.0)\n",
    "# env = ImgObsWrapper(ObjObsWrapper(env))\n",
    "\n",
    "state, _ = env.reset()\n",
    "print(state.keys())\n",
    "plot_state(env)\n",
    "\n",
    "\n",
    "#test the environment\n",
    "total_reward, total_steps = env.find_optimal_path()\n",
    "print(f\"Total reward: {total_reward}, Total steps: {total_steps}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'direction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m move_sequence, illigal_moves, total_reward, ligal_actions \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_agent_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m buf, actions_with_location, buf_list \u001b[38;5;241m=\u001b[39m plot_all_move_sequence(img\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(), move_sequence\u001b[38;5;241m=\u001b[39mmove_sequence, agent_true_actions\u001b[38;5;241m=\u001b[39mligal_actions)\n",
      "File \u001b[1;32mc:\\Users\\matan\\master_thesis\\minigrid_custom\\dpu_clf.py:75\u001b[0m, in \u001b[0;36mcapture_agent_path\u001b[1;34m(copy_env, agent)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     74\u001b[0m     agent_pos_before \u001b[38;5;241m=\u001b[39m copy_env\u001b[38;5;241m.\u001b[39mget_wrapper_attr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_pos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     agent_actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     77\u001b[0m     obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m copy_env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\policies.py:253\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    251\u001b[0m observation \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(observation)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, obs \u001b[38;5;129;01min\u001b[39;00m observation\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 253\u001b[0m     obs_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image_space(obs_space):\n\u001b[0;32m    255\u001b[0m         obs_ \u001b[38;5;241m=\u001b[39m maybe_transpose(obs, obs_space)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'direction'"
     ]
    }
   ],
   "source": [
    "\n",
    "move_sequence, illigal_moves, total_reward, ligal_actions = capture_agent_path(env, agent)\n",
    "buf, actions_with_location, buf_list = plot_all_move_sequence(img=env.render(), move_sequence=move_sequence, agent_true_actions=ligal_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "def load_agent(env, model_path):\n",
    "    # policy_kwargs = dict(features_extractor_class=ObjEnvExtractor)\n",
    "    custom_objects = {\n",
    "        \"policy_kwargs\": {\"features_extractor_class\": ObjEnvExtractor},  # Example kernel size\n",
    "        \"clip_range\": 0.2,  # Example custom parameters\n",
    "        \"lr_schedule\": 0.001  # Example learning rate schedule\n",
    "    }\n",
    "    # Load the model\n",
    "    ppo = PPO.load(f\"models/{model_path}\", custom_objects=custom_objects, env=env)\n",
    "    return ppo\n",
    "\n",
    "def is_illegal_move(action, last_obs, obs, agent_pos_befor, agent_pos):\n",
    "    if action <= 1: # turn is always legal\n",
    "        return False\n",
    "    if action == 2 and agent_pos_befor == agent_pos:\n",
    "        return True\n",
    "    if action > 2 and np.array_equal(obs['image'], last_obs['image']):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# resert the environment and run the agent on that environment to find his path\n",
    "def capture_agent_path(copy_env, agent):\n",
    "    illigal_moves = 0\n",
    "    last_obs = copy_env.unwrapped.current_state\n",
    "    \n",
    "    # last_obs = env.reset()\n",
    "    # last_obs = last_obs[0]\n",
    "    ligal_actions = []\n",
    "    agent_actions = []\n",
    "    state_record = [last_obs]\n",
    "    total_reward = 0    \n",
    "    done = False\n",
    "    # copy_env = copy.deepcopy(env)\n",
    "    # plt.imshow(copy_env.render())\n",
    "    while not done:\n",
    "        agent_pos_before = copy_env.unwrapped.agent_pos\n",
    "        action, _states = agent.predict(last_obs)\n",
    "        agent_actions.append(action)\n",
    "        obs, reward, done, _, info = copy_env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if is_illegal_move(action, last_obs, obs, agent_pos_before, copy_env.agent_pos):\n",
    "            illigal_moves += 1\n",
    "            continue\n",
    "\n",
    "        ligal_actions.append(action)\n",
    "        last_obs = obs\n",
    "        state_record.append(obs)\n",
    "        # plt.imshow(copy_env.render())\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "    number_to_action = {0: 'turn right', 1: 'turn left', 3: 'pickup'}\n",
    "    small_arrow = 'turn ' # small arrow is used to indicate the agent turning left or right\n",
    "    agent_dir = \"right\"\n",
    "    move_sequence = []\n",
    "    for action in ligal_actions:\n",
    "        if action == 0: # turn left\n",
    "            agent_dir = turn_agent(agent_dir, \"left\")\n",
    "            move_sequence.append(small_arrow + agent_dir)\n",
    "        elif action == 1: # turn right\n",
    "            agent_dir = turn_agent(agent_dir, \"right\")\n",
    "            move_sequence.append(small_arrow + agent_dir)\n",
    "        elif action == 2: # move forward\n",
    "            move_sequence.append(agent_dir)\n",
    "        elif action == 3: # pickup\n",
    "            move_sequence.append('pickup ' +  agent_dir)\n",
    "    return move_sequence, illigal_moves, total_reward, agent_actions\n",
    "\n",
    "\n",
    "def turn_agent(agent_dir, turn_dir):\n",
    "    turnning_dict = {(\"up\", \"left\"): \"left\", (\"up\", \"right\"): \"right\", \n",
    "                     (\"down\", \"left\"): \"right\", (\"down\", \"right\"): \"left\",\n",
    "                     (\"left\", \"left\"): \"down\", (\"left\", \"right\"): \"up\",\n",
    "                     (\"right\", \"left\"): \"up\", (\"right\", \"right\"): \"down\"}\n",
    "    return turnning_dict[(agent_dir, turn_dir)]\n",
    "\n",
    "def plot_move_sequence(img, move_sequence, move_color='y', turn_color='orange', pickup_color='purple'):    \n",
    "    start_point = (50, 50)\n",
    "    arrow_size = 20\n",
    "    arrow_head_size = 12\n",
    "    small_shift = 9\n",
    "    all_arrow_size = arrow_size + arrow_head_size\n",
    "    move_arrow_sizes = {'up': (0, -20, 0, -all_arrow_size), \n",
    "                        'down': (0, 20, 0, all_arrow_size), \n",
    "                        'right': (20, 0, all_arrow_size, 0), \n",
    "                        'left': (-20, 0, -all_arrow_size, 0)}\n",
    "    turn_arrow_sizes = {'turn up': (0, -5),\n",
    "                        'turn down': (0, 5),\n",
    "                        'turn right': (5, 0),\n",
    "                        'turn left': (-5, 0)}\n",
    "    pickup_direction = {'up': (0, -1),\n",
    "                         'down': (0, 1),\n",
    "                         'left': (-1, 0),\n",
    "                         'right': (1, 0)}\n",
    "    # arrows_list = ['right', 'right', 'down', 'down', 'down', 'down', 'down', 'right', 'right', 'up', 'right', 'down']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    current_point = start_point\n",
    "    for action_name in move_sequence:\n",
    "        if action_name in move_arrow_sizes.keys(): # a big arrow that represents a move\n",
    "            ax.arrow(current_point[0], current_point[1], move_arrow_sizes[action_name][0], move_arrow_sizes[action_name][1], head_width=10, head_length=10, fc=move_color, ec=move_color)\n",
    "            current_point = (current_point[0] + move_arrow_sizes[action_name][2], current_point[1] + move_arrow_sizes[action_name][3])\n",
    "        else: # a small arrow that represents a turn or a pickup\n",
    "            full_action = action_name.split(' ')\n",
    "            action = full_action[0]\n",
    "            pickup_position = pickup_direction[full_action[1]]\n",
    "            \n",
    "            if action == 'pickup':\n",
    "                ax.plot(current_point[0] + small_shift * pickup_position[0], current_point[1] + small_shift*pickup_position[1], marker='*', markersize=10, color=pickup_color)\n",
    "            else:\n",
    "                ax.arrow(current_point[0], current_point[1], turn_arrow_sizes[action_name][0], turn_arrow_sizes[action_name][1], head_width=7, head_length=6, fc=turn_color, ec=turn_color)\n",
    "            \n",
    "            \n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "colors_reward = {'red': -2, 'green': 1, 'blue': 2}\n",
    "env = CustomEnv(grid_size=8, render_mode='rgb_array', max_steps=2*10**2, agent_view_size=7, highlight=True, lava_cells=0, \n",
    "                partial_obs=False, colors_rewards=colors_reward)\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-2.0)\n",
    "model_path1 = \"LavaHate8_20241112\\iter_500000_steps\"\n",
    "model_path2 = \"LavaLaver8_20241112\\iter_500000_steps\"\n",
    "\n",
    "ppo1 = load_agent(env, \"minigrid_custom_20240907/iter_90^5_steps\")\n",
    "ppo3 = load_agent(env, \"orig_easy8_20241111\\iter_1000000_steps\")\n",
    "ppo7 = load_agent(env, \"LavaLaverRedN8_20241113\\iter_500000_steps\")\n",
    "ppo5 = load_agent(env, model_path2)\n",
    "ppo9 = load_agent(env, model_path1)\n",
    "models = {\"ppo1\": ppo1, \"ppo3\": ppo3, \"ppo5\": ppo5,  \"ppo7\": ppo7,  \"ppo9\": ppo9}\n",
    "colors_list = [\n",
    "    \"cyan\", \"magenta\", \"yellow\", \"white\",\n",
    "    \"orange\", \"purple\", \"pink\", \"brown\", \"gray\", \"olive\", \"teal\", \"navy\",\n",
    "    \"maroon\", \"lime\", \"indigo\", \"gold\"]\n",
    "colors_to_models = {\"ppo1\": \"y\", \"ppo3\": \"w\", \"ppo5\": \"gold\", \"ppo7\": \"c\", \"ppo9\": \"gray\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ppo1, Average reward: 4.0252, Average illegal moves: 4.75\n",
      "Model: ppo3, Average reward: 6.048430000000001, Average illegal moves: 0.2\n",
      "Model: ppo5, Average reward: 5.1891400000000045, Average illegal moves: 0.74\n",
      "Model: ppo7, Average reward: 8.971045000000004, Average illegal moves: 0.18\n",
      "Model: ppo9, Average reward: 4.6684149999999995, Average illegal moves: 0.05\n"
     ]
    }
   ],
   "source": [
    "def evaluate_agent(env, agent, num_episodes=100):\n",
    "    total_reward = 0\n",
    "    total_illegal_moves = 0\n",
    "    for i in range(num_episodes):\n",
    "        env.reset()\n",
    "        move_sequence, illigal_moves, reward, agent_actions = capture_agent_path(env, agent)\n",
    "        total_reward += reward\n",
    "        total_illegal_moves += illigal_moves\n",
    "    return total_reward / num_episodes, total_illegal_moves / num_episodes\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    avg_reward, avg_illegal_moves, avg_moves = evaluate_agent(env, model, num_episodes=100)\n",
    "    print(f\"Model: {model_name}, Average reward: {avg_reward}, Average illegal moves: {avg_illegal_moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset state:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m plot_state(env)\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppo1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m[model_name]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# for model_name, model in models.items():\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     copy_env = copy.deepcopy(env)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     # print(\"copy_env before:\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     # print(\"orig env after:\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     # plot_state(env)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "img = env.render()\n",
    "print(\"reset state:\")\n",
    "plot_state(env)\n",
    "model_name = 'ppo1'\n",
    "model = models[model_name]\n",
    "# for model_name, model in models.items():\n",
    "#     copy_env = copy.deepcopy(env)\n",
    "#     # print(\"copy_env before:\")\n",
    "#     # plot_state(copy_env)\n",
    "#     move_sequence, illigal_moves, total_reward, agent_action = capture_agent_path(copy_env, model)\n",
    "#     # print(\"all actions: \", agent_action)\n",
    "#     print(\"ligal actions: \", move_sequence)\n",
    "#     print(f\"model: {model_name}, illigal moves: {illigal_moves}, total reward: {total_reward}\")\n",
    "\n",
    "#     plot_move_sequence(img, move_sequence, move_color=colors_to_models[model_name])\n",
    "#     # print(\"orig env after:\")\n",
    "#     # plot_state(env)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between 2 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALL_SHIFT_FACTOR = 1\n",
    "WALL_FACTOR = 10\n",
    "DOOR_FACTOR = 0.1\n",
    "BALLS_FACTOR = 3\n",
    "min_ball_distance = 3\n",
    "\n",
    "def manhattan_distance(p1, p2):\n",
    "    return np.abs(p1[0] - p2[0]) + np.abs(p1[1] - p2[1])\n",
    "    \n",
    "def balls_distance(balls):\n",
    "    ball_dist = 0\n",
    "    for i in range(len(balls)-1):\n",
    "        for j in range(i+1, len(balls)):\n",
    "            ball_dist += np.linalg.norm(np.array(balls[i][:-1]) - np.array(balls[j][:-1]))\n",
    "    return ball_dist\n",
    "\n",
    "def balls_groups(balls_list):\n",
    "    print(f\"balls_list: {balls_list}\")\n",
    "    groups = []\n",
    "    in_any_group = set()\n",
    "    for i in range(len(balls_list)):\n",
    "        if i in in_any_group:\n",
    "            continue\n",
    "        group = [balls_list[i]]\n",
    "        need_to_check = [i]\n",
    "        in_any_group.add(i)\n",
    "        while need_to_check:\n",
    "            ball_index = need_to_check.pop()\n",
    "            check_ball = balls_list[ball_index]\n",
    "            for j in range(len(balls_list)):\n",
    "                if j in in_any_group: # TODO: option to switch to a list with all the balls that are not in any group\n",
    "                    continue\n",
    "                if manhattan_distance(check_ball, balls_list[j]) <= min_ball_distance:\n",
    "                    group.append(balls_list[j])\n",
    "                    in_any_group.add(j)\n",
    "                    need_to_check.append(j)\n",
    "        groups.append(group)\n",
    "    print(f\"groups: {groups}\")\n",
    "    \n",
    "    res = []\n",
    "    for group in groups:\n",
    "        x_center = np.mean([ball[0] for ball in group])\n",
    "        y_center = np.mean([ball[1] for ball in group])\n",
    "        res.append((len(group), (x_center, y_center)))\n",
    "    print(f\"res: {res}\")\n",
    "    return res\n",
    "\n",
    "def biggest_group(balls_groups):\n",
    "    max = 0\n",
    "    max_group = None\n",
    "    for group in balls_groups:\n",
    "        if group[0] > max:\n",
    "            max = group[0]\n",
    "            max_group = group\n",
    "    return max_group\n",
    "    \n",
    "def state_distance(objects1, objects2):\n",
    "    distance = 0\n",
    "    if objects1['wall'][0] or objects2['wall'][0]: # if one of the states has a wall\n",
    "        if objects1['wall'][0] != objects2['wall'][0]:\n",
    "            distance += WALL_FACTOR\n",
    "        else:\n",
    "            distance += np.abs((objects1['wall'][2]) - (objects2['wall'][2]))*DOOR_FACTOR\n",
    "            distance += np.abs((objects1['wall'][1]) - (objects2['wall'][1]))*WALL_SHIFT_FACTOR\n",
    "    \n",
    "    ball_groups1 = balls_groups(objects1['balls'])\n",
    "    ball_groups2 = balls_groups(objects2['balls'])\n",
    "    max_group1 = biggest_group(ball_groups1)\n",
    "    max_group2 = biggest_group(ball_groups2)\n",
    "    distance += np.abs(max_group1[0] - max_group2[0])*BALLS_FACTOR # changes in the biggest group size\n",
    "    distance += np.abs(len([group for group in ball_groups1 if group[0] > 1]) - len([group for group in ball_groups2 if group[0] > 1]))# change in number of real groups(more then 1 ball)\n",
    "    # distance += np.abs(balls_distance(objects1['balls']) - balls_distance(objects2['balls']))* BALLS_FACTOR\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# !pip install ipdb\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipdb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_distance\u001b[39m(state1, state2):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Calculate the Euclidean distance between two states represented by images.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    float: The Euclidean distance between the two states.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# !pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "def calculate_distance(state1, state2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two states represented by images.\n",
    "    \n",
    "    Parameters:\n",
    "    state1 (np.ndarray): The first state image.\n",
    "    state2 (np.ndarray): The second state image.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Euclidean distance between the two states.\n",
    "    \"\"\"\n",
    "    # Flatten the images\n",
    "    flat_state1 = state1.flatten()\n",
    "    flat_state2 = state2.flatten()\n",
    "    \n",
    "    # Calculate the Euclidean distance\n",
    "    distance = np.linalg.norm(flat_state1 - flat_state2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "grid_size=10\n",
    "env = CustomEnv(grid_size=grid_size, render_mode='rgb_array', difficult_grid=False, max_steps=100, highlight=True,\n",
    "                num_objects=7, lava_cells=2, train_env=True, image_full_view=False, agent_view_size=grid_size*2-1)\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-2.0)\n",
    "state1, _ = env.reset()\n",
    "state1 = state1['image']\n",
    "plot_state(env)\n",
    "objects1 = env.grid_objects()\n",
    "state2, _ = env.reset()\n",
    "objects2 = env.grid_objects()\n",
    "# plot_state(env)\n",
    "print(f\"objects1: {objects1}\")\n",
    "# print(f\"objects2: {objects2}\")\n",
    "distance = state_distance(objects1, objects2)\n",
    "print(f\"Distance between the two states: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# enable manual control for testing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m manual_control \u001b[38;5;241m=\u001b[39m ManualControl(env, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmanual_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\minigrid\\manual_control.py:29\u001b[0m, in \u001b[0;36mManualControl.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "from minigrid_custom_env import CustomEnv\n",
    "# from base_env import SimpleEnv \n",
    "from minigrid.manual_control import ManualControl\n",
    "\n",
    "env = CustomEnv(render_mode=\"human\", difficult_grid=True, agent_pov=True)\n",
    "\n",
    "# enable manual control for testing\n",
    "manual_control = ManualControl(env, seed=42)\n",
    "manual_control.start()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 39.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016745023 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -6.56e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 56          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012996806 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 439         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 67          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813505 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 70.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017063232 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 373      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 83.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00724918 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013514 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066653113 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016817097 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 82       |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050967913 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 4.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700294 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051882556 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 4.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064221974 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 93.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040440275 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    value_loss           | 4.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027300868 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 93.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322477 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 79.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001761134 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.000244    |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006904303 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045830947 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000986033 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016759988 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000147   |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 96.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 342      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074285967 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 5.2e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 108           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089353387 |\n",
      "|    clip_fraction        | 0.0162        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 4.58e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007995691 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109256245 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074775834 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.864       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 4.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065346584 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.84        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000203    |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005958454 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035281728 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 5.38e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 95.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036199484 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072609335 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 4.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008907542 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000301   |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012195694 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 83968    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837668 |\n",
      "|    clip_fraction        | 0.00122    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.71e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 5.51e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042872117 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 4.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003127471 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757554 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 347      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806638 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469336 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000132   |\n",
      "|    value_loss           | 4.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 94          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544237 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 87.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027082602 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 937          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 3.79e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 346      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 104448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699876 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 5.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021670484 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -7.28e-05    |\n",
      "|    value_loss           | 3.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 200          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318239 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.766       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.00225      |\n",
      "|    value_loss           | 4.52e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 114           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 195           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069240853 |\n",
      "|    clip_fraction        | 0.0885        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.695        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04e+03      |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | 0.00744       |\n",
      "|    value_loss           | 5.34e+03      |\n",
      "-------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    fps             | 340      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132288 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    value_loss           | 3.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962042 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014535714 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915886 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.99     |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 111           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090316555 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.876        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+03      |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 4.56e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005358369 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000219    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027590515 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00389      |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129278 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.000136    |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 97          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009328622 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827135 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000193   |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802983 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.58e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 4.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038080818 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 4.33e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 81.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334834 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884477 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027027782 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000953     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148533825 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 4.61e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 87.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 359      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057178666 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 122          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033629797 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00051      |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007892546 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.000648    |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019677244 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03e+03    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.000685    |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 79       |\n",
      "| time/              |          |\n",
      "|    fps             | 370      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060133724 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.839       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.00149      |\n",
      "|    value_loss           | 3.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 96.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005331138 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033965213 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.841       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000696    |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012086405 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 3.68e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 85.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011505147 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 87.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186378 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 118          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025656747 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.857       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 116          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028238147 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 4.55e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 326      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007451922 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.000854   |\n",
      "|    value_loss           | 5.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165756 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013255063 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091443565 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91       |\n",
      "| time/              |          |\n",
      "|    fps             | 355      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044491906 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.83        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    value_loss           | 3.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058027483 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -6.83e-05    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048686834 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.769       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 3.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648111 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 4.26e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 83.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005274161 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815546 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070802174 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 5.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 188          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054791663 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 3.88e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 321      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 76           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011077174 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.000274     |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046208925 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015564067 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074326093 |\n",
      "|    clip_fraction        | 0.0871       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 3.81e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 98.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 227328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876669 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063385884 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264943 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016652509 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 107           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034711955 |\n",
      "|    clip_fraction        | 0.0244        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.69e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.00085       |\n",
      "|    value_loss           | 4.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016328925 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000263    |\n",
      "|    value_loss           | 4.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003549381 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.000475    |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663654 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.8e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86       |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 92            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 230           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029237106 |\n",
      "|    clip_fraction        | 0.0285        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.787        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+03      |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | 0.000375      |\n",
      "|    value_loss           | 3.43e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059726173 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.792       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    value_loss           | 3.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005957151 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.000321   |\n",
      "|    value_loss           | 4.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033260798 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 4.31e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 99       |\n",
      "| time/              |          |\n",
      "|    fps             | 354      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 258048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006194873 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 92.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021582353 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | 0.00137      |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976463 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037286112 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | 0.000389     |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 268288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017541461 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 0.000427     |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149781 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068907375 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.812       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047259 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00012    |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 100      |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006399434 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008038925 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.000327   |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015558364 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+03    |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016617142 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.856       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 4.99e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 84       |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186628 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+03     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.99       |\n",
      "|    ep_rew_mean          | 102        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01078388 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.895     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    value_loss           | 3.78e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022918442 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 8.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012425364 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 4.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from custom_env import *\n",
    "\n",
    "from custom_env import SimpleEnv \n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "TIMSTEMPS = 10000\n",
    "for i in range(1, 15):\n",
    "    model.learn(total_timesteps=TIMSTEMPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/model_{i}\")\n",
    "# model.learn(2e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{models_dir}/model_13.zip\"\n",
    "load_model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: -0.1, Done: False, Truncated: False, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = CustomEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "num_episodes = 2\n",
    "for i in range(num_episodes):\n",
    "# Reset the environment to get the initial state\n",
    "    state, info = env.reset()\n",
    "    # plot_state(env)\n",
    "    score = 0\n",
    "    # Run the simulation\n",
    "    done = False\n",
    "    plot_state(env)\n",
    "    while not done:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take the action in the environment\n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        if reward != 0:\n",
    "            print(f\"Action: {action},  Reward: {reward}, Done: {done}, Truncated: {truncated}, Info: {info}\")\n",
    "            plot_state(env)\n",
    "\n",
    "    plot_state(env)\n",
    "    print(f\"episode {i}: score: {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Player(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "from app_db import *\n",
    "from datetime import datetime\n",
    "\n",
    "with app.app_context():\n",
    "    db.create_all()\n",
    "    players = Player.query.all()\n",
    "\n",
    "    print(players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
