{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# from IPython import display\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# from gym.wrappers.record_video import RecordVideo\n",
    "from minigrid.wrappers import *\n",
    "\n",
    "from minigrid.wrappers import FullyObsWrapper, ImgObsWrapper, NoDeath\n",
    "from minigrid.core.actions import Actions\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from minigrid_custom_env import *\n",
    "from minigrid_custom_train import *\n",
    "from dpu_clf import *\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\master_thesis\\minigrid_custom\\static\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "print(app.static_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation size: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "#test the environment\n",
    "\n",
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "# env = CustomEnv(size = 8, render_mode='rgb_array', difficult_grid=False, agent_pov=True, step_count_observation=False)\n",
    "# env = ImgObsWrapper(ObjObsWrapper(env))\n",
    "grid_size = 8\n",
    "max_steps = 100\n",
    "agent_view_size = 7\n",
    "lava_cost = -5\n",
    "colors_rewards = {'red':3, 'green': 1, 'blue': 0}\n",
    "env = CustomEnv(grid_size=grid_size, render_mode='rgb_array', max_steps=max_steps, highlight=True, unique_env=0,\n",
    "                        num_objects=4, lava_cells=5, train_env=True, image_full_view=False, agent_view_size=agent_view_size, colors_rewards=colors_rewards)\n",
    "        \n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=lava_cost)\n",
    "# env = ObjObsWrapper(env)\n",
    "\n",
    "\n",
    "current_obs = env.reset()\n",
    "current_obs = current_obs[0]\n",
    "plot_state(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "(5.876679999999806, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = 'models\\\\2,2,2,-3,0.2Steps100Grid8_20241231\\\\best_model'\n",
    "# model_path = 'models\\LavaLaver8_20241112\\iter_500000_steps'\n",
    "model_path = 'models\\\\5,-0.5,-0.5,-4,0.2Steps300Grid8_20250106\\\\best_model'\n",
    "model_path = os.path.join(\"models\", \"3,1,0,-4,0.2Steps300Grid8_20250106\", \"best_model\")\n",
    "agent = load_agent(env, model_path)\n",
    "print(evaluate_agent(env, agent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to videos/episode_video.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAdHZtZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTkgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz04IGxvb2thaGVhZF90aHJlYWRzPTEgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBiX3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29wPTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj00IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAANh2WIhAAR//73iB8yyY1+rXchHnrSIhSC9pJDUx0sVpp0vMiUZTt0IQMP6G7sNlvT312SH/wAD8KVNzI6x8bsqLHRrbZy2SkgTebDw3/eZzytsg7KTi6/Zuq8NEnUOqXCloZd/Mg9tXl7taq6xV2LkiYGkg/Go1JqIE9+zR9z4HWSkZK06/ZhbOZbIIw550+LMCpI0qbrrt5w4Wj5oYQ2/D7lQKisIw/NmCEpc5ofyLIbZ+SWMNNgz4d4/VOTPL6cgsoUkoyACNN1WR8f67/WSXqTMYzbvFkLDfec9U5MSJpdCd3dpk4t4vhRD30FSJEed14D9j2zK/N+iflszJYtYyftRYqx3Ueq2NusohH/Xmiu53ChXV8cr8vbbH9pRdtj8s/3RLJgmVb+TtdiMk8e2OLLS3zWwTKSwo74308sH7YboKMbEIpukL0d57D4PBfYC3FK1kdgF+sW6bGQOv6tPygvjWc5K2QjcfWpoM7b88J/95TllsgMSOysLYvppeJOLP57D8SpOn7M6TvM1g1SZRBjETNfjSGLSDsdfPLAtrK+rGbVUSV60A1vcNu4gCjYflXjkafBymU23u06U+WGeMEn5+bhpiVukKKaHFOVdAUJnpye9xyQ05tWPhqLlyo3QeE3+UqRGHRwxFpp41D+waNdHBOhRTOiigCOaWanc+sUgHUw7+ML07/wUWZBXH1Yu5+IAi3Ti+IrRPyVDQcBI7CwladgwtnUUHnPdmLd+IDX3dORlCrj27ESxVpmk6AFhhesXoOSmOeqZh7ZHfNRDt6f5pvzb84yjnie31tUujWE90rk6F/+Kb1bAvWnqCDlkhYHS315UZ0dnyK/DNzZ9vYD9XQiMXzNOxCtmtPpv+0mHFeowsEr2KdYPl0Oq5FDtoqwCGN+UE5dV+oplxwAqqZGKAUx4JVYHFAJzivtGQLeW/66BaA2Cbz/8IdF0gLeUZ0DiwRFBINh8ybYI+rqumjq/Nrl6Gw+zrnM8f4mx7jj8PJw/9a9bz23VancKfql/rbtCsExPa3gVMk7HXTQMz1lhrxH9bIDgjjS78tymArnZ5gqk0DjkieFzwhryaXRrNRpp9qPwNeCOWFNc2l5tYBc8Cse9UrtqNAehvAL01DZBVMSKyNR67CCYnaR1bz4i68CWcMmCo34VAGFs0kAXwOaGJi9exyjAEL5j3khrCbIGtLZyJbNJwWKL21/Qu+Zai/gERUIQUwvTQENHeZ6r+quTOnLl3Qr8qAyfxBI+IQVSdSYbvynWUeIUuBG59n3t6bLY3aBoNScuIrgaEuz/VvMI359Zxj407KxqxWQayv93reueE9gXlL7K5g+MHfkH/Xe8OR2fChWIRdNZ99rPuGVqE21XrmpwuQz2+AImlSkLYflOK7AszN18unr+NTTOR9t+0ihvUvb1Fw/eISOEPMvwJXNsLJ0YotIFqyGn89h45jww8/s1ELAFlEEUisW/dH2qfisnybQqRmG4Tc+f9RKPvW+5LulbCD7t00hf/n56DnWMu71dg4U18wcorSPfqXdczL85u+K7hCZwhkPaAi5055z6vJnsCJa+3E5Vj/752sGrivCrcXwwMtCHy6lJl3LRGiP44mIqjR0Y41xq5ZWsbk8Q3ZOA2Nc5b8GJtZBuRNs52APcwey5gs5kbQ1ylKPCsjkkaWd+gLk6DhE4wup7bqwvQteibqaY+f50N5+ke4KoXuec/gngYOvtd83beQeOKxBGQG2groGp9UQBFE0xW3HJTm7w2lfXB4PwFY9ktkjOs+NFivH9xAkrvY3bAGRP+vV9L2GrCA5na5pm5V0WAQQIQHOqUKrHjsw0fA0L3O9KQYzTvl9CACqdxxWtrSNpUbc66jTt6VjHOTF1Tw4IOGrvVPkcZK7XxEtMe9bx/X2Jg8Q/lfQ7NuPdbtgQK/QQrWBs4BZ1ZtgO2Drzdr/Bm8UfTCXWWRHOMHTTSMu0wx6bEw9BBBkN6X+PLzhgdhRmw0Agd0Ia3VTwPB4IB56xKGY2XkFcj+688dds/m8kYG4MZuOu18YghjDzIz4mfpgUnQ7P2AZksn2AstGXNiPuCXw53EdvqSCme9B+xqqJ8+AlDyv9gOBmGFYSQ6Kk5F7mRgkgY5aQRawMVtnptWKdkm0a87xf3mN26k6E1Hqq4/UBZzWB0hGbHdgMcyR1U+c12/L57E9cisMmCXXiIHsgqE3S2Iw8fzH2JPj48yFFMtFGieNQwEBb0eps8Ge+h46mpR4C6RS3TMSEI8lutPnBFM5XYDLQ9do/GXc8ok7sh7Ht2Y3m8ODt18fN7sre4q1BdjuOdNdrRfJ1TOPvM5+l/dF1/C88w4d3rwRcGk0Wr2aOg9PUqaaOOoNc1rwCm9AAD6mfbDNUgcgPTBsOt5gdJonkrBFtsEmDuMLRJiNwTT+aIUD8pm0Ed3Mx28eStG5hKiKGuh+tf72iwWJJYB+meCu4Ar6Nnj/+qaJe5jnWN8BSyNzb2pNzHaejo4M0AC2JK1XfkZ1UQsOac2gRnYK8u2cThOJK+WcBwnBpx/9ct6Eb8frq99reA7JVHGSnF5MLuOg+gn49x9tbYC24KN/fVGvmse2w3YdVcSYhjVYOhWnwj7Sv0GFy/VZ/3FlS2uttc2SPR+oyWDbzTtT29X3/gYM7zA+8WExwpS3f3KL/RMtIVVaEoGlENsS3/FQo4urBwg7AwcdJwAi6ob52XutckfyOGc13HSg9oqvxs/24tgmOEKdzWlOsksWUOU6W4+8ZGj8Jl/APOEvXlHNkWZPy5cKA00Mn+7GL1XDNpbmtJ8PpEB4jVjnYeGDwsqmzdAkHXz3Y/hG/QSgM6WYEed3dDEdxulFGzNCxMQkb5fsRFOnGDx/h6ui99U28R/xu+meLba4raiukfcV0+/MzRQnXjm+O9avVOIv4Znc7bgNa9DqL1IWZ+dYKoPcN26H8Rn6urWEYieJntx6EhANz5h7CD4ILDgZYc2YZ2fsVRWBaiIhR4uC1a06wg6242I2kVdib1MShB40jvizgoTTrOT5vzvgiZV8+wVsE5sE5fStT65xHoWsNY0fNP6HE75SLcHhST+Ce4aX/ruHWl3hNEhl7KCOoOlWBgRjmqKrY3eCtCmTTUaaqW31C5rKGcQ0KsoAAG7JPcKix+ZLpif2xdZJMrgBhVdAVVQzRpndLATrzFylvVcoxRj7vVOh329/ylseNA4JJC7dIUuKKOjDwU5ZicGxvC+7/9sa0cDS0FJHy7jn+Aa18dZmvWwwMsjxsLGoLxSgqcI/uT1WDLn4FQSiPFTL3TWHF0kDVfWBppKGJlsm+X4p66N2C728H7ycEGA/xAywfL510C+l6YW8YmmLM1jg2N+I+xj3+/0rC3/EEqATN2f/iyev1qpHkToArkvL5eDGFVRza+5hZsF4ZU1/pX7Jlutc7tLR0g/I7lBebfaQHLRckzAVrQx+7pnMonaDAObLVf1LwOWSe2rEVi7mRTbhVPsFyXCpXtO66Y3vvBc5Aw003Vf9t45ukB4zDqY3l3AcMCf+Lp4Q61wrm4p0Dlo25/fd+6eUyo0SmwGQaDXjjSJ2Bq2fNAdnrHU4aAhBrqbFFTZRpN15fIKicdZoZn7FwXhJN5Uvml2PkjVLfIlhJRLQf2jK/8MH99LUJfSR7jVjijPiyZ3oNTelb4puzIuIu0n+6xygBNVPfLJPGP2jJ0vVzjSOpfsfIpfgi5l+HWak0GHzHsZ+1dxa/PThNP44eTRKMM8lp1OnZr4R+hVqWOJ5hwEv06FCVS6XBQESZt8HE8pGY+Kxi1b3XJiNg9P6ggq8olrgcHm9zbDcNjI/tDbT3kBlDz1d+wsYdFzwPgPWJABgSJ3SNMalKklyIv3miNg9/U2zIBuHMQITB1HPZEnJezm65thWbh8B1ZO7M3YKgg7R0aSiCzeqHtlC+nPfoM/scdeEoufRhuXghVo21eVG+3kPqSHFu0XaUMHiXKA6ASSoMa69eOtFcHnFglSlIsaOLUJPnR35K2mKzXT/8ssxCeen7co4MOBmBh5tW0Hjs00ia3snwBTQhKXwswWTSYqW7w1JjHL7rdW9Rk9Elw6tItsf3s8mxjWceZ6+zOSWPXQch2IRrxCBEnN14/tt3A7vTFDrDwhp5w4qoNOO0j/TofsclpzcBwx5EeMyZzLsJhf+oRLTsq/U0ISqDuySoEaAU8LX7g9qVR/ZekX68L6391Q2f35cSkHlGdw5uE0OYPBtl3ivoFqjkNi/GQedWelCbyDvqjOMpHDJAmPV8vuf5nj5XphE3lI8BDZMhqGAjWfGfsdEOql/yk18pp+9HF/3Y+ZhmF1TpzR3AFlyu4GMTNkxIrs8OoWxgrynpy2GvZu/LqLXbgPQd5iwC+Fkl5s0WVlN0FE9toapFYn6JzsnbtJn//9BV//tU1MFN/YxmL56bNG+1NuEVJt+FJ/bnn1UmStlo08EWfCV/Fa5CTg6mxA7VFOY2xletwRkgeiHtdgZ2Sxtn/vIC++LEZYzVNzsqeVtxKXKFsIOByxSarWw/Xz3526V1lvRfqeMJ+HhuJ+zK47AA04ykBvfL5mmHI7MNfwoumAH3BkdX5YKPEPtXQM4KSwj+dpI4PLUIAAAF7EAAAClQZohbEEP/nO6A9ql5WnAgbiEtjCTk6E8H+5dAJIAWWuSof8RnlkJGiAQ2ejJEPmvGshsIVGZBqKfFXZR3scGKwKNtIYqTJ45j0UbMwuNRCk/fGSTwWQZcfMWNBR7LM25aZNt7VH1tO04N7X7236ECK/pMogPrWSm+pYsC3PMvhYw2qKty9nq5cFXL1+Mz4Ec1LIQorNJgopgFJJsyEorzS5/h/LYAAAD6kGaQknhCEMgg8BVAYoGACABeAiQFUBgAgj/l8d0Unr0TP7oMC7Bp9RjpixKME4Aq5BgfyPg1V+K65HTyEAnv//Cq663/8JSB94XXkAFDkgDpR04mIdOSRJ6KMtUlaGc/7o0jUrpTWIQUbLpkG1b5IcJrhDb5zeDrLUSAUN9ejzcqWk4zWcKruhOCFnp4BMHfQaPCOZq90iC6nOYJnDUj2dXH9yk4tcu8XaixyXN0pfw4CG6pv9zszpr8L0TcXN0HWIaI48OmZqedAm3d/ljuBlWK7V4cbKVDtVOK+x0Gzn0rldoKfUItFIS8Ci3JaVaLUi5BFCeV71R/yR2QecBM2jitSl/Xly1A/isOJecuIgVGTgTTnxwBgfvRPJvODgSW4Vt3pAjlQvsEtjBZ6OpVkmy8b6p8f5nEg1HnHLHQikBrtazImQanjLmuCdPmZQgSoWpKmbq7DHbAchCzFrGUBDH8s/4Rs+dpDf05dDYTwTMQVoLggUNRGYhqrhh7ECfRdLxEt5IfeRRonCQG2HvtQCBcng72rS5xkFnqxJO/QB6+CJLP//9CjZ+MM6dOJLAv6/wkrmn6IrO6kdr5UEeBvxkkDukbkpTt8VbWWjpPksseLvVn6L+DjQGla3znlu2itMSH+YR1I6xrQyYqkG6WELxIQ2XnPEmXUrp+TtzOs8EZ+sgTfDiTVlPE8C6tmIkVdIdpZh2aQsHAV+w8CM04WCZzFSW/inHwlPy6U7kM6kYEkkGGTUzlnkHKYB1S63pk3yTYNrOwYKHIrwYoTnYEok5puzm8s3Md4rlMgfxWHVuXXE4+5LZ6N9ic9L36id8vPBoPOV3ZdDRhJUi9jtzh1pNRJls1vg6p25EdY4mxh5Tdj65oB0SZQIhnmSg82ot1MA3tYfYxWn2+c+K6Mc3DeBVYGlf2WO/TMWoDazRrQvE5TE56PbzDi3r8udxa5HCFY2F1nJcPOTbtobHKsuhwp/BJAIWvLuTyCyoLMwdMQsoMNotDCq/KWWXdoKn3Fa3CAVYk8sWXV/RYNH4PAhbHWsOEuCnc6t6Trp5iz7wqUE/jl86+KlrDE6kWWxGo910whY2xhJoMib1ISx7y+/WFoJx8Pr7SjSfcfDZud6H3HbDgjNbiYVKM+0GVDWe4j2CXEFcHshYUkYLmAh3wTCTPMIA2Iax249PwHeWXO0XQguM8IMZl30v1Oyw97ib/Q/ewG4LUUwIV7woT4+Yjm/S9KnbYPJWh3cJON7D6L9U7RH+t8VTHw5SEnIS6QKF4t6j0OSbBhb2EzzHsspnzUAN99JBT358XMCtC6KWSZ4bCpMRwCfNF5CPAADBuQAAAEpBmmNJ4Q8mUwIIf/6qVQAptxUtnkO7IAbceBpZA7Kh4XuhDMUa0sDnIr7sYyGvN8wQ9VoQZUvvUQJy5NRgsB+XxKR2b+YhXMY1PAAAAeFBmodJ4Q8mUwII//61KoITs3KukkM/ECjQpm6WLheLTSlfFbihYYxPrs/67VZYtqY4WAAiStft2oG/Bnofd2ttypVtLM8CvAAuGVWOB6iF2ww4w9LwixRuhjVmVnqdvcsDrRNRjR+ES1y049qgunrKWgt04TNfPChGHa/akONkWA2j3qBu/Y239RYXD9Y0aiUiljQbuM7dxN3okos9MERfFZWmrGjqh49Fiz0e+h2t+iJdN4p31Pg6e+pP/2oJZE72Baoumm+bPArkFzid59AkknFZ1yg2/57IsEw8VglnXPDjBB2oyDFpC5q0MjCSbPz1BhbmePlISPEMt+kZIRf+V775iweq8kqL7uretd7QdAA0gca1PYKHbG6Rp8uNM3idtzhcntH8YOtvZrrpUdwWf2fXxVQHiZX34TwqMME7adyO4uOOg4vrwSBEKMcQ7cuIgYKb84pka4WgclWkauiNd65HU2rLvAxehvId3XAWVyiMNDW/v6LPoBHAMMiSFbrNr2I2oeUEwW9Yx+c+LqQiHMLt+goTnHqoYLCWRYCRod7piYYGanB9Uh2qPpQI5z3WX+/975bccRd1nl1G+idNtlHNauMGVQEFxcE3tRdLZ30M7RbKHRgJlFRhnZkawNRXAAAA5UGepUURPBH/ADu5ff6V5//rbpVg5mx+/UAN3Z7AVOPvGbkWE2J4IoYQ6vkP40jAh2IVNHoek/82FHLXQ5pSZgJ7mCsbtpHZ2fly5QJF9Fbpy4Qrv2RKsYGw/mql6WM9u3rYKgpP3x/WcQrSwqHOyXyEGtSPLsmnP7ybb6KaOSiy7lnSgJqGkBWPmtmbsgazcFWk/oxWBWpmmLuFhyWFJR5aHzbPdhMEJtHCPNQkTKuP9Z/GYEc9bZ5pBrscHzFDQJIVobASlkXqLvz3hlxciMA08DEAV7oltGefNI70e31ulrm4XW0AAAAaAZ7EdEEPAGowwhG5ups4IJhN7bbt1TcQDwkAAAAmAZ7GakEPAB2KlrJ0Wm+FML5cgAG8tc5gFyFiNuTqm4qsquIlSXkAAAZXQZrJSahBaJlMFPBP//60qTTj4gUQ3P/+bgaLvy8vQ3J9wzMlGhFEw//P1NCbLW/il5SyFYYQDoGHcaQux2lAAAAgD7xOPgzOJqxBSM5DdsgyKD/aUU8BhaBXGY8ou2BH9c0gyagIqfEb7uOd3/m1hQLgH4iSXTmRCHacZDvhnJ2BmaFclH31jnHQy4VLOHT7N5FFmsJN1oKeU2OFjIToxOsKLPTn/hMUFFdguKqFFg2EnBndST5/3azolW3Mg4TbcORT0AUnnIOi2rRSyJhpKkx+UHdbjTiRXhWwMNGs8kYinyexHoGDfgSfWv65wqUycdaBOUss2/j2r7HGmk9L8ricOCVJNVNimxm5zEqCddcDbtlPMok5roTZZoxqhU/bbODLmJnUf0oT9SReYXohIe8hIL+O8pV8Tp+F5hG/V/EhVm2tcRbsrXBna5hQ4mArAGoxvkS4ODfYKc4alFS8VT58FvuxZn4WzEXFS8ESQaubrDYgL3lxqKKsLOLbeOUCgcshCKrhbFujy6oLHQ8kdNjwWqJTqSdmvThCKTVySHweTOM1VzilA9IywrfD1tTedvJyakHl/v5v8P65rDqeKD/8qrl95LioOMa23/vVpn775oVIF/fC/GGj80SOlsV6f/qfB8RS3UcTFdD/6CFBJwEirxKhwGgjBtnD5Oz9I2GnUaZFfGIyVb1umSboSgG2+1JJfNv8lY+uLbbLbX410XEnWIIZb5dv0MkrxmDwz7CTVIno4F81KXETCeFTLVrM+p3KW+1g2Y1EY8sWeoMzkVHkYwchiCVv9xyTpQDoAznnefS4Ez17MO10rrNCLwE8clKGU4Gc4pxYiiIIx9ucU4AHEh/chFfP99fLUMCjiRY67/EIgsU8KzERVSGnC49KSlmz8j4lh2yy0PesO9oNbCSz9H3/VZQIm4DAxJB/I4JPszkmovdeXwbTxbqF+khPpz/Gu8CArUln0oK+jCtDz+9s4MP3HA5YlMG8o5dDa+lXek6O0qQz9tv3qwoRVTqWabET0e/CmMDuRWkhTVF+llzBA/Q5aGB0scPfC1iXdZMHGjS2NFmIzLNEX9DgolQfEstRAS2jkecEoArHGBhAkvPE4JQQLHx4O3G5StA2qUT+Ivw7qz7B3Vxk25MqergPSXiOD5SaXwY8zFuXixJA6v6amdXDFRHn6CfRZwegd26HqiceyX65+1NHC1LTVpQ+U4OKheZrYU4p1ucy5wLBmeA5OkRzvoAlNEzcmd9GGE3a9jn/qSHDjjTjEhh+tytUWKO5Ut+8s5VwW3aO3/yGQuusLjAHOMCWRuTZU6QcFuYI3IyiQzBjSprHj97HIanWSB/bkaEyX754X3koPJEeDRTCYxgjdOH8pwAz7as+gHjis6jtxP6ZYIIQ/RNNwR9ZdNDfNwl0V+4JdSSLetPpgN6JRp5uLJYoRUoZetuQTpsbWvuinwlWr1kLbLbfObc50KrIUDxXqmo6L0Q8iW8N6L99ivTEI7MQeeT8WmyW2OGA3syo3yU2BoYSfsvK8gY2/4htyjiL3r30k1i6P5TchU9Ozma4mWrpihENlktb5FSIYqn1wL9EZ0DMQN1yAcXloliLqZaLxxnFFNAY01fWLjx2JmpvCGR2SSaYHmmzrZrw9cdJlvU6XPW7L7pRgycxuyCGNaTgNzu1uVe+RsLS30OwcwXA140bUuQvoVD3NRGNiai3+8d8TCj8EsEVfuaWAx99BK2Ix0bBOyprtNMMwIGREfrMmouEx1j/2kjjsiZ4XG7bxW1q5LNceMd28EWTW1sev7ZJTbWrzzvQl9vZAnkfobO+CPKH2sWfszdMp2yAfdpYDtNmvmjW+DHLCriHHbMU5QDUa20zmJe92VEjnnNp4QdY+OQKlhALZ/ZlIea4QEy+2OS1LWAXB0JZBA5ohMYgT/udAujfoxsafTYN6Hknxo38/j+EAvHB0MvSwQV1VmxkngJAZC+5m1VtHEEKNjfwnjuFCKCppDEglXeOiHacSb5UVDKnmYJdZgUmlTEElaY9pMGrPJYvWl1sJy7ri7SyXcLDK1+6tiQsxy/L2uD+DbXcGifBbgOyucGADbgtjd8Ul0dBepYmd/vnOevPgiA7DDAf5hsw7U8yJUNVJ3K8H+aPqKjmz3KttSsl/xeYVQGAAPCIAAAASgGe6GpBDxpRmCkGLgGgmdhJOC8SjScmsKVT4amaOrHQA21WQpoKNVoEvXqGmJzb18ptic1csYxfmgyWjKH4yA9kV4QQygPVDwpuAAABe0Ga7UnhClJlMCCX//60dSzeh90vBvQ1IJ1PpExqHLFPigeKI/6mBjIn4IxAXrKZyhHsPjUqDZfpwtiFCydTVADaTBL7NZUe87udgBA0ugP5hwQGjnUVBhI9z+LKGOdOSDp26PizxKAGLdZ5Ymg5tkivOYSp9OO+iSFPzEUH6gT3wPpnDbWZH7u4TzIVX2/zU31g6zZ7yvnWpw7fB/jwv4SQPMO6urpXeIIqg2husfavSP09p17c56FvHrGtrijD+9EZdHWSWEXGZX1JECsVUB4oQptI+9b2FRxr3qMWqpj1+ogG6exq/2fjznQsg5xEutgt35jiWFEpG16SSGBuza2ExDH7gmD7HTkXDdswGEvOXfGjswHeS3BpHtKpw2/by5ooXep/D69irWGvYrCWelQ31d0qt4dLgV3/lMsH/qaNRtgN97g4qEt8A3c4DzSoocBC+amZP5jBjKzSSf2keCyT3VSmg5uWuFFTNDeUusDGAhe1egAUBKAjU0EAAADSQZ8LRTRMEf8LYp0zpBVff8lj1JUzSF3kwNS2C9tuQAbsgh2IVNI1wb/5q1GWbZ2VzMs9moFUqv5u8UZ6IK7i2E054hhLD61sSWI/I+McsXP6pkjHuABZ3ug/G24GUqYe+5eYwLPw/E2c1/7dO+hHKuiPNCADmTodupm7VHcV7ahsUn1xjfS4mZ7xTu47Sb0lTyTJvWJ7YQdtfokZiUAdGAn5mPS6f9zem1AIfF9abe3bt8nue6SO2tZHzNujzYOhBTJgzbyJTHLZLV1c3gAIIEi4AAACBAGfKnRBDw5YdPYuKlDbqvY0psHpjcCdwaatRYuzQR91wh2IALeu5aeuG7LX/4ZatSRpqSz/W/0SeAtnkILrojuZqX6d50iJRlSyBR0Y6V3E0R/HMk3qdp+PPSmS7+TR6hDyBu132tTq0iZCgrAKArX/w/MovSiA9npmxOGG3H//480+HzdJRwXLFuM0U8T+FqEDmVLgMs0WYENBjiaOVHV0xgbmeIz3slDh1wyon5RJo+eAICXdN7G5bj2W04FQeEDzAGTq2I8/D7S7NbSsic3KllBbmiU69Uh/YQWJkL/iwueSxz8w/lmQXg0gRRilLY89VYRDXo3NLB5ew/GvsQ/VbaUDXKa7/pCR1BKJQTd/469EFwLXr7f/4YYbZqeiomISqG46ZkaaYmsVb2iH+LLCl1LYue6HsVP8LyTRHqhn4jgnchKljI6HS19Gbvkr9oB9YQdPL8jf5D62bpP14v1rQSx08juBNSjv6cGqZ8dUH/2bQrS9Ojkm492n4VzSwnpB1mQP1ClGf5+DUHJKAB5I1SJ49o3+gXW2CSZHVjK7i7MbwvYI8Gg7XW9CUNzKqg8Xjv7+qr+NHqj+l7Vhz4GNo0xpSUcJnT/5xcl0FCC8CVLEBlq1DP/xuPHQajnvw7Z845eVsGAMPFOdD17OPIttKjtgzWKG8CksA4vQovAgAHqI0AAAACcBnyxqQQ8AC+39Y0P67oKUqYyCsue1qNqKQLr09H3bP8lEn8dV+PUAAAMCQZsvSahBaJlMFPBD//6qVQAdI8kAR0D82o7CYfP2y6N2Wle+QNO1ZmW03/pX1PkqUs8+I+tKthELAi+f7qCWGZ/XzA3RqXOescF0uOmsqSQ8Mt8KdinOJijXHFxKh6g0xp+WLUG+cgEaCuBbG6UQNxwt5HFWifVBgM/HaqZcVIxNME21YzcoH+Ujh7W/i3CTGz7glZl4FCGVSr/8P37oaPXcii8Muqfm6G7lgI/pYXt6jgswkh/YCSwQWJWrtfVw3zugxKmVhXHY7oSuKI1IERUH+KmF97L5no9mH656l/j1lwcL9QF79gD8TUckO8FudifWOAfRgEd2t5fN7HapZSZoTreiqO4ejd9PufyMtFdxqLs3Xz2IbukMaGtJJWS7BqSy/eyv1OMl/YfEyl8sT5McY793/yII1SgzQxednxAZiDmmufzWqvuSajSjgtcATsqbgIhWIpzjQX6uQbkxDBNKr8FDq6POOsvp1b+8kRSS6z8MfHtOM5dbQb66ysjqGjG8n4L42TVpdr9791TALSkNo6jl1832cUFYkPuhwpFgEQjfS4sgKasCbCVkL374BApDQrhgrp02Enu1EZwZrPfIVZigsjVr9Tkg8YBME6BcM5WPWOyMCAKuMOO4nCfztb9x/VtJhYI7PUHH9g2mKfJmoAs2JlJByV4mjcpeYRDVo197MPXMl2mO4bgqTJ4vMKcR7EXVIC43w1P0QfCscHiGKas69ruKJYAxRDUdxpHPY9xQv7HgAAhV3kr0XvZw86AWJxBaLJhcwzoPX2btGSh73kHZgptvOFKN507gozZVn55LjXcYpnM157rbR8YaFAM+ji2dZ99HS3uLJYKvRkmoNHmDJj/7njkdkLo7TLM/+47gN0rf0awxRh6qnrjKBfsE/xpotNq9x6ENtnnscG9oBEWmfc3/fpf58Bx2y5838jR3lpEI9k73XIlZQYxTHKyG4U7TxnYqypN1hljD/xYFYlutJiwdK/fEI48SD3vNIq8re6PiXN17ogoxZxkxDMkAAAAtAZ9OakEPAAo3z/8IHyiSgVQWYCAGyr+SPwH2qQm1gYXzwZ52HWAu+jgc/G1hAAABg0GbUEnhClJlMCCH//6qVQAQGnjf63rAAG3HgaWJ0BcjbXzyf5CgYYep+P121Bqc5ckJix/sghE0XjJy/qvphRWK/9Zk9GGjOWeL0yJ3K9WmShPyO/J58L/tQK8oh72U/5E+8x7TJozWvBvlP/wXna1wJAnI2IV+izIh7ti+eGK6e8deccXP2mRD0IODZtipabygFLePuBXpA9OoxEliuu2/jBDE5Cg4kbVmZXRfKEjjOt190nNgILTzHM7mLbuXZuJvf/zNkOt3LP02tCDdD207apddIz13zUYSPjx7oQhw8lhgocYY7+gwmiSBHfeepKixLzYm6p0WjHfFGJ4NYFXXXoEG95c02WHoQj8LxOTevkJPS+WJrw5O4kYzgYKjZHEEmXJNFgpqfvFdw842lUpM1K5IRP0NsShTDg22pNEhK9rMbez3CiDjyYVir816w+5MGq+EDk09jI/RHV1gBbrPkCcRM6rcgNGxbaVAz0+KqrCyQvOwLKaTre0PtMUEoAAOVAAAAUNBm3FJ4Q6JlMCCP/61KoAIAec6+i9m517CQD5gBbj2ophsrqDzScf+Erzud58zLIH7Q0WGn6qjXj7Db2PveSDGXady7zH/IvTjVo3SLfAItQmE0tjMr6tG5EZdQxdeJPiXZ1N7RPHVlRpNASyEDqH//zwwNI/TZsta3x9Ez4WUUIs8oQjQ8Qv21EKJM58s82ee2XqMN58shG42aFvV//9WZGZmtV+hfs0AyrOCqY5Ce4Omo3Vo+6i8sIwAX7prIPlz+99jUu3a5E7qg8R7obtRR5Zk6mDtdMtAGPapksSmfGOM1RPqv9JCzFFOTQTr/wKZLWHwiRTrgnmTCab7b0MkhR2M+2kcZN8TenUGVtLlfrXXUcZH+w3DSOHdMeo9Hh8hlTKI/SqI8P/E+xiDcaZk/VyoCUhHImH0xjoqe/zptmu70gAACzBBm5NJ4Q8mUwURPBL//pjXq/EBytVf+bgaLvvX+W+SXg6XqKiOstlBzZIX3CYCOWJgbED0iWBWNSudB1icYGpVyAtbPBfeaBFXEcz17s11skC077vNv6kldf6yMSPO0Y1s21lOjZ9/sIMvnFrzwEJTiH3OkZzvPCl4WGWVuWt7VKdsrf9BhM4KY9SkYQDgvpaVMNN6QLzWMPaOW9r9+sqYzll4uaxDFLVK9xMzLAhHOPpBsw9E7PI2OUWo69cOrm31P3/4R6LKAD69iwD4kJ3c+/j7GWOe94qkzx7/apI+moQDgKGlBv7K+T/oAGW5V4gx4+vOB6Q/F8MFHwkmM/bY0eFbQAfnj1GuzLC8S3GWLVrzGSbaC/Bb5Y0NjPfG2ZhNdoNf1HRtjiwauvRhjVPZWSZll1fBpL1ndtRGCUtWRNjnodS8pcN/sTL9/688i5jafetKIcAO4MTWHBsS6dAb/Q14w155dvVBwve+NGNIIyoJZwz6TVk19bCSIjUETuGwuxWYbfG657pXtpIDGg882wM2ynLdTjvFnChOBUnNlZ3C6lElZSWGEaXtJRxuC30f39KiVQNHk4AuVMmgFcLvVAi1WBEZHUbT438GRMSeXeY91xTtl0TBRW2vh3RLHtsGMtkaziJ5S9X/AXfZu48qbfVaIu3QY92ZA26Bag7ItKvMZSnA7+EU7UdR+r+wNJeQNsxkLZkv2ezaxT6IaYz8rkb1gGGCEcq3u9vUyXgphdoEmSPo+Of7+8AExptJ7mfetxO17JDRONlEpOGQrDZ6YqHLZEYuHGIK6j511nie9H/7fus/27hzZy3xz5I0lwZGgx1NX/KJ0665bLVpNx/fXnHNLhOZfvTBSB5J8dNLHbcFfElQ+Zw9VUECAbF7ac6PlN9iyUxf7UQsneFlT1YMwDozRKf28clPKwoeOIfS4JstJeMOGjKdIUVK8soUNdbCqwojU1LtU1y0L4Pdz38lWLvRzEyb28LRkp5UmRomas9I10Msk/PPb6L5Ys+WKC1Z3ecq4sJjAp4vFb6nVc7pNKaFZmlGFLNViV0vdLVTz0kimkUyAeNkfQlSfp31I3j3Cg0BTsPeSZp9Qst7BFmVN0Bxlo1uRpv9dtDbfx2njHooN/27wPWm9WpNRI3xPQVOp5uGCKtXXxqYvbH44LZZPazA7v/DJnZ4gf7G5ngxjAFMX7bXBRLpMRLjyfVxBGEU6pir5hNbK6E8zj138/usNyyTWx36VCC5BzxUnrFMcficBPW3tIqk2bVkI7P+HjUXSPAntkLeRPDVfmemtU1SRFfejUvdaZ8S2SRgouwzo59kFx9cx3eZjHCYqx8A11XPIYkXOM76stuRFPyIXOp7Ny9d5wOgmKMkZF/z3iQuWu+fzTkMboIo2Ihg4mtDq5jg6JF/jZpzBHNCc7dLFiJj/yqOFnHyCyQFLncJlQ4rmFDXFBBAGWb9h7KwPTO+EgG6r3ze/TqGoCa8Q+gi5rZBRR0CIWgaQOywQJ2UO1zL/XieSJQTVXT3e7Vcorwy4vYR2Tiuf5jtQihW6u6Sl4SRUNsDQjyqTGIMJjffqDAEaurn6UJMdiXberOeRkAt9ucyoO4kPjeTt8RiXJrq7L+9tDLXcX9nn6JU4jWxis3JrJsyaePQSjQqom06lyDd2K+MNlSPUv/MFA5Z//o5NDnTWEZ7xlL3jt1qduvyiIbco1ZYS74hNDZx3Sn7x2VNIZWtXUjYDUsooBymkptvisssW9hnC30Btw5NGEHhTsV5lfXqNcff2neF79AQOKsOqX+2WFLCVKftTR8Q9wWdBdLcsM3IB293gtQU9hXtjGtIfJ8vwcSVGZLg7r7PGqcrgFURoGsHwQsG0VgnAknfonVEdLaUr7IjVbE7HR7LxlJezveKe4smXip7kZPOmn0FAWW7FWA3nbmE3sIhG3qFB8KDdl6dTQpXijOeQBoGrFUGzsC9Aj1LKyeNxhcPXiyXCByevu2MA7t9McQlsPsUos0lZ263WMCFx0yhHIpARQhWO1BqH5FUngcfSEPJakMPXDQ1jf+FG9vTncrSxLRqxoZwZT43bEmJTDY7Ic33DI+AAuWHXO7FI+1Zw5QK6AZh2Y3sUDo2YQcUmOZmalQxyO5q4D4T+eU+4qIM5A4gTSse/60r2sqqt8BirrzUOYqL9EK2fV6eP+9drPwdPr6bWJnTX7+ocs4czfxS/cJigWfcTsYo9qwIM2DA1gjlcXf5EdanyjHVGP3JaRQ2qJnATWDHrLSr+RXytKsIlesVTceZJiXiePY2eBJbMEgoySKzvFkFABnXXB79azr/jtLNa9pkBtOF8ikuf98jOOAxA/zXHYuVYMyk6QYllwqvmqT9UBnovq/AgChB+Ri/pIxN6Scp2EDfVaWzytARIW7cIzioEmVt3HW9tBxz/4tU0lAKpqHyH81p2rzMauAATBt8XWa09D8TvAEOZw+yy5ftOTD14QbD+SnXRb7IXg3GDPaLuLKA0QKQkcew4vl3DzRVt0fP7Oam5tOV4T3Fd5/iG50vU9maB/LPVJ4z25yknh2JEn8KbEot0UUkxh3uPXO+AM7IsWZB92ohU7qA5rEnbVGhN8NAiF+6BivCEoAm/XMu8XhYlBPLIJN3d3qCkFOirXkxzEY9KSJ2bnu7KoKvLLmprdJzf1dVwD7n83M84bS0R7AD0ZQ/Vl2LFQNqdq/XTPu9ziScbDVDR7WxNT+y8/D9/FkQ1E59wOjdc1BDcrtjkML8I0ZDb6EGkwidtRJIw4q9Z38AQmC6M+bn9XVzeyM2qLAulWCCVQR+0bxIoZVT3se0uEKSYWsF2lJvRxOWbn/ob2bCDrDNHFPYNvsD1Jimhh4A405rS9BFxBbiVxPfVehCjw4ehinTXmJkyPTxOjuNzcI2LEV5AciHlLFtA4k2Jk/BZVjQlMUbfvxKOc2OuLS+wS8AKPBMOLKyG6aLPkhbv4GHQvpaG1yvgMhw2euZH+HS2vShh+ScfgKDrPqkvecED62ssY4ZpUHaflzl0RWvT8hHsJK2IdVZfLDGsLla3DmFk2FHUB2ZBwJpj6W3D8obkNJlsh83+hJ0g+jSWPXTanvcP/vP9g61ZkKscjU9mkCXqf+IsikfaC8L/JD+kdjFqdXz5koYdip6UzL6tKCgJ0NF0c0TKzs+ECir8ijx0+mnIHLiObYpnT6gB3Cx3F4sEFjHtlHkcxy2UWrHwBejV0ivCXvYtWUieDRR5p8wls3bZgS9hHNFRkLf5B5K5z6KvfUNRZr7TNC65Lr9+pz12g6vnEgTNXNoJeYsguBShFVRU9MtW+zS8hg5QhpkQxPu41faWtjfkhJIRJuRwoYpyJByZVtjFaKF0g3pr/0+N8KwTI/TDNsly4ekM1HXIFjBxdyqZFRTPu8wocAnQYZjvg6cABDLM6zw2sBPqyKO/cu1PaLcmWqD05JegK/Csw9oJJ2wZrDu5W4kF6PWEPm4FTaEKE/dwKglrsw1pMekg4tX3JpU1GzuP+eWLCpYvckreCAOI68B/xpYDz5XCty4LX6AjsnK5m69tg2yojNfqdd/9/vYfv86nGj+n87wL4ZZipoZztEjJAKThmoh85a1JWgqG/h7/Sl4v/VYjWNrsUNjhmrcTHR+st8cbAwmXxkYOkHxxrrZG4mgFDHUPTmKsaxouqFhFzDxaRI6HhFMVU6RYg2z3tiIISETDHsEMg66f05hYslMh/zHc9tmpAcax0xpD/pFhFd7w8fdQ4zezvGlkcfRhC/1eu6oBSt+cTp/iKCPH+O3G5xSX08mm/d2UCeae5RmyGGZUw1whYcmoQAAAPMBn7JqQQ8xBqD71ZHTS6UAJZRY9HVu0u6oBpP+JBSQmUk9A61kBsKEfgKk1+DbO/xOB+tqroyLfPZ1tfIOe/HspX5CiT+UVMHY7DVGMeCCsjKweRyQQgu4Ip0fMlJ1nO8T8+T0/Rpx3sQYllYPj7b4mucHoDgxSmKj2XRefBROE0oe8vJ+OshYXb3aAuD3wPKztjTucQ9/nI5B7iILYelnqB5n1C+fEiXBUlB+lW/fDbbpft5X+EIofvVR/GOlSCUdcMG3dw+Jo5C9xa0yU213rsgzTjHaw3gmZvYZHuKZST77hIDcYqwVkCYsXtDqUZejb6IAAAtEQZu2SeEPJlMCCP/+hnkkJustz9o6v5PhRQD5pbNz0K4oebb0sKl8CUpIMoiTrR0QIg6aWVxQ4k6YcosOJwFnt9oCXcxzrt6Hb/8JKiGwAIdE2OrbQod0TCdxnmR1DvT9oAcDLAakyfb9rUQiFxOizXmn7fz8pplQ2TVeqU6qsGG2uDOBhSncATtTXE4q+lyA6Jx8jEUaxzMD7fK8m0JSaKwjet5FQDii0YSuuL0pvL/rzsJ315Xr5IZ/lsYl6pXumSRukk0Bpe4ap2vjl97UHJKmNQKqxCU7ql0VkhbmbAgnJMQGExQy9+1VeEXc2wOjeDXeNo5sSEJhXyOkl4BPWlYsS1uAvlau6hQxd82u0LX3/J0etbYtL9SC6CfBGLzHpZnp94Rt8Xr+hfig7pFQDrV/NcCHO5y7LWrbklrvaemJwCdZ/HrKrKGWlv+hxPkerr2vHqy/K6MwFC6dtHghyzEt/+PuLWo/y8SIYtNEaZZZzsTer4Zvf/wccTmcLJfx/hHMxXBIIezT0dhwE5l3rGoRzgEdPFxSTDEk3CuxuStIPhXKuoUUZWyilsiWdu/I3LJ3PK1qyTx7hW+khLG5ytwPuoL9+3el9wkJdjhNIR1p/W532uSu5ydmHUqf4jQu3jlj7AYuOAHcEtVGhxxW3hsKHtkQz3Ytn0DzwkkKsJ3uFtem0H8mC/ghc4ECMKwZ9wUOJhCRjgOLilgg7WnLytYWx0ev1wf9lx5tzQ8ZQjqjmuevF0Fdkmh43eCQ8bq0RbyO6NQp8Y+Q5iEfxncWYS3f/DVySYLBG2Q46v59CN5L38RgXLEir4kg9ttFJAPYLcRmiw83gAhcR5Rc/bTYVbHR/B71C/KMlfqvl7NHdk9ZtTkLDg77Sce8EMZgXGyrWTCtMR/YuyVg9ADabpGZ1J1Sj30h/W+x4LCiPhKJ6a+Iy3hM1PMmQQ9eB/b819YVWJApaHJfkXJfM1iEs0yGQeoGCc3eO7Zk4MCJI3S52dM+tLi68++j+bra+/GPLgYFjZ99DfSRe2bjhBg7rYWj8Mbb5V4RSGo74Tm9qoMqWuVDYwRBnstEPC+C9FL8LDJDiDARR4auqHwsVDIyaxnEEWuw77kEX6qEQzqm4ov/ENRGWBJHq/KUhB+d2moRRZXVXy09XIAh5qkMqVaIqKIPUThaOR2wHpLcSPUfoyp296JSTRPvL83zHebyQjsnzJ4Z2e+8rCxNDcvjTh9nhZPgEm6pejMcX0+wA7g1Lx95jkHXkmVN2U/KA3y+BsdShcK9BTb+SsAHMM5dO3ohka7YMsQ4UqNKXFxtykK69DsW1kqHfyUE52AZ99dJOoXlCmc8g0G2U8gqL53HNIr9o4RA/bL3dL91SGD5d/nQPF25OIV6lfM9M5mYByAgQ2vKNA8w4y1VOQQg8YycVMDpM+4pHI7/QOVJJok6ZHh1ouxoLCbrjjhyR22AMRdoEYrlKOIzkOOQ9ec605dIMUYqTca29mR+wPcnpOkvW1DbKW2jxtyDcF5pZAqhRDynvM/xML/ftGBAXgmHbRGmQCGZ//kChwem/XzCa2zwc3WEIo4QEx+wjz1UvnUR/BYgr3NDEVrXtsEZI44/LxvKSz+bRtU1u5as1W/GUrHr7yWS751FCKOkWmn2F5+MWYnIvEg0iU01MSRblfrjpAISXpBuyWXfyxctGFXnOT6mdXmtBO605eqHVU74o80D7CZ5LDhrVQqLkpFVucOPsvl8s4c4OQVgs/0dAgtxgN3JHzw62VUcb0AaYlwkO6BiW6rfCll0ji6LlVd8M44zM3cY9RJoFrqzGcMBXaoJrVNlmvqO+6xISH5YDORAVVu6uLg131jfcCoZ1xyUZK2GcX4iU3O7O0XlQ8lgHGUbv28w16aMpt98C9t1GTeYSsGjMHZwb5bmcwmf2QVLOdIBuYDlkLq9WAvi/9rYRioxn9FXFWAe4CSTwxPSohIyHkHLULYEAjziRThCRXO3bFOLG51F2Uxs974MAYirvwINRduWcW8xJc+TbloLfnLgETbQc2W0+GSn23sl3FKKXr6SjcQY70q4B/lkHGR4Hl+C3qW59D5aI0FyxmP+c9Jpqbfh5ZvQMk3rZXWAVMq616kiGStccLmFlrE9CSowzGzc+P2lHOMnpVfWJAG3kpzNWlpSMBW8LFbb1h/d03mzve4JvURm04u3Gu4BHEEVnP/z4bDgTR3UitQPYBxLrOdEH3xP6EfL5dPkqJ8eEB9uoUt3y08j3TPR+8YTZAvgV5+UeQAppQ2r/xB/mbZmtyv5uv0g9Q8hMmtN2idVNYN970nbq1311hZku9kCjVbhRxjxCtvDPS3/63fR2Cc2EBPx7KvEuYb0wo/1XfE+IYskWZCzVSGyKz5ve+N7Du+rTOsNfrRnF/gbN1iy3pnNDWVce2jTIopS0EcLw2RcWvQ49zvaL+51k0S5eb16y+9sxY0sRdQ0CtJp9ZPzKGJ8mtL3kzb66be15X6rZVdV+5vgH+/Sz95y+Qr7W2GrzOZxxRV2Wd2MPFUSSrDbmwPbmJIh9VaZ1o4DeOQm3RkOIIJ2pHWnBb7+F29cU2uXdlM1C6hiHu8moTuVIHmJg4XkUMIkOxdzQk8fxA5jz49OCWq1BiB5cVaY57n5saxq+TOhG9uH3A9ozVndb8HJBrePJbj7sA8/GD1HBiHXU68qyTdOQGZBCjhEbUH/m/ECWUgUgJH6N1740mSKYochu1UHPpvecIuyvgrnbEH7CplLA1UbCyAMVXws3LCNJklHbrSbI/vonLbGtM1rREWKHvLG+cLAot53MD84wptBoelYdZA4VnU8SBgD332YRqYNwG1UXtUdqTNGXXlIcxXX0aUQineL6PJ/1dEvpdTuaLdkqElnoNlk60DUmz6nYyaICHwdcg9vZ4mX16RmxhAeNHbEf6Gm41AMvX4nXYAEE6tgUoO+nFuMc/rgTovVZ2XrgO80EUom7wwRZk6VTNc0sd/5byj1m/sOdoKB6orYaLkAP3afJRg5MtP39/UdXwzN1xUG67PxrhoJfIP2QQLc8tzDE5xOSUJGp0bXtFg1dHruKje0paRQFlHVHZmnfnW2yTTaae8OfZXwQZF0oJOkuPr171J/9dyRXTTYVVu/z6hS5c6y4Zc7BfofVMHH3/6KNgNK6imXCZjuCB7SOUYHAnlqGb0u6XZAm2ZSTYS/HqKsiDqSkIF5DLtEDpmQR1m2DzOAcbhmxotxgP6oA5t8SOjtiqVA+oBSXFCvyh3PvUvF2/ZRUwqQJH5sQvR85mbGBUXKEHqiHTkf3+80beoJqCtdV1GQ+/cYZnf+9YDAreA7tIVwT3OBY9RQWtsHkhSLlY/mtntabtEAZzxpwFbYPutHyN7aDCSzwrXYSNTe15AMT3Jqt08pWVMcrr8+rN5aCjz4rB2GJ3MmxfjE8rQJd8hsBzwelOiVQFEiXFfkSW7dqwcrb8ap4DNQO9IKh0tlWarK4a8b2PFHnJHOX36Lwgr1VTkQFn6TnZPRMVEO/lOZ7I2zKbwh5KVd2j2KSEIh1aN1iCyf7goA++rkfT+/QxmJbaH9Z4xt3m2ysk7FGCfqVuL8yM2P0VQE8wxKaFHaGjgc7/CSUw3ty+Op9xYBho9Rl2EbLG0/7PUquYZXT8gw3PzNaapJgSDBxQfLMuDLiwFBC2P3UTT2qXdoU/EXHsC4ipqe9T/6lHRZ8PBuivp0qHtbUbyviyf62W/FYDTyu5l3Jsp4pbgviq91GxrlMr2eCO63qjpDNTHXKwnvHKnVCDs9aCxqa5pOkoxxjpFVhLwEVGZ5W0pIyq2TzN0Kt7EGtMFK/BnQdnreDe3RSmpv5sATjAAAATZBn9RFETwQ/zEGoPvWBMDv8JFT1/+Eok26LGbz2QmVygCD5aDry0wVSoS2+4G/Gk6bW3w2MfZFaG+GgVj2nNSpngc7ukH80ovPSmey6WywN9fLI7N4nbc1Af2QeiGR8oma+lRYa+5C5/DA0MEbmptSW9NwuF1meB95HbaTh7Ehkx0uc3jO3K0IGCmVebU4pokxz4WKgRhZmuNTppra3+IM9f7tApiIq7oVXNLJgpvoIP3vWYkzGOrp2CD/ZNldqxka4eYiOP1a0khpmrnsN7b5sr8zT0GhjUxIpu4h42Q0uMjoh3t8uFgJJEVT5M4DKPu2+PW/qI6+WomDFAaMjv2WFDvRSqJeod58mPHNtpPdQ6tutqXlF5Yzmx/of3SOE3iIrH7rNDMyF7Y41FvvRQqz/gAEJFe/AAAAxAGf9WpBDwBqQwRE+eb4Uwtha0dVSfe9wzGJlHLxAu8MwAC6rhiDnEaG//hj0qPCm24HsW1SYLofnfJng9V36XcQadtqR1nx3lFBvuJSm7bs5PIJAeKwwNQ+FOhjA9OaNv/41GVymo4kbtPPeh+e859oQMFNpJUrFAPzKOQmKe6JZlvckO3qPtHzfreHjHZ6v2xJLZgjdnTxhjV4DMjFzRLkqPeF+VFz2vPaLt+9FzHdm24ZgIn4sssVf93RtSGnstZAu4AAAAKHQZv4SahBaJlMFPBH//61KoAUvWZgB7zV5ItJcx+zlS142tw/ZBmvrBPcgWlei6WALUf/4uESuUuj7p7fdTwolsgRuIqbTta2JUSDm5g3fQvwkkGUqTR2AADBU+fZb3IuXIrW5r78JsTDHx+iV842CMVw8G7FaH9IdyvYmVR7TeS4NZpiqarHWfr8hdte5zrF+oe+QzQDfU2/DfUCZFZ+MK+FHcHOd5b4MRneZXS59c5Nk9Su9Og8rPn6EvNxplaDEe442b+mG+FFpNdOwVkQ67GLZ6NhnAGh0XsTmAtmWO0RZzMHFnfqqub3fHjpnuWqDQagegblPoMnMAuH77/T10DGdZOUdZJE0+J2Iwbt/sos5O5hakxsYYOsc0u67imUqkUjc1VWOowl97rjRu2DFmVG77XwJi830ny+qACOa7ggG5T0+vEJ8U31a/fLySR+itwJiiFJuNdB5emuLKodbr7bj5SKhF4DWr8bYcQfUlZrWxTkAeFYUakuXucqaLBplNJl0Iw/MVz9lWNAPtZvch44UeUAABD9muaXVfXCPAln9P5nbYXu7Vn86mC5Mu8lz25kzIYuW3fKFfM/E6PyyEQ8pst6gBuadpX8fo+0ctBzB4pUVzDcEaMexJfgLYiTZxmclNevlZi7lJWk4BE1DDKnO4eohWLDUNefgUdYNr5k6w65UerJRhFob1zHBZaNzcqaGjW2hVMQoc1iNg0YZwRuA63Zb97wAaegjRO+HzAK9y7u/QSHylpYVYrW0AAhUBiQ0VcW1WxZvagaGSBtt86obKeK8w00R2WthLv2Zxw7K5Z+HHmoOxhOl5CgPcwo8C7aPWEUeCGnMPHcVh6FgMOe6XSTwe8AAADtAZ4XakEPAA0tWCInzzfCmF+VaAFqIWtnhdDeVVSdaVzR+O3/3q1QMRIrZKh/dIcWqdZ6dA2l5aBmZX/+fgdZ/t4/uy1Gj31bbZXdEbAmI8yLWQeiGOOtmK3TpqHNsfl+cPODG2iTIpWuOnIN1g6UxzsaNWtLYx6h+eXyMUuN/9pTiF+lBUMWnXlsVyFHSi4h3PIYb3LvEBK70J8/g7GK8PNecLgCSEe3rTAG4UMefyecRTukY/0HfIIeeLmkQRFSaG3tRD4DZrhbvaOslTkOjMLXGWgxeeRAHSsW1BggMot7nDK6OxUmmc7DEqIfAAACJ0GaHEnhClJlMCCX//61KoAThJ0k6p66+qAbfx/++AAtiDXF0dYP59SvEEnLgzY+B475EX//hKJNvi2YOKfrTq10o9R+h7aOCmG4RT/jJKDwotWsH+tA9wO0yIomETwIIQEVZI75WEioNQ2AwHTAJERQstEoYMsMB2sIURzGpmAkosaESxm4msobLHF5C+zV0vu9rmzgj+PksDog22JU92ZdZNW9hUDOPLQcdT5xMRmIBwGTPQ9p2rSO2QljWnPFUhutow8ZVf7wz+84W6OHfvb7THTRjmnSNize+GzlXMJERbIKFVjgZq2fFrEiKaxg7CDghzmCyATurymTJ+dxvkLvtkJivlKgzeV1V2Fgk96ZuyzpXPjmlgWFVSsgth1LxmxjOMv3Mq9hp15Sg3Vh8h37N9vw0PtosoHQp2iUqD6TSd4nzlqSqnAmsBL4mL3GdvfIc7LOE8uYJ8A9/DpkDTEFtRmKPmNdczx9vUtm+RGbIKRnO0csWI+1noaEbiT0wpTXwcuM1UH6Py/fBbSmJu8M7BajWX4HY7tECeZaa91iGfvuSbWpDACUhdmpsH4DVp6M1mu29skG2wUcGsldN0oW0ENtTyYdW3/wlEko7cc5+x/pU4WT1/gCfUIHPrUNuvZEnCNb3MihDgbA8y8gkdUKoHaFgWrcF2jed/hmxPkQ/husMBwOZANOIOoEgo9SbO32yy1wazctReUmQtDflhce07GBShggAAAAeEGeOkU0TBH/AA4TuNGeqqcTBnx6AIdmTdiE0cmT6sbt0WtISPrWMh+VcTcaNVGKbleESOKTd31jgQGUnfHHWN1YqfUQ8zlTe4ZpNrNzP0DHV0K6BBejeNNb6h5iVBkGSyAnzmeK8uVsd/8ea8Na/FSAW+vGy15p+QAAAC0Bnll0QQ8AGtlCfNObIwytgBkm8vbVPsRMOISZLTXbSySVfEejee1YOg5QC8AAAAAyAZ5bakEPABraHTK3WW3/7AaSJnjDjb2OcPLiqJXNYKKOJsp+asjEkwW/TX/BzuI7MF8AAAL4QZpeSahBaJlMFPBH//61KoAThFxHm0dnvTsZ2boIOM/aEaR/m36m0DBibWafLpTJVgCRuAnyesmFKXOex8Ny/pb2ujIqXk+ZhIpcWqSlsQjxosmqVJ3l3EK6+ordosKdNNFtsi7cgqGgQw3/mbrvpAWihw7Oe0cdcL/0iRi/JJqG/+yx660SujTu2wPTJjvT6Miig+OdAzbD/xuPVtVHXTay3ZrG2qEZD07AoUegC0LASgq/8I86N2XPk2HA8uuYYWUnYL9ELQ3L3Awfqx1SNplD7vlhVkJzYe41P9mPj0SD+5lnQ9di+kWkbU5Kmicvku+4hR5ytgrKkRqLkzGzlKlYy9ivRVQWq826Az+iMRgVD+Tpsbxm4Wsf0iwb5yRgzA4qAu5blAGlmdvTBVuk7/wBZab9tb66Yd8bBOIMkCOdMJQM3pIzLYKFJjJI3ZyJA0WgirgN/0sOsyzjROPd8K8bqabv+w2sHIg2O0bWOAGCsMUPtS2H98OTxQcagbxdPcufwFbIJthOvGoA29QYwl3hodGN/LVmQlUnaFoSmOIqq5kQQjnM7jni67SrvukCv8tjktEQccGK+GPwFsyFj56SNkE30B4oCq9WbFhjSbCy9GyFMEA/Q2MjiOCXCEQkRFonZSK4/SdOGPhnHSDjbpZXsjJzZyqcEg899nyyazAnv5jNyKBq+JsjhicT0zkTqyxknb9STr8UGCXmf3x9QKOsQcZ5zEzQ+bYTZIH2HZKiCLKz8Vx1BLBdxZjVoA9sg4B/8k9yXqz7Agw75U/nr6UkyGu/7xpV30GibFN572+WC/GEYwiV8wFtYCgZyBbvSwB30Iteg8On8rj2gM5fJNUE5mk0GXHaPeSEAE/GZ1ddzWybXNuZoyWG5TYGymOFPiYYUZDZXNgBcuhBvXl0Q7KXi0SxDYSkYFaszWt9mmPquQzEq0gSvfRcS4BkS1iMTp8e2ra8XJogYW7bkg1YV61Tg4J5aGn/qPoQzNIBvEJu7/QBlQCYoQAAAQUBnn1qQQ8AGFodMnlvNOY67va6U/G72I6JLrsmzX8MAEPrkqIBleBy0SKCKi2YTonyML4+j/yIjYoLcjdqfy/5pSzTBMWN3TAnbGPkk3iPG/SNt16/j5t2D/4V4ZhvbCIQdHWYPaWEWRm4dzbtS9xLetYluQjBfQk6TmF4pqC0NFFt029O1fQJ+hnx84bP5ITts2zpEf/VM0fe5dxEG7/A9FJXySH2GCEALxpzKho15kEWvJMx6UMeEBHeA73XQHk3i5H9QvQ11XJPAyRtXJv2H+dNHQDsMYG0KtZqJZQxF51svqNYIenfYHeTzIYZyjqZEYdKbgjvuXQLK6XTXICQUijtgoAAAAHoQZphSeEKUmUwII///rUqgFqIqQwJ+2l+Xf2yDNYdX96FLgY7I0sbZnRueak70TMvc6r3s2Xbi8EVN4AUnwXze5Kr4FBRgxgbmB+AKmhRB0iGLjWe3fYuB/zakwM6vqZ97uMV/x/7OiDz55P2BWJPfKU2JLjmzUEUVmt30E0qbJhTHy0VFb0N4kqlf/w9GjVFZ0wshmMsaJyRbnCDAh/QMVEu1GMaZqiggL7JHaldIPnDap3CLq+IXBhKyjQ0bbYdaQdNYfDSMEbaXCsYB//xgAXOzurkJ7BcmVSEiH/D28GPArhoMSHdrszdtYPkmytYAL3O7WWA35UHi3zoil8+fxTCMIwey5qq8194pz9IWe7ghzmknyaPC2DzUqNao5/CVFr76PEwx18rXozDll4rYGzcEZzJ+an94UytWci3/6EBp4oKm9xo0TNL3BbgMlU6bRgDvEhAgouJ3QAnDoZ43leyNKhOngdbvyCmGt5GnADw4fTMthbJUfTOTuX/+e898ebnZfKpD5KZw8DMG6GHyY/LUZm6SxCwWxAhdjrV1GmP10OP/DqXKBOkhqZy3lyByBvyEoi5gm1YQVCreS49n2iraze97eNee4Au+G6HFxY4zPK7L1UV89wBY8Nr8IolCzAAAAMAi/AAAAESQZ6fRTRMEf8ABau7nvt6i6MGbDIqHKZ4Q48eDidJBbd9o0p13yEbDUF2la5jQeQGS89CaNSIROCcx95MP+Dd0uABY55Db/l3bouCdWRIonNjDdl7/8MuWpI3Jemiwq+B/MUDxijkd2+yQzZ2+OYLpic9ETrv7VaCX6IQafaykHUTdR/yaPUK8r3qd7O+FKpUSfxOaiCHKe4SewMtdhLq3iGZx3I7aYKeDUGHJ398bLfXMFckq3tgnNMTU9jEwT0UL6hR1dqP5PC+UBU3zDFOLUzoV8YqcORZIZfgP3/WGuk+A0xMw5G08cV1T35/9sBhMlxudh6ltvBym6kFeEqFwnbjEEezxfhuy8NlkAX2+Q3DKQAAAOQBnqBqQQ8ACsfOmVustv/2A0pdkvzayF4R3d3pVUoAS1dy09cN2Wv/wy1akjTUlmTbc/MX5k7pJ8sYHLgfC7gISmo/FRm0hj7VFMPiDPHcDsT/QYTDpdRfIFdibD+oR6iEkP/pPEnTRTWYiJSK7GR1C6TVDfEiqEzn/lTG/KuxSjHX5p8P4kOg91GbNfO/ZNhapFx9NGtgD5V0p2wD/Q/TuNtvbiZp+sC1vRqLCMD8Ld6NhpzcAawNowlzJglUdcAASpjhf3ZPuXfBboxlLfFfHOtlU2vW+KQ2N8ko0c5to1gfmRgAAArVQZqlS6hCEFohxEC8BigOQOAPIdAvAYACCP+Xx3RSevRM/ugusTWbH9jkAF9QYZe6cGYOVE1iqyd5GPSkoDu7/4Q+Ct/+Ephy7QTKgBC9AZk9rFPSyxeJmJSEhhKqCRExUIanq2yC2sulC4ywuNUw43KDlgloMUDzQJws3MZrGFJN4Xn8quaU05yFvTtfIMhV0qmiUsXhZPudQkjN20LG5VJTLGQ6/1KMylC19I0/raQrwt0rMjX0WfMAX1dJWQVTw6yNvdiBgDUhYuANCjkpgKMBGVqsbabPq85ObsZZPJKHBHFEbMoL6/BGn8oCS2BDUSWzbKxzZmK3C27VZqw4xWdU0FqG0pHt+kxvX6+OEKlMzjvqMIdnHQdcQwrCwEtbHHol1o9t9s4lamby0oBdkyNJQeh9mouCfidCdkvOTUYwyMbai6qu62yKq+zWcwbNgfLKM6c+Fi+1Z2/5p5vHrtgc0q5d1mGpD2TUR/WuqZVjPhhn5jazQ0apPtKpKPDDgCepaLk/yvyP0l3tHRInpMUiSAuTSuIqkWCDZlQNR2TIiAbQP4Esm7AW4G3V55wpfkKAC/c8pQ64goj8QlmNfkPdu6xISv5S1S5MqsEnN8TCU6+3t9th/uuQQQ4lp926zxoj23RRSGBJ6kuqkOcp63ZRcJbH07EX23rnRQ5EdR7x2okqXlFqSfhpJTIHfPYPocxBkY36OyMyzlZktv0+Uxg2dUJUkffC+Q+u2k+NhuqbzeTagQscu9TBIQZnk3+RkpjfwCM1a0EF3LUNEiGgDhmgLBr4rSHJTMr8m1Z4nrA529q8wYViqc5jipAYmv979JCrNEw0RmiV+zU94YAGdKT6KdoL0CIJnTvuO/XQuPC1/wjP9kRTK5rHnxnBFRSRKBwf0gUpzBEMJnZUx8S8RIkC+W5oIgxzXk0DqsTfhEqZFyvHoEi8p8OE8wV8Z/3IskoiPr/0Ir1Z1b3/+7FiWqVDIvUrkm+NC8dAWHWHBeatw3dV2FwhcCoi0VklpHDanZw65GAiLrZ/WU6LN9c/jqsHpAXdFmG7/Bb4HKeGRlitsIPzbg4ishSIlt9tpP2UZllhN9LI30v8tmdWgo2YuiSZcFJAR2ebRPFaah2kodw5cSBvI0KMdaiq+NiYZXHhl3N6gLNWY5C+D0uSZP3Q2Wu+DpGCl3z9405ik8AbDoL3tGJ+4HBi/wcaGEg3/NwItMr/9zI09mttME1tPAhZR7vfNG6cTwyXvPYn26Slz3trauSnpVrtIDcZZnMyCwB+KWbRKyVviCACKzFCI0UGQ0WSyFnhZHZJAtWBTZgXX7oEHnbzhaiRttJWPGieK9um/6QKNCDucYYY9fWK4LxNxECPChiukT4d8eA017TbMF0aAe03uf7MQDZBH2g+6/u1r0LUkAS4ldCVv4HQr2LoBSDcJUaTB24ow4HsQdBTmpKMVrBm30RHs26PJqACHa75+Gtjc9327DPhTtw8Qf/jrGocKXO4TTur4VC1YJie2aq3Gev100Cn0DWJAALi9qVlcsNsM2367R9E2yYOyjYZKx2f0mgLf2P5N5+TR6EegxX/mlxKkyqDj+2EYOz2ux2vlZLjcuOAUmbjPd4BE7RINhsWTQz5Vrdry+4DjfSv4wX2MvfQSrvyy0GLjHrZhP4pSruvKfVpYGfdlvziwqfIRwTWmrrDrLTczPdqUOL3eeUSp/6YlptrgYdnlp7Ll5TikboQA0ljfc5FYYMeWIFZI3/zFlZnvVF0CiseoZhTncPMR8xCeOoRYoRbIBslutty0AG04DKaJkEnP+fj+OMX7CblU+rxCwKh640rfz8c1B0CiV2QN4lt1+m0gSYpU5FIm+0OQ8kpNYdsnotnnph9yhBjy87Npps7llfxEX2MXeanBzWOQTum+YNBaynRZbav5bfpx1p6J5ig6r6rISR0B73XFJr0vVkaPptaZFSYF6kYadW+EIiG6qTowKfC0QKwnkQcHDUzgzJBJXthbOcLDhx1+WQuZHds8bl3/WfBSNrnnGyaTwx74Nv8tp8+/7VH9QhFmQ/G6sRmAX+Z/RKJ4655mmACQ9kwKaYfEjowcWmTfdiOgTq6NlMKXX3wF5UNBrQi0kCPlGiSJL3+ZFql3Og7H1L1FKTIbimMCmukk+J6CZLa1B50H0VhQKctGRbpwwpPbucYRWMNJy0UU3L2m8BPgwbwbRkNIsbLjn0ieC0twn+pnC61sELYDVflYy06GaODmybgJzDVAtFObVyFSdlqsnImVSNt7QSVlj7Eatl5t5KFqMSqua5495P9sGWP4iscthARSnt0awySv20Bqs+LnILfygnKhTNo19gJJ62EF1XkQ23PJu+nmxaFKTDtpkZ/IAKFnGCVzcnDezJUHEdPCDizBx9dFUGeKGB593bsM1gEIAARhQmRZGARx4+Yx0Xsi7mrT8z3+/6tvBXFv7yOjMDOqBvaDXsm2AC6p8uhX6992mWLMczJlXdytJ0YSEJa9om265l8CxZuZ/wV3ixaW9dlUkA6AVdcYYtkyB5N1vcxUBZp4NyoV7bFh1HhYGCS5GYioMkDlBcOwSna+O6EeFXKJQsSILc+aONGzTPkft3xHo7yz5LhHkvLYjCUlkrIfWvLsMF4lEgpm+uIzOZh1u4vGwkN9mCHIZkTpsSQJRuOqRIvBc3hdSHZs9RuoHFfz9YywYhs+meCRlnxBU2MYtG6ciLI8mXjGl/0Y61mIkdT5yql//fNJPwN5tEzm73yAxvKzhR7Vojnbai9aZ2JcCwBLZG0ycGeeJuAVzIIK4L34iS/QMb86uo/KnaJf/vHbkIk+lCnW3CHpaQ8hOqOLcVhZQzcAhKLbmUREHFls30dRDfELOcXt0SjNaxMeFyPPrBazrikiEFU4JmWusM7yZWXxHYoVXAOrNd1gwRjw4SwCBJYScLJYThA07oeIllmFVVm5zor805oXZswQ5fhALSe5qNqkMk7/tM8d7yFho2Ux6EE62i/+vioPXGwzrD5tv4vLmrJJWJrOUrCUl/1xsPCOrY2JRd++YDwnXnlVmzKh22BDMAXvnZQuHvaKqGomDVedFjnvLM05s1QIZ7TDFoyHeVjCkNTg+wwSgOrPEU243r8/u+9vgK8AvvXQ5UmZDhnSqIq32PD7KbdI4sWNVQqffxij/S/TuVGm9G5txHiv0fK44rUTE1D5XlF7ngfQiYeVkm+zDH/9ZBZkVZiInjKlnhnwSZAA7GUp8MZ06ETsuKTOmF64IaZBnf1ENdZAkXTnn9P5cA/wGI9qGYLCajICVMsJpR5Rlaw8ja0MukgSVAgVctiAPlPldcVwk/cpqpjjM/8vVfpqE8cn91J5A5M40j6IG47gGtCewTRbOpDfg84cIKOENtvbNehWOwreELF5XAY5zxBqGPj6wakJhTB2MBasa/EQwXxzHGuzck9gGn7iOs6SN/WkKXDWpSxhGb4IMymM7MAOMVg4bWlk0Lp1AajBgI93qNCO0ffJT+sHYMWQzJNdaEcE8udiB8z1Vv5ZV9EA0zuneUx65M3D6CDd3nh15TFzNFXMLcI7e173ADDXZ2TSY/4GuyMKyxqSHG52jmQi6y5ubj/O4LwlJB1g8k3DqMXeW8t2lLMmAAG8K1woZxUGy5WDFjly9GwO2qS7G3fjEIGRibiIoT0vMzAQyA/wSNcwR2nZmHBYAAfRQAABSxBnsNFESwR/yX5CXw/x+X/4SkD7lc3d6761s5EYg8LRqxFRCtpdpNzZhsPpXU6S/DZw3UD8ztLtgfGZSOAG24sr38k8Ed1qjuMh9uXChhsi+iODz9tFZav75Yu2p2/ijwEkrqrWQUKMfTqMKIGT1mE6o2k6BLBLXlxf7ZRhY4y3xRLxosx6w/jn6bKLmI3MisyFUS8XPdc4L5tL3cA7Pgwnd5JwlwTyjheFs2IkVvb4srOyMWlLxvHcsDv+RH6qb6xfDeebDu5vkroBYO8C+GmRX0f4kgl5JywG6iFvPZggQ7tgvmL3p8dJweuoThC73pXhWBZ+465kbzxgkTjYd97bAqlb3fI4WeLfidPetsDy6yIZk5NMzTGn2Yqonm/Au6hI8QygPvVX/QeIdaOyhDDQzj+ifaYz/v3iJqHpCOMoyIs7W//CCsOv9yFm9vGwHRQP25AQICc0/ETrePLBckqO2I5cbut3hhd038z3OufPdSG9hJH6yGWO8m9EsAE3vcY7X7LGpYKMClwJGtHxNpQetPyU8ZyTr4vr7eu/IHN3w7kTmQoco/xnJ43QOIHuCqbRQY2Sg3dyGAyJAJ33mB8nGXTQYIh4WNfSVR0rlAq/r/QGBtSZauhpunDV1WpcxcTOYp8wZ2hEFYSGujI1fecUwYi3O8yeYRfSjcVAhieXQBxtOS73Qszdn1P6DUYPVUNy2W4+2nZelWGqjEh/cuXLM4AS9hatnPreCOADs0HoYOKQ4OrvpC+D8n05VyymWLeHQyvKMeLutNXOd25M1XQBSaDWqdxdCIiC08T5GrfElQCF7CL3BzzTVObDsGYtchVm579rv9BMZNjQVPqilaIc2RoNKnKd80rxkNXmi0Wfv+cZ5rsp8+Cc2R/5ptkyN/7E7Eiod4Tbhoq26zKKJSsw21HivR5kNw7KAdZrQw0wL3NPUg2ZSwgOdFV/gwUON93RyuAPm49hyebIQJAF6TpN1CtdG2umYBWy9OR2r7zHWF45IuyMeLxkd8Sh1posmoFjxakq+QMV79pXJYYmgZ+PndicibB4Hhpm1OO1/4J5pdS2oMAZHhz2X3rN9oBXwrFDOlR37gkk3YIuF5yytxmkjVuIF5hEiqhMcEt/JBHOL45Bn1oTLJZCkx7YgvGQFZptxkoxTpNWniSzECatXcIUGYiQVCa3k16xcXniFeUwyaV6rPe7Q19HW8lnLBhAhUMeQTSa+mrFtEN0sYUA91VcG6SspCzrdN+bn5ZMuMOZPPH72vUbccL9P7EUOX8yS3BLd84GUkcvfkkz+rv6W6DLHDIe1xSmE0s8vJR7UQCuzxiFgzcL2mOpNWaN2uj2P5i236j0baX0oaGNvWDJut7QZHt5wpTJ2wLZ2fcXpff5sm2Hd9SW5AtxtmEGzwA8ioWaqlgxHLYdhnPwrDUOKLkuVy0cIBJW+fplnVj1nLZpKsyKau/JADAfaqrsLUe3UN0H61Edpkw0XjdnSpvDFnZpkW3jzFmBOJGAwELa2dYn7EGAN4JSBLeaVmTL4JhgKaoziCREFrjHUi2zG5/J84AdDYJNA6zobqQGPTXUq0dvKQ/fY/WEqyKTDpfLsZ1dfYRVPeaDhlCPx40Ip/Q1RLSpgQrojGjNJSDt4gMRIBnSWrHzSMxy+NLqFwMD2klbwxxZQvclsBTyjmvY82hGwuTxu8ue/xvCqxVSvA81jBTTCAr55EOtKAwo1c2Gn0AH/TZrk/mFaOv+VXOYe/dbr/QIeMlbiIhLt3cvTOgAAABHAGe4nRBDzDh0H2nY7wne9mXe0sAtIAPjLCAfxHFDWqZeAJuogeXuxLZ5O1g6Zd403h9EevUMjrnkFsyEfm+EJRYpte/ijOC7kX5y/QrIPOoeFjAJ3PCoSvUm/BqWqYOhTKLJgBfEebYTHnkZfGyMOxEMo1Mef3QK7E+M4PMhRG472Me7k1zKuvJXMh/dBocM9X31HZ1OjQHe+7cunKwPwp9vAEqZEY4NUhEIB4wjw88X6YaTrJoIGfAUSlgah/QbnAoq/dMhKE2H32N75oxsy8UyK4nMv67SDYiUdzxLMGCPAOZaoLDIvZp9UoJducUJzIZsbkwJSwLbutzSph82R6DsCrlhKCSDcEX6mTYGr1tb3x45mlZGdHx3o0lAAAAFAGe5GpBDzEGoPvWDaV6/WMdIZHxAAABIUGa6UmoQWyZTAgj//61KoITs3KujtHkOwujz312Pgkv+f/YABoWZM+di3jlsJnQxXycb/YyDevtGBPWLlFmQ0MZ85Aep7rdEqw/LC31DtxT7hnb9V2zpZgzAz//4tSR4kOgR1GLzA98lGmZ0pDnH9fLjBbx6v5jBl7unYRpOwdGlRUDaWqoDxWmK1kPHQWexZm9Vwd5sxaJc8Z+KgX5z7ogYKaMJgmfTZamJq8bfhGzMinQKi5/cv5+t5Ds8UiJF8NrQF2hzAOOuWVoYGWG3+aHpmAcATI33vpuJ8yuCEasclnDhj2ICOie8xe4KUO90rMNDgvfmUlw+PU2z9V52w+YaEOWBBlr8+XeDitqodXogTZSvJoLbk6oaqFhFqgYF5kAAAAsQZ8HRRUsEf8AO8qmFNKuSndC6vFAEWk5mcR/bskBGhivcBb2qCKf1gpwsoEAAAAKAZ8mdEEPAAA3oAAAABkBnyhqQQ8AalxCRSF2qZp1F8In+2WqBbFlAAAJoEGbLUmoQWyZTAgj//61KoCAeJ91d6ADiVARdWPA7/7El6asPs9b/8Ix8O0UtHZVqROeTaYqpBrE54v5YmmarSKn70sDoXU7BgnK3cirk7rFL1fjGDTZuLV75FCxhmorzQGLm3DOTdWvjr9oCyPZx8FagETmoCOl8Oc/tmIYU4lgtZ8mX55g9f70SkWV4G4TiH55pLc0WDqmF7Js2mo6x4boH1ER61vRFqvOXNyv0++K1gcK0YG3rvyHf/xetocxZXf52KtsuQRntiANteEU5xpUkWYvXGdP26HSMo0QwQyffWE1c/7aH3TGvsnf99rZzhGzn/j7t3JwzXH+yu2DAgQEETQtxDjCxdsQ1JPyoSFMno0MIHMGEqRmFSNSHM2QOCLjbq6RNr/BTmawOyfR14LmbHIiHNIgMLMTqR5RZxitI/k1rss19/4UhQ3Eh/Qzqu+EEFAayULuKnX2HUYAs6lEa60s0sABUndkL5zvVbqtqhN8PVgQY/T+jmqnz70IU2KqKFzHuTQ54tps+rJrGZ4O4JMPOCnrD0RfARXt13U7g7sP0Cc5p3Jjxx3ls8DR763sGDL3L5Z9DqeFZF+dvhpHbtB9/76O93TXE5A2rykhz3LQNtGmVmlwvCjw8F3jElTDW+qCQXRNl0C0WSE0npa5yt4u40WJttV74MYB6DrBAEsmJ/BBi0vXryyOZ9PdLrasbFO0xtIPurIwxvb7nOQZhenpTWqLXqBv00n9CzWE8h9o9qSFX/+AiUJ9CB6Wz5sLaFDjsUtNxbGiShjMvioEtqn6o6SZ/w+TAEYBWSGU9XyqsBeWCXHBjFUx/dEjsFUBKHnV0ERVeUeFJ17cCSinkrNpUdfpc7Vb1NtENlRuAKMIaMITXexSMejou0PikG/mqFKNrLQiIuws5BqwysHv8mI6/OaT6efh9asVfMJhaPnuUZEJgT1jsP+3TxiXUnrvcvSQiT/UUxupRBf/JnP1R0kvMxPXNPIQvreU/bwqISOb4ryDCD1GxAizPrKnu6qxWgj/ivRXzl05VKH7A1iqDRXsDCCZM9L+Mc7FvsEqw65yeMLBfH4UH69URprpWdNQ3/BcvxMGmec1JhXXLfOJ8iAPsMn7WyP9wnX0f+rAaqryU3eSXdhRWyhgonZV51rpf3o5IG+fPl1LS6zrubex3t6IKUE8Oy39FsNaMa1TeYZ01wYEu8BgcDpjQ1y65VH0bU3+ybWoW2UcMpOumTHOS/Ll4A5IYvgZtO9edscgWwpr2XyeIAnXDo5G0YGByiXoaGzFGouDv1rZRS37NNDaHx7Dx2ui28+X521WSEFiyRLRVUYSTJKEwwR7wp9n7vLL1I23sPy8ga6GLvdG+AvkW9kmvaU5u9k76cEc/uTUQVqILMH1FOcHWDWdnaOVQHBB1P5w5gLXuFBRKkLRiQL31uWrCfVjH5rPJiGLlbueKlFYq+SIoLXB8vpUZydUC6UFoe2iK49OBXN+kCpRN/ikp9ZQkYaxQNJcdOtC4MQc/DUo1Hvooi5mWWW82B9eeMUMO/OYp7sxDRfKcXMMVWAQutZAbu5LZj2Kr9f+SKHpOdu1Zd6pSaJHdIiBKzWP8a4YF/gvrSTObw4DCHHglwBx5rnQv1+08pcFAO7D+Af4EsjYHXTHeuSzTlP2lWqHwnd0OIn5o6QnAEWG9JsUDYAYpfgvwrVbcHlfkpFOtz/wf1iiQlXfPgNrP5/VseRSLgXf3HiJV5Xes+0JoC8eZUuek5pqGy8ebBYpR6x+9YSXEfhY5dbTwWDgpzGSg17a0iuhYH/fmFX2R1mSuinIF9HYb4r5qeg/n1ZK/7pP6zuJjESxfkSffeI7AZiPoarIfPrnDSY1Q8pzHEKc7YRDziXSOGJNTgBl3C1Q1n1hQ+gy5IqU/FHyc2lI6mEH7I8N706ezAErUa35+2tOLkemtp6W+i8zFxwjS1GBiyN3VlqkAeaYjpw74Ja+bgyrH6Z2Xd3DxVECv51GLq2WbFnNu/9dj3zjg0izytafG1Bz4fYLFHWkmFF2cGo4EiLJTPpbzP7oYrkareAHrvqnYruATAiA09T2fyZjIozL8hXqQs94XdZV2F878fvwEpAQJeEjrEAZHnpRSmolePFRQtbQEuuaHk67rc5Dqjk2FplwSLP+3J8TFgdxXbPE45Z0qTSRzclcwTtY8FgGI8z60XRgC/XPxFqXu0ol0Pj+WCeq5nsQw0T1/N17v3tDtBgItCaLN5rfvsVEIihU83f1tNQ3z49pp2i3z1+7s7f14DW8Jw+j9VS7zcFWnaRv252XWT49ZWXMul5zosjrmg4Z4i0NM358omqxL2MInpzMDiLvCmOvKs1vfGCUqYdwPxDrztgo61NNB/8+s7QmDY0o/Wws7kVtWd+Ud00ucVWvONbshk9yjJLPMVk4x5itDHVv9dDTO1U+j0V7WvuKv7hE//ep9ZD8ent1yxZFCPd4DXgtxkXC96CL15qVT1JxSpGXkA94MCQq9v0Wrg/pjvMuXpZio4orIrPuX334Gcky7CmLhq11JuIwd5SSGigA/kb1QtEteJu2PWZl6KFGpxEoOeWopEVmbFfk7wfB4JHy9FbiobzPdWhC1r1EIf+Cd1QzTzR8f+SLBQ8Upg6hYIcXPnn3fs3TE1LxPBxZYvy2pybbttlOO4c7kST8IVeF4X7SNb0KaMNugzZkWXRjQDnk0PYjKUChATu4KKVYFpYnHOoY21h9VvCFzYKyuWbPkAvIkNMtucZS6okUF+xRoFVpgp0Mq681iQdE5g9oou99N3ibUIAxF5q/d0L7ZIWcJ3zuogK/9i6cyxkMar8dSE2KYu+b/JjEcSpZLohW2zUtivDsid2W7THOANsjGAWEaIUiiGdF/v1Iok3OHY1gT31LzSTl0J0q1QoJY9krAWBRLQBBquP+tEo9T8CsaDQvkTxR4/ks4LU9XA4Pl73anaR5uaaLrbnc8LkuPlTlJLBSQjm389bnGk4qeVxdd4sw8QrM69ghiQG8ftNiYJAvUNMMiy6ewmysfQto6mt1DozviJ2hNR1Gr/Vj/tLI0eDCnft7EUVAttt3zTfIcYx/GOCtXDDIYCudro0g3G6fE2fy4FZRcyfDuWCYk9+0EfhCmrhsp3eCwjok0eHqQCGYXE3CQRSuCCcyPagRsGIKgVhLzh0iXs3ye64NMcXTFBULslWjoZzrz+REGzLZ+wVe0uqVaJNqMHFmEAUA7BZoO+1J3fYXVqMc28Gz1uvG5rB256IBU3ctfCd6PCbtJZx7JIFuh4L0JJUAAADeQZ9LRRUsEf8AD3NXystef/zvyZS0o2YqqTkrcvUUogHD8YAJq9z+8jsFW//hj0qPPYeIGYglmRk4z54CpPQkP6+WTmbxO21Mtf48niXR94wOgE5OSAqoDxYD/qPwqL1N/k91t//Gmw+H7OvjDD3aeR3zzn3RAwU2mtamgh6f7J6UjXBG6zBYwNvaBsvN+t4ieBDIYW4zHIZj2AXNkmea3j4JaJclXFocgfE0My0L4xT671+nR8i8eHvzjgPCyYJczcM8EhMU6j5AGvg7UfVLhxRFydBs6S/Vd700EOriAAAA3QGfanRBDwAdiTIMwuoTZwQTCb36rVSXwG5tLt5KgAlq4Yg5xGhv/4Y9KjwptuB4JWbeYLqTikXobwHqu/S7iDTttSOs+O8ooN9xKU3bdnJ5BIDxWGBqHwp0La3gN1t//Gjrua1e/gta470Jf3nPtCBgptJKlYoB+ZRyExT3RLMt7kh29R9o+b9bw/jtTwVffkwMx6TsmNCikTK5bmhgaopGJtAl+SkBMjfeyXuEbJH2DUPkXjLyLMb4sTzJ8Qsem57piYaHAwa9fuLqU/pwAD8L/Pu13csTTSLZiyVMAAAA5QGfbGpBDwAKgVx6NXAyS8f3qtq5Avetl9TrMYjpbBAc0KTDPFWXw0ALeuGIOcRob/+GPSo7wPYSJnKQXofndzQO48yESaSkAbB50TxP91anyyI0nBOhT7HM/zXzAtSQVmJEoiP82+//KlH/eDnA6Rx+09hW98nu+ndfGYeNUHylUpxKRPrEwuGkSst72KJ4bdI+B6+HMB/JZlakiX2Qgv66qvz4XKbJdAb4UMXN5+hG4D7r9V8o8TKy1C8wZ95SB6kwg38pfN8xYWqlG2sVU2MAD4fNWQ2DAHjYG61LXhu31Q1ZC2kAAAHgQZtxSahBbJlMCCH//qpVAGq3qgAVwhf9LbYM16OgXv3kDIJNjln/6V2uSpUgft3gbpiYewEopuWUq1xS+I6RLH8Hf/wlMOXd38KiNW0FI+20rr3oEAG6ajOW+kOBxEZbu6H0YqYpbFlXR8QIxAccHUnuyvo1aQHK/Qc9gn606ma8rm6oTwxFlYNBuM+4ZlGQCKprRPQQFrnMGoXcBoPvVcq5A9ATnxLPDSWIJzGGurEyKbuMSRlT0M09H/3x2dbTQ+5FrWZEIeS5TlQL/ic0DxcHl0hxTQoHpNW7A0NDARXp3rNu7bTxcF9YZR3sb/iz7tWB7N0HExml1RT4f6mCaKh72h07LsopRQOvIxsTRfxxj/HeLZjedfYj+SYC4/FyVGHqMQxNSwGHdlrNknAAM0FCjoRZhM8/hDi11oNu7LN8BJ2UOk85u4ggx8yFPaECFI+rU/uWqbPmRjCBA7vgOet0idoTfKzxg4DJIP+mfEJ+N1v37MX0Qvv3OLh2TO4r5apUQihQDuXrdQG+ZREmXh1DI4p4gFXtL+oQd97zZfgnAAg29crFeX588zdZZO9uEeuAU7GDL6owQNUsZNgcoz/utaoKpuH3rLVhO7dj2iO9VbGXCasZw43dZOoAO11JAAAAYkGfj0UVLBH/AA0cN197vL1SUHjy7sU80TaAi4rhVSNdVG+lw9MPDXEOvJNczmo5c0/7nap5dQAsh82vkeYHRlau/RlB1WyaK0aV6azSIf4HLm7Zb9IhoVHwkZde4bcJzwllAAAAcAGfrnRBDwAL0va1gD3rsgBtx4GlkDvhIo16Q1Nd4GIlsJ1lbahhWpBejncd3fbUYnCAkHLDr9GT4kev8By1fONgapy5mlDQuXIkjLjd/hxMwZq20lD4flYnkr4x7GNh+2BfEs5sqThNk6MNZt/icNAAAAAsAZ+wakEPAAtXzplbrMPo+N25vJF9dHbAoUElpgDeuf6dVORGPoQ5n2KPd0gAAAEeQZuySahBbJlMCCH//qpVABAGO5p3CWvILGaV0T83YCGHrZ36CMhFWf5/9PAA3G8lSjAOPWIxA26u7UDDZR7+zKV5q0f/8KRJCGJ+q2+tW0DxFcGyvtbOD6OGmV3nbB9vU3AHLRGyxQNpEUs3hEQIvFlP6xLf/+iAj6yXMe/4DuQfxz2HbB91YC5tENm2Y7TWog3Xta9nIF/28/PKrv7n/osbmyxCy77/J+Eaqvgc+VJL1DdqpRucWxTnWOj5YvNxLRz/lIwohbqH/xmffNfh3dUg9TKdzzZ3FYQUMeiUj5oTMwFTahlZ6jdB8P2Ktk5f5R+JHC3CmzCl5I+/FpcSbSbnBcW4roZImWFnSKC//8jXc5ha7fQUu5J9/j8NgQAABUZtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAxzgABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAEcHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAxzgAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABAAAAAQAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAMc4AACAAAAEAAAAAA+htZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAAEAAAAMwAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAOTbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAADU3N0YmwAAACXc3RzZAAAAAAAAAABAAAAh2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABAAEAAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkAAz/4QAYZ2QADKzZQQCGhAAAAwAEAAADACA8UKZYAQAGaOvjyyLAAAAAGHN0dHMAAAAAAAAAAQAAADMAABAAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAF4Y3R0cwAAAAAAAAAtAAAABAAAIAAAAAABAABQAAAAAAEAACAAAAAAAQAAAAAAAAABAAAQAAAAAAEAADAAAAAAAQAAEAAAAAABAABQAAAAAAEAACAAAAAAAQAAAAAAAAABAAAQAAAAAAEAADAAAAAAAQAAEAAAAAACAAAgAAAAAAEAADAAAAAAAQAAEAAAAAABAABAAAAAAAIAABAAAAAAAQAAMAAAAAABAAAQAAAAAAEAAFAAAAAAAQAAIAAAAAABAAAAAAAAAAEAABAAAAAAAQAAMAAAAAABAAAQAAAAAAEAAEAAAAAAAgAAEAAAAAABAABQAAAAAAEAACAAAAAAAQAAAAAAAAABAAAQAAAAAAEAAFAAAAAAAQAAIAAAAAABAAAAAAAAAAEAABAAAAAAAQAAUAAAAAABAAAgAAAAAAEAAAAAAAAAAQAAEAAAAAABAABQAAAAAAEAACAAAAAAAQAAAAAAAAABAAAQAAAAAAEAACAAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAzAAAAAQAAAOBzdHN6AAAAAAAAAAAAAAAzAAAQLgAAAKkAAAPuAAAATgAAAeUAAADpAAAAHgAAACoAAAZbAAAATgAAAX8AAADWAAACCAAAACsAAAMGAAAAMQAAAYcAAAFHAAALNAAAAPcAAAtIAAABOgAAAMgAAAKLAAAA8QAAAisAAAB8AAAAMQAAADYAAAL8AAABCQAAAewAAAEWAAAA6AAACtkAAAUwAAABIAAAABgAAAElAAAAMAAAAA4AAAAdAAAJpAAAAOIAAADhAAAA6QAAAeQAAABmAAAAdAAAADAAAAEiAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def create_video_from_images(imgs_action_list, output_path='episode_video.mp4', fps=1):\n",
    "    \"\"\"Save images to a video file.\"\"\"\n",
    "    # Write images to a video file\n",
    "    imageio.mimsave(output_path, imgs_action_list, fps=fps)\n",
    "    print(f\"Video saved to {output_path}\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "video_path = 'videos/episode_video.mp4'\n",
    "os.makedirs(os.path.dirname(video_path), exist_ok=True)\n",
    "\n",
    "# Collect images for the video\n",
    "images_list = []\n",
    "for i in range(3):  # Two episodes\n",
    "    done = False\n",
    "    current_obs = env.reset()\n",
    "    current_obs = current_obs[0]\n",
    "    while not done:\n",
    "        action, _ = agent.predict(current_obs)\n",
    "        current_obs, reward, done, _, info = env.step(action.item())\n",
    "        img = env.render()  # Get the rendered frame\n",
    "        images_list.append(img)\n",
    "        time.sleep(0.5)  # Slow down for visualization\n",
    "\n",
    "# Ensure images_list is not empty\n",
    "if images_list:\n",
    "    create_video_from_images(images_list, output_path=video_path, fps=4)\n",
    "\n",
    "    # Display the video inline in Jupyter\n",
    "    display(Video(video_path, embed=True))\n",
    "else:\n",
    "    print(\"No images to create video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n",
      "reached max steps=100\n"
     ]
    }
   ],
   "source": [
    "# save in CSV preference vector and evaluation\n",
    "\n",
    "name = 'LavaLaverNR_Grid8_20241113'\n",
    "model_path = 'models\\LavaLaverRedN8_20241113\\iter_500000_steps' \n",
    "pref_vector = [-2,2,2,0,-0.1] # (red ball, green ball, blue ball, lava, step penalty)\n",
    "evaluation = evaluate_agent(env, load_agent(env, model_path), num_episodes=100)\n",
    "add_path_to_csv(name, model_path, pref_vector, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'direction', 'mission'])\n",
      "observation size: 7\n",
      "dict_keys(['image'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points {0: (1, 1, 0), 1: (2, 5, 2), 2: (2, 3, 2), 3: (2, 5, 2), 4: (5, 5, 2)}\n",
      "Total reward: 6.0, Total steps: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.find_optimal_path to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.find_optimal_path` for environment variables or `env.get_wrapper_attr('find_optimal_path')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#test the environment\n",
    "\n",
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = CustomEnv(grid_size=8, render_mode='rgb_array', difficult_grid=False, max_steps=300, highlight=True, unique_env=0,\n",
    "                        num_objects=5, lava_cells=2, train_env=True, image_full_view=False, agent_view_size=7, partial_obs=False)\n",
    "state, _ = env.reset()\n",
    "print(state.keys())\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-1.0)\n",
    "# env = ImgObsWrapper(ObjObsWrapper(env))\n",
    "\n",
    "state, _ = env.reset()\n",
    "print(state.keys())\n",
    "plot_state(env)\n",
    "\n",
    "\n",
    "#test the environment\n",
    "total_reward, total_steps = env.find_optimal_path()\n",
    "print(f\"Total reward: {total_reward}, Total steps: {total_steps}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'direction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m move_sequence, illigal_moves, total_reward, ligal_actions \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_agent_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m buf, actions_with_location, buf_list \u001b[38;5;241m=\u001b[39m plot_all_move_sequence(img\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(), move_sequence\u001b[38;5;241m=\u001b[39mmove_sequence, agent_true_actions\u001b[38;5;241m=\u001b[39mligal_actions)\n",
      "File \u001b[1;32mc:\\Users\\matan\\master_thesis\\minigrid_custom\\dpu_clf.py:75\u001b[0m, in \u001b[0;36mcapture_agent_path\u001b[1;34m(copy_env, agent)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     74\u001b[0m     agent_pos_before \u001b[38;5;241m=\u001b[39m copy_env\u001b[38;5;241m.\u001b[39mget_wrapper_attr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_pos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     agent_actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     77\u001b[0m     obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m copy_env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\stable_baselines3\\common\\policies.py:253\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    251\u001b[0m observation \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(observation)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, obs \u001b[38;5;129;01min\u001b[39;00m observation\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 253\u001b[0m     obs_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image_space(obs_space):\n\u001b[0;32m    255\u001b[0m         obs_ \u001b[38;5;241m=\u001b[39m maybe_transpose(obs, obs_space)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'direction'"
     ]
    }
   ],
   "source": [
    "\n",
    "move_sequence, illigal_moves, total_reward, ligal_actions = capture_agent_path(env, agent)\n",
    "buf, actions_with_location, buf_list = plot_all_move_sequence(img=env.render(), move_sequence=move_sequence, agent_true_actions=ligal_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "def load_agent(env, model_path):\n",
    "    # policy_kwargs = dict(features_extractor_class=ObjEnvExtractor)\n",
    "    custom_objects = {\n",
    "        \"policy_kwargs\": {\"features_extractor_class\": ObjEnvExtractor},  # Example kernel size\n",
    "        \"clip_range\": 0.2,  # Example custom parameters\n",
    "        \"lr_schedule\": 0.001  # Example learning rate schedule\n",
    "    }\n",
    "    # Load the model\n",
    "    ppo = PPO.load(f\"models/{model_path}\", custom_objects=custom_objects, env=env)\n",
    "    return ppo\n",
    "\n",
    "def is_illegal_move(action, last_obs, obs, agent_pos_befor, agent_pos):\n",
    "    if action <= 1: # turn is always legal\n",
    "        return False\n",
    "    if action == 2 and agent_pos_befor == agent_pos:\n",
    "        return True\n",
    "    if action > 2 and np.array_equal(obs['image'], last_obs['image']):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# resert the environment and run the agent on that environment to find his path\n",
    "def capture_agent_path(copy_env, agent):\n",
    "    illigal_moves = 0\n",
    "    last_obs = copy_env.unwrapped.current_state\n",
    "    \n",
    "    # last_obs = env.reset()\n",
    "    # last_obs = last_obs[0]\n",
    "    ligal_actions = []\n",
    "    agent_actions = []\n",
    "    state_record = [last_obs]\n",
    "    total_reward = 0    \n",
    "    done = False\n",
    "    # copy_env = copy.deepcopy(env)\n",
    "    # plt.imshow(copy_env.render())\n",
    "    while not done:\n",
    "        agent_pos_before = copy_env.unwrapped.agent_pos\n",
    "        action, _states = agent.predict(last_obs)\n",
    "        agent_actions.append(action)\n",
    "        obs, reward, done, _, info = copy_env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if is_illegal_move(action, last_obs, obs, agent_pos_before, copy_env.agent_pos):\n",
    "            illigal_moves += 1\n",
    "            continue\n",
    "\n",
    "        ligal_actions.append(action)\n",
    "        last_obs = obs\n",
    "        state_record.append(obs)\n",
    "        # plt.imshow(copy_env.render())\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "    number_to_action = {0: 'turn right', 1: 'turn left', 3: 'pickup'}\n",
    "    small_arrow = 'turn ' # small arrow is used to indicate the agent turning left or right\n",
    "    agent_dir = \"right\"\n",
    "    move_sequence = []\n",
    "    for action in ligal_actions:\n",
    "        if action == 0: # turn left\n",
    "            agent_dir = turn_agent(agent_dir, \"left\")\n",
    "            move_sequence.append(small_arrow + agent_dir)\n",
    "        elif action == 1: # turn right\n",
    "            agent_dir = turn_agent(agent_dir, \"right\")\n",
    "            move_sequence.append(small_arrow + agent_dir)\n",
    "        elif action == 2: # move forward\n",
    "            move_sequence.append(agent_dir)\n",
    "        elif action == 3: # pickup\n",
    "            move_sequence.append('pickup ' +  agent_dir)\n",
    "    return move_sequence, illigal_moves, total_reward, agent_actions\n",
    "\n",
    "\n",
    "def turn_agent(agent_dir, turn_dir):\n",
    "    turnning_dict = {(\"up\", \"left\"): \"left\", (\"up\", \"right\"): \"right\", \n",
    "                     (\"down\", \"left\"): \"right\", (\"down\", \"right\"): \"left\",\n",
    "                     (\"left\", \"left\"): \"down\", (\"left\", \"right\"): \"up\",\n",
    "                     (\"right\", \"left\"): \"up\", (\"right\", \"right\"): \"down\"}\n",
    "    return turnning_dict[(agent_dir, turn_dir)]\n",
    "\n",
    "def plot_move_sequence(img, move_sequence, move_color='y', turn_color='orange', pickup_color='purple'):    \n",
    "    start_point = (50, 50)\n",
    "    arrow_size = 20\n",
    "    arrow_head_size = 12\n",
    "    small_shift = 9\n",
    "    all_arrow_size = arrow_size + arrow_head_size\n",
    "    move_arrow_sizes = {'up': (0, -20, 0, -all_arrow_size), \n",
    "                        'down': (0, 20, 0, all_arrow_size), \n",
    "                        'right': (20, 0, all_arrow_size, 0), \n",
    "                        'left': (-20, 0, -all_arrow_size, 0)}\n",
    "    turn_arrow_sizes = {'turn up': (0, -5),\n",
    "                        'turn down': (0, 5),\n",
    "                        'turn right': (5, 0),\n",
    "                        'turn left': (-5, 0)}\n",
    "    pickup_direction = {'up': (0, -1),\n",
    "                         'down': (0, 1),\n",
    "                         'left': (-1, 0),\n",
    "                         'right': (1, 0)}\n",
    "    # arrows_list = ['right', 'right', 'down', 'down', 'down', 'down', 'down', 'right', 'right', 'up', 'right', 'down']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    current_point = start_point\n",
    "    for action_name in move_sequence:\n",
    "        if action_name in move_arrow_sizes.keys(): # a big arrow that represents a move\n",
    "            ax.arrow(current_point[0], current_point[1], move_arrow_sizes[action_name][0], move_arrow_sizes[action_name][1], head_width=10, head_length=10, fc=move_color, ec=move_color)\n",
    "            current_point = (current_point[0] + move_arrow_sizes[action_name][2], current_point[1] + move_arrow_sizes[action_name][3])\n",
    "        else: # a small arrow that represents a turn or a pickup\n",
    "            full_action = action_name.split(' ')\n",
    "            action = full_action[0]\n",
    "            pickup_position = pickup_direction[full_action[1]]\n",
    "            \n",
    "            if action == 'pickup':\n",
    "                ax.plot(current_point[0] + small_shift * pickup_position[0], current_point[1] + small_shift*pickup_position[1], marker='*', markersize=10, color=pickup_color)\n",
    "            else:\n",
    "                ax.arrow(current_point[0], current_point[1], turn_arrow_sizes[action_name][0], turn_arrow_sizes[action_name][1], head_width=7, head_length=6, fc=turn_color, ec=turn_color)\n",
    "            \n",
    "            \n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "colors_reward = {'red': -2, 'green': 1, 'blue': 2}\n",
    "env = CustomEnv(grid_size=8, render_mode='rgb_array', max_steps=2*10**2, agent_view_size=7, highlight=True, lava_cells=0, \n",
    "                partial_obs=False, colors_rewards=colors_reward)\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-2.0)\n",
    "model_path1 = \"LavaHate8_20241112\\iter_500000_steps\"\n",
    "model_path2 = \"LavaLaver8_20241112\\iter_500000_steps\"\n",
    "\n",
    "ppo1 = load_agent(env, \"minigrid_custom_20240907/iter_90^5_steps\")\n",
    "ppo3 = load_agent(env, \"orig_easy8_20241111\\iter_1000000_steps\")\n",
    "ppo7 = load_agent(env, \"LavaLaverRedN8_20241113\\iter_500000_steps\")\n",
    "ppo5 = load_agent(env, model_path2)\n",
    "ppo9 = load_agent(env, model_path1)\n",
    "models = {\"ppo1\": ppo1, \"ppo3\": ppo3, \"ppo5\": ppo5,  \"ppo7\": ppo7,  \"ppo9\": ppo9}\n",
    "colors_list = [\n",
    "    \"cyan\", \"magenta\", \"yellow\", \"white\",\n",
    "    \"orange\", \"purple\", \"pink\", \"brown\", \"gray\", \"olive\", \"teal\", \"navy\",\n",
    "    \"maroon\", \"lime\", \"indigo\", \"gold\"]\n",
    "colors_to_models = {\"ppo1\": \"y\", \"ppo3\": \"w\", \"ppo5\": \"gold\", \"ppo7\": \"c\", \"ppo9\": \"gray\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\master_env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ppo1, Average reward: 4.0252, Average illegal moves: 4.75\n",
      "Model: ppo3, Average reward: 6.048430000000001, Average illegal moves: 0.2\n",
      "Model: ppo5, Average reward: 5.1891400000000045, Average illegal moves: 0.74\n",
      "Model: ppo7, Average reward: 8.971045000000004, Average illegal moves: 0.18\n",
      "Model: ppo9, Average reward: 4.6684149999999995, Average illegal moves: 0.05\n"
     ]
    }
   ],
   "source": [
    "def evaluate_agent(env, agent, num_episodes=100):\n",
    "    total_reward = 0\n",
    "    total_illegal_moves = 0\n",
    "    for i in range(num_episodes):\n",
    "        env.reset()\n",
    "        move_sequence, illigal_moves, reward, agent_actions = capture_agent_path(env, agent)\n",
    "        total_reward += reward\n",
    "        total_illegal_moves += illigal_moves\n",
    "    return total_reward / num_episodes, total_illegal_moves / num_episodes\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    avg_reward, avg_illegal_moves = evaluate_agent(env, model, num_episodes=100)\n",
    "    print(f\"Model: {model_name}, Average reward: {avg_reward}, Average illegal moves: {avg_illegal_moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset state:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m plot_state(env)\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppo1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m[model_name]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# for model_name, model in models.items():\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     copy_env = copy.deepcopy(env)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     # print(\"copy_env before:\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     # print(\"orig env after:\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     # plot_state(env)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "img = env.render()\n",
    "print(\"reset state:\")\n",
    "plot_state(env)\n",
    "model_name = 'ppo1'\n",
    "model = models[model_name]\n",
    "# for model_name, model in models.items():\n",
    "#     copy_env = copy.deepcopy(env)\n",
    "#     # print(\"copy_env before:\")\n",
    "#     # plot_state(copy_env)\n",
    "#     move_sequence, illigal_moves, total_reward, agent_action = capture_agent_path(copy_env, model)\n",
    "#     # print(\"all actions: \", agent_action)\n",
    "#     print(\"ligal actions: \", move_sequence)\n",
    "#     print(f\"model: {model_name}, illigal moves: {illigal_moves}, total reward: {total_reward}\")\n",
    "\n",
    "#     plot_move_sequence(img, move_sequence, move_color=colors_to_models[model_name])\n",
    "#     # print(\"orig env after:\")\n",
    "#     # plot_state(env)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between 2 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALL_SHIFT_FACTOR = 1\n",
    "WALL_FACTOR = 10\n",
    "DOOR_FACTOR = 0.1\n",
    "BALLS_FACTOR = 3\n",
    "min_ball_distance = 3\n",
    "\n",
    "def manhattan_distance(p1, p2):\n",
    "    return np.abs(p1[0] - p2[0]) + np.abs(p1[1] - p2[1])\n",
    "    \n",
    "def balls_distance(balls):\n",
    "    ball_dist = 0\n",
    "    for i in range(len(balls)-1):\n",
    "        for j in range(i+1, len(balls)):\n",
    "            ball_dist += np.linalg.norm(np.array(balls[i][:-1]) - np.array(balls[j][:-1]))\n",
    "    return ball_dist\n",
    "\n",
    "def balls_groups(balls_list):\n",
    "    print(f\"balls_list: {balls_list}\")\n",
    "    groups = []\n",
    "    in_any_group = set()\n",
    "    for i in range(len(balls_list)):\n",
    "        if i in in_any_group:\n",
    "            continue\n",
    "        group = [balls_list[i]]\n",
    "        need_to_check = [i]\n",
    "        in_any_group.add(i)\n",
    "        while need_to_check:\n",
    "            ball_index = need_to_check.pop()\n",
    "            check_ball = balls_list[ball_index]\n",
    "            for j in range(len(balls_list)):\n",
    "                if j in in_any_group: # TODO: option to switch to a list with all the balls that are not in any group\n",
    "                    continue\n",
    "                if manhattan_distance(check_ball, balls_list[j]) <= min_ball_distance:\n",
    "                    group.append(balls_list[j])\n",
    "                    in_any_group.add(j)\n",
    "                    need_to_check.append(j)\n",
    "        groups.append(group)\n",
    "    print(f\"groups: {groups}\")\n",
    "    \n",
    "    res = []\n",
    "    for group in groups:\n",
    "        x_center = np.mean([ball[0] for ball in group])\n",
    "        y_center = np.mean([ball[1] for ball in group])\n",
    "        res.append((len(group), (x_center, y_center)))\n",
    "    print(f\"res: {res}\")\n",
    "    return res\n",
    "\n",
    "def biggest_group(balls_groups):\n",
    "    max = 0\n",
    "    max_group = None\n",
    "    for group in balls_groups:\n",
    "        if group[0] > max:\n",
    "            max = group[0]\n",
    "            max_group = group\n",
    "    return max_group\n",
    "    \n",
    "def state_distance(objects1, objects2):\n",
    "    distance = 0\n",
    "    if objects1['wall'][0] or objects2['wall'][0]: # if one of the states has a wall\n",
    "        if objects1['wall'][0] != objects2['wall'][0]:\n",
    "            distance += WALL_FACTOR\n",
    "        else:\n",
    "            distance += np.abs((objects1['wall'][2]) - (objects2['wall'][2]))*DOOR_FACTOR\n",
    "            distance += np.abs((objects1['wall'][1]) - (objects2['wall'][1]))*WALL_SHIFT_FACTOR\n",
    "    \n",
    "    ball_groups1 = balls_groups(objects1['balls'])\n",
    "    ball_groups2 = balls_groups(objects2['balls'])\n",
    "    max_group1 = biggest_group(ball_groups1)\n",
    "    max_group2 = biggest_group(ball_groups2)\n",
    "    distance += np.abs(max_group1[0] - max_group2[0])*BALLS_FACTOR # changes in the biggest group size\n",
    "    distance += np.abs(len([group for group in ball_groups1 if group[0] > 1]) - len([group for group in ball_groups2 if group[0] > 1]))# change in number of real groups(more then 1 ball)\n",
    "    # distance += np.abs(balls_distance(objects1['balls']) - balls_distance(objects2['balls']))* BALLS_FACTOR\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# !pip install ipdb\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipdb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_distance\u001b[39m(state1, state2):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Calculate the Euclidean distance between two states represented by images.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    float: The Euclidean distance between the two states.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# !pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "def calculate_distance(state1, state2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two states represented by images.\n",
    "    \n",
    "    Parameters:\n",
    "    state1 (np.ndarray): The first state image.\n",
    "    state2 (np.ndarray): The second state image.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Euclidean distance between the two states.\n",
    "    \"\"\"\n",
    "    # Flatten the images\n",
    "    flat_state1 = state1.flatten()\n",
    "    flat_state2 = state2.flatten()\n",
    "    \n",
    "    # Calculate the Euclidean distance\n",
    "    distance = np.linalg.norm(flat_state1 - flat_state2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "grid_size=10\n",
    "env = CustomEnv(grid_size=grid_size, render_mode='rgb_array', difficult_grid=False, max_steps=100, highlight=True,\n",
    "                num_objects=7, lava_cells=2, train_env=True, image_full_view=False, agent_view_size=grid_size*2-1)\n",
    "env = NoDeath(ObjObsWrapper(env), no_death_types=('lava',), death_cost=-2.0)\n",
    "state1, _ = env.reset()\n",
    "state1 = state1['image']\n",
    "plot_state(env)\n",
    "objects1 = env.grid_objects()\n",
    "state2, _ = env.reset()\n",
    "objects2 = env.grid_objects()\n",
    "# plot_state(env)\n",
    "print(f\"objects1: {objects1}\")\n",
    "# print(f\"objects2: {objects2}\")\n",
    "distance = state_distance(objects1, objects2)\n",
    "print(f\"Distance between the two states: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# enable manual control for testing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m manual_control \u001b[38;5;241m=\u001b[39m ManualControl(env, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmanual_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\minigrid\\manual_control.py:29\u001b[0m, in \u001b[0;36mManualControl.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "from minigrid_custom_env import CustomEnv\n",
    "# from base_env import SimpleEnv \n",
    "from minigrid.manual_control import ManualControl\n",
    "\n",
    "env = CustomEnv(render_mode=\"human\", difficult_grid=True, agent_pov=True)\n",
    "\n",
    "# enable manual control for testing\n",
    "manual_control = ManualControl(env, seed=42)\n",
    "manual_control.start()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 39.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016745023 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -6.56e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 56          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012996806 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 439         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 67          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813505 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 70.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017063232 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 373      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 83.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00724918 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013514 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066653113 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016817097 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 82       |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050967913 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 4.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700294 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051882556 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 4.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064221974 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 93.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040440275 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    value_loss           | 4.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027300868 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 93.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322477 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 79.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001761134 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.000244    |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006904303 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045830947 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000986033 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016759988 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000147   |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 96.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 342      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074285967 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 5.2e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 108           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089353387 |\n",
      "|    clip_fraction        | 0.0162        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 4.58e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007995691 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109256245 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074775834 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.864       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 4.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065346584 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.84        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000203    |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005958454 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035281728 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 5.38e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 95.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036199484 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072609335 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 4.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008907542 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000301   |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012195694 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 83968    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837668 |\n",
      "|    clip_fraction        | 0.00122    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.71e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 5.51e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042872117 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 4.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003127471 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757554 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 347      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806638 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469336 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000132   |\n",
      "|    value_loss           | 4.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 94          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544237 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 87.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027082602 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 937          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 3.79e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 346      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 104448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699876 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 5.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021670484 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -7.28e-05    |\n",
      "|    value_loss           | 3.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 200          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318239 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.766       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.00225      |\n",
      "|    value_loss           | 4.52e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 114           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 195           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069240853 |\n",
      "|    clip_fraction        | 0.0885        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.695        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04e+03      |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | 0.00744       |\n",
      "|    value_loss           | 5.34e+03      |\n",
      "-------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    fps             | 340      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132288 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    value_loss           | 3.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962042 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014535714 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915886 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.99     |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 111           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090316555 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.876        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+03      |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 4.56e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005358369 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000219    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027590515 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00389      |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129278 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.000136    |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 97          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009328622 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827135 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000193   |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802983 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.58e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 4.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038080818 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 4.33e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 81.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334834 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884477 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027027782 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000953     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148533825 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 4.61e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 87.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 359      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057178666 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 122          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033629797 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00051      |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007892546 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.000648    |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019677244 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03e+03    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.000685    |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 79       |\n",
      "| time/              |          |\n",
      "|    fps             | 370      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060133724 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.839       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.00149      |\n",
      "|    value_loss           | 3.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 96.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005331138 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033965213 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.841       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000696    |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012086405 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 3.68e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 85.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011505147 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 87.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186378 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 118          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025656747 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.857       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 116          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028238147 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 4.55e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 326      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007451922 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.000854   |\n",
      "|    value_loss           | 5.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165756 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013255063 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091443565 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91       |\n",
      "| time/              |          |\n",
      "|    fps             | 355      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044491906 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.83        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    value_loss           | 3.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058027483 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -6.83e-05    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048686834 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.769       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 3.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648111 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 4.26e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 83.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005274161 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815546 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070802174 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 5.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 188          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054791663 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 3.88e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 321      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 76           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011077174 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.000274     |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046208925 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015564067 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074326093 |\n",
      "|    clip_fraction        | 0.0871       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 3.81e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 98.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 227328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876669 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063385884 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264943 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016652509 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 107           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034711955 |\n",
      "|    clip_fraction        | 0.0244        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.69e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.00085       |\n",
      "|    value_loss           | 4.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016328925 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000263    |\n",
      "|    value_loss           | 4.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003549381 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.000475    |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663654 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.8e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86       |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 92            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 230           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029237106 |\n",
      "|    clip_fraction        | 0.0285        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.787        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+03      |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | 0.000375      |\n",
      "|    value_loss           | 3.43e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059726173 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.792       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    value_loss           | 3.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005957151 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.000321   |\n",
      "|    value_loss           | 4.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033260798 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 4.31e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 99       |\n",
      "| time/              |          |\n",
      "|    fps             | 354      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 258048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006194873 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 92.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021582353 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | 0.00137      |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976463 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037286112 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | 0.000389     |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 268288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017541461 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 0.000427     |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149781 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068907375 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.812       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047259 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00012    |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 100      |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006399434 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008038925 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.000327   |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015558364 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+03    |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016617142 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.856       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 4.99e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 84       |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186628 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+03     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.99       |\n",
      "|    ep_rew_mean          | 102        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01078388 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.895     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    value_loss           | 3.78e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022918442 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 8.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012425364 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 4.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from custom_env import *\n",
    "\n",
    "from custom_env import SimpleEnv \n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "TIMSTEMPS = 10000\n",
    "for i in range(1, 15):\n",
    "    model.learn(total_timesteps=TIMSTEMPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/model_{i}\")\n",
    "# model.learn(2e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{models_dir}/model_13.zip\"\n",
    "load_model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: -0.1, Done: False, Truncated: False, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = CustomEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "num_episodes = 2\n",
    "for i in range(num_episodes):\n",
    "# Reset the environment to get the initial state\n",
    "    state, info = env.reset()\n",
    "    # plot_state(env)\n",
    "    score = 0\n",
    "    # Run the simulation\n",
    "    done = False\n",
    "    plot_state(env)\n",
    "    while not done:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take the action in the environment\n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        if reward != 0:\n",
    "            print(f\"Action: {action},  Reward: {reward}, Done: {done}, Truncated: {truncated}, Info: {info}\")\n",
    "            plot_state(env)\n",
    "\n",
    "    plot_state(env)\n",
    "    print(f\"episode {i}: score: {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Player(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "from app_db import *\n",
    "from datetime import datetime\n",
    "\n",
    "with app.app_context():\n",
    "    db.create_all()\n",
    "    players = Player.query.all()\n",
    "\n",
    "    print(players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
