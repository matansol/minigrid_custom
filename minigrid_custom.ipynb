{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym_minigrid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# from IPython.display import HTML\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# from IPython import display\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# from IPython.display import clear_output\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from gym.wrappers.record_video import RecordVideo\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym_minigrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminigrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FullyObsWrapper\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym_minigrid'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# from IPython import display\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# from gym.wrappers.record_video import RecordVideo\n",
    "from gym_minigrid.wrappers import *\n",
    "\n",
    "from minigrid.wrappers import FullyObsWrapper\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from custom_env import *\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.5, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from minigrid_custom_env import *\n",
    "from minigrid_custom_train import *\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "env = CustomEnv(size = 7, render_mode='rgb_array')\n",
    "env = ObjObsWrapper(env)\n",
    "\n",
    "current_obs = env.reset()\n",
    "current_obs = current_obs[0]\n",
    "img = env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "def load_agent(env, model_path):\n",
    "    # policy_kwargs = dict(features_extractor_class=ObjEnvExtractor)\n",
    "    custom_objects = {\n",
    "        \"policy_kwargs\": {\"features_extractor_class\": ObjEnvExtractor},  # Example kernel size\n",
    "        \"clip_range\": 0.2,  # Example custom parameters\n",
    "        \"lr_schedule\": 0.001  # Example learning rate schedule\n",
    "    }\n",
    "    # Load the model\n",
    "    ppo = PPO.load(f\"models/{model_path}\", custom_objects=custom_objects, env=env)\n",
    "    return ppo\n",
    "\n",
    "def turn_agent(agent_dir, turn_dir):\n",
    "    turnning_dict = {(\"up\", \"left\"): \"left\", (\"up\", \"right\"): \"right\", \n",
    "                     (\"down\", \"left\"): \"right\", (\"down\", \"right\"): \"left\",\n",
    "                     (\"left\", \"left\"): \"down\", (\"left\", \"right\"): \"up\",\n",
    "                     (\"right\", \"left\"): \"up\", (\"right\", \"right\"): \"down\"}\n",
    "    return turnning_dict[(agent_dir, turn_dir)]\n",
    "\n",
    "def plot_move_sequence(img, move_sequence, move_color='y', turn_color='orange', pickup_color='purple'):    \n",
    "    start_point = (50, 50)\n",
    "    arrow_size = 20\n",
    "    arrow_head_size = 12\n",
    "    small_shift = 9\n",
    "    all_arrow_size = arrow_size + arrow_head_size\n",
    "    move_arrow_sizes = {'up': (0, -20, 0, -all_arrow_size), \n",
    "                        'down': (0, 20, 0, all_arrow_size), \n",
    "                        'right': (20, 0, all_arrow_size, 0), \n",
    "                        'left': (-20, 0, -all_arrow_size, 0)}\n",
    "    turn_arrow_sizes = {'turn up': (0, -5),\n",
    "                        'turn down': (0, 5),\n",
    "                        'turn right': (5, 0),\n",
    "                        'turn left': (-5, 0)}\n",
    "    # arrows_list = ['right', 'right', 'down', 'down', 'down', 'down', 'down', 'right', 'right', 'up', 'right', 'down']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    current_point = start_point\n",
    "    for arrow in move_sequence:\n",
    "        if arrow in move_arrow_sizes.keys(): # a big arrow that represents a move\n",
    "            ax.arrow(current_point[0], current_point[1], move_arrow_sizes[arrow][0], move_arrow_sizes[arrow][1], head_width=10, head_length=10, fc=move_color, ec=move_color)\n",
    "            current_point = (current_point[0] + move_arrow_sizes[arrow][2], current_point[1] + move_arrow_sizes[arrow][3])\n",
    "        else: # a small arrow that represents a turn or a pickup\n",
    "            if arrow == 'pickup':\n",
    "                # plt.text(current_point[0], current_point[1], 'P', fontsize=14, color='purple')\n",
    "                ax.plot(current_point[0] + small_shift, current_point[1] - small_shift, marker='*', markersize=10, color=pickup_color)\n",
    "            else:\n",
    "                ax.arrow(current_point[0], current_point[1], turn_arrow_sizes[arrow][0], turn_arrow_sizes[arrow][1], head_width=7, head_length=6, fc=turn_color, ec=turn_color)\n",
    "            \n",
    "            \n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "model_path = \"minigrid_custom_20240907/iter_90^5_steps\"\n",
    "ppo = load_agent(env, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resert the environment and run the agent on that environment to find his path\n",
    "current_obs = env.reset()\n",
    "current_obs = current_obs[0]\n",
    "img = env.render()\n",
    "action_record = []\n",
    "state_record = [current_obs]\n",
    "total_reward = 0    \n",
    "copy_env = copy.deepcopy(env)\n",
    "plt.imshow(env.render())\n",
    "while True:\n",
    "    action, _states = ppo.predict(current_obs)\n",
    "    obs, reward, done, _, info = copy_env.step(action)\n",
    "    total_reward += reward\n",
    "    if np.array_equal(obs['image'], current_obs['image']): # if there is no change in the state, the agent made an invalid move that didn't change the state so we skip it\n",
    "        print(\"same\")\n",
    "        continue\n",
    "    action_record.append(action)\n",
    "    current_obs = obs\n",
    "    state_record.append(obs)\n",
    "    # plt.imshow(copy_env.render())\n",
    "    # plt.show()\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "number_to_action = {0: 'turn right', 1: 'turn left', 3: 'pickup'}\n",
    "small_arrow = 'turn ' # small arrow is used to indicate the agent turning left or right\n",
    "agent_dir = \"right\"\n",
    "move_sequence = []\n",
    "for action in action_record:\n",
    "    if action == 0: # turn left\n",
    "        agent_dir = turn_agent(agent_dir, \"left\")\n",
    "        move_sequence.append(small_arrow + agent_dir)\n",
    "    elif action == 1: # turn right\n",
    "        agent_dir = turn_agent(agent_dir, \"right\")\n",
    "        move_sequence.append(small_arrow + agent_dir)\n",
    "    elif action == 2: # move forward\n",
    "        move_sequence.append(agent_dir)\n",
    "    elif action == 3: # pickup\n",
    "        move_sequence.append('pickup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(3, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(1, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n",
      "['pickup', 'turn down', 'down', 'turn right', 'pickup', 'right', 'right', 'right', 'right', 'turn down', 'down', 'down', 'down']\n",
      "total reward: 2.7942857142857154\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(action_record)\n",
    "print(move_sequence)\n",
    "print(f\"total reward: {total_reward}\")\n",
    "plot_move_sequence(img, move_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# enable manual control for testing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m manual_control \u001b[38;5;241m=\u001b[39m ManualControl(env, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmanual_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\minigrid\\manual_control.py:29\u001b[0m, in \u001b[0;36mManualControl.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "from minigrid_custom_env import CustomEnv\n",
    "# from base_env import SimpleEnv \n",
    "from minigrid.manual_control import ManualControl\n",
    "\n",
    "env = CustomEnv(render_mode=\"human\")\n",
    "\n",
    "# enable manual control for testing\n",
    "manual_control = ManualControl(env, seed=42)\n",
    "manual_control.start()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '__version__' from 'tensorflow.keras' (c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent  \u001b[38;5;66;03m# pip install keras-rl2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BoltzmannQPolicy  \u001b[38;5;66;03m# important to have gym==0.25.2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialMemory\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\agents\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent, NAFAgent, ContinuousDQNAgent\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mddpg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPGAgent\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CEMAgent\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\agents\\dqn.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lambda, Input, Layer, Dense\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EpsGreedyQPolicy, GreedyQPolicy\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\core.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m History\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     CallbackList,\n\u001b[0;32m      9\u001b[0m     TestLogger,\n\u001b[0;32m     10\u001b[0m     TrainEpisodeLogger,\n\u001b[0;32m     11\u001b[0m     TrainIntervalLogger,\n\u001b[0;32m     12\u001b[0m     Visualizer\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAgent\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class for all implemented agents.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Each agent interacts with the environment (as defined by the `Env` class) by first observing the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        processor (`Processor` instance): See [Processor](#processor) for details.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\rl\\callbacks.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m KERAS_VERSION\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback \u001b[38;5;28;01mas\u001b[39;00m KerasCallback, CallbackList \u001b[38;5;28;01mas\u001b[39;00m KerasCallbackList\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Progbar\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '__version__' from 'tensorflow.keras' (c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from rl.agents import DQNAgent  # pip install keras-rl2\n",
    "from rl.policy import BoltzmannQPolicy  # important to have gym==0.25.2\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(states)\n",
    "print(actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1, states)))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(actions, activation=\"linear\"))\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    memory=SequentialMemory(limit=50000, window_length=1),\n",
    "    policy=BoltzmannQPolicy(),\n",
    "    nb_actions=actions,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=0.01\n",
    ")\n",
    "agent.compile(Adam(lr=0.001), metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fit(env, nb_steps=100000, visualize=False, verbose=1)\n",
    "\n",
    "results = agent.test(env, nb_episodes=10, visualize=True)\n",
    "print(np.mean(results.history[\"episode_reward\"]))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 32.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 39.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016745023 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -6.56e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 56          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012996806 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 439         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 67          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813505 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 70.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017063232 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 373      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 83.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00724918 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013514 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066653113 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016817097 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 82       |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 251          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050967913 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 4.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006700294 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051882556 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 4.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064221974 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 93.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040440275 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    value_loss           | 4.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027300868 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 93.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322477 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 79.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001761134 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.000244    |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006904303 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045830947 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000986033 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016759988 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000147   |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 96.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 342      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074285967 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 5.2e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 108           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089353387 |\n",
      "|    clip_fraction        | 0.0162        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.867        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    value_loss           | 4.58e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007995691 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 114          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 193          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109256245 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074775834 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.864       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 4.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065346584 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.84        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000203    |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005958454 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 82.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035281728 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 5.38e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 95.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036199484 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072609335 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 4.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 78.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008907542 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000301   |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012195694 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 83968    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837668 |\n",
      "|    clip_fraction        | 0.00122    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.961     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.71e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 5.51e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042872117 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 4.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003127471 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757554 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 347      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806638 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469336 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000132   |\n",
      "|    value_loss           | 4.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 94          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006544237 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 87.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 196          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027082602 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.899       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 937          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 3.79e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    fps             | 346      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 104448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699876 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 5.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021670484 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -7.28e-05    |\n",
      "|    value_loss           | 3.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 104          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 200          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318239 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.766       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.00225      |\n",
      "|    value_loss           | 4.52e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 114           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 195           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069240853 |\n",
      "|    clip_fraction        | 0.0885        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.695        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.04e+03      |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | 0.00744       |\n",
      "|    value_loss           | 5.34e+03      |\n",
      "-------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    fps             | 340      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132288 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    value_loss           | 3.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962042 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014535714 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015915886 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 4.43e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.99     |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 124928   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 111           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090316555 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.876        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+03      |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 4.56e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005358369 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000219    |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027590515 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00389      |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129278 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.000136    |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    fps             | 343      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 97          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009328622 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827135 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000193   |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802983 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.58e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 4.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038080818 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 4.33e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 81.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334834 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884477 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.99         |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027027782 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000953     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148533825 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 4.61e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 87.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 359      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057178666 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 122          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033629797 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00051      |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007892546 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.000648    |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 98          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019677244 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03e+03    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.000685    |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 79       |\n",
      "| time/              |          |\n",
      "|    fps             | 370      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060133724 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.839       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.00149      |\n",
      "|    value_loss           | 3.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 96.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005331138 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 86.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033965213 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.841       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000696    |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012086405 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 3.68e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 83.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 85.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011505147 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 87.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186378 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 118          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025656747 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.857       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 116          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028238147 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 4.55e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 326      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007451922 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.000854   |\n",
      "|    value_loss           | 5.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165756 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013255063 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091443565 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 91       |\n",
      "| time/              |          |\n",
      "|    fps             | 355      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044491906 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.83        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    value_loss           | 3.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058027483 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -6.83e-05    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048686834 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.769       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 3.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648111 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 4.26e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 83.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005274161 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815546 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070802174 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 5.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 97           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 188          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054791663 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 3.88e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 85       |\n",
      "| time/              |          |\n",
      "|    fps             | 321      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 76           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011077174 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.000274     |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 110          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046208925 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015564067 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 183          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074326093 |\n",
      "|    clip_fraction        | 0.0871       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 3.81e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 98.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 345      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 227328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876669 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 102          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063385884 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264943 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 81.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016652509 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.849       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 107           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034711955 |\n",
      "|    clip_fraction        | 0.0244        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.936        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.69e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.00085       |\n",
      "|    value_loss           | 4.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016328925 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000263    |\n",
      "|    value_loss           | 4.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003549381 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.000475    |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663654 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 3.8e+03     |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 86       |\n",
      "| time/              |          |\n",
      "|    fps             | 322      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 247808   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 10            |\n",
      "|    ep_rew_mean          | 92            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 230           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029237106 |\n",
      "|    clip_fraction        | 0.0285        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.787        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+03      |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | 0.000375      |\n",
      "|    value_loss           | 3.43e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 106          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059726173 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.792       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    value_loss           | 3.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005957151 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.000321   |\n",
      "|    value_loss           | 4.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033260798 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 4.31e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 99       |\n",
      "| time/              |          |\n",
      "|    fps             | 354      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 258048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006194873 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 92.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021582353 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | 0.00137      |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976463 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 100          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 197          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037286112 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | 0.000389     |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    fps             | 352      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 268288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 90.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017541461 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 0.000427     |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149781 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068907375 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.812       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 91          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 200         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047259 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00012    |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 100      |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006399434 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 95.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008038925 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.000327   |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015558364 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+03    |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10           |\n",
      "|    ep_rew_mean          | 93           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 199          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016617142 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.856       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 4.99e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 84       |\n",
      "| time/              |          |\n",
      "|    fps             | 351      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186628 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+03     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.99       |\n",
      "|    ep_rew_mean          | 102        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01078388 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.895     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    value_loss           | 3.78e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022918442 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 8.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 192         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012425364 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 4.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import minigrid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from stable_baselines3 import PPO\n",
    "from custom_env import *\n",
    "\n",
    "from custom_env import SimpleEnv \n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = FullyObsWrapper(env)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "TIMSTEMPS = 10000\n",
    "for i in range(1, 15):\n",
    "    model.learn(total_timesteps=TIMSTEMPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/model_{i}\")\n",
    "# model.learn(2e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{models_dir}/model_13.zip\"\n",
    "load_model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('image': Box(0, 255, (7, 7, 3), uint8))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (5 x 1). Kernel size: (2 x 2). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mobservation_space)\n\u001b[1;32m---> 12\u001b[0m extractor \u001b[38;5;241m=\u001b[39m \u001b[43mMinigridFeaturesExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Use the model to predict the next action\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# obs = torch.from_numpy(obs[0]).float().unsqueeze(0)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# obs = extractor.forward(obs)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\technion\\master\\experiment\\my_project\\minigrid\\custom_env.py:132\u001b[0m, in \u001b[0;36mMinigridFeaturesExtractor.__init__\u001b[1;34m(self, observation_space, features_dim, normalized_image)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Compute shape by doing one forward pass\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 132\u001b[0m     n_flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(n_flatten, features_dim), nn\u001b[38;5;241m.\u001b[39mReLU())\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (5 x 1). Kernel size: (2 x 2). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# extractor = MinigridFeaturesExtractor(env.observation_space, features_dim=128)\n",
    "test_env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10, change_reward=True)\n",
    "test_env = ImgObsWrapper(test_env)  # Wrap the environment if needed\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "env = ObjObsWrapper(env)\n",
    "# Reset the environment to get the initial observation\n",
    "obs = env.reset()\n",
    "print(env.observation_space)\n",
    "extractor = MinigridFeaturesExtractor(env.observation_space['image'], features_dim=128)\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "# Use the model to predict the next action\n",
    "    # obs = torch.from_numpy(obs[0]).float().unsqueeze(0)\n",
    "    # obs = extractor.forward(obs)\n",
    "    obs = extractor.forward(obs)\n",
    "    print(obs.shape)\n",
    "\n",
    "    action, _states = model.predict(obs[0], deterministic=True)\n",
    "    \n",
    "    # You can then take the action in the environment to move to the next state\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "\n",
    "    # If you want to visualize the action taken, you can render the environment\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoToObject base code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train] [--load_model LOAD_MODEL]\n",
      "                             [--render]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\matan\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-12600ExN17fKT334V.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\miniconda3\\envs\\my_project\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from minigrid_gotoobj_train import *\n",
    "from custom_env import SimpleEnv\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--train\", action=\"store_true\", help=\"train the model\")\n",
    "parser.add_argument(\n",
    "    \"--load_model\",\n",
    "    default=\"minigrid_gotoobj/iter_2000000_steps.zip\",\n",
    ")\n",
    "parser.add_argument(\"--render\", action=\"store_true\", help=\"render trained models\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "policy_kwargs = dict(features_extractor_class=ObjEnvExtractor)\n",
    "\n",
    "# Create time stamp of experiment\n",
    "stamp = datetime.fromtimestamp(time()).strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if args.train:\n",
    "    env = SimpleEnv()\n",
    "    env = ObjObsWrapper(env)\n",
    "\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=1e5,\n",
    "        save_path=f\"./models/ppo/minigrid_gotoobj_{stamp}/\",\n",
    "        name_prefix=\"iter\",\n",
    "    )\n",
    "\n",
    "    model = PPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./logs/ppo/minigrid_gotoobj_tensorboard/\",\n",
    "    )\n",
    "    model.learn(\n",
    "        2e4, # epochs to train\n",
    "        tb_log_name=f\"{stamp}\",\n",
    "        callback=checkpoint_callback,\n",
    "    )\n",
    "else:\n",
    "    if args.render:\n",
    "        env = SimpleEnv(render_mode=\"human\")\n",
    "    else:\n",
    "        env = SimpleEnv()\n",
    "    env = ObjObsWrapper(env)\n",
    "\n",
    "    ppo = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "    # add the experiment time stamp\n",
    "    ppo = ppo.load(f\"models/ppo/{args.load_model}\", env=env)\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    rewards = 0\n",
    "\n",
    "    for i in range(2000):\n",
    "        action, _state = ppo.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            print(f\"Test reward: {rewards}\")\n",
    "            obs, info = env.reset()\n",
    "            rewards = 0\n",
    "            continue\n",
    "\n",
    "    print(f\"Test reward: {rewards}\")\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 2, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 1.5, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2,  Reward: -110.69, Done: True, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0: score: -107.19\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3,  Reward: 1, Done: False, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2,  Reward: -31.580000000000005, Done: True, Truncated: True, Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1: score: -30.580000000000005\n"
     ]
    }
   ],
   "source": [
    "def plot_state(env):\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "env = SimpleEnv(render_mode=\"rgb_array\", max_steps=10)\n",
    "num_episodes = 2\n",
    "for i in range(num_episodes):\n",
    "# Reset the environment to get the initial state\n",
    "    state, info = env.reset()\n",
    "    # plot_state(env)\n",
    "    score = 0\n",
    "    # Run the simulation\n",
    "    done = False\n",
    "    plot_state(env)\n",
    "    while not done:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take the action in the environment\n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        if reward != 0:\n",
    "            print(f\"Action: {action},  Reward: {reward}, Done: {done}, Truncated: {truncated}, Info: {info}\")\n",
    "            plot_state(env)\n",
    "            \n",
    "    plot_state(env)\n",
    "    print(f\"episode {i}: score: {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Player(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "from app_db import *\n",
    "from datetime import datetime\n",
    "\n",
    "with app.app_context():\n",
    "    db.create_all()\n",
    "    players = Player.query.all()\n",
    "\n",
    "    print(players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
