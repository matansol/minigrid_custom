Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Loaded model from models\orig_easy8_20241111\iter_1000000_steps. Continuing training.
Logging to ./logs/ppo/minigrid_custom_tensorboard/20241225_1
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000002CEAD79C2E0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000002CEA7214D30>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.5     |
|    ep_rew_mean     | 9.64     |
| time/              |          |
|    fps             | 242      |
|    iterations      | 1        |
|    time_elapsed    | 8        |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.2       |
|    ep_rew_mean          | 9.71       |
| time/                   |            |
|    fps                  | 250        |
|    iterations           | 2          |
|    time_elapsed         | 16         |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.09053302 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.215     |
|    explained_variance   | 0.355      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.338      |
|    n_updates            | 9770       |
|    policy_gradient_loss | 0.00106    |
|    value_loss           | 1.16       |
----------------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.3        |
|    ep_rew_mean          | 9.74        |
| time/                   |             |
|    fps                  | 249         |
|    iterations           | 3           |
|    time_elapsed         | 24          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.041454755 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.242      |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.248       |
|    n_updates            | 9780        |
|    policy_gradient_loss | -0.00488    |
|    value_loss           | 0.948       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.4        |
|    ep_rew_mean          | 9.64        |
| time/                   |             |
|    fps                  | 253         |
|    iterations           | 4           |
|    time_elapsed         | 32          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.079253905 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.259      |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 9790        |
|    policy_gradient_loss | -0.0144     |
|    value_loss           | 0.931       |
-----------------------------------------
reached max steps=250
reached max steps=250
reached max steps=250
Eval num_timesteps=10000, episode_reward=7.11 +/- 6.96
Episode length: 39.80 +/- 42.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.8       |
|    mean_reward          | 7.11       |
| time/                   |            |
|    total_timesteps      | 10000      |
| train/                  |            |
|    approx_kl            | 0.06970445 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.207     |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.179      |
|    n_updates            | 9800       |
|    policy_gradient_loss | -0.0155    |
|    value_loss           | 0.531      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.6     |
|    ep_rew_mean     | 9.59     |
| time/              |          |
|    fps             | 232      |
|    iterations      | 5        |
|    time_elapsed    | 44       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.6        |
|    ep_rew_mean          | 10.2        |
| time/                   |             |
|    fps                  | 232         |
|    iterations           | 6           |
|    time_elapsed         | 52          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.079564884 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.236      |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.333       |
|    n_updates            | 9810        |
|    policy_gradient_loss | -0.0471     |
|    value_loss           | 0.593       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 221         |
|    iterations           | 7           |
|    time_elapsed         | 64          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.117688015 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.163      |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.18        |
|    n_updates            | 9820        |
|    policy_gradient_loss | -0.0239     |
|    value_loss           | 0.457       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 9.99       |
| time/                   |            |
|    fps                  | 220        |
|    iterations           | 8          |
|    time_elapsed         | 74         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.07815558 |
|    clip_fraction        | 0.127      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.157     |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.113      |
|    n_updates            | 9830       |
|    policy_gradient_loss | -0.0186    |
|    value_loss           | 0.455      |
----------------------------------------
reached max steps=250
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.1      |
|    ep_rew_mean          | 9.74      |
| time/                   |           |
|    fps                  | 223       |
|    iterations           | 9         |
|    time_elapsed         | 82        |
|    total_timesteps      | 18432     |
| train/                  |           |
|    approx_kl            | 0.0624213 |
|    clip_fraction        | 0.157     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.207    |
|    explained_variance   | 0.647     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.226     |
|    n_updates            | 9840      |
|    policy_gradient_loss | -0.0241   |
|    value_loss           | 0.633     |
---------------------------------------
Eval num_timesteps=20000, episode_reward=10.66 +/- 1.30
Episode length: 20.00 +/- 3.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 10.7       |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.34987324 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.178     |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.385      |
|    n_updates            | 9850       |
|    policy_gradient_loss | -0.0187    |
|    value_loss           | 0.717      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22       |
|    ep_rew_mean     | 9.96     |
| time/              |          |
|    fps             | 224      |
|    iterations      | 10       |
|    time_elapsed    | 91       |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.3        |
|    ep_rew_mean          | 9.64        |
| time/                   |             |
|    fps                  | 218         |
|    iterations           | 11          |
|    time_elapsed         | 103         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.061390594 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.163       |
|    n_updates            | 9860        |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.457       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 9.99       |
| time/                   |            |
|    fps                  | 207        |
|    iterations           | 12         |
|    time_elapsed         | 118        |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.06939273 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.181     |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 9870       |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.705      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.1        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 209         |
|    iterations           | 13          |
|    time_elapsed         | 126         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.042752508 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.192      |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.22        |
|    n_updates            | 9880        |
|    policy_gradient_loss | -0.0311     |
|    value_loss           | 0.687       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 204         |
|    iterations           | 14          |
|    time_elapsed         | 140         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.053203497 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.144      |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 9890        |
|    policy_gradient_loss | -0.0174     |
|    value_loss           | 0.492       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=30000, episode_reward=6.02 +/- 9.29
Episode length: 38.80 +/- 43.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 38.8       |
|    mean_reward          | 6.02       |
| time/                   |            |
|    total_timesteps      | 30000      |
| train/                  |            |
|    approx_kl            | 0.04416379 |
|    clip_fraction        | 0.0978     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.127     |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.107      |
|    n_updates            | 9900       |
|    policy_gradient_loss | -0.014     |
|    value_loss           | 0.373      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 10.3     |
| time/              |          |
|    fps             | 205      |
|    iterations      | 15       |
|    time_elapsed    | 149      |
|    total_timesteps | 30720    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 203        |
|    iterations           | 16         |
|    time_elapsed         | 160        |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.13198802 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.168      |
|    n_updates            | 9910       |
|    policy_gradient_loss | -0.0147    |
|    value_loss           | 0.393      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 206        |
|    iterations           | 17         |
|    time_elapsed         | 168        |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.05152026 |
|    clip_fraction        | 0.0973     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.123     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.077      |
|    n_updates            | 9920       |
|    policy_gradient_loss | -0.0155    |
|    value_loss           | 0.305      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 207        |
|    iterations           | 18         |
|    time_elapsed         | 177        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.14979693 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.166     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0935     |
|    n_updates            | 9930       |
|    policy_gradient_loss | -0.0206    |
|    value_loss           | 0.395      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 209         |
|    iterations           | 19          |
|    time_elapsed         | 185         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.051541593 |
|    clip_fraction        | 0.0916      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.812       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 9940        |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 0.356       |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=10.51 +/- 1.21
Episode length: 17.60 +/- 3.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 17.6       |
|    mean_reward          | 10.5       |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.07869192 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.127      |
|    n_updates            | 9950       |
|    policy_gradient_loss | -0.0191    |
|    value_loss           | 0.394      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.3     |
|    ep_rew_mean     | 10.3     |
| time/              |          |
|    fps             | 211      |
|    iterations      | 20       |
|    time_elapsed    | 193      |
|    total_timesteps | 40960    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 10.3       |
| time/                   |            |
|    fps                  | 214        |
|    iterations           | 21         |
|    time_elapsed         | 200        |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.06884112 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.169     |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.141      |
|    n_updates            | 9960       |
|    policy_gradient_loss | -0.016     |
|    value_loss           | 0.535      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 217        |
|    iterations           | 22         |
|    time_elapsed         | 207        |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.03622592 |
|    clip_fraction        | 0.106      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.157     |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0765     |
|    n_updates            | 9970       |
|    policy_gradient_loss | -0.0164    |
|    value_loss           | 0.394      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 219         |
|    iterations           | 23          |
|    time_elapsed         | 214         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.041924115 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 9980        |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.399       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 10.3       |
| time/                   |            |
|    fps                  | 219        |
|    iterations           | 24         |
|    time_elapsed         | 223        |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.03619971 |
|    clip_fraction        | 0.0876     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0644     |
|    n_updates            | 9990       |
|    policy_gradient_loss | -0.0134    |
|    value_loss           | 0.3        |
----------------------------------------
reached max steps=250
Eval num_timesteps=50000, episode_reward=10.91 +/- 0.97
Episode length: 21.40 +/- 2.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 10.9       |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.12300612 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.159     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.037      |
|    n_updates            | 10000      |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.414      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 10.3     |
| time/              |          |
|    fps             | 220      |
|    iterations      | 25       |
|    time_elapsed    | 232      |
|    total_timesteps | 51200    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 221        |
|    iterations           | 26         |
|    time_elapsed         | 240        |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.04102846 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.177     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.185      |
|    n_updates            | 10010      |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.396      |
----------------------------------------
reached max steps=250
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 10.2       |
| time/                   |            |
|    fps                  | 222        |
|    iterations           | 27         |
|    time_elapsed         | 248        |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.07143514 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.124     |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 10020      |
|    policy_gradient_loss | -0.014     |
|    value_loss           | 0.317      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 222        |
|    iterations           | 28         |
|    time_elapsed         | 257        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.15650985 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.241     |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0394     |
|    n_updates            | 10030      |
|    policy_gradient_loss | -0.0544    |
|    value_loss           | 0.53       |
----------------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.7        |
|    ep_rew_mean          | 10.2        |
| time/                   |             |
|    fps                  | 224         |
|    iterations           | 29          |
|    time_elapsed         | 264         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.060356416 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.054       |
|    n_updates            | 10040       |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.326       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=10.74 +/- 0.99
Episode length: 19.20 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.2       |
|    mean_reward          | 10.7       |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.08203926 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.202     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0844     |
|    n_updates            | 10050      |
|    policy_gradient_loss | -0.0427    |
|    value_loss           | 0.498      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 225      |
|    iterations      | 30       |
|    time_elapsed    | 272      |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 226         |
|    iterations           | 31          |
|    time_elapsed         | 280         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.041398402 |
|    clip_fraction        | 0.0958      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 10060       |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.317       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 228        |
|    iterations           | 32         |
|    time_elapsed         | 286        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.12136063 |
|    clip_fraction        | 0.0979     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.119     |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.226      |
|    n_updates            | 10070      |
|    policy_gradient_loss | -0.0217    |
|    value_loss           | 0.364      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 229        |
|    iterations           | 33         |
|    time_elapsed         | 294        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.11877615 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0897    |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0864     |
|    n_updates            | 10080      |
|    policy_gradient_loss | -0.0396    |
|    value_loss           | 0.437      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 230         |
|    iterations           | 34          |
|    time_elapsed         | 302         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.047451593 |
|    clip_fraction        | 0.084       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 10090       |
|    policy_gradient_loss | -0.00823    |
|    value_loss           | 0.345       |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=11.07 +/- 1.17
Episode length: 23.60 +/- 4.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.6        |
|    mean_reward          | 11.1        |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.043252178 |
|    clip_fraction        | 0.0811      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0877      |
|    n_updates            | 10100       |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.31        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 230      |
|    iterations      | 35       |
|    time_elapsed    | 310      |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 230        |
|    iterations           | 36         |
|    time_elapsed         | 319        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.04970173 |
|    clip_fraction        | 0.0908     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.105     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0926     |
|    n_updates            | 10110      |
|    policy_gradient_loss | -0.0152    |
|    value_loss           | 0.393      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 232         |
|    iterations           | 37          |
|    time_elapsed         | 326         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.045235977 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.139       |
|    n_updates            | 10120       |
|    policy_gradient_loss | -0.0109     |
|    value_loss           | 0.421       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 233        |
|    iterations           | 38         |
|    time_elapsed         | 332        |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.09265836 |
|    clip_fraction        | 0.109      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0893     |
|    n_updates            | 10130      |
|    policy_gradient_loss | -0.00988   |
|    value_loss           | 0.377      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21        |
|    ep_rew_mean          | 10.6      |
| time/                   |           |
|    fps                  | 234       |
|    iterations           | 39        |
|    time_elapsed         | 340       |
|    total_timesteps      | 79872     |
| train/                  |           |
|    approx_kl            | 0.0412506 |
|    clip_fraction        | 0.0766    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0925   |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0629    |
|    n_updates            | 10140     |
|    policy_gradient_loss | -0.0135   |
|    value_loss           | 0.268     |
---------------------------------------
Eval num_timesteps=80000, episode_reward=11.58 +/- 0.37
Episode length: 22.60 +/- 3.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 22.6        |
|    mean_reward          | 11.6        |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.046417832 |
|    clip_fraction        | 0.0864      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0953     |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0787      |
|    n_updates            | 10150       |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.266       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.7     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 235      |
|    iterations      | 40       |
|    time_elapsed    | 347      |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 236         |
|    iterations           | 41          |
|    time_elapsed         | 354         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.040629614 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 10160       |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.399       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 237        |
|    iterations           | 42         |
|    time_elapsed         | 362        |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.06791896 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.121     |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.11       |
|    n_updates            | 10170      |
|    policy_gradient_loss | -0.0179    |
|    value_loss           | 0.266      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 238         |
|    iterations           | 43          |
|    time_elapsed         | 368         |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.050037906 |
|    clip_fraction        | 0.0865      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0667      |
|    n_updates            | 10180       |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.309       |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=10.57 +/- 1.48
Episode length: 20.80 +/- 2.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.8        |
|    mean_reward          | 10.6        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.048336588 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 10190       |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.291       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.8     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 239      |
|    iterations      | 44       |
|    time_elapsed    | 375      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 240         |
|    iterations           | 45          |
|    time_elapsed         | 382         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.047399502 |
|    clip_fraction        | 0.0928      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0631      |
|    n_updates            | 10200       |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 0.337       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 242        |
|    iterations           | 46         |
|    time_elapsed         | 388        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.13320734 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.113     |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0715     |
|    n_updates            | 10210      |
|    policy_gradient_loss | 0.165      |
|    value_loss           | 0.437      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 10.5      |
| time/                   |           |
|    fps                  | 243       |
|    iterations           | 47        |
|    time_elapsed         | 394       |
|    total_timesteps      | 96256     |
| train/                  |           |
|    approx_kl            | 0.0634488 |
|    clip_fraction        | 0.0813    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.101    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0634    |
|    n_updates            | 10220     |
|    policy_gradient_loss | -0.0132   |
|    value_loss           | 0.211     |
---------------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 9.98        |
| time/                   |             |
|    fps                  | 245         |
|    iterations           | 48          |
|    time_elapsed         | 401         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.032346394 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0678      |
|    n_updates            | 10230       |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.27        |
-----------------------------------------
reached max steps=250
Eval num_timesteps=100000, episode_reward=6.50 +/- 8.52
Episode length: 41.80 +/- 41.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.8        |
|    mean_reward          | 6.5         |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.079104125 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.17       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.249       |
|    n_updates            | 10240       |
|    policy_gradient_loss | -0.0197     |
|    value_loss           | 0.547       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 246      |
|    iterations      | 49       |
|    time_elapsed    | 407      |
|    total_timesteps | 100352   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 20.8     |
|    ep_rew_mean          | 10.7     |
| time/                   |          |
|    fps                  | 247      |
|    iterations           | 50       |
|    time_elapsed         | 413      |
|    total_timesteps      | 102400   |
| train/                  |          |
|    approx_kl            | 0.046717 |
|    clip_fraction        | 0.0816   |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0974  |
|    explained_variance   | 0.865    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.123    |
|    n_updates            | 10250    |
|    policy_gradient_loss | -0.0105  |
|    value_loss           | 0.248    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 248        |
|    iterations           | 51         |
|    time_elapsed         | 420        |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.05149333 |
|    clip_fraction        | 0.0874     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0961    |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0667     |
|    n_updates            | 10260      |
|    policy_gradient_loss | -0.0114    |
|    value_loss           | 0.259      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 249        |
|    iterations           | 52         |
|    time_elapsed         | 426        |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.08077225 |
|    clip_fraction        | 0.0858     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0803     |
|    n_updates            | 10270      |
|    policy_gradient_loss | -0.0132    |
|    value_loss           | 0.221      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 250        |
|    iterations           | 53         |
|    time_elapsed         | 433        |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.04719753 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0457     |
|    n_updates            | 10280      |
|    policy_gradient_loss | -0.016     |
|    value_loss           | 0.203      |
----------------------------------------
Eval num_timesteps=110000, episode_reward=10.97 +/- 0.71
Episode length: 20.80 +/- 4.07
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 20.8      |
|    mean_reward          | 11        |
| time/                   |           |
|    total_timesteps      | 110000    |
| train/                  |           |
|    approx_kl            | 0.0498247 |
|    clip_fraction        | 0.102     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.13     |
|    explained_variance   | 0.868     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.109     |
|    n_updates            | 10290     |
|    policy_gradient_loss | -0.0156   |
|    value_loss           | 0.281     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 251      |
|    iterations      | 54       |
|    time_elapsed    | 439      |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 252         |
|    iterations           | 55          |
|    time_elapsed         | 445         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.046164203 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.163       |
|    n_updates            | 10300       |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.486       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 253        |
|    iterations           | 56         |
|    time_elapsed         | 452        |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.10978736 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.142     |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 10310      |
|    policy_gradient_loss | -0.0392    |
|    value_loss           | 0.398      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 254         |
|    iterations           | 57          |
|    time_elapsed         | 458         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.045792505 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.114       |
|    n_updates            | 10320       |
|    policy_gradient_loss | -0.00905    |
|    value_loss           | 0.29        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.2      |
|    ep_rew_mean          | 10.6      |
| time/                   |           |
|    fps                  | 255       |
|    iterations           | 58        |
|    time_elapsed         | 465       |
|    total_timesteps      | 118784    |
| train/                  |           |
|    approx_kl            | 0.0368243 |
|    clip_fraction        | 0.0879    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.11     |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.12      |
|    n_updates            | 10330     |
|    policy_gradient_loss | -0.0128   |
|    value_loss           | 0.285     |
---------------------------------------
Eval num_timesteps=120000, episode_reward=10.76 +/- 1.35
Episode length: 19.00 +/- 3.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19          |
|    mean_reward          | 10.8        |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.028626218 |
|    clip_fraction        | 0.0841      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.111       |
|    n_updates            | 10340       |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 256      |
|    iterations      | 59       |
|    time_elapsed    | 471      |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 257         |
|    iterations           | 60          |
|    time_elapsed         | 478         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.032800026 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0965     |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0487      |
|    n_updates            | 10350       |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.315       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 258         |
|    iterations           | 61          |
|    time_elapsed         | 484         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.075135134 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0254      |
|    n_updates            | 10360       |
|    policy_gradient_loss | -0.0384     |
|    value_loss           | 0.461       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 258        |
|    iterations           | 62         |
|    time_elapsed         | 490        |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.05050899 |
|    clip_fraction        | 0.13       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.12      |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.159      |
|    n_updates            | 10370      |
|    policy_gradient_loss | -0.0402    |
|    value_loss           | 0.446      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 63          |
|    time_elapsed         | 496         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.056298748 |
|    clip_fraction        | 0.0845      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0893     |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0591      |
|    n_updates            | 10380       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.277       |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=10.63 +/- 0.63
Episode length: 20.20 +/- 3.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 10.6        |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.053500768 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0925      |
|    n_updates            | 10390       |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.329       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 260      |
|    iterations      | 64       |
|    time_elapsed    | 502      |
|    total_timesteps | 131072   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 261        |
|    iterations           | 65         |
|    time_elapsed         | 509        |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.13702169 |
|    clip_fraction        | 0.0743     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0811    |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.104      |
|    n_updates            | 10400      |
|    policy_gradient_loss | -0.0106    |
|    value_loss           | 0.297      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 262         |
|    iterations           | 66          |
|    time_elapsed         | 515         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.046494782 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0904     |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0464      |
|    n_updates            | 10410       |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.271       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 262        |
|    iterations           | 67         |
|    time_elapsed         | 522        |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.10007556 |
|    clip_fraction        | 0.0976     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.101     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0889     |
|    n_updates            | 10420      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.375      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 263         |
|    iterations           | 68          |
|    time_elapsed         | 528         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.075225525 |
|    clip_fraction        | 0.0964      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0745     |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0614      |
|    n_updates            | 10430       |
|    policy_gradient_loss | 0.0586      |
|    value_loss           | 0.25        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=11.88 +/- 0.27
Episode length: 19.80 +/- 2.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 11.9        |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.054220155 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.106       |
|    n_updates            | 10440       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.327       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 263      |
|    iterations      | 69       |
|    time_elapsed    | 535      |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 264         |
|    iterations           | 70          |
|    time_elapsed         | 541         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.044357292 |
|    clip_fraction        | 0.0787      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0837     |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.135       |
|    n_updates            | 10450       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.308       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 265        |
|    iterations           | 71         |
|    time_elapsed         | 547        |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.06787002 |
|    clip_fraction        | 0.085      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.091     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.116      |
|    n_updates            | 10460      |
|    policy_gradient_loss | -0.0136    |
|    value_loss           | 0.323      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 266         |
|    iterations           | 72          |
|    time_elapsed         | 554         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.027982134 |
|    clip_fraction        | 0.0779      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0901     |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 10470       |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.295       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 266         |
|    iterations           | 73          |
|    time_elapsed         | 560         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.039001625 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.118       |
|    n_updates            | 10480       |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.287       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=150000, episode_reward=7.72 +/- 6.23
Episode length: 41.60 +/- 41.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.6        |
|    mean_reward          | 7.72        |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.056248307 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.144      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0786      |
|    n_updates            | 10490       |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.346       |
-----------------------------------------
reached max steps=250
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 267      |
|    iterations      | 74       |
|    time_elapsed    | 567      |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 267         |
|    iterations           | 75          |
|    time_elapsed         | 573         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.106952205 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.142      |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.132       |
|    n_updates            | 10500       |
|    policy_gradient_loss | 0.00273     |
|    value_loss           | 0.386       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 268        |
|    iterations           | 76         |
|    time_elapsed         | 580        |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.21549594 |
|    clip_fraction        | 0.0763     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.139      |
|    n_updates            | 10510      |
|    policy_gradient_loss | -0.00895   |
|    value_loss           | 0.336      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 268        |
|    iterations           | 77         |
|    time_elapsed         | 586        |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.04159662 |
|    clip_fraction        | 0.0975     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.129     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0865     |
|    n_updates            | 10520      |
|    policy_gradient_loss | -0.00968   |
|    value_loss           | 0.354      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 269        |
|    iterations           | 78         |
|    time_elapsed         | 592        |
|    total_timesteps      | 159744     |
| train/                  |            |
|    approx_kl            | 0.09537189 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.129     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0521     |
|    n_updates            | 10530      |
|    policy_gradient_loss | -0.0191    |
|    value_loss           | 0.288      |
----------------------------------------
Eval num_timesteps=160000, episode_reward=11.10 +/- 0.78
Episode length: 19.60 +/- 2.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 11.1       |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.16365513 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0911    |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.103      |
|    n_updates            | 10540      |
|    policy_gradient_loss | -0.0228    |
|    value_loss           | 0.237      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 269      |
|    iterations      | 79       |
|    time_elapsed    | 599      |
|    total_timesteps | 161792   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 270        |
|    iterations           | 80         |
|    time_elapsed         | 605        |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.04369041 |
|    clip_fraction        | 0.0728     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0747    |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.111      |
|    n_updates            | 10550      |
|    policy_gradient_loss | -0.0124    |
|    value_loss           | 0.29       |
----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 270        |
|    iterations           | 81         |
|    time_elapsed         | 612        |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.07965769 |
|    clip_fraction        | 0.0804     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0779    |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0451     |
|    n_updates            | 10560      |
|    policy_gradient_loss | -0.0133    |
|    value_loss           | 0.3        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 271         |
|    iterations           | 82          |
|    time_elapsed         | 618         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.038708486 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 10570       |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.378       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 272         |
|    iterations           | 83          |
|    time_elapsed         | 624         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.036105216 |
|    clip_fraction        | 0.0838      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0612      |
|    n_updates            | 10580       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.364       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=10.83 +/- 1.39
Episode length: 18.40 +/- 3.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.4       |
|    mean_reward          | 10.8       |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.11987345 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.124     |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.194      |
|    n_updates            | 10590      |
|    policy_gradient_loss | -0.0209    |
|    value_loss           | 0.38       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 272      |
|    iterations      | 84       |
|    time_elapsed    | 631      |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 272         |
|    iterations           | 85          |
|    time_elapsed         | 637         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.036214657 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0931     |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0833      |
|    n_updates            | 10600       |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 0.346       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.9        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 273         |
|    iterations           | 86          |
|    time_elapsed         | 644         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.080992766 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.208       |
|    n_updates            | 10610       |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.371       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 273        |
|    iterations           | 87         |
|    time_elapsed         | 650        |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.08219233 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.165      |
|    n_updates            | 10620      |
|    policy_gradient_loss | -0.0155    |
|    value_loss           | 0.456      |
----------------------------------------
Eval num_timesteps=180000, episode_reward=10.32 +/- 1.37
Episode length: 19.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.4        |
|    mean_reward          | 10.3        |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.060657404 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.125      |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 10630       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.314       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    fps             | 274      |
|    iterations      | 88       |
|    time_elapsed    | 657      |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 274         |
|    iterations           | 89          |
|    time_elapsed         | 663         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.065216504 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.123       |
|    n_updates            | 10640       |
|    policy_gradient_loss | -0.0186     |
|    value_loss           | 0.433       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 274         |
|    iterations           | 90          |
|    time_elapsed         | 670         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.054441765 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.128      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.136       |
|    n_updates            | 10650       |
|    policy_gradient_loss | -0.0171     |
|    value_loss           | 0.339       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 275         |
|    iterations           | 91          |
|    time_elapsed         | 676         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.052369874 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 10660       |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.285       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 10.3       |
| time/                   |            |
|    fps                  | 275        |
|    iterations           | 92         |
|    time_elapsed         | 683        |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.04478284 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.152     |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0501     |
|    n_updates            | 10670      |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.378      |
----------------------------------------
reached max steps=250
Eval num_timesteps=190000, episode_reward=6.67 +/- 9.61
Episode length: 40.20 +/- 42.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.2       |
|    mean_reward          | 6.67       |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.24705333 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0376     |
|    n_updates            | 10680      |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.306      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 275      |
|    iterations      | 93       |
|    time_elapsed    | 690      |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 94          |
|    time_elapsed         | 696         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.038678642 |
|    clip_fraction        | 0.0942      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.092       |
|    n_updates            | 10690       |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.361       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 95          |
|    time_elapsed         | 703         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.042123497 |
|    clip_fraction        | 0.096       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0839      |
|    n_updates            | 10700       |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.315       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 96          |
|    time_elapsed         | 709         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.062052675 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.139      |
|    explained_variance   | 0.513       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 10710       |
|    policy_gradient_loss | -0.0355     |
|    value_loss           | 0.4         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 277        |
|    iterations           | 97         |
|    time_elapsed         | 715        |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.04212118 |
|    clip_fraction        | 0.0851     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.105     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0887     |
|    n_updates            | 10720      |
|    policy_gradient_loss | -0.0134    |
|    value_loss           | 0.274      |
----------------------------------------
reached max steps=250
Eval num_timesteps=200000, episode_reward=10.83 +/- 1.02
Episode length: 18.40 +/- 1.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.4        |
|    mean_reward          | 10.8        |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.044092216 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.222       |
|    n_updates            | 10730       |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.298       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.2     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 277      |
|    iterations      | 98       |
|    time_elapsed    | 722      |
|    total_timesteps | 200704   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.5      |
|    ep_rew_mean          | 10.8      |
| time/                   |           |
|    fps                  | 278       |
|    iterations           | 99        |
|    time_elapsed         | 728       |
|    total_timesteps      | 202752    |
| train/                  |           |
|    approx_kl            | 0.3652396 |
|    clip_fraction        | 0.129     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0953   |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.105     |
|    n_updates            | 10740     |
|    policy_gradient_loss | -0.0364   |
|    value_loss           | 0.389     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 100        |
|    time_elapsed         | 735        |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.04991653 |
|    clip_fraction        | 0.0737     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.084     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0246     |
|    n_updates            | 10750      |
|    policy_gradient_loss | -0.0109    |
|    value_loss           | 0.242      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 101        |
|    time_elapsed         | 741        |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.05084742 |
|    clip_fraction        | 0.0857     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0981    |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.121      |
|    n_updates            | 10760      |
|    policy_gradient_loss | -0.0126    |
|    value_loss           | 0.223      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 102         |
|    time_elapsed         | 748         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.056222606 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0603      |
|    n_updates            | 10770       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.312       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=10.46 +/- 1.10
Episode length: 21.80 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.8        |
|    mean_reward          | 10.5        |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.049917944 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.133      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0587      |
|    n_updates            | 10780       |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.348       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.3     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 103      |
|    time_elapsed    | 754      |
|    total_timesteps | 210944   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 104         |
|    time_elapsed         | 761         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.051016245 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.202       |
|    n_updates            | 10790       |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.399       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 105        |
|    time_elapsed         | 767        |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.13690217 |
|    clip_fraction        | 0.156      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00861    |
|    n_updates            | 10800      |
|    policy_gradient_loss | -0.0108    |
|    value_loss           | 0.395      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 106         |
|    time_elapsed         | 773         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.034952685 |
|    clip_fraction        | 0.0865      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.118      |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0484      |
|    n_updates            | 10810       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.284       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 107         |
|    time_elapsed         | 779         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.048798043 |
|    clip_fraction        | 0.089       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.118      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.13        |
|    n_updates            | 10820       |
|    policy_gradient_loss | -0.00681    |
|    value_loss           | 0.271       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=220000, episode_reward=6.38 +/- 9.48
Episode length: 39.20 +/- 42.90
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 39.2      |
|    mean_reward          | 6.38      |
| time/                   |           |
|    total_timesteps      | 220000    |
| train/                  |           |
|    approx_kl            | 0.0450591 |
|    clip_fraction        | 0.0997    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.128    |
|    explained_variance   | 0.882     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0786    |
|    n_updates            | 10830     |
|    policy_gradient_loss | -0.0207   |
|    value_loss           | 0.271     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 108      |
|    time_elapsed    | 786      |
|    total_timesteps | 221184   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 109         |
|    time_elapsed         | 792         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.038689934 |
|    clip_fraction        | 0.0972      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.125      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0882      |
|    n_updates            | 10840       |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.283       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 110         |
|    time_elapsed         | 798         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.056768723 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0532      |
|    n_updates            | 10850       |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.388       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 111         |
|    time_elapsed         | 804         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.053636618 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.189       |
|    n_updates            | 10860       |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.28        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 112        |
|    time_elapsed         | 811        |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.04159701 |
|    clip_fraction        | 0.0889     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0997    |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0939     |
|    n_updates            | 10870      |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=250
Eval num_timesteps=230000, episode_reward=8.16 +/- 6.37
Episode length: 41.20 +/- 42.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.2        |
|    mean_reward          | 8.16        |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.029664353 |
|    clip_fraction        | 0.0749      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.105       |
|    n_updates            | 10880       |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.269       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.7     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 282      |
|    iterations      | 113      |
|    time_elapsed    | 817      |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 114        |
|    time_elapsed         | 824        |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.03763403 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.121     |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0961     |
|    n_updates            | 10890      |
|    policy_gradient_loss | -0.0231    |
|    value_loss           | 0.359      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 115        |
|    time_elapsed         | 830        |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.04884247 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.826      |
|    n_updates            | 10900      |
|    policy_gradient_loss | 0.02       |
|    value_loss           | 0.38       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 116         |
|    time_elapsed         | 836         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.044875722 |
|    clip_fraction        | 0.0765      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0928     |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0816      |
|    n_updates            | 10910       |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.259       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 284        |
|    iterations           | 117        |
|    time_elapsed         | 842        |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.03861347 |
|    clip_fraction        | 0.0819     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.1       |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0961     |
|    n_updates            | 10920      |
|    policy_gradient_loss | -0.0124    |
|    value_loss           | 0.24       |
----------------------------------------
reached max steps=250
Eval num_timesteps=240000, episode_reward=7.05 +/- 8.80
Episode length: 40.40 +/- 42.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 40.4        |
|    mean_reward          | 7.05        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.059939247 |
|    clip_fraction        | 0.0863      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.108      |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0617      |
|    n_updates            | 10930       |
|    policy_gradient_loss | -0.0144     |
|    value_loss           | 0.254       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 284      |
|    iterations      | 118      |
|    time_elapsed    | 849      |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 119         |
|    time_elapsed         | 855         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.046165384 |
|    clip_fraction        | 0.0956      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 10940       |
|    policy_gradient_loss | -0.0183     |
|    value_loss           | 0.359       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 120         |
|    time_elapsed         | 862         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.035646528 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.149      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0825      |
|    n_updates            | 10950       |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 0.354       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 121         |
|    time_elapsed         | 868         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.033409365 |
|    clip_fraction        | 0.0839      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0362      |
|    n_updates            | 10960       |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.312       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 122         |
|    time_elapsed         | 874         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.039771684 |
|    clip_fraction        | 0.0822      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0851      |
|    n_updates            | 10970       |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.235       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=11.03 +/- 0.77
Episode length: 20.20 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 11          |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.040827602 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 10980       |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.284       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 123      |
|    time_elapsed    | 881      |
|    total_timesteps | 251904   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.4      |
|    ep_rew_mean          | 10.5      |
| time/                   |           |
|    fps                  | 286       |
|    iterations           | 124       |
|    time_elapsed         | 887       |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.1079099 |
|    clip_fraction        | 0.128     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.146    |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0697    |
|    n_updates            | 10990     |
|    policy_gradient_loss | -0.0254   |
|    value_loss           | 0.305     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 125         |
|    time_elapsed         | 893         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.041003264 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.157      |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0984      |
|    n_updates            | 11000       |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.336       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 126        |
|    time_elapsed         | 899        |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.04462579 |
|    clip_fraction        | 0.0937     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.132      |
|    n_updates            | 11010      |
|    policy_gradient_loss | -0.0161    |
|    value_loss           | 0.286      |
----------------------------------------
reached max steps=250
Eval num_timesteps=260000, episode_reward=7.17 +/- 8.85
Episode length: 43.00 +/- 41.27
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 43         |
|    mean_reward          | 7.17       |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.07930515 |
|    clip_fraction        | 0.0992     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.135     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.055      |
|    n_updates            | 11020      |
|    policy_gradient_loss | -0.0159    |
|    value_loss           | 0.261      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 286      |
|    iterations      | 127      |
|    time_elapsed    | 906      |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 287         |
|    iterations           | 128         |
|    time_elapsed         | 912         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.035638034 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.133      |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00904     |
|    n_updates            | 11030       |
|    policy_gradient_loss | -0.0159     |
|    value_loss           | 0.272       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 287         |
|    iterations           | 129         |
|    time_elapsed         | 919         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.022092596 |
|    clip_fraction        | 0.071       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0419      |
|    n_updates            | 11040       |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.214       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 287        |
|    iterations           | 130        |
|    time_elapsed         | 925        |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.03411261 |
|    clip_fraction        | 0.0989     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.162     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.167      |
|    n_updates            | 11050      |
|    policy_gradient_loss | -0.0158    |
|    value_loss           | 0.25       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 287         |
|    iterations           | 131         |
|    time_elapsed         | 931         |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.048902437 |
|    clip_fraction        | 0.0955      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0791      |
|    n_updates            | 11060       |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.271       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=10.83 +/- 0.85
Episode length: 18.40 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.4       |
|    mean_reward          | 10.8       |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.03770798 |
|    clip_fraction        | 0.0828     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.107      |
|    n_updates            | 11070      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.244      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 288      |
|    iterations      | 132      |
|    time_elapsed    | 938      |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 10.8      |
| time/                   |           |
|    fps                  | 288       |
|    iterations           | 133       |
|    time_elapsed         | 944       |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0548071 |
|    clip_fraction        | 0.0893    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.112    |
|    explained_variance   | 0.867     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0851    |
|    n_updates            | 11080     |
|    policy_gradient_loss | -0.0115   |
|    value_loss           | 0.299     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 288        |
|    iterations           | 134        |
|    time_elapsed         | 951        |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.26647505 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0935    |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0681     |
|    n_updates            | 11090      |
|    policy_gradient_loss | -0.0282    |
|    value_loss           | 0.284      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 288        |
|    iterations           | 135        |
|    time_elapsed         | 957        |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.04616959 |
|    clip_fraction        | 0.081      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0913    |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0755     |
|    n_updates            | 11100      |
|    policy_gradient_loss | -0.0153    |
|    value_loss           | 0.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 11.1       |
| time/                   |            |
|    fps                  | 288        |
|    iterations           | 136        |
|    time_elapsed         | 964        |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.10642789 |
|    clip_fraction        | 0.0827     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0998    |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.042      |
|    n_updates            | 11110      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.194      |
----------------------------------------
reached max steps=250
Eval num_timesteps=280000, episode_reward=8.21 +/- 6.39
Episode length: 40.80 +/- 42.15
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.8       |
|    mean_reward          | 8.21       |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.04796607 |
|    clip_fraction        | 0.0707     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0962    |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0975     |
|    n_updates            | 11120      |
|    policy_gradient_loss | -0.0119    |
|    value_loss           | 0.246      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 288      |
|    iterations      | 137      |
|    time_elapsed    | 970      |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 138         |
|    time_elapsed         | 977         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.061723724 |
|    clip_fraction        | 0.0836      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0507      |
|    n_updates            | 11130       |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.236       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 139         |
|    time_elapsed         | 983         |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.051616006 |
|    clip_fraction        | 0.0942      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 11140       |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.222       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 140         |
|    time_elapsed         | 989         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.064219266 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.148      |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0978      |
|    n_updates            | 11150       |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.288       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 141         |
|    time_elapsed         | 996         |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.112749934 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.098       |
|    n_updates            | 11160       |
|    policy_gradient_loss | -0.0318     |
|    value_loss           | 0.332       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=290000, episode_reward=6.98 +/- 9.75
Episode length: 41.00 +/- 42.09
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 41         |
|    mean_reward          | 6.98       |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.06221547 |
|    clip_fraction        | 0.111      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.133     |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0637     |
|    n_updates            | 11170      |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.308      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 289      |
|    iterations      | 142      |
|    time_elapsed    | 1003     |
|    total_timesteps | 290816   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 290       |
|    iterations           | 143       |
|    time_elapsed         | 1009      |
|    total_timesteps      | 292864    |
| train/                  |           |
|    approx_kl            | 0.1519118 |
|    clip_fraction        | 0.119     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.136    |
|    explained_variance   | 0.832     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0392    |
|    n_updates            | 11180     |
|    policy_gradient_loss | -0.0268   |
|    value_loss           | 0.291     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 144         |
|    time_elapsed         | 1016        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.027814142 |
|    clip_fraction        | 0.0805      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0937      |
|    n_updates            | 11190       |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.231       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 145         |
|    time_elapsed         | 1022        |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.049021192 |
|    clip_fraction        | 0.0989      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.159      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.095       |
|    n_updates            | 11200       |
|    policy_gradient_loss | -0.0171     |
|    value_loss           | 0.31        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.2      |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 290       |
|    iterations           | 146       |
|    time_elapsed         | 1028      |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 0.0617715 |
|    clip_fraction        | 0.11      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.135    |
|    explained_variance   | 0.881     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0836    |
|    n_updates            | 11210     |
|    policy_gradient_loss | -0.0193   |
|    value_loss           | 0.282     |
---------------------------------------
Eval num_timesteps=300000, episode_reward=10.66 +/- 1.53
Episode length: 20.00 +/- 3.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 10.7       |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.03894893 |
|    clip_fraction        | 0.0904     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.149     |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.158      |
|    n_updates            | 11220      |
|    policy_gradient_loss | -0.0165    |
|    value_loss           | 0.297      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 290      |
|    iterations      | 147      |
|    time_elapsed    | 1035     |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 148         |
|    time_elapsed         | 1042        |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.053416565 |
|    clip_fraction        | 0.0857      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0561      |
|    n_updates            | 11230       |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.212       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 291        |
|    iterations           | 149        |
|    time_elapsed         | 1048       |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.04501807 |
|    clip_fraction        | 0.122      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.166     |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0297     |
|    n_updates            | 11240      |
|    policy_gradient_loss | -0.0207    |
|    value_loss           | 0.29       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 150         |
|    time_elapsed         | 1054        |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.046043202 |
|    clip_fraction        | 0.0959      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0448      |
|    n_updates            | 11250       |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.278       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 291        |
|    iterations           | 151        |
|    time_elapsed         | 1061       |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.08246726 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.074      |
|    n_updates            | 11260      |
|    policy_gradient_loss | -0.0244    |
|    value_loss           | 0.322      |
----------------------------------------
Eval num_timesteps=310000, episode_reward=11.01 +/- 1.06
Episode length: 20.40 +/- 2.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.4       |
|    mean_reward          | 11         |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.03342492 |
|    clip_fraction        | 0.0871     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.124     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0916     |
|    n_updates            | 11270      |
|    policy_gradient_loss | -0.0135    |
|    value_loss           | 0.291      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 291      |
|    iterations      | 152      |
|    time_elapsed    | 1067     |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 153         |
|    time_elapsed         | 1074        |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.032127112 |
|    clip_fraction        | 0.0712      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0947      |
|    n_updates            | 11280       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.331       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 154         |
|    time_elapsed         | 1080        |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.041090995 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0693      |
|    n_updates            | 11290       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.319       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 292        |
|    iterations           | 155        |
|    time_elapsed         | 1086       |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.10842253 |
|    clip_fraction        | 0.0918     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0365     |
|    n_updates            | 11300      |
|    policy_gradient_loss | -0.0185    |
|    value_loss           | 0.271      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 156         |
|    time_elapsed         | 1093        |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.043187134 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0832      |
|    n_updates            | 11310       |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.274       |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=11.65 +/- 0.68
Episode length: 18.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.2        |
|    mean_reward          | 11.6        |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.048730314 |
|    clip_fraction        | 0.0955      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0326      |
|    n_updates            | 11320       |
|    policy_gradient_loss | -0.00826    |
|    value_loss           | 0.238       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 11       |
| time/              |          |
|    fps             | 292      |
|    iterations      | 157      |
|    time_elapsed    | 1100     |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 158         |
|    time_elapsed         | 1106        |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.036687355 |
|    clip_fraction        | 0.066       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0829     |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.106       |
|    n_updates            | 11330       |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.261       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 292        |
|    iterations           | 159        |
|    time_elapsed         | 1112       |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.08818568 |
|    clip_fraction        | 0.0681     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.079     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0362     |
|    n_updates            | 11340      |
|    policy_gradient_loss | -0.01      |
|    value_loss           | 0.208      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 160         |
|    time_elapsed         | 1118        |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.042830605 |
|    clip_fraction        | 0.0669      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0795     |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0908      |
|    n_updates            | 11350       |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.311       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 161         |
|    time_elapsed         | 1125        |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.048663758 |
|    clip_fraction        | 0.0694      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.074      |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0485      |
|    n_updates            | 11360       |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.222       |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=11.56 +/- 0.68
Episode length: 19.00 +/- 2.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19         |
|    mean_reward          | 11.6       |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.05096007 |
|    clip_fraction        | 0.0891     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 11370      |
|    policy_gradient_loss | -0.0189    |
|    value_loss           | 0.334      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.9     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 162      |
|    time_elapsed    | 1131     |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 163        |
|    time_elapsed         | 1138       |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.05295092 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.139     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.12       |
|    n_updates            | 11380      |
|    policy_gradient_loss | -0.0147    |
|    value_loss           | 0.468      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 164         |
|    time_elapsed         | 1144        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.041376863 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.128       |
|    n_updates            | 11390       |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.371       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 165        |
|    time_elapsed         | 1151       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.04878948 |
|    clip_fraction        | 0.0713     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0947    |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.168      |
|    n_updates            | 11400      |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 0.33       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 166        |
|    time_elapsed         | 1157       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.07125374 |
|    clip_fraction        | 0.0855     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.13      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0527     |
|    n_updates            | 11410      |
|    policy_gradient_loss | -0.0168    |
|    value_loss           | 0.355      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=11.52 +/- 0.73
Episode length: 19.40 +/- 2.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.4       |
|    mean_reward          | 11.5       |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.06165272 |
|    clip_fraction        | 0.0867     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.111     |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.116      |
|    n_updates            | 11420      |
|    policy_gradient_loss | -0.0121    |
|    value_loss           | 0.265      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 167      |
|    time_elapsed    | 1164     |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 168        |
|    time_elapsed         | 1170       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.05540864 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0457     |
|    n_updates            | 11430      |
|    policy_gradient_loss | -0.022     |
|    value_loss           | 0.336      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 294        |
|    iterations           | 169        |
|    time_elapsed         | 1176       |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.05197484 |
|    clip_fraction        | 0.0898     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.105      |
|    n_updates            | 11440      |
|    policy_gradient_loss | -0.0177    |
|    value_loss           | 0.273      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 170         |
|    time_elapsed         | 1183        |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.039499946 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0927     |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 11450       |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.242       |
-----------------------------------------
reached max steps=250
reached max steps=250
Eval num_timesteps=350000, episode_reward=4.26 +/- 9.63
Episode length: 60.60 +/- 52.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60.6        |
|    mean_reward          | 4.26        |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.043493506 |
|    clip_fraction        | 0.0862      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.097      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0224      |
|    n_updates            | 11460       |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 0.247       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 294      |
|    iterations      | 171      |
|    time_elapsed    | 1190     |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 172         |
|    time_elapsed         | 1196        |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.026850462 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.123      |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0952      |
|    n_updates            | 11470       |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 0.271       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 294        |
|    iterations           | 173        |
|    time_elapsed         | 1202       |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.02598964 |
|    clip_fraction        | 0.0786     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 11480      |
|    policy_gradient_loss | -0.0122    |
|    value_loss           | 0.308      |
----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 294        |
|    iterations           | 174        |
|    time_elapsed         | 1209       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.03165734 |
|    clip_fraction        | 0.0938     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0617     |
|    n_updates            | 11490      |
|    policy_gradient_loss | -0.0211    |
|    value_loss           | 0.269      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.5      |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 294       |
|    iterations           | 175       |
|    time_elapsed         | 1215      |
|    total_timesteps      | 358400    |
| train/                  |           |
|    approx_kl            | 0.6602004 |
|    clip_fraction        | 0.141     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.142    |
|    explained_variance   | 0.64      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0779    |
|    n_updates            | 11500     |
|    policy_gradient_loss | -0.0366   |
|    value_loss           | 0.431     |
---------------------------------------
reached max steps=250
Eval num_timesteps=360000, episode_reward=7.81 +/- 7.19
Episode length: 40.80 +/- 42.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 40.8        |
|    mean_reward          | 7.81        |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.030562054 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.128      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0924      |
|    n_updates            | 11510       |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.288       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 294      |
|    iterations      | 176      |
|    time_elapsed    | 1222     |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 295        |
|    iterations           | 177        |
|    time_elapsed         | 1228       |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.17383248 |
|    clip_fraction        | 0.128      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.136     |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0542     |
|    n_updates            | 11520      |
|    policy_gradient_loss | -0.0243    |
|    value_loss           | 0.316      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 178         |
|    time_elapsed         | 1234        |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.037950978 |
|    clip_fraction        | 0.0853      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0635      |
|    n_updates            | 11530       |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 0.226       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 295        |
|    iterations           | 179        |
|    time_elapsed         | 1241       |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.05835489 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.126     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0635     |
|    n_updates            | 11540      |
|    policy_gradient_loss | -0.0193    |
|    value_loss           | 0.264      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 295        |
|    iterations           | 180        |
|    time_elapsed         | 1247       |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.05669856 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.125     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0477     |
|    n_updates            | 11550      |
|    policy_gradient_loss | -0.0215    |
|    value_loss           | 0.263      |
----------------------------------------
Eval num_timesteps=370000, episode_reward=10.71 +/- 1.06
Episode length: 23.20 +/- 3.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.2        |
|    mean_reward          | 10.7        |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.031114535 |
|    clip_fraction        | 0.0973      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0815      |
|    n_updates            | 11560       |
|    policy_gradient_loss | -0.0184     |
|    value_loss           | 0.293       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 295      |
|    iterations      | 181      |
|    time_elapsed    | 1254     |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 295        |
|    iterations           | 182        |
|    time_elapsed         | 1260       |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.02667267 |
|    clip_fraction        | 0.0891     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.16      |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.221      |
|    n_updates            | 11570      |
|    policy_gradient_loss | -0.0127    |
|    value_loss           | 0.327      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 183         |
|    time_elapsed         | 1267        |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.048471145 |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0408      |
|    n_updates            | 11580       |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.216       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 184         |
|    time_elapsed         | 1273        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.027360607 |
|    clip_fraction        | 0.0757      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0623      |
|    n_updates            | 11590       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.266       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 185         |
|    time_elapsed         | 1279        |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.043949947 |
|    clip_fraction        | 0.0903      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.146      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0723      |
|    n_updates            | 11600       |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.25        |
-----------------------------------------
reached max steps=250
Eval num_timesteps=380000, episode_reward=7.30 +/- 5.91
Episode length: 41.80 +/- 41.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.8        |
|    mean_reward          | 7.3         |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.044662125 |
|    clip_fraction        | 0.0885      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0743      |
|    n_updates            | 11610       |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.243       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 296      |
|    iterations      | 186      |
|    time_elapsed    | 1286     |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 187         |
|    time_elapsed         | 1292        |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.049401302 |
|    clip_fraction        | 0.0958      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0481      |
|    n_updates            | 11620       |
|    policy_gradient_loss | -0.019      |
|    value_loss           | 0.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 188         |
|    time_elapsed         | 1299        |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.040850595 |
|    clip_fraction        | 0.0832      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.123      |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.232       |
|    n_updates            | 11630       |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.262       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 296        |
|    iterations           | 189        |
|    time_elapsed         | 1305       |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.03609281 |
|    clip_fraction        | 0.0856     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0443     |
|    n_updates            | 11640      |
|    policy_gradient_loss | -0.0157    |
|    value_loss           | 0.225      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 190         |
|    time_elapsed         | 1311        |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.043617688 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.175      |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0784      |
|    n_updates            | 11650       |
|    policy_gradient_loss | -0.0213     |
|    value_loss           | 0.288       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=390000, episode_reward=6.38 +/- 9.55
Episode length: 39.20 +/- 42.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39.2        |
|    mean_reward          | 6.38        |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.036751747 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.174      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 11660       |
|    policy_gradient_loss | -0.0173     |
|    value_loss           | 0.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 296      |
|    iterations      | 191      |
|    time_elapsed    | 1318     |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 296        |
|    iterations           | 192        |
|    time_elapsed         | 1324       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.03337264 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.142     |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.174      |
|    n_updates            | 11670      |
|    policy_gradient_loss | -0.021     |
|    value_loss           | 0.321      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 296        |
|    iterations           | 193        |
|    time_elapsed         | 1331       |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.05152834 |
|    clip_fraction        | 0.0994     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0873     |
|    n_updates            | 11680      |
|    policy_gradient_loss | -0.0203    |
|    value_loss           | 0.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 194         |
|    time_elapsed         | 1337        |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.041833103 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 11690       |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.282       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 195         |
|    time_elapsed         | 1343        |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.048265688 |
|    clip_fraction        | 0.078       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0927     |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0166      |
|    n_updates            | 11700       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.173       |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=10.89 +/- 0.76
Episode length: 17.80 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 17.8        |
|    mean_reward          | 10.9        |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.032294985 |
|    clip_fraction        | 0.0756      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 11710       |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 0.27        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 11       |
| time/              |          |
|    fps             | 297      |
|    iterations      | 196      |
|    time_elapsed    | 1350     |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 197         |
|    time_elapsed         | 1356        |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.027185423 |
|    clip_fraction        | 0.0483      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0764     |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0508      |
|    n_updates            | 11720       |
|    policy_gradient_loss | -0.00999    |
|    value_loss           | 0.266       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 198        |
|    time_elapsed         | 1362       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.03834686 |
|    clip_fraction        | 0.0828     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.158      |
|    n_updates            | 11730      |
|    policy_gradient_loss | -0.0171    |
|    value_loss           | 0.258      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 199        |
|    time_elapsed         | 1369       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.04030327 |
|    clip_fraction        | 0.0731     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0162     |
|    n_updates            | 11740      |
|    policy_gradient_loss | -0.0145    |
|    value_loss           | 0.179      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 200         |
|    time_elapsed         | 1375        |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.038667977 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0757      |
|    n_updates            | 11750       |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.279       |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=9.98 +/- 1.07
Episode length: 18.80 +/- 2.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.8        |
|    mean_reward          | 9.98        |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.049083535 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.131      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0896      |
|    n_updates            | 11760       |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.266       |
-----------------------------------------
reached max steps=250
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 297      |
|    iterations      | 201      |
|    time_elapsed    | 1382     |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 202         |
|    time_elapsed         | 1389        |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.036670808 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.158      |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0163      |
|    n_updates            | 11770       |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.499       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 203        |
|    time_elapsed         | 1395       |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.06725637 |
|    clip_fraction        | 0.0807     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0887    |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0135     |
|    n_updates            | 11780      |
|    policy_gradient_loss | -0.0156    |
|    value_loss           | 0.2        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 204         |
|    time_elapsed         | 1401        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.060325794 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.18       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.137       |
|    n_updates            | 11790       |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.343       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 298        |
|    iterations           | 205        |
|    time_elapsed         | 1407       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.03419888 |
|    clip_fraction        | 0.0776     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.123     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0563     |
|    n_updates            | 11800      |
|    policy_gradient_loss | -0.0118    |
|    value_loss           | 0.249      |
----------------------------------------
reached max steps=250
Eval num_timesteps=420000, episode_reward=7.07 +/- 7.83
Episode length: 40.20 +/- 42.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.2       |
|    mean_reward          | 7.07       |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.06592732 |
|    clip_fraction        | 0.0985     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0192     |
|    n_updates            | 11810      |
|    policy_gradient_loss | -0.0209    |
|    value_loss           | 0.305      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 298      |
|    iterations      | 206      |
|    time_elapsed    | 1414     |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 207         |
|    time_elapsed         | 1421        |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.073151775 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0773      |
|    n_updates            | 11820       |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 0.254       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 298        |
|    iterations           | 208        |
|    time_elapsed         | 1427       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.03016652 |
|    clip_fraction        | 0.069      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.104     |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0455     |
|    n_updates            | 11830      |
|    policy_gradient_loss | -0.0139    |
|    value_loss           | 0.221      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 209         |
|    time_elapsed         | 1434        |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.046380922 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0981     |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0931      |
|    n_updates            | 11840       |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 0.207       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=430000, episode_reward=6.06 +/- 9.31
Episode length: 38.40 +/- 43.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 38.4       |
|    mean_reward          | 6.06       |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.10151276 |
|    clip_fraction        | 0.124      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.126     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.091      |
|    n_updates            | 11850      |
|    policy_gradient_loss | -0.0227    |
|    value_loss           | 0.285      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 298      |
|    iterations      | 210      |
|    time_elapsed    | 1440     |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 211         |
|    time_elapsed         | 1447        |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.040268328 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 11860       |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.304       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 212         |
|    time_elapsed         | 1453        |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.040770695 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.123      |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0823      |
|    n_updates            | 11870       |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.262       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 10.4       |
| time/                   |            |
|    fps                  | 298        |
|    iterations           | 213        |
|    time_elapsed         | 1459       |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.06854343 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.181     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0972     |
|    n_updates            | 11880      |
|    policy_gradient_loss | -0.0171    |
|    value_loss           | 0.431      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 214         |
|    time_elapsed         | 1466        |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.035600323 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.155      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.222       |
|    n_updates            | 11890       |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.382       |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=9.96 +/- 1.57
Episode length: 19.00 +/- 3.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19         |
|    mean_reward          | 9.96       |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.04415725 |
|    clip_fraction        | 0.089      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0224     |
|    n_updates            | 11900      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.232      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.8     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 298      |
|    iterations      | 215      |
|    time_elapsed    | 1473     |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 299        |
|    iterations           | 216        |
|    time_elapsed         | 1479       |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.05013584 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.14      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0807     |
|    n_updates            | 11910      |
|    policy_gradient_loss | -0.0188    |
|    value_loss           | 0.277      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 217         |
|    time_elapsed         | 1485        |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.048559442 |
|    clip_fraction        | 0.0645      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0861     |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.118       |
|    n_updates            | 11920       |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.219       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 10.3       |
| time/                   |            |
|    fps                  | 299        |
|    iterations           | 218        |
|    time_elapsed         | 1492       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.04578755 |
|    clip_fraction        | 0.0785     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0429     |
|    n_updates            | 11930      |
|    policy_gradient_loss | -0.0141    |
|    value_loss           | 0.218      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 219         |
|    time_elapsed         | 1498        |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.039680954 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.072       |
|    n_updates            | 11940       |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 0.428       |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=10.99 +/- 0.65
Episode length: 20.60 +/- 3.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 11         |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.05153247 |
|    clip_fraction        | 0.0775     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.117     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.087      |
|    n_updates            | 11950      |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.351      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 299      |
|    iterations      | 220      |
|    time_elapsed    | 1504     |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 221         |
|    time_elapsed         | 1511        |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.024271809 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0987     |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.133       |
|    n_updates            | 11960       |
|    policy_gradient_loss | -0.0153     |
|    value_loss           | 0.235       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 222         |
|    time_elapsed         | 1517        |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.033923976 |
|    clip_fraction        | 0.0729      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 11970       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.296       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 223         |
|    time_elapsed         | 1523        |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.031751886 |
|    clip_fraction        | 0.0827      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.197       |
|    n_updates            | 11980       |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.315       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 224         |
|    time_elapsed         | 1529        |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.047098145 |
|    clip_fraction        | 0.0863      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.128      |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.154       |
|    n_updates            | 11990       |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.373       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=460000, episode_reward=6.79 +/- 9.65
Episode length: 42.80 +/- 41.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 42.8        |
|    mean_reward          | 6.79        |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.030578658 |
|    clip_fraction        | 0.0865      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0984      |
|    n_updates            | 12000       |
|    policy_gradient_loss | -0.0159     |
|    value_loss           | 0.333       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 299      |
|    iterations      | 225      |
|    time_elapsed    | 1536     |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 226         |
|    time_elapsed         | 1542        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.054485038 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0723      |
|    n_updates            | 12010       |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.284       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 300        |
|    iterations           | 227        |
|    time_elapsed         | 1549       |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.08132087 |
|    clip_fraction        | 0.093      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.117     |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 12020      |
|    policy_gradient_loss | -0.0202    |
|    value_loss           | 0.253      |
----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 300        |
|    iterations           | 228        |
|    time_elapsed         | 1555       |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.07463087 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.156     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0282     |
|    n_updates            | 12030      |
|    policy_gradient_loss | -0.0188    |
|    value_loss           | 0.311      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 300        |
|    iterations           | 229        |
|    time_elapsed         | 1562       |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.06064886 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.171     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0835     |
|    n_updates            | 12040      |
|    policy_gradient_loss | -0.0158    |
|    value_loss           | 0.487      |
----------------------------------------
Eval num_timesteps=470000, episode_reward=11.56 +/- 0.71
Episode length: 19.00 +/- 3.16
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 19        |
|    mean_reward          | 11.6      |
| time/                   |           |
|    total_timesteps      | 470000    |
| train/                  |           |
|    approx_kl            | 0.1911898 |
|    clip_fraction        | 0.115     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.152    |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.136     |
|    n_updates            | 12050     |
|    policy_gradient_loss | -0.0207   |
|    value_loss           | 0.387     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 300      |
|    iterations      | 230      |
|    time_elapsed    | 1568     |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 231         |
|    time_elapsed         | 1574        |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.019531999 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0735      |
|    n_updates            | 12060       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.374       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 300        |
|    iterations           | 232        |
|    time_elapsed         | 1581       |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.04856224 |
|    clip_fraction        | 0.0903     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0969     |
|    n_updates            | 12070      |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.277      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 233         |
|    time_elapsed         | 1587        |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.039445214 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.158       |
|    n_updates            | 12080       |
|    policy_gradient_loss | -0.0177     |
|    value_loss           | 0.292       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 11          |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 234         |
|    time_elapsed         | 1593        |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.096158475 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0851      |
|    n_updates            | 12090       |
|    policy_gradient_loss | -0.0228     |
|    value_loss           | 0.287       |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=10.78 +/- 1.39
Episode length: 18.80 +/- 2.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.8        |
|    mean_reward          | 10.8        |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.040219277 |
|    clip_fraction        | 0.0804      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0555      |
|    n_updates            | 12100       |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.276       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 300      |
|    iterations      | 235      |
|    time_elapsed    | 1600     |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 300        |
|    iterations           | 236        |
|    time_elapsed         | 1606       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.04185974 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.148     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.151      |
|    n_updates            | 12110      |
|    policy_gradient_loss | -0.0168    |
|    value_loss           | 0.384      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 237         |
|    time_elapsed         | 1613        |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.036865376 |
|    clip_fraction        | 0.0882      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.064       |
|    n_updates            | 12120       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 238         |
|    time_elapsed         | 1619        |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.047960136 |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0797      |
|    n_updates            | 12130       |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 0.285       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 239         |
|    time_elapsed         | 1625        |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.025341405 |
|    clip_fraction        | 0.0699      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0803      |
|    n_updates            | 12140       |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.299       |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=9.23 +/- 1.30
Episode length: 18.40 +/- 3.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.4        |
|    mean_reward          | 9.23        |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.034630705 |
|    clip_fraction        | 0.0786      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.137      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.143       |
|    n_updates            | 12150       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.284       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22       |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 301      |
|    iterations      | 240      |
|    time_elapsed    | 1632     |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 241         |
|    time_elapsed         | 1638        |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.030809324 |
|    clip_fraction        | 0.0845      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.157      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.1         |
|    n_updates            | 12160       |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.355       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 242         |
|    time_elapsed         | 1645        |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.037022732 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0443      |
|    n_updates            | 12170       |
|    policy_gradient_loss | -0.0183     |
|    value_loss           | 0.248       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 243         |
|    time_elapsed         | 1651        |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.042250607 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.197      |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 12180       |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.345       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 244         |
|    time_elapsed         | 1657        |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.046790704 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.158      |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 12190       |
|    policy_gradient_loss | -0.0216     |
|    value_loss           | 0.377       |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=11.56 +/- 0.67
Episode length: 19.00 +/- 2.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19         |
|    mean_reward          | 11.6       |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.05868417 |
|    clip_fraction        | 0.0866     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0647     |
|    n_updates            | 12200      |
|    policy_gradient_loss | -0.0147    |
|    value_loss           | 0.291      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 301      |
|    iterations      | 245      |
|    time_elapsed    | 1664     |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 246         |
|    time_elapsed         | 1670        |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.049565483 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 12210       |
|    policy_gradient_loss | -0.00237    |
|    value_loss           | 0.377       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 301        |
|    iterations           | 247        |
|    time_elapsed         | 1676       |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.03135482 |
|    clip_fraction        | 0.0917     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0602     |
|    n_updates            | 12220      |
|    policy_gradient_loss | -0.0204    |
|    value_loss           | 0.246      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 248         |
|    time_elapsed         | 1683        |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.023590859 |
|    clip_fraction        | 0.0611      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0905     |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0711      |
|    n_updates            | 12230       |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.226       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 301        |
|    iterations           | 249        |
|    time_elapsed         | 1689       |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.03075577 |
|    clip_fraction        | 0.064      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.089     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0686     |
|    n_updates            | 12240      |
|    policy_gradient_loss | -0.012     |
|    value_loss           | 0.253      |
----------------------------------------
Eval num_timesteps=510000, episode_reward=11.33 +/- 0.90
Episode length: 17.40 +/- 1.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 17.4        |
|    mean_reward          | 11.3        |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.038397834 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0892     |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0186      |
|    n_updates            | 12250       |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 0.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 301      |
|    iterations      | 250      |
|    time_elapsed    | 1695     |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 251         |
|    time_elapsed         | 1702        |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.048002966 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0542      |
|    n_updates            | 12260       |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 252         |
|    time_elapsed         | 1708        |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.029475203 |
|    clip_fraction        | 0.0767      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.106      |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0966      |
|    n_updates            | 12270       |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 0.249       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 302         |
|    iterations           | 253         |
|    time_elapsed         | 1715        |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.048347995 |
|    clip_fraction        | 0.0821      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0953     |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0731      |
|    n_updates            | 12280       |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.225       |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=10.81 +/- 0.86
Episode length: 18.60 +/- 1.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.6        |
|    mean_reward          | 10.8        |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.028142484 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.142       |
|    n_updates            | 12290       |
|    policy_gradient_loss | -0.0132     |
|    value_loss           | 0.273       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 301      |
|    iterations      | 254      |
|    time_elapsed    | 1722     |
|    total_timesteps | 520192   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 301        |
|    iterations           | 255        |
|    time_elapsed         | 1734       |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.02879924 |
|    clip_fraction        | 0.0806     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.111     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.06       |
|    n_updates            | 12300      |
|    policy_gradient_loss | -0.0149    |
|    value_loss           | 0.263      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 256         |
|    time_elapsed         | 1743        |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.049702264 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.13       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0737      |
|    n_updates            | 12310       |
|    policy_gradient_loss | -0.0251     |
|    value_loss           | 0.318       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 257         |
|    time_elapsed         | 1750        |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.025070444 |
|    clip_fraction        | 0.0614      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.092      |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 12320       |
|    policy_gradient_loss | -0.012      |
|    value_loss           | 0.318       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 258         |
|    time_elapsed         | 1757        |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.032594595 |
|    clip_fraction        | 0.0744      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.046       |
|    n_updates            | 12330       |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.27        |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=11.03 +/- 0.76
Episode length: 20.20 +/- 4.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 11          |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.031424843 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0781      |
|    n_updates            | 12340       |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.265       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 299      |
|    iterations      | 259      |
|    time_elapsed    | 1768     |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 260         |
|    time_elapsed         | 1775        |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.041104667 |
|    clip_fraction        | 0.0805      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0414      |
|    n_updates            | 12350       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.227       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 299        |
|    iterations           | 261        |
|    time_elapsed         | 1783       |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.13552678 |
|    clip_fraction        | 0.0981     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0693     |
|    n_updates            | 12360      |
|    policy_gradient_loss | 0.0164     |
|    value_loss           | 0.226      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 262         |
|    time_elapsed         | 1790        |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.042086594 |
|    clip_fraction        | 0.0817      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0877      |
|    n_updates            | 12370       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.223       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 299        |
|    iterations           | 263        |
|    time_elapsed         | 1799       |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.05868712 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.14      |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0996     |
|    n_updates            | 12380      |
|    policy_gradient_loss | -0.0193    |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=250
Eval num_timesteps=540000, episode_reward=7.16 +/- 7.87
Episode length: 39.40 +/- 42.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39.4        |
|    mean_reward          | 7.16        |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.044918895 |
|    clip_fraction        | 0.0747      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0312      |
|    n_updates            | 12390       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.267       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 299      |
|    iterations      | 264      |
|    time_elapsed    | 1807     |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 265         |
|    time_elapsed         | 1815        |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.042652436 |
|    clip_fraction        | 0.076       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0499      |
|    n_updates            | 12400       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.258       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 266         |
|    time_elapsed         | 1821        |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.055653203 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.111       |
|    n_updates            | 12410       |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.259       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 299        |
|    iterations           | 267        |
|    time_elapsed         | 1828       |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.03838776 |
|    clip_fraction        | 0.0903     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.076      |
|    n_updates            | 12420      |
|    policy_gradient_loss | -0.0167    |
|    value_loss           | 0.313      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 268         |
|    time_elapsed         | 1835        |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.041357815 |
|    clip_fraction        | 0.0795      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00385    |
|    n_updates            | 12430       |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.227       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=10.01 +/- 0.90
Episode length: 18.60 +/- 3.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.6       |
|    mean_reward          | 10         |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.06337066 |
|    clip_fraction        | 0.129      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.162     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 12440      |
|    policy_gradient_loss | -0.0229    |
|    value_loss           | 0.389      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 298      |
|    iterations      | 269      |
|    time_elapsed    | 1844     |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 11          |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 270         |
|    time_elapsed         | 1851        |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.056204326 |
|    clip_fraction        | 0.0946      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.137       |
|    n_updates            | 12450       |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 0.318       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 298        |
|    iterations           | 271        |
|    time_elapsed         | 1861       |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.03792585 |
|    clip_fraction        | 0.075      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.103     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0711     |
|    n_updates            | 12460      |
|    policy_gradient_loss | -0.0168    |
|    value_loss           | 0.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 298        |
|    iterations           | 272        |
|    time_elapsed         | 1869       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.04223339 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.168     |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 12470      |
|    policy_gradient_loss | -0.0191    |
|    value_loss           | 0.339      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 273        |
|    time_elapsed         | 1876       |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.07099509 |
|    clip_fraction        | 0.0858     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.119     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.147      |
|    n_updates            | 12480      |
|    policy_gradient_loss | -0.0171    |
|    value_loss           | 0.35       |
----------------------------------------
reached max steps=250
Eval num_timesteps=560000, episode_reward=7.93 +/- 6.29
Episode length: 39.60 +/- 42.71
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 39.6      |
|    mean_reward          | 7.93      |
| time/                   |           |
|    total_timesteps      | 560000    |
| train/                  |           |
|    approx_kl            | 0.0320994 |
|    clip_fraction        | 0.0657    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0933   |
|    explained_variance   | 0.884     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0424    |
|    n_updates            | 12490     |
|    policy_gradient_loss | -0.0136   |
|    value_loss           | 0.221     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.2     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 297      |
|    iterations      | 274      |
|    time_elapsed    | 1883     |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 10.2       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 275        |
|    time_elapsed         | 1890       |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.04092177 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.141     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0682     |
|    n_updates            | 12500      |
|    policy_gradient_loss | -0.0195    |
|    value_loss           | 0.355      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 276        |
|    time_elapsed         | 1899       |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.29631394 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.156     |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0939     |
|    n_updates            | 12510      |
|    policy_gradient_loss | -0.0245    |
|    value_loss           | 0.354      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 277        |
|    time_elapsed         | 1907       |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.02480853 |
|    clip_fraction        | 0.0933     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.135     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0788     |
|    n_updates            | 12520      |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.327      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 297        |
|    iterations           | 278        |
|    time_elapsed         | 1914       |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.05399029 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.172     |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.187      |
|    n_updates            | 12530      |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.544      |
----------------------------------------
Eval num_timesteps=570000, episode_reward=11.71 +/- 0.38
Episode length: 21.40 +/- 3.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 11.7       |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.07809506 |
|    clip_fraction        | 0.0966     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0787     |
|    n_updates            | 12540      |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.294      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 11       |
| time/              |          |
|    fps             | 297      |
|    iterations      | 279      |
|    time_elapsed    | 1922     |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 280         |
|    time_elapsed         | 1930        |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.034379043 |
|    clip_fraction        | 0.0608      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0823     |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0303      |
|    n_updates            | 12550       |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.216       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 296        |
|    iterations           | 281        |
|    time_elapsed         | 1939       |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.04938281 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0832     |
|    n_updates            | 12560      |
|    policy_gradient_loss | -0.0153    |
|    value_loss           | 0.237      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 282         |
|    time_elapsed         | 1947        |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.044413067 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0745      |
|    n_updates            | 12570       |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.357       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 283         |
|    time_elapsed         | 1955        |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.039681613 |
|    clip_fraction        | 0.0838      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.135      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0486      |
|    n_updates            | 12580       |
|    policy_gradient_loss | -0.00869    |
|    value_loss           | 0.314       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=580000, episode_reward=5.96 +/- 9.33
Episode length: 39.40 +/- 42.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.4       |
|    mean_reward          | 5.96       |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.04199019 |
|    clip_fraction        | 0.0806     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.117     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0936     |
|    n_updates            | 12590      |
|    policy_gradient_loss | -0.0132    |
|    value_loss           | 0.204      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 296      |
|    iterations      | 284      |
|    time_elapsed    | 1963     |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 285         |
|    time_elapsed         | 1970        |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.057000153 |
|    clip_fraction        | 0.096       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.135      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0495      |
|    n_updates            | 12600       |
|    policy_gradient_loss | -0.0194     |
|    value_loss           | 0.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 286         |
|    time_elapsed         | 1979        |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.054326154 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0959     |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0617      |
|    n_updates            | 12610       |
|    policy_gradient_loss | -0.00824    |
|    value_loss           | 0.214       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 287         |
|    time_elapsed         | 1987        |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.088856004 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.135      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0997      |
|    n_updates            | 12620       |
|    policy_gradient_loss | -0.0237     |
|    value_loss           | 0.321       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 295        |
|    iterations           | 288        |
|    time_elapsed         | 1995       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.09021889 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.122     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.139      |
|    n_updates            | 12630      |
|    policy_gradient_loss | -0.017     |
|    value_loss           | 0.309      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=10.81 +/- 0.70
Episode length: 18.60 +/- 3.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.6       |
|    mean_reward          | 10.8       |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.16709161 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0618     |
|    n_updates            | 12640      |
|    policy_gradient_loss | 0.0567     |
|    value_loss           | 0.415      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 295      |
|    iterations      | 289      |
|    time_elapsed    | 2002     |
|    total_timesteps | 591872   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 290         |
|    time_elapsed         | 2011        |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.038655326 |
|    clip_fraction        | 0.0787      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0733      |
|    n_updates            | 12650       |
|    policy_gradient_loss | -0.0166     |
|    value_loss           | 0.258       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 295         |
|    iterations           | 291         |
|    time_elapsed         | 2019        |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.113701805 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.207       |
|    n_updates            | 12660       |
|    policy_gradient_loss | 0.102       |
|    value_loss           | 0.315       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 294        |
|    iterations           | 292        |
|    time_elapsed         | 2027       |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.24372882 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.129     |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.136      |
|    n_updates            | 12670      |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.358      |
----------------------------------------
Eval num_timesteps=600000, episode_reward=10.03 +/- 0.24
Episode length: 18.40 +/- 2.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.4        |
|    mean_reward          | 10          |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.026418906 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0972     |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.102       |
|    n_updates            | 12680       |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.265       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 294      |
|    iterations      | 293      |
|    time_elapsed    | 2034     |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 294         |
|    time_elapsed         | 2042        |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.055019572 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.109       |
|    n_updates            | 12690       |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.378       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 295         |
|    time_elapsed         | 2050        |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.032359816 |
|    clip_fraction        | 0.0713      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0289      |
|    n_updates            | 12700       |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.276       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 296         |
|    time_elapsed         | 2060        |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.052453917 |
|    clip_fraction        | 0.0828      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.122       |
|    n_updates            | 12710       |
|    policy_gradient_loss | -0.0172     |
|    value_loss           | 0.246       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 297         |
|    time_elapsed         | 2068        |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.036254905 |
|    clip_fraction        | 0.0823      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0816      |
|    n_updates            | 12720       |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 0.255       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=610000, episode_reward=6.96 +/- 6.87
Episode length: 41.20 +/- 41.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.2        |
|    mean_reward          | 6.96        |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.053861775 |
|    clip_fraction        | 0.083       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0428      |
|    n_updates            | 12730       |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.205       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 298      |
|    time_elapsed    | 2075     |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 299         |
|    time_elapsed         | 2084        |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.045267735 |
|    clip_fraction        | 0.0809      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 12740       |
|    policy_gradient_loss | -0.0176     |
|    value_loss           | 0.263       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 300         |
|    time_elapsed         | 2090        |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.049909968 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0661      |
|    n_updates            | 12750       |
|    policy_gradient_loss | -0.0199     |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 301         |
|    time_elapsed         | 2098        |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.085014105 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.174      |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.109       |
|    n_updates            | 12760       |
|    policy_gradient_loss | -0.023      |
|    value_loss           | 0.448       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.5      |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 293       |
|    iterations           | 302       |
|    time_elapsed         | 2105      |
|    total_timesteps      | 618496    |
| train/                  |           |
|    approx_kl            | 0.0313843 |
|    clip_fraction        | 0.0842    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.129    |
|    explained_variance   | 0.868     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.157     |
|    n_updates            | 12770     |
|    policy_gradient_loss | -0.017    |
|    value_loss           | 0.308     |
---------------------------------------
Eval num_timesteps=620000, episode_reward=9.92 +/- 1.64
Episode length: 19.40 +/- 4.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.4        |
|    mean_reward          | 9.92        |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.025773332 |
|    clip_fraction        | 0.0765      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.134      |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0867      |
|    n_updates            | 12780       |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 303      |
|    time_elapsed    | 2112     |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 304         |
|    time_elapsed         | 2119        |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.031772383 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 12790       |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.219       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 305         |
|    time_elapsed         | 2126        |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.041327592 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0744      |
|    n_updates            | 12800       |
|    policy_gradient_loss | -0.0196     |
|    value_loss           | 0.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 306         |
|    time_elapsed         | 2134        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.034782745 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.185      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0685      |
|    n_updates            | 12810       |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.358       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 307        |
|    time_elapsed         | 2141       |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.03428567 |
|    clip_fraction        | 0.0843     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.161     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0449     |
|    n_updates            | 12820      |
|    policy_gradient_loss | -0.0128    |
|    value_loss           | 0.363      |
----------------------------------------
reached max steps=250
Eval num_timesteps=630000, episode_reward=6.71 +/- 6.68
Episode length: 39.80 +/- 42.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.8       |
|    mean_reward          | 6.71       |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.04021675 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.187     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0624     |
|    n_updates            | 12830      |
|    policy_gradient_loss | -0.0198    |
|    value_loss           | 0.323      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 308      |
|    time_elapsed    | 2148     |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 309         |
|    time_elapsed         | 2155        |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.042953495 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0807      |
|    n_updates            | 12840       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.314       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 310        |
|    time_elapsed         | 2161       |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.10046089 |
|    clip_fraction        | 0.155      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.178     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.176      |
|    n_updates            | 12850      |
|    policy_gradient_loss | -0.025     |
|    value_loss           | 0.3        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 311        |
|    time_elapsed         | 2168       |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.03476308 |
|    clip_fraction        | 0.0998     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.164     |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0813     |
|    n_updates            | 12860      |
|    policy_gradient_loss | -0.0145    |
|    value_loss           | 0.277      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 312         |
|    time_elapsed         | 2175        |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.071494244 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0756      |
|    n_updates            | 12870       |
|    policy_gradient_loss | -0.0211     |
|    value_loss           | 0.259       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=11.29 +/- 0.76
Episode length: 17.80 +/- 2.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 17.8        |
|    mean_reward          | 11.3        |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.051694226 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.142      |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0922      |
|    n_updates            | 12880       |
|    policy_gradient_loss | -0.0151     |
|    value_loss           | 0.276       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22       |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 313      |
|    time_elapsed    | 2182     |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 314        |
|    time_elapsed         | 2188       |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.05006466 |
|    clip_fraction        | 0.0869     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.137     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.169      |
|    n_updates            | 12890      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.389      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 315        |
|    time_elapsed         | 2195       |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.08688271 |
|    clip_fraction        | 0.087      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.127     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.117      |
|    n_updates            | 12900      |
|    policy_gradient_loss | -0.0223    |
|    value_loss           | 0.272      |
----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 316        |
|    time_elapsed         | 2201       |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.06793216 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.145      |
|    n_updates            | 12910      |
|    policy_gradient_loss | -0.011     |
|    value_loss           | 0.391      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 317        |
|    time_elapsed         | 2209       |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.11507954 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.181     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.103      |
|    n_updates            | 12920      |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.418      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=10.46 +/- 1.38
Episode length: 21.80 +/- 3.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.8        |
|    mean_reward          | 10.5        |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.028159028 |
|    clip_fraction        | 0.0811      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.135       |
|    n_updates            | 12930       |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 0.292       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 293      |
|    iterations      | 318      |
|    time_elapsed    | 2220     |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 319         |
|    time_elapsed         | 2228        |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.044350654 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.14       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 12940       |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.366       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.8        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 320         |
|    time_elapsed         | 2237        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.042798743 |
|    clip_fraction        | 0.0788      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0922      |
|    n_updates            | 12950       |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.222       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 321         |
|    time_elapsed         | 2245        |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.092305094 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 12960       |
|    policy_gradient_loss | -0.0395     |
|    value_loss           | 0.518       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 322         |
|    time_elapsed         | 2264        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.033730567 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 12970       |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 0.348       |
-----------------------------------------
reached max steps=250
reached max steps=250
Eval num_timesteps=660000, episode_reward=1.86 +/- 10.15
Episode length: 60.60 +/- 52.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.6       |
|    mean_reward          | 1.86       |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.03930124 |
|    clip_fraction        | 0.0902     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.15      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.172      |
|    n_updates            | 12980      |
|    policy_gradient_loss | -0.0155    |
|    value_loss           | 0.284      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    fps             | 290      |
|    iterations      | 323      |
|    time_elapsed    | 2274     |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 324         |
|    time_elapsed         | 2283        |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.039572008 |
|    clip_fraction        | 0.0943      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0926      |
|    n_updates            | 12990       |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 0.385       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 325         |
|    time_elapsed         | 2293        |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.059755456 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.167      |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0815      |
|    n_updates            | 13000       |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.279       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 326         |
|    time_elapsed         | 2302        |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.045486927 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.139      |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.059       |
|    n_updates            | 13010       |
|    policy_gradient_loss | -0.0183     |
|    value_loss           | 0.292       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 289        |
|    iterations           | 327        |
|    time_elapsed         | 2310       |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.04641676 |
|    clip_fraction        | 0.106      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0833     |
|    n_updates            | 13020      |
|    policy_gradient_loss | -0.019     |
|    value_loss           | 0.218      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=11.29 +/- 0.91
Episode length: 17.80 +/- 0.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 17.8        |
|    mean_reward          | 11.3        |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.038949758 |
|    clip_fraction        | 0.0723      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.027       |
|    n_updates            | 13030       |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.199       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 289      |
|    iterations      | 328      |
|    time_elapsed    | 2318     |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 329         |
|    time_elapsed         | 2329        |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.045053054 |
|    clip_fraction        | 0.0901      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0687      |
|    n_updates            | 13040       |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 0.256       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 288         |
|    iterations           | 330         |
|    time_elapsed         | 2340        |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.035461165 |
|    clip_fraction        | 0.0735      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0822      |
|    n_updates            | 13050       |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.256       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 288         |
|    iterations           | 331         |
|    time_elapsed         | 2350        |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.037467267 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.123      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 13060       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.241       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 288         |
|    iterations           | 332         |
|    time_elapsed         | 2360        |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.044298463 |
|    clip_fraction        | 0.0667      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0949     |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0386      |
|    n_updates            | 13070       |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 0.22        |
-----------------------------------------
reached max steps=250
Eval num_timesteps=680000, episode_reward=7.15 +/- 7.83
Episode length: 43.20 +/- 41.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 43.2        |
|    mean_reward          | 7.15        |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.030765092 |
|    clip_fraction        | 0.097       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0783      |
|    n_updates            | 13080       |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.333       |
-----------------------------------------
reached max steps=250
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 287      |
|    iterations      | 333      |
|    time_elapsed    | 2371     |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 334        |
|    time_elapsed         | 2385       |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.06907881 |
|    clip_fraction        | 0.0874     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.122     |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.127      |
|    n_updates            | 13090      |
|    policy_gradient_loss | -0.0127    |
|    value_loss           | 0.403      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 20.8     |
|    ep_rew_mean          | 11       |
| time/                   |          |
|    fps                  | 286      |
|    iterations           | 335      |
|    time_elapsed         | 2394     |
|    total_timesteps      | 686080   |
| train/                  |          |
|    approx_kl            | 0.047266 |
|    clip_fraction        | 0.0812   |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.108   |
|    explained_variance   | 0.882    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.08     |
|    n_updates            | 13100    |
|    policy_gradient_loss | -0.0148  |
|    value_loss           | 0.235    |
--------------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.5        |
|    ep_rew_mean          | 10.2        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 336         |
|    time_elapsed         | 2405        |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.045276053 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.147      |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0861      |
|    n_updates            | 13110       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.232       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=690000, episode_reward=7.01 +/- 7.82
Episode length: 40.80 +/- 42.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.8       |
|    mean_reward          | 7.01       |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.23355204 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.221     |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.169      |
|    n_updates            | 13120      |
|    policy_gradient_loss | -0.0366    |
|    value_loss           | 0.544      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.2     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 337      |
|    time_elapsed    | 2413     |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 285        |
|    iterations           | 338        |
|    time_elapsed         | 2420       |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.06829515 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.123      |
|    n_updates            | 13130      |
|    policy_gradient_loss | -0.0196    |
|    value_loss           | 0.308      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 339         |
|    time_elapsed         | 2427        |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.042769857 |
|    clip_fraction        | 0.0718      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.1        |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.15        |
|    n_updates            | 13140       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.303       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 285        |
|    iterations           | 340        |
|    time_elapsed         | 2434       |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.04253417 |
|    clip_fraction        | 0.0613     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0819    |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0737     |
|    n_updates            | 13150      |
|    policy_gradient_loss | -0.0124    |
|    value_loss           | 0.228      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 341         |
|    time_elapsed         | 2442        |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.048534393 |
|    clip_fraction        | 0.0888      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 13160       |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.283       |
-----------------------------------------
reached max steps=250
reached max steps=250
Eval num_timesteps=700000, episode_reward=7.13 +/- 6.85
Episode length: 39.60 +/- 42.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.6       |
|    mean_reward          | 7.13       |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.13312557 |
|    clip_fraction        | 0.129      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.116     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0637     |
|    n_updates            | 13170      |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 0.229      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 342      |
|    time_elapsed    | 2449     |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 343        |
|    time_elapsed         | 2456       |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.10833343 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.139     |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0857     |
|    n_updates            | 13180      |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.41       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 344         |
|    time_elapsed         | 2463        |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.035984527 |
|    clip_fraction        | 0.0627      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0899     |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.081       |
|    n_updates            | 13190       |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.241       |
-----------------------------------------
reached max steps=250
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 345         |
|    time_elapsed         | 2470        |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.048726898 |
|    clip_fraction        | 0.0796      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0897     |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0646      |
|    n_updates            | 13200       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.243       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21        |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 285       |
|    iterations           | 346       |
|    time_elapsed         | 2478      |
|    total_timesteps      | 708608    |
| train/                  |           |
|    approx_kl            | 0.3296069 |
|    clip_fraction        | 0.196     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.166    |
|    explained_variance   | 0.56      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0771    |
|    n_updates            | 13210     |
|    policy_gradient_loss | -0.0514   |
|    value_loss           | 0.439     |
---------------------------------------
reached max steps=250
Eval num_timesteps=710000, episode_reward=6.92 +/- 7.75
Episode length: 41.60 +/- 41.75
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 41.6      |
|    mean_reward          | 6.92      |
| time/                   |           |
|    total_timesteps      | 710000    |
| train/                  |           |
|    approx_kl            | 0.0531031 |
|    clip_fraction        | 0.0853    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.116    |
|    explained_variance   | 0.86      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0225    |
|    n_updates            | 13220     |
|    policy_gradient_loss | -0.0161   |
|    value_loss           | 0.286     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 347      |
|    time_elapsed    | 2486     |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 285        |
|    iterations           | 348        |
|    time_elapsed         | 2493       |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.06459496 |
|    clip_fraction        | 0.0867     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.111     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0527     |
|    n_updates            | 13230      |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.251      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 349         |
|    time_elapsed         | 2499        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.054963715 |
|    clip_fraction        | 0.0824      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0999     |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0358      |
|    n_updates            | 13240       |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.253       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 10.3        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 350         |
|    time_elapsed         | 2506        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.032745294 |
|    clip_fraction        | 0.074       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.106      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 13250       |
|    policy_gradient_loss | -0.0117     |
|    value_loss           | 0.221       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 351        |
|    time_elapsed         | 2513       |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.04161442 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0501     |
|    n_updates            | 13260      |
|    policy_gradient_loss | -0.011     |
|    value_loss           | 0.293      |
----------------------------------------
reached max steps=250
reached max steps=250
Eval num_timesteps=720000, episode_reward=3.78 +/- 8.52
Episode length: 61.40 +/- 51.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61.4       |
|    mean_reward          | 3.78       |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.04393013 |
|    clip_fraction        | 0.0866     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 13270      |
|    policy_gradient_loss | -0.0113    |
|    value_loss           | 0.242      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 11       |
| time/              |          |
|    fps             | 285      |
|    iterations      | 352      |
|    time_elapsed    | 2520     |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 353        |
|    time_elapsed         | 2527       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.03372376 |
|    clip_fraction        | 0.0703     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0897     |
|    n_updates            | 13280      |
|    policy_gradient_loss | -0.00875   |
|    value_loss           | 0.214      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 354         |
|    time_elapsed         | 2533        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.043364346 |
|    clip_fraction        | 0.0837      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.132      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0385      |
|    n_updates            | 13290       |
|    policy_gradient_loss | -0.0196     |
|    value_loss           | 0.262       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 355         |
|    time_elapsed         | 2540        |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.086089104 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.132       |
|    n_updates            | 13300       |
|    policy_gradient_loss | -0.0252     |
|    value_loss           | 0.421       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 356        |
|    time_elapsed         | 2547       |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.07674061 |
|    clip_fraction        | 0.1        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.16      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.13       |
|    n_updates            | 13310      |
|    policy_gradient_loss | -0.0221    |
|    value_loss           | 0.391      |
----------------------------------------
Eval num_timesteps=730000, episode_reward=11.71 +/- 0.38
Episode length: 21.40 +/- 3.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 11.7       |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.08005364 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.16      |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0843     |
|    n_updates            | 13320      |
|    policy_gradient_loss | -0.0159    |
|    value_loss           | 0.306      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 286      |
|    iterations      | 357      |
|    time_elapsed    | 2555     |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 358         |
|    time_elapsed         | 2561        |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.046997316 |
|    clip_fraction        | 0.087       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.008       |
|    n_updates            | 13330       |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.269       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 359        |
|    time_elapsed         | 2568       |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.04501395 |
|    clip_fraction        | 0.0927     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.124     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0318     |
|    n_updates            | 13340      |
|    policy_gradient_loss | -0.012     |
|    value_loss           | 0.272      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 360         |
|    time_elapsed         | 2575        |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.056321308 |
|    clip_fraction        | 0.0938      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.135      |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0859      |
|    n_updates            | 13350       |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.266       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 361         |
|    time_elapsed         | 2582        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.030835256 |
|    clip_fraction        | 0.0758      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0942     |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.067       |
|    n_updates            | 13360       |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.216       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=740000, episode_reward=5.76 +/- 9.15
Episode length: 41.20 +/- 41.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.2        |
|    mean_reward          | 5.76        |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.050485738 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0873      |
|    n_updates            | 13370       |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.317       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 286      |
|    iterations      | 362      |
|    time_elapsed    | 2590     |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 363         |
|    time_elapsed         | 2597        |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.038226787 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0893     |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.2         |
|    n_updates            | 13380       |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.361       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 364         |
|    time_elapsed         | 2603        |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.043781437 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.047       |
|    n_updates            | 13390       |
|    policy_gradient_loss | -0.0186     |
|    value_loss           | 0.222       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 286         |
|    iterations           | 365         |
|    time_elapsed         | 2610        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.043127727 |
|    clip_fraction        | 0.0899      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.102      |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0175      |
|    n_updates            | 13400       |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.256       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 286        |
|    iterations           | 366        |
|    time_elapsed         | 2617       |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.04817676 |
|    clip_fraction        | 0.0951     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0986    |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.026      |
|    n_updates            | 13410      |
|    policy_gradient_loss | -0.0238    |
|    value_loss           | 0.265      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=11.48 +/- 0.63
Episode length: 19.80 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 11.5        |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.043687083 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0757     |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0956      |
|    n_updates            | 13420       |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.261       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 367      |
|    time_elapsed    | 2629     |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 285        |
|    iterations           | 368        |
|    time_elapsed         | 2639       |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.04156255 |
|    clip_fraction        | 0.0667     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0877    |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0555     |
|    n_updates            | 13430      |
|    policy_gradient_loss | -0.013     |
|    value_loss           | 0.278      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 369         |
|    time_elapsed         | 2647        |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.041546576 |
|    clip_fraction        | 0.0863      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.108       |
|    n_updates            | 13440       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.315       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 370         |
|    time_elapsed         | 2656        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.042292997 |
|    clip_fraction        | 0.0818      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0727      |
|    n_updates            | 13450       |
|    policy_gradient_loss | -0.0176     |
|    value_loss           | 0.265       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.6        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 371         |
|    time_elapsed         | 2664        |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.054081444 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0997     |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.122       |
|    n_updates            | 13460       |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.247       |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=10.72 +/- 0.98
Episode length: 19.40 +/- 2.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.4       |
|    mean_reward          | 10.7       |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.03288529 |
|    clip_fraction        | 0.0607     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0832    |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0878     |
|    n_updates            | 13470      |
|    policy_gradient_loss | -0.0112    |
|    value_loss           | 0.204      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 372      |
|    time_elapsed    | 2672     |
|    total_timesteps | 761856   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.5      |
|    ep_rew_mean          | 10.6      |
| time/                   |           |
|    fps                  | 285       |
|    iterations           | 373       |
|    time_elapsed         | 2679      |
|    total_timesteps      | 763904    |
| train/                  |           |
|    approx_kl            | 0.3933845 |
|    clip_fraction        | 0.17      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.145    |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0583    |
|    n_updates            | 13480     |
|    policy_gradient_loss | -0.0354   |
|    value_loss           | 0.292     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.6        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 285         |
|    iterations           | 374         |
|    time_elapsed         | 2686        |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.031487785 |
|    clip_fraction        | 0.0837      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.042       |
|    n_updates            | 13490       |
|    policy_gradient_loss | -0.0201     |
|    value_loss           | 0.264       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 285        |
|    iterations           | 375        |
|    time_elapsed         | 2694       |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.05072874 |
|    clip_fraction        | 0.0696     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0826    |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0586     |
|    n_updates            | 13500      |
|    policy_gradient_loss | -0.0108    |
|    value_loss           | 0.194      |
----------------------------------------
reached max steps=250
Eval num_timesteps=770000, episode_reward=7.09 +/- 7.83
Episode length: 40.00 +/- 42.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 40          |
|    mean_reward          | 7.09        |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.039158635 |
|    clip_fraction        | 0.076       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.083      |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0914      |
|    n_updates            | 13510       |
|    policy_gradient_loss | -0.0186     |
|    value_loss           | 0.202       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 284      |
|    iterations      | 376      |
|    time_elapsed    | 2704     |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 377         |
|    time_elapsed         | 2716        |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.032237332 |
|    clip_fraction        | 0.0815      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.17        |
|    n_updates            | 13520       |
|    policy_gradient_loss | -0.00891    |
|    value_loss           | 0.267       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 378        |
|    time_elapsed         | 2726       |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.03270569 |
|    clip_fraction        | 0.0647     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0961    |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0686     |
|    n_updates            | 13530      |
|    policy_gradient_loss | -0.0132    |
|    value_loss           | 0.199      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 379        |
|    time_elapsed         | 2734       |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.03341694 |
|    clip_fraction        | 0.0811     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.122     |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0624     |
|    n_updates            | 13540      |
|    policy_gradient_loss | -0.0142    |
|    value_loss           | 0.259      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 380         |
|    time_elapsed         | 2742        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.024537727 |
|    clip_fraction        | 0.0623      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0843     |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0389      |
|    n_updates            | 13550       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.199       |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=11.50 +/- 0.74
Episode length: 19.60 +/- 1.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 11.5       |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.03712812 |
|    clip_fraction        | 0.0979     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.119     |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0522     |
|    n_updates            | 13560      |
|    policy_gradient_loss | -0.00953   |
|    value_loss           | 0.272      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 283      |
|    iterations      | 381      |
|    time_elapsed    | 2750     |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 382        |
|    time_elapsed         | 2757       |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.02645902 |
|    clip_fraction        | 0.0757     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.119     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.109      |
|    n_updates            | 13570      |
|    policy_gradient_loss | -0.0199    |
|    value_loss           | 0.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 383         |
|    time_elapsed         | 2766        |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.055705436 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0469      |
|    n_updates            | 13580       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.301       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 384         |
|    time_elapsed         | 2777        |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.039355773 |
|    clip_fraction        | 0.0754      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.103      |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0804      |
|    n_updates            | 13590       |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.241       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 385        |
|    time_elapsed         | 2784       |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.13250214 |
|    clip_fraction        | 0.0868     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.103     |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.109      |
|    n_updates            | 13600      |
|    policy_gradient_loss | -0.0181    |
|    value_loss           | 0.295      |
----------------------------------------
Eval num_timesteps=790000, episode_reward=10.01 +/- 1.23
Episode length: 18.60 +/- 2.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.6        |
|    mean_reward          | 10          |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.036161162 |
|    clip_fraction        | 0.0717      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0978     |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0277      |
|    n_updates            | 13610       |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.223       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 282      |
|    iterations      | 386      |
|    time_elapsed    | 2796     |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 387         |
|    time_elapsed         | 2805        |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.030608606 |
|    clip_fraction        | 0.0804      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.137       |
|    n_updates            | 13620       |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.267       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 388        |
|    time_elapsed         | 2813       |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.05214841 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0267     |
|    n_updates            | 13630      |
|    policy_gradient_loss | -0.0249    |
|    value_loss           | 0.323      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 389        |
|    time_elapsed         | 2821       |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.03385881 |
|    clip_fraction        | 0.0787     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 13640      |
|    policy_gradient_loss | -0.0187    |
|    value_loss           | 0.273      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 390         |
|    time_elapsed         | 2827        |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.044521853 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0265      |
|    n_updates            | 13650       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.223       |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=10.74 +/- 0.95
Episode length: 19.20 +/- 2.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.2        |
|    mean_reward          | 10.7        |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.055782203 |
|    clip_fraction        | 0.0838      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0506      |
|    n_updates            | 13660       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.231       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 282      |
|    iterations      | 391      |
|    time_elapsed    | 2834     |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 392        |
|    time_elapsed         | 2841       |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.03956773 |
|    clip_fraction        | 0.0782     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0746     |
|    n_updates            | 13670      |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.265      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 393        |
|    time_elapsed         | 2847       |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.25529504 |
|    clip_fraction        | 0.0973     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.123     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0676     |
|    n_updates            | 13680      |
|    policy_gradient_loss | -0.0227    |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 394         |
|    time_elapsed         | 2855        |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.035351112 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.136       |
|    n_updates            | 13690       |
|    policy_gradient_loss | -0.0353     |
|    value_loss           | 0.311       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 395        |
|    time_elapsed         | 2864       |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.07804822 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0999    |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.11       |
|    n_updates            | 13700      |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.273      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=11.37 +/- 0.69
Episode length: 20.80 +/- 3.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.8        |
|    mean_reward          | 11.4        |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.031002704 |
|    clip_fraction        | 0.0594      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0822     |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0489      |
|    n_updates            | 13710       |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.232       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 282      |
|    iterations      | 396      |
|    time_elapsed    | 2873     |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 397        |
|    time_elapsed         | 2881       |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.04103847 |
|    clip_fraction        | 0.0647     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0737    |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0778     |
|    n_updates            | 13720      |
|    policy_gradient_loss | -0.0109    |
|    value_loss           | 0.237      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 398        |
|    time_elapsed         | 2889       |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.07208702 |
|    clip_fraction        | 0.0912     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.112     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0657     |
|    n_updates            | 13730      |
|    policy_gradient_loss | -0.0157    |
|    value_loss           | 0.321      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 399         |
|    time_elapsed         | 2896        |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.029431853 |
|    clip_fraction        | 0.0556      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0759     |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.216       |
|    n_updates            | 13740       |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 0.236       |
-----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 400         |
|    time_elapsed         | 2905        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.029721122 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.117      |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.102       |
|    n_updates            | 13750       |
|    policy_gradient_loss | -0.0155     |
|    value_loss           | 0.296       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=10.87 +/- 1.47
Episode length: 18.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18         |
|    mean_reward          | 10.9       |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.04152312 |
|    clip_fraction        | 0.0883     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0774    |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0727     |
|    n_updates            | 13760      |
|    policy_gradient_loss | -0.018     |
|    value_loss           | 0.317      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 401      |
|    time_elapsed    | 2913     |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 402         |
|    time_elapsed         | 2922        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.044492334 |
|    clip_fraction        | 0.0645      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0946     |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0854      |
|    n_updates            | 13770       |
|    policy_gradient_loss | -0.0027     |
|    value_loss           | 0.304       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 403         |
|    time_elapsed         | 2931        |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.039577868 |
|    clip_fraction        | 0.0683      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0853     |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.017       |
|    n_updates            | 13780       |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.268       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 404         |
|    time_elapsed         | 2942        |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.035043467 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0821     |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0879      |
|    n_updates            | 13790       |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 0.257       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 405         |
|    time_elapsed         | 2953        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.052306935 |
|    clip_fraction        | 0.0609      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0763     |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0571      |
|    n_updates            | 13800       |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.261       |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=10.68 +/- 1.68
Episode length: 19.80 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 10.7        |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.032126263 |
|    clip_fraction        | 0.07        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.091      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0479      |
|    n_updates            | 13810       |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.275       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 406      |
|    time_elapsed    | 2962     |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 407        |
|    time_elapsed         | 2970       |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.05768627 |
|    clip_fraction        | 0.0616     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0781    |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.121      |
|    n_updates            | 13820      |
|    policy_gradient_loss | -0.0127    |
|    value_loss           | 0.359      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 408         |
|    time_elapsed         | 2978        |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.030923355 |
|    clip_fraction        | 0.0699      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0953     |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0889      |
|    n_updates            | 13830       |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 11          |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 409         |
|    time_elapsed         | 2989        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.033122286 |
|    clip_fraction        | 0.0614      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0821     |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 13840       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 410         |
|    time_elapsed         | 2997        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.034367613 |
|    clip_fraction        | 0.0804      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.185       |
|    n_updates            | 13850       |
|    policy_gradient_loss | -0.01       |
|    value_loss           | 0.254       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=840000, episode_reward=6.78 +/- 6.74
Episode length: 39.20 +/- 42.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.2       |
|    mean_reward          | 6.78       |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.39392713 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0904    |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0736     |
|    n_updates            | 13860      |
|    policy_gradient_loss | -0.0389    |
|    value_loss           | 0.322      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 411      |
|    time_elapsed    | 3004     |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 412         |
|    time_elapsed         | 3011        |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.052192565 |
|    clip_fraction        | 0.0649      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.081      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0883      |
|    n_updates            | 13870       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.241       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 413         |
|    time_elapsed         | 3021        |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.038272344 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0849     |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.034       |
|    n_updates            | 13880       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.23        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 414        |
|    time_elapsed         | 3028       |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.04594765 |
|    clip_fraction        | 0.0826     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.12      |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0688     |
|    n_updates            | 13890      |
|    policy_gradient_loss | -0.0146    |
|    value_loss           | 0.261      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 415         |
|    time_elapsed         | 3034        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.034633264 |
|    clip_fraction        | 0.0695      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0569      |
|    n_updates            | 13900       |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.199       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=850000, episode_reward=7.45 +/- 7.01
Episode length: 40.40 +/- 42.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.4       |
|    mean_reward          | 7.45       |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.03464035 |
|    clip_fraction        | 0.0981     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.147     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0993     |
|    n_updates            | 13910      |
|    policy_gradient_loss | -0.0182    |
|    value_loss           | 0.291      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 416      |
|    time_elapsed    | 3040     |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 417         |
|    time_elapsed         | 3047        |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.060741432 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.136      |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0338      |
|    n_updates            | 13920       |
|    policy_gradient_loss | 0.0112      |
|    value_loss           | 0.346       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 418         |
|    time_elapsed         | 3054        |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.041770197 |
|    clip_fraction        | 0.0749      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0945      |
|    n_updates            | 13930       |
|    policy_gradient_loss | -0.0195     |
|    value_loss           | 0.308       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 419        |
|    time_elapsed         | 3061       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.03948384 |
|    clip_fraction        | 0.0698     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.101     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.043      |
|    n_updates            | 13940      |
|    policy_gradient_loss | -0.0129    |
|    value_loss           | 0.244      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=11.06 +/- 0.84
Episode length: 20.00 +/- 2.76
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 11.1       |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.18613324 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.126     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.139      |
|    n_updates            | 13950      |
|    policy_gradient_loss | -0.00573   |
|    value_loss           | 0.289      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 420      |
|    time_elapsed    | 3071     |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 421         |
|    time_elapsed         | 3080        |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.044883743 |
|    clip_fraction        | 0.0776      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.113      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0379      |
|    n_updates            | 13960       |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.224       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 422         |
|    time_elapsed         | 3090        |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.039988995 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0904      |
|    n_updates            | 13970       |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.225       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 279        |
|    iterations           | 423        |
|    time_elapsed         | 3099       |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.04747777 |
|    clip_fraction        | 0.0993     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.147     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0324     |
|    n_updates            | 13980      |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.276      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 424         |
|    time_elapsed         | 3111        |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.048611075 |
|    clip_fraction        | 0.088       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.149      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0469      |
|    n_updates            | 13990       |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.279       |
-----------------------------------------
reached max steps=250
reached max steps=250
reached max steps=250
Eval num_timesteps=870000, episode_reward=-1.09 +/- 10.24
Episode length: 82.40 +/- 52.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 82.4        |
|    mean_reward          | -1.09       |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.047528375 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.167      |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0838      |
|    n_updates            | 14000       |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.267       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 10.8     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 425      |
|    time_elapsed    | 3120     |
|    total_timesteps | 870400   |
---------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 426         |
|    time_elapsed         | 3128        |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.049804997 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.162      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.111       |
|    n_updates            | 14010       |
|    policy_gradient_loss | -0.019      |
|    value_loss           | 0.301       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 11         |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 427        |
|    time_elapsed         | 3139       |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.12072901 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.15      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0342     |
|    n_updates            | 14020      |
|    policy_gradient_loss | -0.0398    |
|    value_loss           | 0.408      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 428         |
|    time_elapsed         | 3148        |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.039716393 |
|    clip_fraction        | 0.0833      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0709      |
|    n_updates            | 14030       |
|    policy_gradient_loss | -0.0147     |
|    value_loss           | 0.246       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 429        |
|    time_elapsed         | 3156       |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.09659317 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.186      |
|    n_updates            | 14040      |
|    policy_gradient_loss | -0.0151    |
|    value_loss           | 0.359      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=11.25 +/- 0.97
Episode length: 18.20 +/- 1.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.2        |
|    mean_reward          | 11.2        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.021866173 |
|    clip_fraction        | 0.0625      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 14050       |
|    policy_gradient_loss | -0.0097     |
|    value_loss           | 0.243       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 430      |
|    time_elapsed    | 3166     |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 431        |
|    time_elapsed         | 3172       |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.07079572 |
|    clip_fraction        | 0.0892     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.119     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0844     |
|    n_updates            | 14060      |
|    policy_gradient_loss | -0.0198    |
|    value_loss           | 0.249      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 432         |
|    time_elapsed         | 3180        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.049072012 |
|    clip_fraction        | 0.0835      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0479      |
|    n_updates            | 14070       |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.243       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 433        |
|    time_elapsed         | 3187       |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.15408921 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.138     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.168      |
|    n_updates            | 14080      |
|    policy_gradient_loss | 0.0207     |
|    value_loss           | 0.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 434         |
|    time_elapsed         | 3195        |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.024346001 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0379      |
|    n_updates            | 14090       |
|    policy_gradient_loss | -0.00991    |
|    value_loss           | 0.23        |
-----------------------------------------
Eval num_timesteps=890000, episode_reward=9.98 +/- 1.00
Episode length: 18.80 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.8        |
|    mean_reward          | 9.98        |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.052478794 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.106      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0649      |
|    n_updates            | 14100       |
|    policy_gradient_loss | -0.0173     |
|    value_loss           | 0.274       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 435      |
|    time_elapsed    | 3202     |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 436         |
|    time_elapsed         | 3209        |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.034696728 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.104      |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0961      |
|    n_updates            | 14110       |
|    policy_gradient_loss | -0.0144     |
|    value_loss           | 0.222       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 437         |
|    time_elapsed         | 3216        |
|    total_timesteps      | 894976      |
| train/                  |             |
|    approx_kl            | 0.047532387 |
|    clip_fraction        | 0.092       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0996      |
|    n_updates            | 14120       |
|    policy_gradient_loss | -0.0198     |
|    value_loss           | 0.284       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 438         |
|    time_elapsed         | 3223        |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.042378202 |
|    clip_fraction        | 0.0849      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.137      |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.15        |
|    n_updates            | 14130       |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 439         |
|    time_elapsed         | 3230        |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.031002117 |
|    clip_fraction        | 0.0908      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.148      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.195       |
|    n_updates            | 14140       |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.297       |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=10.83 +/- 1.39
Episode length: 18.40 +/- 2.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.4       |
|    mean_reward          | 10.8       |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.03272844 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.189     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.107      |
|    n_updates            | 14150      |
|    policy_gradient_loss | -0.0183    |
|    value_loss           | 0.39       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.9     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 440      |
|    time_elapsed    | 3238     |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 441         |
|    time_elapsed         | 3245        |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.035958096 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 14160       |
|    policy_gradient_loss | -0.0199     |
|    value_loss           | 0.499       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 10.4        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 442         |
|    time_elapsed         | 3252        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.037945084 |
|    clip_fraction        | 0.0988      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.149      |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.155       |
|    n_updates            | 14170       |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.296       |
-----------------------------------------
reached max steps=250
reached max steps=250
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.2      |
|    ep_rew_mean          | 10.4      |
| time/                   |           |
|    fps                  | 278       |
|    iterations           | 443       |
|    time_elapsed         | 3258      |
|    total_timesteps      | 907264    |
| train/                  |           |
|    approx_kl            | 0.2538841 |
|    clip_fraction        | 0.226     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.24     |
|    explained_variance   | 0.65      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.183     |
|    n_updates            | 14180     |
|    policy_gradient_loss | -0.0457   |
|    value_loss           | 0.476     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 444         |
|    time_elapsed         | 3265        |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.090739146 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.185      |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0684      |
|    n_updates            | 14190       |
|    policy_gradient_loss | -0.0372     |
|    value_loss           | 0.483       |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=10.68 +/- 0.93
Episode length: 19.80 +/- 3.19
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 10.7       |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.04517135 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.153     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0524     |
|    n_updates            | 14200      |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.304      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 445      |
|    time_elapsed    | 3273     |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 446         |
|    time_elapsed         | 3280        |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.038463395 |
|    clip_fraction        | 0.0723      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0945     |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0468      |
|    n_updates            | 14210       |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.243       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 447        |
|    time_elapsed         | 3287       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.04707621 |
|    clip_fraction        | 0.0824     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.101     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.137      |
|    n_updates            | 14220      |
|    policy_gradient_loss | -0.0158    |
|    value_loss           | 0.262      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 448         |
|    time_elapsed         | 3294        |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.032489553 |
|    clip_fraction        | 0.0743      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.07        |
|    n_updates            | 14230       |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.254       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 449         |
|    time_elapsed         | 3301        |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.032030843 |
|    clip_fraction        | 0.0612      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0752     |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0534      |
|    n_updates            | 14240       |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.172       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=920000, episode_reward=8.02 +/- 7.30
Episode length: 38.80 +/- 43.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 38.8        |
|    mean_reward          | 8.02        |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.040542945 |
|    clip_fraction        | 0.0935      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.045       |
|    n_updates            | 14250       |
|    policy_gradient_loss | -0.0284     |
|    value_loss           | 0.249       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 450      |
|    time_elapsed    | 3308     |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 451        |
|    time_elapsed         | 3314       |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.04216602 |
|    clip_fraction        | 0.0679     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0799    |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0649     |
|    n_updates            | 14260      |
|    policy_gradient_loss | -0.0125    |
|    value_loss           | 0.275      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 452        |
|    time_elapsed         | 3321       |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.09308273 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0302     |
|    n_updates            | 14270      |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.255      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 453         |
|    time_elapsed         | 3328        |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.042562865 |
|    clip_fraction        | 0.0679      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0913     |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0996      |
|    n_updates            | 14280       |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.216       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 454         |
|    time_elapsed         | 3335        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.045833234 |
|    clip_fraction        | 0.0852      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 14290       |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.283       |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=11.23 +/- 1.02
Episode length: 18.40 +/- 2.15
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 18.4      |
|    mean_reward          | 11.2      |
| time/                   |           |
|    total_timesteps      | 930000    |
| train/                  |           |
|    approx_kl            | 0.0457785 |
|    clip_fraction        | 0.0783    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0914   |
|    explained_variance   | 0.911     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0827    |
|    n_updates            | 14300     |
|    policy_gradient_loss | -0.0105   |
|    value_loss           | 0.206     |
---------------------------------------
reached max steps=250
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 455      |
|    time_elapsed    | 3343     |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 10.9       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 456        |
|    time_elapsed         | 3350       |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.05328548 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.172     |
|    explained_variance   | 0.554      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.13       |
|    n_updates            | 14310      |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.555      |
----------------------------------------
reached max steps=250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 457         |
|    time_elapsed         | 3357        |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.066257894 |
|    clip_fraction        | 0.0774      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.093      |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.054       |
|    n_updates            | 14320       |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.231       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 458         |
|    time_elapsed         | 3364        |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.039281093 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.124      |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 14330       |
|    policy_gradient_loss | -0.016      |
|    value_loss           | 0.319       |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=10.97 +/- 0.85
Episode length: 20.80 +/- 2.56
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 20.8     |
|    mean_reward          | 11       |
| time/                   |          |
|    total_timesteps      | 940000   |
| train/                  |          |
|    approx_kl            | 0.047726 |
|    clip_fraction        | 0.0885   |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.114   |
|    explained_variance   | 0.851    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.113    |
|    n_updates            | 14340    |
|    policy_gradient_loss | -0.0196  |
|    value_loss           | 0.311    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 459      |
|    time_elapsed    | 3371     |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 460         |
|    time_elapsed         | 3378        |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.042300582 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.15       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0249      |
|    n_updates            | 14350       |
|    policy_gradient_loss | -0.0267     |
|    value_loss           | 0.374       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 461         |
|    time_elapsed         | 3386        |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.032095365 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.157       |
|    n_updates            | 14360       |
|    policy_gradient_loss | -0.0174     |
|    value_loss           | 0.285       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 10.9        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 462         |
|    time_elapsed         | 3394        |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.045040578 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 14370       |
|    policy_gradient_loss | -0.0202     |
|    value_loss           | 0.318       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 463         |
|    time_elapsed         | 3402        |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.030238062 |
|    clip_fraction        | 0.0753      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.116      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 14380       |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.259       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=950000, episode_reward=6.18 +/- 9.38
Episode length: 41.00 +/- 42.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41          |
|    mean_reward          | 6.18        |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.068935044 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.145      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 14390       |
|    policy_gradient_loss | -0.0219     |
|    value_loss           | 0.322       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 10.5     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 464      |
|    time_elapsed    | 3412     |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 10.5        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 465         |
|    time_elapsed         | 3420        |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.042638585 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.155      |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 14400       |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.333       |
-----------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 10.5       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 466        |
|    time_elapsed         | 3427       |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.03733011 |
|    clip_fraction        | 0.0872     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0598     |
|    n_updates            | 14410      |
|    policy_gradient_loss | -0.0165    |
|    value_loss           | 0.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 467        |
|    time_elapsed         | 3434       |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.05301053 |
|    clip_fraction        | 0.128      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.168     |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.107      |
|    n_updates            | 14420      |
|    policy_gradient_loss | -0.024     |
|    value_loss           | 0.39       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 468         |
|    time_elapsed         | 3442        |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.042103723 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.064       |
|    n_updates            | 14430       |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.278       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=960000, episode_reward=11.03 +/- 1.01
Episode length: 20.20 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 11          |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.043608025 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 14440       |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.352       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 469      |
|    time_elapsed    | 3450     |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 10.6        |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 470         |
|    time_elapsed         | 3462        |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.057470452 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.16       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.18        |
|    n_updates            | 14450       |
|    policy_gradient_loss | -0.0229     |
|    value_loss           | 0.456       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 277        |
|    iterations           | 471        |
|    time_elapsed         | 3473       |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.03581828 |
|    clip_fraction        | 0.0759     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.105     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0732     |
|    n_updates            | 14460      |
|    policy_gradient_loss | -0.0147    |
|    value_loss           | 0.298      |
----------------------------------------
reached max steps=250
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 10.3       |
| time/                   |            |
|    fps                  | 277        |
|    iterations           | 472        |
|    time_elapsed         | 3484       |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.07007093 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.169     |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.135      |
|    n_updates            | 14470      |
|    policy_gradient_loss | -0.0197    |
|    value_loss           | 0.393      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 277        |
|    iterations           | 473        |
|    time_elapsed         | 3492       |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.18018591 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.18      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.198      |
|    n_updates            | 14480      |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.674      |
----------------------------------------
reached max steps=250
reached max steps=250
Eval num_timesteps=970000, episode_reward=1.95 +/- 9.40
Episode length: 59.80 +/- 53.24
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 59.8      |
|    mean_reward          | 1.95      |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.0430341 |
|    clip_fraction        | 0.0792    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.111    |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0855    |
|    n_updates            | 14490     |
|    policy_gradient_loss | -0.0136   |
|    value_loss           | 0.326     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    fps             | 277      |
|    iterations      | 474      |
|    time_elapsed    | 3501     |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 475         |
|    time_elapsed         | 3509        |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.043663308 |
|    clip_fraction        | 0.0694      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0964     |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0918      |
|    n_updates            | 14500       |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.279       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 476         |
|    time_elapsed         | 3519        |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.050388105 |
|    clip_fraction        | 0.0963      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.131      |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0493      |
|    n_updates            | 14510       |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.305       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 276        |
|    iterations           | 477        |
|    time_elapsed         | 3527       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.09943174 |
|    clip_fraction        | 0.0838     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0688     |
|    n_updates            | 14520      |
|    policy_gradient_loss | -0.0138    |
|    value_loss           | 0.235      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.2      |
|    ep_rew_mean          | 10.8      |
| time/                   |           |
|    fps                  | 276       |
|    iterations           | 478       |
|    time_elapsed         | 3535      |
|    total_timesteps      | 978944    |
| train/                  |           |
|    approx_kl            | 0.0539662 |
|    clip_fraction        | 0.0884    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.104    |
|    explained_variance   | 0.895     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.05      |
|    n_updates            | 14530     |
|    policy_gradient_loss | -0.0175   |
|    value_loss           | 0.205     |
---------------------------------------
reached max steps=250
Eval num_timesteps=980000, episode_reward=7.70 +/- 7.14
Episode length: 41.80 +/- 41.65
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 41.8     |
|    mean_reward          | 7.7      |
| time/                   |          |
|    total_timesteps      | 980000   |
| train/                  |          |
|    approx_kl            | 0.042231 |
|    clip_fraction        | 0.0995   |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.132   |
|    explained_variance   | 0.892    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.0686   |
|    n_updates            | 14540    |
|    policy_gradient_loss | -0.0162  |
|    value_loss           | 0.222    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 276      |
|    iterations      | 479      |
|    time_elapsed    | 3543     |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 10.8       |
| time/                   |            |
|    fps                  | 276        |
|    iterations           | 480        |
|    time_elapsed         | 3551       |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.03199595 |
|    clip_fraction        | 0.0871     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.138     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0748     |
|    n_updates            | 14550      |
|    policy_gradient_loss | -0.0137    |
|    value_loss           | 0.35       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 10.8        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 481         |
|    time_elapsed         | 3559        |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.019754501 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0948     |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0512      |
|    n_updates            | 14560       |
|    policy_gradient_loss | -0.0122     |
|    value_loss           | 0.195       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.2      |
|    ep_rew_mean          | 10.7      |
| time/                   |           |
|    fps                  | 276       |
|    iterations           | 482       |
|    time_elapsed         | 3567      |
|    total_timesteps      | 987136    |
| train/                  |           |
|    approx_kl            | 0.0477136 |
|    clip_fraction        | 0.099     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.125    |
|    explained_variance   | 0.82      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0823    |
|    n_updates            | 14570     |
|    policy_gradient_loss | -0.0226   |
|    value_loss           | 0.265     |
---------------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 276        |
|    iterations           | 483        |
|    time_elapsed         | 3576       |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.04596137 |
|    clip_fraction        | 0.0785     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00263    |
|    n_updates            | 14580      |
|    policy_gradient_loss | -0.0164    |
|    value_loss           | 0.193      |
----------------------------------------
reached max steps=250
Eval num_timesteps=990000, episode_reward=7.68 +/- 7.17
Episode length: 42.00 +/- 41.58
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 42        |
|    mean_reward          | 7.68      |
| time/                   |           |
|    total_timesteps      | 990000    |
| train/                  |           |
|    approx_kl            | 0.5617305 |
|    clip_fraction        | 0.121     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.112    |
|    explained_variance   | 0.46      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0364    |
|    n_updates            | 14590     |
|    policy_gradient_loss | -0.0393   |
|    value_loss           | 0.461     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 276      |
|    iterations      | 484      |
|    time_elapsed    | 3588     |
|    total_timesteps | 991232   |
---------------------------------
reached max steps=250
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 276        |
|    iterations           | 485        |
|    time_elapsed         | 3597       |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.03691306 |
|    clip_fraction        | 0.0801     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.111     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.156      |
|    n_updates            | 14600      |
|    policy_gradient_loss | -0.0154    |
|    value_loss           | 0.341      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 10.6       |
| time/                   |            |
|    fps                  | 276        |
|    iterations           | 486        |
|    time_elapsed         | 3604       |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.06327772 |
|    clip_fraction        | 0.104      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.12      |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0669     |
|    n_updates            | 14610      |
|    policy_gradient_loss | -0.029     |
|    value_loss           | 0.494      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 487         |
|    time_elapsed         | 3612        |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.039104193 |
|    clip_fraction        | 0.0959      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.109      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 14620       |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.267       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 10.7        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 488         |
|    time_elapsed         | 3620        |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.041340567 |
|    clip_fraction        | 0.0853      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.11       |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0533      |
|    n_updates            | 14630       |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.251       |
-----------------------------------------
reached max steps=250
Eval num_timesteps=1000000, episode_reward=7.18 +/- 5.93
Episode length: 39.20 +/- 42.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.2       |
|    mean_reward          | 7.18       |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.04681596 |
|    clip_fraction        | 0.0818     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0938     |
|    n_updates            | 14640      |
|    policy_gradient_loss | -0.0127    |
|    value_loss           | 0.289      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    fps             | 275      |
|    iterations      | 489      |
|    time_elapsed    | 3628     |
|    total_timesteps | 1001472  |
---------------------------------
