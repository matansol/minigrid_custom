2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_setup.py:_flush():68] Current SDK version is 0.19.1
2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_setup.py:_flush():68] Configure stats pid to 17844
2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_setup.py:_flush():68] Loading settings from C:\Users\matan\.config\wandb\settings
2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_setup.py:_flush():68] Loading settings from C:\Users\matan\master_thesis\minigrid_custom\wandb\settings
2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-01-05 15:02:34,910 INFO    MainThread:17844 [wandb_init.py:_log_setup():528] Logging user logs to C:\Users\matan\master_thesis\minigrid_custom\wandb\run-20250105_150234-p6izn7cd\logs\debug.log
2025-01-05 15:02:34,918 INFO    MainThread:17844 [wandb_init.py:_log_setup():529] Logging internal logs to C:\Users\matan\master_thesis\minigrid_custom\wandb\run-20250105_150234-p6izn7cd\logs\debug-internal.log
2025-01-05 15:02:34,918 INFO    MainThread:17844 [wandb_init.py:init():644] calling init triggers
2025-01-05 15:02:34,918 INFO    MainThread:17844 [wandb_init.py:init():650] wandb.init called with sweep_config: {}
config: {'algorithm': 'PPO', 'max_steps': 300, 'preference_vector': [5, -0.5, -0.5, -4, 0.2]}
2025-01-05 15:02:34,918 INFO    MainThread:17844 [wandb_init.py:init():680] starting backend
2025-01-05 15:02:34,918 INFO    MainThread:17844 [wandb_init.py:init():684] sending inform_init request
2025-01-05 15:02:34,925 INFO    MainThread:17844 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=spawn, using: spawn
2025-01-05 15:02:34,934 INFO    MainThread:17844 [wandb_init.py:init():697] backend started and connected
2025-01-05 15:02:34,935 INFO    MainThread:17844 [wandb_init.py:init():790] updated telemetry
2025-01-05 15:02:35,114 INFO    MainThread:17844 [wandb_init.py:init():822] communicating run to backend with 90.0 second timeout
2025-01-05 15:02:35,443 INFO    MainThread:17844 [wandb_init.py:init():874] starting run threads in backend
2025-01-05 15:02:35,669 INFO    MainThread:17844 [wandb_run.py:_console_start():2374] atexit reg
2025-01-05 15:02:35,669 INFO    MainThread:17844 [wandb_run.py:_redirect():2224] redirect: wrap_raw
2025-01-05 15:02:35,670 INFO    MainThread:17844 [wandb_run.py:_redirect():2289] Wrapping output streams.
2025-01-05 15:02:35,670 INFO    MainThread:17844 [wandb_run.py:_redirect():2314] Redirects installed.
2025-01-05 15:02:35,673 INFO    MainThread:17844 [wandb_init.py:init():916] run started, returning control to user process
2025-01-05 15:02:38,674 INFO    MainThread:17844 [wandb_watch.py:_watch():71] Watching
2025-01-05 15:02:38,677 INFO    MainThread:17844 [wandb_run.py:_config_callback():1279] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.MultiInputActorCriticPolicy'>", 'device': 'cuda', 'verbose': 1, 'policy_kwargs': "{'features_extractor_class': <class '__main__.ObjEnvExtractor'>}", 'num_timesteps': 0, '_total_timesteps': 300000.0, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1736082158670813400, 'learning_rate': 0.01, 'tensorboard_log': 'None', '_last_obs': "OrderedDict([('image', array([[[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 2, 2, 2, 2, 2, 2],\n         [2, 1, 1, 1, 1, 1, 1],\n         [2, 1, 9, 6, 1, 1, 1],\n         [2, 1, 1, 1, 6, 1, 1],\n         [2, 1, 9, 1, 6, 9, 9]],\n\n        [[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [5, 5, 5, 5, 5, 5, 5],\n         [5, 0, 0, 0, 0, 0, 0],\n         [5, 0, 0, 2, 0, 0, 0],\n         [5, 0, 0, 0, 0, 0, 0],\n         [5, 0, 0, 0, 0, 0, 0]],\n\n        [[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]]]], dtype=uint8))])", '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000001AF081315D0>', '_vec_normalize_env': 'None', 'observation_space': "Dict('image': Box(0, 255, (3, 7, 7), uint8))", 'action_space': 'Discrete(7)', 'n_envs': 1, 'n_steps': 64, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.DictRolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 16, 'n_epochs': 10, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x000001AF1C95E050>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x000001AF0E679120>', 'rollout_buffer': '<stable_baselines3.common.buffers.DictRolloutBuffer object at 0x000001AF08131750>', 'policy': 'MultiInputActorCriticPolicy(\n  (features_extractor): ObjEnvExtractor(\n    (extractors): ModuleDict(\n      (image): Sequential(\n        (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n        (7): Linear(in_features=1024, out_features=64, bias=True)\n        (8): ReLU()\n      )\n    )\n  )\n  (pi_features_extractor): ObjEnvExtractor(\n    (extractors): ModuleDict(\n      (image): Sequential(\n        (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n        (7): Linear(in_features=1024, out_features=64, bias=True)\n        (8): ReLU()\n      )\n    )\n  )\n  (vf_features_extractor): ObjEnvExtractor(\n    (extractors): ModuleDict(\n      (image): Sequential(\n        (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n        (7): Linear(in_features=1024, out_features=64, bias=True)\n        (8): ReLU()\n      )\n    )\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=7, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x000001AF1C943190>'}
2025-01-05 15:15:29,011 INFO    MainThread:17844 [sb3.py:save_model():147] Saving model checkpoint to ./models/wandb_models/[5, -0.5, -0.5, -4, 0.2]\model.zip
2025-01-05 15:28:11,561 INFO    MainThread:17844 [sb3.py:save_model():147] Saving model checkpoint to ./models/wandb_models/[5, -0.5, -0.5, -4, 0.2]\model.zip
2025-01-05 15:40:31,396 INFO    MainThread:17844 [sb3.py:save_model():147] Saving model checkpoint to ./models/wandb_models/[5, -0.5, -0.5, -4, 0.2]\model.zip
2025-01-05 15:40:31,708 INFO    MainThread:17844 [sb3.py:save_model():147] Saving model checkpoint to ./models/wandb_models/[5, -0.5, -0.5, -4, 0.2]\model.zip
2025-01-05 15:40:31,736 WARNING MsgRouterThr:17844 [router.py:message_loop():75] message_loop has been closed
