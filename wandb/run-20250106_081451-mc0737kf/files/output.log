Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x0000024AE6921570> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000024AE6921300>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | -28.1    |
| time/              |          |
|    fps             | 240      |
|    iterations      | 1        |
|    time_elapsed    | 8        |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 140        |
|    ep_rew_mean          | -27.7      |
| time/                   |            |
|    fps                  | 231        |
|    iterations           | 2          |
|    time_elapsed         | 17         |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.00795505 |
|    clip_fraction        | 0.0301     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.94      |
|    explained_variance   | -0.003     |
|    learning_rate        | 0.001      |
|    loss                 | 0.23       |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.00666   |
|    value_loss           | 0.769      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -28.7       |
| time/                   |             |
|    fps                  | 223         |
|    iterations           | 3           |
|    time_elapsed         | 27          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010534875 |
|    clip_fraction        | 0.0707      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | -0.14       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0671     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 0.319       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | -28.3       |
| time/                   |             |
|    fps                  | 210         |
|    iterations           | 4           |
|    time_elapsed         | 38          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.013991896 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.372      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0984      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00723    |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.012697509 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.0361     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0574     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.19        |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -28.5    |
| time/              |          |
|    fps             | 177      |
|    iterations      | 5        |
|    time_elapsed    | 57       |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -28.5       |
| time/                   |             |
|    fps                  | 149         |
|    iterations           | 6           |
|    time_elapsed         | 82          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.013251311 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.415      |
|    learning_rate        | 0.001       |
|    loss                 | 0.105       |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00624    |
|    value_loss           | 0.123       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -28.7      |
| time/                   |            |
|    fps                  | 133        |
|    iterations           | 7          |
|    time_elapsed         | 107        |
|    total_timesteps      | 14336      |
| train/                  |            |
|    approx_kl            | 0.02019282 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.89      |
|    explained_variance   | -0.0573    |
|    learning_rate        | 0.001      |
|    loss                 | 0.0202     |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.0122    |
|    value_loss           | 0.168      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 8           |
|    time_elapsed         | 131         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.031158876 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.431      |
|    learning_rate        | 0.001       |
|    loss                 | 0.052       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.0382      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -29.1       |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 9           |
|    time_elapsed         | 156         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.027649332 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -0.0358     |
|    learning_rate        | 0.001       |
|    loss                 | -0.062      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0247     |
|    value_loss           | 0.138       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.02385436 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | -0.471     |
|    learning_rate        | 0.001      |
|    loss                 | -0.041     |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0229    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -29.1    |
| time/              |          |
|    fps             | 112      |
|    iterations      | 10       |
|    time_elapsed    | 182      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 149        |
|    ep_rew_mean          | -29        |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 11         |
|    time_elapsed         | 206        |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.02051669 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.85      |
|    explained_variance   | -0.0482    |
|    learning_rate        | 0.001      |
|    loss                 | 0.0681     |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.0162    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -29.4       |
| time/                   |             |
|    fps                  | 106         |
|    iterations           | 12          |
|    time_elapsed         | 230         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.024458475 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -0.114      |
|    learning_rate        | 0.001       |
|    loss                 | 0.00727     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 0.0918      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 149        |
|    ep_rew_mean          | -29.7      |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 13         |
|    time_elapsed         | 254        |
|    total_timesteps      | 26624      |
| train/                  |            |
|    approx_kl            | 0.03120667 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | -0.371     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0134    |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.0265    |
|    value_loss           | 0.132      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 148        |
|    ep_rew_mean          | -29.5      |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 14         |
|    time_elapsed         | 277        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03694099 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.84      |
|    explained_variance   | -0.446     |
|    learning_rate        | 0.001      |
|    loss                 | -0.102     |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0273    |
|    value_loss           | 0.073      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-28.33 +/- 2.36
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -28.3       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.029385261 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -0.335      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0557     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 0.113       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -29.3    |
| time/              |          |
|    fps             | 101      |
|    iterations      | 15       |
|    time_elapsed    | 302      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -29.1      |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 16         |
|    time_elapsed         | 326        |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.02901691 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.85      |
|    explained_variance   | -0.248     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0769    |
|    n_updates            | 150        |
|    policy_gradient_loss | -0.0277    |
|    value_loss           | 0.19       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -29.1      |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 17         |
|    time_elapsed         | 351        |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.02911995 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.84      |
|    explained_variance   | -0.529     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0302     |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 98          |
|    iterations           | 18          |
|    time_elapsed         | 375         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.033563357 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -0.275      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0384     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0329     |
|    value_loss           | 0.106       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 144        |
|    ep_rew_mean          | -28.5      |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 19         |
|    time_elapsed         | 399        |
|    total_timesteps      | 38912      |
| train/                  |            |
|    approx_kl            | 0.03126525 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.83      |
|    explained_variance   | -0.0481    |
|    learning_rate        | 0.001      |
|    loss                 | -0.0414    |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.0229    |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.031279843 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -0.0653     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0352      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0257     |
|    value_loss           | 0.303       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -28.2    |
| time/              |          |
|    fps             | 96       |
|    iterations      | 20       |
|    time_elapsed    | 425      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 142         |
|    ep_rew_mean          | -27.6       |
| time/                   |             |
|    fps                  | 95          |
|    iterations           | 21          |
|    time_elapsed         | 449         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.028757649 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -0.627      |
|    learning_rate        | 0.001       |
|    loss                 | -0.114      |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.041      |
|    value_loss           | 0.0788      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 141        |
|    ep_rew_mean          | -27.3      |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 22         |
|    time_elapsed         | 473        |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.03735792 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.81      |
|    explained_variance   | -0.184     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0524     |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.18       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 141        |
|    ep_rew_mean          | -27.4      |
| time/                   |            |
|    fps                  | 94         |
|    iterations           | 23         |
|    time_elapsed         | 498        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.03857346 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.79      |
|    explained_variance   | -0.953     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0446     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0307    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 142         |
|    ep_rew_mean          | -27.2       |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 24          |
|    time_elapsed         | 522         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.039845042 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | -0.0487     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0873     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0369     |
|    value_loss           | 0.158       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.040185247 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | -0.203      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0482      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0293     |
|    value_loss           | 0.127       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -27      |
| time/              |          |
|    fps             | 93       |
|    iterations      | 25       |
|    time_elapsed    | 549      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -27.4       |
| time/                   |             |
|    fps                  | 92          |
|    iterations           | 26          |
|    time_elapsed         | 573         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.043327957 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | -0.791      |
|    learning_rate        | 0.001       |
|    loss                 | -0.108      |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0279     |
|    value_loss           | 0.095       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 143        |
|    ep_rew_mean          | -27.5      |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 27         |
|    time_elapsed         | 597        |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.03837595 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.75      |
|    explained_variance   | 0.0843     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0997    |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.063      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -27.3       |
| time/                   |             |
|    fps                  | 92          |
|    iterations           | 28          |
|    time_elapsed         | 622         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.036342464 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0853     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0286     |
|    value_loss           | 0.161       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 142         |
|    ep_rew_mean          | -27         |
| time/                   |             |
|    fps                  | 91          |
|    iterations           | 29          |
|    time_elapsed         | 646         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.046563625 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | -0.156      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0249     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0296     |
|    value_loss           | 0.118       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.042916156 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.485       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0911     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0357     |
|    value_loss           | 0.157       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -26.9    |
| time/              |          |
|    fps             | 91       |
|    iterations      | 30       |
|    time_elapsed    | 674      |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 135         |
|    ep_rew_mean          | -25.1       |
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 31          |
|    time_elapsed         | 698         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.041968897 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.063       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0856     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0294     |
|    value_loss           | 0.135       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 119        |
|    ep_rew_mean          | -20.9      |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 32         |
|    time_elapsed         | 723        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.04784272 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.68      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0514    |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 110        |
|    ep_rew_mean          | -18.8      |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 33         |
|    time_elapsed         | 733        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.04240107 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.6       |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0894     |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0305    |
|    value_loss           | 0.234      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 108         |
|    ep_rew_mean          | -18.6       |
| time/                   |             |
|    fps                  | 93          |
|    iterations           | 34          |
|    time_elapsed         | 742         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.043218322 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0909     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 0.183       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.041877527 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0504     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0262     |
|    value_loss           | 0.147       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | -17.2    |
| time/              |          |
|    fps             | 95       |
|    iterations      | 35       |
|    time_elapsed    | 752      |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 97.6       |
|    ep_rew_mean          | -15.7      |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 36         |
|    time_elapsed         | 761        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.04306925 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.65      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0172    |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0246    |
|    value_loss           | 0.242      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 101        |
|    ep_rew_mean          | -16.4      |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 37         |
|    time_elapsed         | 771        |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.04650303 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.54      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00265    |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0221    |
|    value_loss           | 0.2        |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 93.4        |
|    ep_rew_mean          | -14.5       |
| time/                   |             |
|    fps                  | 99          |
|    iterations           | 38          |
|    time_elapsed         | 783         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.042113446 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0206      |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0245     |
|    value_loss           | 0.273       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85.9        |
|    ep_rew_mean          | -12.9       |
| time/                   |             |
|    fps                  | 100         |
|    iterations           | 39          |
|    time_elapsed         | 793         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.055508226 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0278     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0259     |
|    value_loss           | 0.171       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=80000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.047631063 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0144     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0209     |
|    value_loss           | 0.278       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 101      |
|    iterations      | 40       |
|    time_elapsed    | 806      |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.7        |
|    ep_rew_mean          | -13.1       |
| time/                   |             |
|    fps                  | 102         |
|    iterations           | 41          |
|    time_elapsed         | 815         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.047918722 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0445     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0241     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 84.5       |
|    ep_rew_mean          | -13.2      |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 42         |
|    time_elapsed         | 826        |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.04159501 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.61      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.001      |
|    loss                 | -0.126     |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0196    |
|    value_loss           | 0.0263     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 83.5       |
|    ep_rew_mean          | -12.8      |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 43         |
|    time_elapsed         | 836        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.03334675 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.001      |
|    loss                 | -0.077     |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0128    |
|    value_loss           | 0.0732     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.03442478 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.344      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0458     |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0267    |
|    value_loss           | 0.255      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.9     |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    fps             | 106      |
|    iterations      | 44       |
|    time_elapsed    | 848      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 78.5       |
|    ep_rew_mean          | -11.5      |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 45         |
|    time_elapsed         | 859        |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.05127132 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.53      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0598    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 82.4        |
|    ep_rew_mean          | -12.4       |
| time/                   |             |
|    fps                  | 108         |
|    iterations           | 46          |
|    time_elapsed         | 869         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.043345943 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0338     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0266     |
|    value_loss           | 0.189       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.7        |
|    ep_rew_mean          | -13.2       |
| time/                   |             |
|    fps                  | 109         |
|    iterations           | 47          |
|    time_elapsed         | 878         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.043266818 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.001       |
|    loss                 | 0.112       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0159     |
|    value_loss           | 0.172       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.8        |
|    ep_rew_mean          | -14.6       |
| time/                   |             |
|    fps                  | 110         |
|    iterations           | 48          |
|    time_elapsed         | 890         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.036343332 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0402     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.184       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.042987376 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0693      |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0202     |
|    value_loss           | 0.141       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 94.6     |
|    ep_rew_mean     | -15.1    |
| time/              |          |
|    fps             | 111      |
|    iterations      | 49       |
|    time_elapsed    | 902      |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 90.7        |
|    ep_rew_mean          | -14         |
| time/                   |             |
|    fps                  | 112         |
|    iterations           | 50          |
|    time_elapsed         | 912         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.049779315 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0765     |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0242     |
|    value_loss           | 0.256       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 81.6        |
|    ep_rew_mean          | -11.8       |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 51          |
|    time_elapsed         | 923         |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.039907627 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.001       |
|    loss                 | 0.242       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0269     |
|    value_loss           | 0.154       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76.3        |
|    ep_rew_mean          | -10.8       |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 52          |
|    time_elapsed         | 934         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.043162562 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0594     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0259     |
|    value_loss           | 0.162       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 74.6       |
|    ep_rew_mean          | -10.6      |
| time/                   |            |
|    fps                  | 114        |
|    iterations           | 53         |
|    time_elapsed         | 945        |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.05563713 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.45      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.001      |
|    loss                 | -0.028     |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0214    |
|    value_loss           | 0.208      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=110000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.038320232 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0225     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0245     |
|    value_loss           | 0.156       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 69.7     |
|    ep_rew_mean     | -9.2     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 54       |
|    time_elapsed    | 957      |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76.4        |
|    ep_rew_mean          | -10.6       |
| time/                   |             |
|    fps                  | 116         |
|    iterations           | 55          |
|    time_elapsed         | 968         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.039092034 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.47       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00102    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0249     |
|    value_loss           | 0.219       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 117       |
|    iterations           | 56        |
|    time_elapsed         | 979       |
|    total_timesteps      | 114688    |
| train/                  |           |
|    approx_kl            | 0.0402466 |
|    clip_fraction        | 0.328     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.54     |
|    explained_variance   | 0.646     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0963   |
|    n_updates            | 550       |
|    policy_gradient_loss | -0.0259   |
|    value_loss           | 0.17      |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 82.5        |
|    ep_rew_mean          | -12.1       |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 57          |
|    time_elapsed         | 990         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.043511823 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.001       |
|    loss                 | 0.28        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0248     |
|    value_loss           | 0.165       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 87.5        |
|    ep_rew_mean          | -13.1       |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 58          |
|    time_elapsed         | 1001        |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.041377626 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0584     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0252     |
|    value_loss           | 0.103       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.041037973 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.47       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.001       |
|    loss                 | 0.386       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.267       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.9     |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 119      |
|    iterations      | 59       |
|    time_elapsed    | 1013     |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 68.3        |
|    ep_rew_mean          | -8.29       |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 60          |
|    time_elapsed         | 1024        |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.053365905 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.001       |
|    loss                 | -0.011      |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0318     |
|    value_loss           | 0.167       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 65          |
|    ep_rew_mean          | -7.85       |
| time/                   |             |
|    fps                  | 120         |
|    iterations           | 61          |
|    time_elapsed         | 1035        |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.051562425 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.001       |
|    loss                 | -0.042      |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0268     |
|    value_loss           | 0.229       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 57.6        |
|    ep_rew_mean          | -6.23       |
| time/                   |             |
|    fps                  | 121         |
|    iterations           | 62          |
|    time_elapsed         | 1046        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.047879886 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0655      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0274     |
|    value_loss           | 0.107       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.6        |
|    ep_rew_mean          | -7.09       |
| time/                   |             |
|    fps                  | 121         |
|    iterations           | 63          |
|    time_elapsed         | 1058        |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.040619224 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0635      |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0276     |
|    value_loss           | 0.244       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=130000, episode_reward=3.53 +/- 0.00
Episode length: 12.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12          |
|    mean_reward          | 3.53        |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.042357698 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0163      |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0312     |
|    value_loss           | 0.241       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 53.5     |
|    ep_rew_mean     | -5.08    |
| time/              |          |
|    fps             | 122      |
|    iterations      | 64       |
|    time_elapsed    | 1068     |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.7       |
|    ep_rew_mean          | -3.1       |
| time/                   |            |
|    fps                  | 123        |
|    iterations           | 65         |
|    time_elapsed         | 1079       |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.04986093 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0455    |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.455      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41.5       |
|    ep_rew_mean          | -2.37      |
| time/                   |            |
|    fps                  | 123        |
|    iterations           | 66         |
|    time_elapsed         | 1090       |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.04585129 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0313    |
|    value_loss           | 0.258      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 48.3        |
|    ep_rew_mean          | -4.08       |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 67          |
|    time_elapsed         | 1101        |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.053920634 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.001       |
|    loss                 | 0.04        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.223       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.6        |
|    ep_rew_mean          | -5.96       |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 68          |
|    time_elapsed         | 1115        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.054721978 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0843     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.036      |
|    value_loss           | 0.198       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=140000, episode_reward=3.53 +/- 0.00
Episode length: 12.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12          |
|    mean_reward          | 3.53        |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.042793192 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.454       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00587    |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.341       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 67.1     |
|    ep_rew_mean     | -8.17    |
| time/              |          |
|    fps             | 125      |
|    iterations      | 69       |
|    time_elapsed    | 1126     |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.8        |
|    ep_rew_mean          | -9.56       |
| time/                   |             |
|    fps                  | 126         |
|    iterations           | 70          |
|    time_elapsed         | 1136        |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.054938264 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | -0.209      |
|    learning_rate        | 0.001       |
|    loss                 | 0.311       |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0423     |
|    value_loss           | 0.515       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 72.7       |
|    ep_rew_mean          | -9.12      |
| time/                   |            |
|    fps                  | 126        |
|    iterations           | 71         |
|    time_elapsed         | 1147       |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.05748102 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.45      |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0584     |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0424    |
|    value_loss           | 0.444      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 62.9        |
|    ep_rew_mean          | -6.69       |
| time/                   |             |
|    fps                  | 127         |
|    iterations           | 72          |
|    time_elapsed         | 1159        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.052990302 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.648       |
|    learning_rate        | 0.001       |
|    loss                 | 0.218       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.037      |
|    value_loss           | 0.31        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 53.1        |
|    ep_rew_mean          | -4.8        |
| time/                   |             |
|    fps                  | 127         |
|    iterations           | 73          |
|    time_elapsed         | 1169        |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.056460176 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0384     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0366     |
|    value_loss           | 0.151       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=150000, episode_reward=-7.88 +/- 15.64
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -7.88       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.060381535 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0373      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.304       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.7     |
|    ep_rew_mean     | -3.3     |
| time/              |          |
|    fps             | 128      |
|    iterations      | 74       |
|    time_elapsed    | 1182     |
|    total_timesteps | 151552   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.1        |
|    ep_rew_mean          | -1.11       |
| time/                   |             |
|    fps                  | 128         |
|    iterations           | 75          |
|    time_elapsed         | 1194        |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.052531306 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.28       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.001       |
|    loss                 | 0.303       |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.028      |
|    value_loss           | 0.249       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.7       |
|    ep_rew_mean          | -1.27      |
| time/                   |            |
|    fps                  | 129        |
|    iterations           | 76         |
|    time_elapsed         | 1204       |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.05124478 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.16      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0625     |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.269      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.3        |
|    ep_rew_mean          | -2.08       |
| time/                   |             |
|    fps                  | 129         |
|    iterations           | 77          |
|    time_elapsed         | 1215        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.051722698 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0704      |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0346     |
|    value_loss           | 0.219       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.2        |
|    ep_rew_mean          | -3.3        |
| time/                   |             |
|    fps                  | 130         |
|    iterations           | 78          |
|    time_elapsed         | 1226        |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.048833005 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0483      |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0322     |
|    value_loss           | 0.227       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=160000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.04950186 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0312    |
|    n_updates            | 780        |
|    policy_gradient_loss | -0.0325    |
|    value_loss           | 0.195      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48.5     |
|    ep_rew_mean     | -3.51    |
| time/              |          |
|    fps             | 130      |
|    iterations      | 79       |
|    time_elapsed    | 1238     |
|    total_timesteps | 161792   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.8        |
|    ep_rew_mean          | -3.9        |
| time/                   |             |
|    fps                  | 131         |
|    iterations           | 80          |
|    time_elapsed         | 1249        |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.047558527 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0926      |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.034      |
|    value_loss           | 0.357       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 49.8       |
|    ep_rew_mean          | -3.84      |
| time/                   |            |
|    fps                  | 131        |
|    iterations           | 81         |
|    time_elapsed         | 1260       |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.04858276 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.001      |
|    loss                 | 0.302      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0273    |
|    value_loss           | 0.306      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 52          |
|    ep_rew_mean          | -4.33       |
| time/                   |             |
|    fps                  | 132         |
|    iterations           | 82          |
|    time_elapsed         | 1271        |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.050776765 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0791     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.203       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.4        |
|    ep_rew_mean          | -4.16       |
| time/                   |             |
|    fps                  | 132         |
|    iterations           | 83          |
|    time_elapsed         | 1282        |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.063615546 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0114      |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0348     |
|    value_loss           | 0.127       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=170000, episode_reward=-17.16 +/- 14.77
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -17.2       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.051005207 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.28       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0534     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0307     |
|    value_loss           | 0.145       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.4     |
|    ep_rew_mean     | -2.86    |
| time/              |          |
|    fps             | 132      |
|    iterations      | 84       |
|    time_elapsed    | 1293     |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.5        |
|    ep_rew_mean          | -3          |
| time/                   |             |
|    fps                  | 133         |
|    iterations           | 85          |
|    time_elapsed         | 1304        |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.059883505 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0782      |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0364     |
|    value_loss           | 0.171       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.9       |
|    ep_rew_mean          | -2.07      |
| time/                   |            |
|    fps                  | 133        |
|    iterations           | 86         |
|    time_elapsed         | 1315       |
|    total_timesteps      | 176128     |
| train/                  |            |
|    approx_kl            | 0.05430075 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0342    |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.333      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.9       |
|    ep_rew_mean          | -1.83      |
| time/                   |            |
|    fps                  | 134        |
|    iterations           | 87         |
|    time_elapsed         | 1326       |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.05170698 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.22      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0221    |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.319      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=180000, episode_reward=-28.33 +/- 2.36
Episode length: 150.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 150       |
|    mean_reward          | -28.3     |
| time/                   |           |
|    total_timesteps      | 180000    |
| train/                  |           |
|    approx_kl            | 0.0663602 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.21     |
|    explained_variance   | 0.813     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0022   |
|    n_updates            | 870       |
|    policy_gradient_loss | -0.0372   |
|    value_loss           | 0.227     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44       |
|    ep_rew_mean     | -2.55    |
| time/              |          |
|    fps             | 134      |
|    iterations      | 88       |
|    time_elapsed    | 1338     |
|    total_timesteps | 180224   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.2        |
|    ep_rew_mean          | -1          |
| time/                   |             |
|    fps                  | 135         |
|    iterations           | 89          |
|    time_elapsed         | 1349        |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.054094918 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0375     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0359     |
|    value_loss           | 0.23        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38         |
|    ep_rew_mean          | -0.577     |
| time/                   |            |
|    fps                  | 135        |
|    iterations           | 90         |
|    time_elapsed         | 1360       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.06670293 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | -0.027     |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.257      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.4       |
|    ep_rew_mean          | -2.27      |
| time/                   |            |
|    fps                  | 135        |
|    iterations           | 91         |
|    time_elapsed         | 1371       |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.05461006 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.09      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0356     |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.378      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.1        |
|    ep_rew_mean          | -2.62       |
| time/                   |             |
|    fps                  | 136         |
|    iterations           | 92          |
|    time_elapsed         | 1381        |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.055565238 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0685     |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0377     |
|    value_loss           | 0.164       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=190000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.05624128 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.16      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.001      |
|    loss                 | -0.105     |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0348    |
|    value_loss           | 0.22       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.6     |
|    ep_rew_mean     | -2.68    |
| time/              |          |
|    fps             | 136      |
|    iterations      | 93       |
|    time_elapsed    | 1393     |
|    total_timesteps | 190464   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 42.5        |
|    ep_rew_mean          | -2.14       |
| time/                   |             |
|    fps                  | 137         |
|    iterations           | 94          |
|    time_elapsed         | 1404        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.048487034 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0416     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.258       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | -0.803      |
| time/                   |             |
|    fps                  | 137         |
|    iterations           | 95          |
|    time_elapsed         | 1415        |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.062457334 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0784     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.219       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.8        |
|    ep_rew_mean          | -1.48       |
| time/                   |             |
|    fps                  | 137         |
|    iterations           | 96          |
|    time_elapsed         | 1425        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.051205505 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0678      |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0319     |
|    value_loss           | 0.268       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.9        |
|    ep_rew_mean          | -2.51       |
| time/                   |             |
|    fps                  | 138         |
|    iterations           | 97          |
|    time_elapsed         | 1436        |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.068607196 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0428      |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0415     |
|    value_loss           | 0.222       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=200000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.06336106 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.23      |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0405    |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.186      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.6     |
|    ep_rew_mean     | -1.81    |
| time/              |          |
|    fps             | 138      |
|    iterations      | 98       |
|    time_elapsed    | 1447     |
|    total_timesteps | 200704   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | -0.307      |
| time/                   |             |
|    fps                  | 139         |
|    iterations           | 99          |
|    time_elapsed         | 1458        |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.059497617 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0654     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.031      |
|    value_loss           | 0.283       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.2        |
|    ep_rew_mean          | 0.325       |
| time/                   |             |
|    fps                  | 139         |
|    iterations           | 100         |
|    time_elapsed         | 1468        |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.061168317 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0279     |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0364     |
|    value_loss           | 0.427       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.5       |
|    ep_rew_mean          | -0.735     |
| time/                   |            |
|    fps                  | 139        |
|    iterations           | 101        |
|    time_elapsed         | 1479       |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.09083005 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.001      |
|    loss                 | 0.041      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.0506    |
|    value_loss           | 0.287      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.2        |
|    ep_rew_mean          | -1.16       |
| time/                   |             |
|    fps                  | 140         |
|    iterations           | 102         |
|    time_elapsed         | 1490        |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.093698144 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0122      |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0389     |
|    value_loss           | 0.191       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=210000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.069563806 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | 0.311       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0289     |
|    value_loss           | 0.244       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 39.1     |
|    ep_rew_mean     | -1.23    |
| time/              |          |
|    fps             | 140      |
|    iterations      | 103      |
|    time_elapsed    | 1502     |
|    total_timesteps | 210944   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.7       |
|    ep_rew_mean          | 0.729      |
| time/                   |            |
|    fps                  | 140        |
|    iterations           | 104        |
|    time_elapsed         | 1512       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.06202286 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0706    |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.195      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.1       |
|    ep_rew_mean          | -0.67      |
| time/                   |            |
|    fps                  | 141        |
|    iterations           | 105        |
|    time_elapsed         | 1523       |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.06520425 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.892     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00308   |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0316    |
|    value_loss           | 0.17       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 38.8      |
|    ep_rew_mean          | -0.992    |
| time/                   |           |
|    fps                  | 141       |
|    iterations           | 106       |
|    time_elapsed         | 1533      |
|    total_timesteps      | 217088    |
| train/                  |           |
|    approx_kl            | 0.0793356 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.1      |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.001     |
|    loss                 | -0.00813  |
|    n_updates            | 1050      |
|    policy_gradient_loss | -0.0309   |
|    value_loss           | 0.17      |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36         |
|    ep_rew_mean          | 0.295      |
| time/                   |            |
|    fps                  | 141        |
|    iterations           | 107        |
|    time_elapsed         | 1544       |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.06922759 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.03      |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00558   |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.0263    |
|    value_loss           | 0.235      |
----------------------------------------
Eval num_timesteps=220000, episode_reward=3.53 +/- 0.00
Episode length: 12.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12         |
|    mean_reward          | 3.53       |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.05735732 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.998     |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00219    |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.28       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.9     |
|    ep_rew_mean     | 0.268    |
| time/              |          |
|    fps             | 142      |
|    iterations      | 108      |
|    time_elapsed    | 1555     |
|    total_timesteps | 221184   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.6       |
|    ep_rew_mean          | 0.375      |
| time/                   |            |
|    fps                  | 142        |
|    iterations           | 109        |
|    time_elapsed         | 1565       |
|    total_timesteps      | 223232     |
| train/                  |            |
|    approx_kl            | 0.07178357 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.001      |
|    loss                 | 0.118      |
|    n_updates            | 1080       |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.271      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.9       |
|    ep_rew_mean          | 0.331      |
| time/                   |            |
|    fps                  | 142        |
|    iterations           | 110        |
|    time_elapsed         | 1576       |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.06844352 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.943     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0967     |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0269    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.8       |
|    ep_rew_mean          | 0.595      |
| time/                   |            |
|    fps                  | 143        |
|    iterations           | 111        |
|    time_elapsed         | 1587       |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.07382301 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.983     |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.001      |
|    loss                 | -0.025     |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.037     |
|    value_loss           | 0.225      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | 0.618       |
| time/                   |             |
|    fps                  | 143         |
|    iterations           | 112         |
|    time_elapsed         | 1599        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.059290797 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.962      |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00506    |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0259     |
|    value_loss           | 0.223       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=230000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 104       |
|    mean_reward          | -18.8     |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0733656 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.02     |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0531   |
|    n_updates            | 1120      |
|    policy_gradient_loss | -0.0391   |
|    value_loss           | 0.198     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 2.17     |
| time/              |          |
|    fps             | 143      |
|    iterations      | 113      |
|    time_elapsed    | 1610     |
|    total_timesteps | 231424   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 2.06       |
| time/                   |            |
|    fps                  | 144        |
|    iterations           | 114        |
|    time_elapsed         | 1621       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.06249973 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.895     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | -0.051     |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.289      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.9        |
|    ep_rew_mean          | 1.2         |
| time/                   |             |
|    fps                  | 144         |
|    iterations           | 115         |
|    time_elapsed         | 1631        |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.059464104 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.899      |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.001       |
|    loss                 | 0.107       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0328     |
|    value_loss           | 0.358       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29         |
|    ep_rew_mean          | 1.47       |
| time/                   |            |
|    fps                  | 144        |
|    iterations           | 116        |
|    time_elapsed         | 1642       |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.07700147 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.897     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0429    |
|    n_updates            | 1150       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.188      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.4        |
|    ep_rew_mean          | 1.05        |
| time/                   |             |
|    fps                  | 144         |
|    iterations           | 117         |
|    time_elapsed         | 1654        |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.063875616 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.923      |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0172     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.251       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=240000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.060030304 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.001       |
|    loss                 | -0.051      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.179       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.8     |
|    ep_rew_mean     | 0.176    |
| time/              |          |
|    fps             | 145      |
|    iterations      | 118      |
|    time_elapsed    | 1665     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.7        |
|    ep_rew_mean          | 0.758       |
| time/                   |             |
|    fps                  | 145         |
|    iterations           | 119         |
|    time_elapsed         | 1675        |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.082175836 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.97       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00682    |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0362     |
|    value_loss           | 0.241       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.1       |
|    ep_rew_mean          | -0.37      |
| time/                   |            |
|    fps                  | 145        |
|    iterations           | 120        |
|    time_elapsed         | 1686       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.07768677 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.955     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.001      |
|    loss                 | -0.029     |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.0341    |
|    value_loss           | 0.21       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.3       |
|    ep_rew_mean          | -1.24      |
| time/                   |            |
|    fps                  | 145        |
|    iterations           | 121        |
|    time_elapsed         | 1697       |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.06547239 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0469    |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.0355    |
|    value_loss           | 0.254      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.6       |
|    ep_rew_mean          | 0.517      |
| time/                   |            |
|    fps                  | 146        |
|    iterations           | 122        |
|    time_elapsed         | 1708       |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.05966706 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0644    |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0351    |
|    value_loss           | 0.128      |
----------------------------------------
Eval num_timesteps=250000, episode_reward=4.44 +/- 2.75
Episode length: 15.67 +/- 2.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 15.7        |
|    mean_reward          | 4.44        |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.047960356 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0219     |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.208       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.7     |
|    ep_rew_mean     | -0.419   |
| time/              |          |
|    fps             | 146      |
|    iterations      | 123      |
|    time_elapsed    | 1719     |
|    total_timesteps | 251904   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32          |
|    ep_rew_mean          | 0.385       |
| time/                   |             |
|    fps                  | 146         |
|    iterations           | 124         |
|    time_elapsed         | 1730        |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.062682346 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0274     |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0386     |
|    value_loss           | 0.217       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.5       |
|    ep_rew_mean          | 1.48       |
| time/                   |            |
|    fps                  | 146        |
|    iterations           | 125        |
|    time_elapsed         | 1741       |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.06326773 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.934     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0137    |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.212      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.5        |
|    ep_rew_mean          | 1.1         |
| time/                   |             |
|    fps                  | 147         |
|    iterations           | 126         |
|    time_elapsed         | 1752        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.055477872 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.898      |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0452      |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0325     |
|    value_loss           | 0.209       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=260000, episode_reward=-6.19 +/- 16.93
Episode length: 59.00 +/- 64.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -6.19      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.06378232 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.962     |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0862    |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0392    |
|    value_loss           | 0.178      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.9     |
|    ep_rew_mean     | 0.933    |
| time/              |          |
|    fps             | 147      |
|    iterations      | 127      |
|    time_elapsed    | 1765     |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.7        |
|    ep_rew_mean          | 2.02        |
| time/                   |             |
|    fps                  | 147         |
|    iterations           | 128         |
|    time_elapsed         | 1775        |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.067024715 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00968    |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.0378     |
|    value_loss           | 0.217       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.9       |
|    ep_rew_mean          | 1.02       |
| time/                   |            |
|    fps                  | 147        |
|    iterations           | 129        |
|    time_elapsed         | 1786       |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.06280674 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.94      |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.001      |
|    loss                 | 0.189      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.0405    |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28         |
|    ep_rew_mean          | 1.63       |
| time/                   |            |
|    fps                  | 148        |
|    iterations           | 130        |
|    time_elapsed         | 1797       |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.07249108 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.905     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | 0.114      |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.16       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.7        |
|    ep_rew_mean          | 1.99        |
| time/                   |             |
|    fps                  | 148         |
|    iterations           | 131         |
|    time_elapsed         | 1809        |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.061817467 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.974      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.001       |
|    loss                 | 0.205       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0348     |
|    value_loss           | 0.257       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=270000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.07192692 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.943     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0743    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.291      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.8     |
|    ep_rew_mean     | 2.27     |
| time/              |          |
|    fps             | 148      |
|    iterations      | 132      |
|    time_elapsed    | 1820     |
|    total_timesteps | 270336   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.8        |
|    ep_rew_mean          | 2.12        |
| time/                   |             |
|    fps                  | 148         |
|    iterations           | 133         |
|    time_elapsed         | 1831        |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.054499827 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.873      |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0632     |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0316     |
|    value_loss           | 0.347       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.3       |
|    ep_rew_mean          | 1.49       |
| time/                   |            |
|    fps                  | 149        |
|    iterations           | 134        |
|    time_elapsed         | 1841       |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.05850465 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.977     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0356     |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.0385    |
|    value_loss           | 0.215      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.3        |
|    ep_rew_mean          | 1.01        |
| time/                   |             |
|    fps                  | 149         |
|    iterations           | 135         |
|    time_elapsed         | 1852        |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.064865425 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.001       |
|    loss                 | 0.085       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0356     |
|    value_loss           | 0.271       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.5       |
|    ep_rew_mean          | 0.691      |
| time/                   |            |
|    fps                  | 149        |
|    iterations           | 136        |
|    time_elapsed         | 1863       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.06732824 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0418     |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0414    |
|    value_loss           | 0.221      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=-19.13 +/- 15.73
Episode length: 104.67 +/- 64.11
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 105       |
|    mean_reward          | -19.1     |
| time/                   |           |
|    total_timesteps      | 280000    |
| train/                  |           |
|    approx_kl            | 0.0748702 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.16     |
|    explained_variance   | 0.887     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0116   |
|    n_updates            | 1360      |
|    policy_gradient_loss | -0.0397   |
|    value_loss           | 0.178     |
---------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.3     |
|    ep_rew_mean     | 0.597    |
| time/              |          |
|    fps             | 149      |
|    iterations      | 137      |
|    time_elapsed    | 1874     |
|    total_timesteps | 280576   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34          |
|    ep_rew_mean          | 1.27        |
| time/                   |             |
|    fps                  | 149         |
|    iterations           | 138         |
|    time_elapsed         | 1886        |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.054162495 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.663       |
|    learning_rate        | 0.001       |
|    loss                 | -0.000312   |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0302     |
|    value_loss           | 0.724       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 2.41       |
| time/                   |            |
|    fps                  | 150        |
|    iterations           | 139        |
|    time_elapsed         | 1897       |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.08704132 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.001      |
|    loss                 | 0.673      |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0423    |
|    value_loss           | 0.409      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.3       |
|    ep_rew_mean          | 1.67       |
| time/                   |            |
|    fps                  | 150        |
|    iterations           | 140        |
|    time_elapsed         | 1908       |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.09433335 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.933     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0224     |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 0.29       |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 33        |
|    ep_rew_mean          | 1.26      |
| time/                   |           |
|    fps                  | 150       |
|    iterations           | 141       |
|    time_elapsed         | 1919      |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0667928 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.05     |
|    explained_variance   | 0.812     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0342    |
|    n_updates            | 1400      |
|    policy_gradient_loss | -0.0388   |
|    value_loss           | 0.265     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=290000, episode_reward=-18.96 +/- 15.61
Episode length: 104.67 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -19        |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.06296474 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.981     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0552     |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0394    |
|    value_loss           | 0.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.8     |
|    ep_rew_mean     | 1.78     |
| time/              |          |
|    fps             | 150      |
|    iterations      | 142      |
|    time_elapsed    | 1930     |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.9        |
|    ep_rew_mean          | 2.2         |
| time/                   |             |
|    fps                  | 150         |
|    iterations           | 143         |
|    time_elapsed         | 1941        |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.072625235 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0222     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0345     |
|    value_loss           | 0.197       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.41       |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 144        |
|    time_elapsed         | 1952       |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.08710144 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.929     |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0671     |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0503    |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.5       |
|    ep_rew_mean          | 1.91       |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 145        |
|    time_elapsed         | 1963       |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.06657575 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.901     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0327    |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.223      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35          |
|    ep_rew_mean          | 0.854       |
| time/                   |             |
|    fps                  | 151         |
|    iterations           | 146         |
|    time_elapsed         | 1974        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.065409064 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.927      |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.001       |
|    loss                 | -0.025      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.218       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=300000, episode_reward=-18.96 +/- 15.61
Episode length: 104.67 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -19        |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.07257335 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.951     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | 0.000825   |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0326    |
|    value_loss           | 0.217      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.1     |
|    ep_rew_mean     | 0.781    |
| time/              |          |
|    fps             | 151      |
|    iterations      | 147      |
|    time_elapsed    | 1985     |
|    total_timesteps | 301056   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.11       |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 148        |
|    time_elapsed         | 1996       |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.10153742 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.932     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.001      |
|    loss                 | 0.217      |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.218      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 3.17        |
| time/                   |             |
|    fps                  | 152         |
|    iterations           | 149         |
|    time_elapsed         | 2006        |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.074733615 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.001       |
|    loss                 | -0.0309     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.038      |
|    value_loss           | 0.157       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.9        |
|    ep_rew_mean          | 3           |
| time/                   |             |
|    fps                  | 152         |
|    iterations           | 150         |
|    time_elapsed         | 2017        |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.061232165 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.761      |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.001       |
|    loss                 | 0.0208      |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0393     |
|    value_loss           | 0.333       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.2       |
|    ep_rew_mean          | 2.84       |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 151        |
|    time_elapsed         | 2028       |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.05915626 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.813     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0367     |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.318      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=310000, episode_reward=-18.99 +/- 15.92
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -19        |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.06400081 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.759     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0152    |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.292      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.3     |
|    ep_rew_mean     | 2.06     |
| time/              |          |
|    fps             | 152      |
|    iterations      | 152      |
|    time_elapsed    | 2040     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28         |
|    ep_rew_mean          | 1.72       |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 153        |
|    time_elapsed         | 2051       |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.07407357 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.863     |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.001      |
|    loss                 | 0.119      |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.0264    |
|    value_loss           | 0.254      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 1.57       |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 154        |
|    time_elapsed         | 2062       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.07267757 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.824     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0282     |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0377    |
|    value_loss           | 0.235      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 2.8        |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 155        |
|    time_elapsed         | 2073       |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.06182793 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.861     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0768    |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 2.21       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 156        |
|    time_elapsed         | 2086       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.08609933 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.814     |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.001      |
|    loss                 | 0.277      |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0403    |
|    value_loss           | 0.248      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=320000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.061420668 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.855      |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0831      |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0299     |
|    value_loss           | 0.241       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 2.55     |
| time/              |          |
|    fps             | 153      |
|    iterations      | 157      |
|    time_elapsed    | 2099     |
|    total_timesteps | 321536   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 1.57       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 158        |
|    time_elapsed         | 2111       |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.06428275 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.878     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00848    |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.0401    |
|    value_loss           | 0.272      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.7        |
|    ep_rew_mean          | 1.05        |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 159         |
|    time_elapsed         | 2122        |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.078451365 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.862      |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0171      |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.287       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.68       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 160        |
|    time_elapsed         | 2134       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.08550545 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.997     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | 0.000404   |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.181      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 2.72       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 161        |
|    time_elapsed         | 2147       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.06674634 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.88      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.001      |
|    loss                 | 0.146      |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.277      |
----------------------------------------
reached max steps=300
Eval num_timesteps=330000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58         |
|    mean_reward          | -7.65      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.07024068 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.832     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | 0.104      |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.273      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 2.28     |
| time/              |          |
|    fps             | 153      |
|    iterations      | 162      |
|    time_elapsed    | 2160     |
|    total_timesteps | 331776   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 1.96       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 163        |
|    time_elapsed         | 2177       |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.05785343 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.922     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0177     |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.259      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.9        |
|    ep_rew_mean          | 2.3         |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 164         |
|    time_elapsed         | 2190        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.071769394 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.87       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0451     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0369     |
|    value_loss           | 0.266       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.6       |
|    ep_rew_mean          | 2.31       |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 165        |
|    time_elapsed         | 2201       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.07097164 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.822     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0216    |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0326    |
|    value_loss           | 0.229      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.1        |
|    ep_rew_mean          | 1.77        |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 166         |
|    time_elapsed         | 2212        |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.069571584 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.911      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0699     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0329     |
|    value_loss           | 0.16        |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=340000, episode_reward=-17.16 +/- 14.77
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -17.2       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.073504806 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.909      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.001       |
|    loss                 | 0.129       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0418     |
|    value_loss           | 0.266       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 2.27     |
| time/              |          |
|    fps             | 153      |
|    iterations      | 167      |
|    time_elapsed    | 2221     |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.1        |
|    ep_rew_mean          | 3.15        |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 168         |
|    time_elapsed         | 2232        |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.066122405 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.907      |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0115      |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.0356     |
|    value_loss           | 0.27        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31          |
|    ep_rew_mean          | 1.93        |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 169         |
|    time_elapsed         | 2245        |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.068562984 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.845      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00792    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0405     |
|    value_loss           | 0.258       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.9      |
|    ep_rew_mean          | 2.79      |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 170       |
|    time_elapsed         | 2258      |
|    total_timesteps      | 348160    |
| train/                  |           |
|    approx_kl            | 0.0592401 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.01     |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0246   |
|    n_updates            | 1690      |
|    policy_gradient_loss | -0.0413   |
|    value_loss           | 0.216     |
---------------------------------------
reached max steps=300
Eval num_timesteps=350000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.058679976 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.814      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00625     |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0411     |
|    value_loss           | 0.259       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 2.09     |
| time/              |          |
|    fps             | 154      |
|    iterations      | 171      |
|    time_elapsed    | 2272     |
|    total_timesteps | 350208   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 2.19       |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 172        |
|    time_elapsed         | 2284       |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.07477503 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.976     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0628    |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.193      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 3.16       |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 173        |
|    time_elapsed         | 2295       |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.06669396 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.939     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0597    |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.189      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 1.96       |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 174        |
|    time_elapsed         | 2306       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.07077645 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.814     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0322     |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0394    |
|    value_loss           | 0.344      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.5       |
|    ep_rew_mean          | 2.14       |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 175        |
|    time_elapsed         | 2319       |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.07643229 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.978     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0817     |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0463    |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=360000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 104      |
|    mean_reward          | -18.8    |
| time/                   |          |
|    total_timesteps      | 360000   |
| train/                  |          |
|    approx_kl            | 0.06054  |
|    clip_fraction        | 0.331    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.907   |
|    explained_variance   | 0.902    |
|    learning_rate        | 0.001    |
|    loss                 | 0.0281   |
|    n_updates            | 1750     |
|    policy_gradient_loss | -0.0345  |
|    value_loss           | 0.165    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.7     |
|    ep_rew_mean     | 1.89     |
| time/              |          |
|    fps             | 154      |
|    iterations      | 176      |
|    time_elapsed    | 2332     |
|    total_timesteps | 360448   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.3        |
|    ep_rew_mean          | 2.21        |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 177         |
|    time_elapsed         | 2342        |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.082556635 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.926      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.001       |
|    loss                 | 2.51        |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00589    |
|    value_loss           | 0.206       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.5        |
|    ep_rew_mean          | 3.08        |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 178         |
|    time_elapsed         | 2351        |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.074875355 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.969      |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.001       |
|    loss                 | 0.111       |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.037      |
|    value_loss           | 0.258       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.8        |
|    ep_rew_mean          | 2.55        |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 179         |
|    time_elapsed         | 2360        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.052713398 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.873      |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0913      |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0283     |
|    value_loss           | 0.308       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.1        |
|    ep_rew_mean          | 1.81        |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 180         |
|    time_elapsed         | 2368        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.079368964 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.862      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0418     |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0396     |
|    value_loss           | 0.263       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=370000, episode_reward=-17.64 +/- 17.48
Episode length: 106.33 +/- 61.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 106        |
|    mean_reward          | -17.6      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.06851938 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.937     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0431    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.164      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.7     |
|    ep_rew_mean     | 3.21     |
| time/              |          |
|    fps             | 155      |
|    iterations      | 181      |
|    time_elapsed    | 2377     |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.7        |
|    ep_rew_mean          | 2.17        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 182         |
|    time_elapsed         | 2386        |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.068009034 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.823      |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.001       |
|    loss                 | -0.07       |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0384     |
|    value_loss           | 0.174       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 1.55       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 183        |
|    time_elapsed         | 2394       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.06936827 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.841     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0614    |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.284      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.9        |
|    ep_rew_mean          | 3.02        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 184         |
|    time_elapsed         | 2402        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.089342885 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.931      |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0326      |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0387     |
|    value_loss           | 0.229       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 2.42       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 185        |
|    time_elapsed         | 2411       |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.06475691 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.881     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.001      |
|    loss                 | -0.051     |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.261      |
----------------------------------------
reached max steps=300
Eval num_timesteps=380000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -7.65       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.061325453 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.811      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0161     |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0394     |
|    value_loss           | 0.212       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 2.92     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 186      |
|    time_elapsed    | 2420     |
|    total_timesteps | 380928   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 3.44       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 187        |
|    time_elapsed         | 2430       |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.07688986 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.751     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0813     |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.299      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 2.52       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 188        |
|    time_elapsed         | 2441       |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.12511028 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.763     |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.001      |
|    loss                 | 0.431      |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.325      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 2.92       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 189        |
|    time_elapsed         | 2451       |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.06272087 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.842     |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.001      |
|    loss                 | 0.154      |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.408      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.6        |
|    ep_rew_mean          | 2.79        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 190         |
|    time_elapsed         | 2463        |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.063948244 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.82       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0404      |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0306     |
|    value_loss           | 0.249       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=390000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -6.05      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.06863688 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.695     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0163    |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.34       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 3.02     |
| time/              |          |
|    fps             | 158      |
|    iterations      | 191      |
|    time_elapsed    | 2472     |
|    total_timesteps | 391168   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 3.53       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 192        |
|    time_elapsed         | 2485       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.06082896 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.704     |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.001      |
|    loss                 | 0.122      |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.0147    |
|    value_loss           | 0.348      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 2.49       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 193        |
|    time_elapsed         | 2496       |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.07151129 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.652     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0228     |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.298      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.9        |
|    ep_rew_mean          | 2.75        |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 194         |
|    time_elapsed         | 2508        |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.092908315 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.802      |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0324     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0403     |
|    value_loss           | 0.216       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 3.09       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 195        |
|    time_elapsed         | 2522       |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.08083743 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.854     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0996     |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.303      |
----------------------------------------
reached max steps=300
Eval num_timesteps=400000, episode_reward=-7.79 +/- 15.71
Episode length: 58.67 +/- 64.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -7.79      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.07484318 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.814     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0419     |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0355    |
|    value_loss           | 0.206      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.4     |
|    ep_rew_mean     | 1.61     |
| time/              |          |
|    fps             | 158      |
|    iterations      | 196      |
|    time_elapsed    | 2537     |
|    total_timesteps | 401408   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.1       |
|    ep_rew_mean          | 2.35       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 197        |
|    time_elapsed         | 2548       |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.07294382 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.878     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0621    |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.188      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 2.56        |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 198         |
|    time_elapsed         | 2558        |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.080680154 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.855      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0516      |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0401     |
|    value_loss           | 0.25        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 3.78       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 199        |
|    time_elapsed         | 2566       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07711998 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.759     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0464    |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.204      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 3.13       |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 200        |
|    time_elapsed         | 2575       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.05953768 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.631     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | 0.257      |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.287      |
----------------------------------------
Eval num_timesteps=410000, episode_reward=3.29 +/- 0.33
Episode length: 12.33 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.3       |
|    mean_reward          | 3.29       |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.07139398 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.772     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0498    |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.195      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 3.92     |
| time/              |          |
|    fps             | 159      |
|    iterations      | 201      |
|    time_elapsed    | 2583     |
|    total_timesteps | 411648   |
---------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 28.6      |
|    ep_rew_mean          | 2.1       |
| time/                   |           |
|    fps                  | 159       |
|    iterations           | 202       |
|    time_elapsed         | 2592      |
|    total_timesteps      | 413696    |
| train/                  |           |
|    approx_kl            | 0.0635453 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.718    |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0667   |
|    n_updates            | 2010      |
|    policy_gradient_loss | -0.0339   |
|    value_loss           | 0.279     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 3.54       |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 203        |
|    time_elapsed         | 2601       |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.07586487 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.909     |
|    explained_variance   | 0.82       |
|    learning_rate        | 0.001      |
|    loss                 | 0.607      |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.042     |
|    value_loss           | 0.262      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.5        |
|    ep_rew_mean          | 2.93        |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 204         |
|    time_elapsed         | 2609        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.062483594 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.644      |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0577      |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0379     |
|    value_loss           | 0.368       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 3.59       |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 205        |
|    time_elapsed         | 2618       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.07653057 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | -0.069     |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.036     |
|    value_loss           | 0.184      |
----------------------------------------
reached max steps=300
Eval num_timesteps=420000, episode_reward=-6.19 +/- 16.93
Episode length: 59.00 +/- 64.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 59          |
|    mean_reward          | -6.19       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.055841196 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.705      |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0103      |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.03       |
|    value_loss           | 0.328       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 4.01     |
| time/              |          |
|    fps             | 160      |
|    iterations      | 206      |
|    time_elapsed    | 2627     |
|    total_timesteps | 421888   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.5        |
|    ep_rew_mean          | 2.63        |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 207         |
|    time_elapsed         | 2636        |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.083248444 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.608      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.001       |
|    loss                 | 0.162       |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0295     |
|    value_loss           | 0.311       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 2.58       |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 208        |
|    time_elapsed         | 2649       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.08661151 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.836     |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00194   |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0214    |
|    value_loss           | 0.18       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 2.02       |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 209        |
|    time_elapsed         | 2661       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.05346463 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.914     |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0283    |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.277      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=3.53 +/- 0.00
Episode length: 12.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12         |
|    mean_reward          | 3.53       |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.07668874 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.821     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0553    |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.221      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.6     |
|    ep_rew_mean     | 2.65     |
| time/              |          |
|    fps             | 160      |
|    iterations      | 210      |
|    time_elapsed    | 2672     |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 3.29       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 211        |
|    time_elapsed         | 2683       |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.06925297 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.789     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.001      |
|    loss                 | 0.000669   |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0317    |
|    value_loss           | 0.338      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.3        |
|    ep_rew_mean          | 2.54        |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 212         |
|    time_elapsed         | 2693        |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.060615525 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.724      |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0354      |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.341       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 3.25       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 213        |
|    time_elapsed         | 2705       |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.07611503 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.847     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0441     |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.248      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.9      |
|    ep_rew_mean          | 2.11      |
| time/                   |           |
|    fps                  | 161       |
|    iterations           | 214       |
|    time_elapsed         | 2716      |
|    total_timesteps      | 438272    |
| train/                  |           |
|    approx_kl            | 0.0550413 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.818    |
|    explained_variance   | 0.882     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0709   |
|    n_updates            | 2130      |
|    policy_gradient_loss | -0.0239   |
|    value_loss           | 0.2       |
---------------------------------------
reached max steps=300
Eval num_timesteps=440000, episode_reward=-6.19 +/- 16.97
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -6.19      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.07190217 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.873     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0392    |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0338    |
|    value_loss           | 0.254      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.5     |
|    ep_rew_mean     | 3.09     |
| time/              |          |
|    fps             | 161      |
|    iterations      | 215      |
|    time_elapsed    | 2726     |
|    total_timesteps | 440320   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 2.46       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 216        |
|    time_elapsed         | 2735       |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.06946338 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.76      |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0178    |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0361    |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 2.35       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 217        |
|    time_elapsed         | 2745       |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.06184924 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.82      |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0359    |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.197      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 2.15        |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 218         |
|    time_elapsed         | 2755        |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.090265356 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.835      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0166      |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.276       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 2.47       |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 219        |
|    time_elapsed         | 2765       |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.07510297 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.941     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0495    |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=450000, episode_reward=-4.45 +/- 18.48
Episode length: 58.67 +/- 64.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.7        |
|    mean_reward          | -4.45       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.080586284 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.806      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.001       |
|    loss                 | 0.187       |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0277     |
|    value_loss           | 0.304       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.3     |
|    ep_rew_mean     | 2.75     |
| time/              |          |
|    fps             | 162      |
|    iterations      | 220      |
|    time_elapsed    | 2774     |
|    total_timesteps | 450560   |
---------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.8      |
|    ep_rew_mean          | 3.21      |
| time/                   |           |
|    fps                  | 162       |
|    iterations           | 221       |
|    time_elapsed         | 2786      |
|    total_timesteps      | 452608    |
| train/                  |           |
|    approx_kl            | 0.0814383 |
|    clip_fraction        | 0.286     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.699    |
|    explained_variance   | 0.803     |
|    learning_rate        | 0.001     |
|    loss                 | 0.167     |
|    n_updates            | 2200      |
|    policy_gradient_loss | -0.0346   |
|    value_loss           | 0.302     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 2.3        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 222        |
|    time_elapsed         | 2796       |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.07771051 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.724     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0203    |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0262    |
|    value_loss           | 0.229      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25          |
|    ep_rew_mean          | 2.33        |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 223         |
|    time_elapsed         | 2806        |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.058287006 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.721      |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0209     |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0285     |
|    value_loss           | 0.296       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 3.41        |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 224         |
|    time_elapsed         | 2816        |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.083949104 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.759      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0263     |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.042      |
|    value_loss           | 0.233       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=460000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -7.65       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.063013926 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.652      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0449      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0334     |
|    value_loss           | 0.345       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.8     |
|    ep_rew_mean     | 3.26     |
| time/              |          |
|    fps             | 162      |
|    iterations      | 225      |
|    time_elapsed    | 2828     |
|    total_timesteps | 460800   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.7        |
|    ep_rew_mean          | 2.98        |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 226         |
|    time_elapsed         | 2838        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.063001126 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00478    |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0239     |
|    value_loss           | 0.297       |
-----------------------------------------
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 22       |
|    ep_rew_mean          | 3.19     |
| time/                   |          |
|    fps                  | 163      |
|    iterations           | 227      |
|    time_elapsed         | 2847     |
|    total_timesteps      | 464896   |
| train/                  |          |
|    approx_kl            | 0.140447 |
|    clip_fraction        | 0.307    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.733   |
|    explained_variance   | 0.753    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0408  |
|    n_updates            | 2260     |
|    policy_gradient_loss | -0.0529  |
|    value_loss           | 0.237    |
--------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.8        |
|    ep_rew_mean          | 3.07        |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 228         |
|    time_elapsed         | 2857        |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.073008254 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.7        |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0759      |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.319       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 3.73        |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 229         |
|    time_elapsed         | 2867        |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.059700467 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.78       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0241      |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.248       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=470000, episode_reward=4.99 +/- 2.07
Episode length: 13.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 4.99       |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.09382153 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0768    |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0316    |
|    value_loss           | 0.327      |
----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 2.46     |
| time/              |          |
|    fps             | 163      |
|    iterations      | 230      |
|    time_elapsed    | 2876     |
|    total_timesteps | 471040   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.75       |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 231        |
|    time_elapsed         | 2886       |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.07277605 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.776     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0542    |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.1        |
|    ep_rew_mean          | 1.92        |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 232         |
|    time_elapsed         | 2896        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.096216105 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.804      |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0459     |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0309     |
|    value_loss           | 0.326       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 3.82       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 233        |
|    time_elapsed         | 2906       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.07052551 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.774     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0696     |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0156    |
|    value_loss           | 0.163      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.7      |
|    ep_rew_mean          | 1.98      |
| time/                   |           |
|    fps                  | 164       |
|    iterations           | 234       |
|    time_elapsed         | 2916      |
|    total_timesteps      | 479232    |
| train/                  |           |
|    approx_kl            | 0.0771547 |
|    clip_fraction        | 0.28      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.638    |
|    explained_variance   | 0.871     |
|    learning_rate        | 0.001     |
|    loss                 | -0.017    |
|    n_updates            | 2330      |
|    policy_gradient_loss | -0.0346   |
|    value_loss           | 0.242     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=480000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -18.8       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.075758114 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.712      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0282      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0301     |
|    value_loss           | 0.14        |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | 2.91     |
| time/              |          |
|    fps             | 164      |
|    iterations      | 235      |
|    time_elapsed    | 2926     |
|    total_timesteps | 481280   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.01       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 236        |
|    time_elapsed         | 2937       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.08393128 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.756     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0966     |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.228      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.8       |
|    ep_rew_mean          | 1.73       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 237        |
|    time_elapsed         | 2947       |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.08794626 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.609     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0295     |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.283      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.5       |
|    ep_rew_mean          | 1.32       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 238        |
|    time_elapsed         | 2957       |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.08147818 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.944     |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0108     |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.0402    |
|    value_loss           | 0.179      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 3.29       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 239        |
|    time_elapsed         | 2967       |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.07900119 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.778     |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0689     |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.244      |
----------------------------------------
reached max steps=300
Eval num_timesteps=490000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58         |
|    mean_reward          | -7.65      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.08847116 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.618     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0245    |
|    n_updates            | 2390       |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.222      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.9     |
|    ep_rew_mean     | 2.75     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 240      |
|    time_elapsed    | 2978     |
|    total_timesteps | 491520   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.8       |
|    ep_rew_mean          | 3.23       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 241        |
|    time_elapsed         | 2988       |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.09312067 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.756     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0539    |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.176      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.7       |
|    ep_rew_mean          | 2.03       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 242        |
|    time_elapsed         | 3000       |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.07381968 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.707     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0315     |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0227    |
|    value_loss           | 0.301      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 2.09       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 243        |
|    time_elapsed         | 3012       |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.08275415 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.782     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0126    |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.0368    |
|    value_loss           | 0.23       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 3.84       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 244        |
|    time_elapsed         | 3022       |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.07043907 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.658     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00967   |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.258      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=500000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.06589797 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.557     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0142     |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.261      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 2.61     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 245      |
|    time_elapsed    | 3034     |
|    total_timesteps | 501760   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 3.22       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 246        |
|    time_elapsed         | 3047       |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.07884287 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.829     |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0887     |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.238      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29         |
|    ep_rew_mean          | 1.4        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 247        |
|    time_elapsed         | 3057       |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.07458312 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.669     |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00389    |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.195      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 3.16       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 248        |
|    time_elapsed         | 3068       |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.08751217 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.904     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0463     |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.0334    |
|    value_loss           | 0.202      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.4        |
|    ep_rew_mean          | 3.84        |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 249         |
|    time_elapsed         | 3078        |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.072412044 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.603      |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.001       |
|    loss                 | -0.071      |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0301     |
|    value_loss           | 0.213       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=510000, episode_reward=-6.29 +/- 16.85
Episode length: 58.67 +/- 64.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.7        |
|    mean_reward          | -6.29       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.062366635 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.582      |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.001       |
|    loss                 | -0.062      |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.022      |
|    value_loss           | 0.299       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.3     |
|    ep_rew_mean     | 3.08     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 250      |
|    time_elapsed    | 3088     |
|    total_timesteps | 512000   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 2.39       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 251        |
|    time_elapsed         | 3099       |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.15021333 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.727     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0157     |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0419    |
|    value_loss           | 0.238      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 2.52       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 252        |
|    time_elapsed         | 3113       |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.08279599 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.796     |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0157    |
|    n_updates            | 2510       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.171      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.7       |
|    ep_rew_mean          | 2.03       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 253        |
|    time_elapsed         | 3123       |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.09945859 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.85      |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0606    |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.241      |
----------------------------------------
reached max steps=300
Eval num_timesteps=520000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.081330374 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.746      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.001       |
|    loss                 | 0.037       |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0271     |
|    value_loss           | 0.262       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.9     |
|    ep_rew_mean     | 3.12     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 254      |
|    time_elapsed    | 3137     |
|    total_timesteps | 520192   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 3.86       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 255        |
|    time_elapsed         | 3149       |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.08502606 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0914     |
|    n_updates            | 2540       |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.237      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 4.67       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 256        |
|    time_elapsed         | 3161       |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.08163332 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0275     |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.0345    |
|    value_loss           | 0.251      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 4.29       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 257        |
|    time_elapsed         | 3173       |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.10542865 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0378    |
|    n_updates            | 2560       |
|    policy_gradient_loss | -0.0384    |
|    value_loss           | 0.362      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.9      |
|    ep_rew_mean          | 4.37      |
| time/                   |           |
|    fps                  | 165       |
|    iterations           | 258       |
|    time_elapsed         | 3186      |
|    total_timesteps      | 528384    |
| train/                  |           |
|    approx_kl            | 0.1612359 |
|    clip_fraction        | 0.308     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.621    |
|    explained_variance   | 0.823     |
|    learning_rate        | 0.001     |
|    loss                 | 0.199     |
|    n_updates            | 2570      |
|    policy_gradient_loss | -0.0427   |
|    value_loss           | 0.386     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=530000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.07008785 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.603     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0813     |
|    n_updates            | 2580       |
|    policy_gradient_loss | -0.0325    |
|    value_loss           | 0.309      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | 2.64     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 259      |
|    time_elapsed    | 3198     |
|    total_timesteps | 530432   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.7       |
|    ep_rew_mean          | 2.09       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 260        |
|    time_elapsed         | 3210       |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.07897454 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.774     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.001      |
|    loss                 | 0.126      |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.024     |
|    value_loss           | 0.173      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 4.28       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 261        |
|    time_elapsed         | 3221       |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.10786207 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.73      |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.001      |
|    loss                 | 0.00762    |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 2.93       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 262        |
|    time_elapsed         | 3232       |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.08400714 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.552     |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00684    |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0394    |
|    value_loss           | 0.28       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 3.18       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 263        |
|    time_elapsed         | 3242       |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.07297624 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.759     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0491    |
|    n_updates            | 2620       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.2        |
----------------------------------------
reached max steps=300
Eval num_timesteps=540000, episode_reward=-4.38 +/- 14.71
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -4.38      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.11002299 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.84      |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0949     |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.0397    |
|    value_loss           | 0.245      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.5     |
|    ep_rew_mean     | 3.22     |
| time/              |          |
|    fps             | 166      |
|    iterations      | 264      |
|    time_elapsed    | 3252     |
|    total_timesteps | 540672   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 3.08       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 265        |
|    time_elapsed         | 3261       |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.08462019 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0195     |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.218      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 3.28        |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 266         |
|    time_elapsed         | 3273        |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.083692685 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.71       |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0589     |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.035      |
|    value_loss           | 0.231       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 4.35       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 267        |
|    time_elapsed         | 3285       |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.08073213 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.649     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00244    |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0382    |
|    value_loss           | 0.217      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.2        |
|    ep_rew_mean          | 3.85        |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 268         |
|    time_elapsed         | 3298        |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.066552885 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.501      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0599      |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0304     |
|    value_loss           | 0.298       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=550000, episode_reward=6.72 +/- 2.26
Episode length: 12.67 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 6.72       |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.07320861 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.621     |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0424    |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.407      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.9     |
|    ep_rew_mean     | 3.82     |
| time/              |          |
|    fps             | 166      |
|    iterations      | 269      |
|    time_elapsed    | 3307     |
|    total_timesteps | 550912   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 3.69        |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 270         |
|    time_elapsed         | 3320        |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.086321235 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.721      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0442     |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.233       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 3.76       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 271        |
|    time_elapsed         | 3330       |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.07783025 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.62      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0606    |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0295    |
|    value_loss           | 0.255      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 4.56       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 272        |
|    time_elapsed         | 3340       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.06322922 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.683     |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0309     |
|    n_updates            | 2710       |
|    policy_gradient_loss | -0.028     |
|    value_loss           | 0.341      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 3.15       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 273        |
|    time_elapsed         | 3349       |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.11012466 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.001      |
|    loss                 | 0.116      |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.26       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=560000, episode_reward=-25.00 +/- 4.08
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -25        |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.10339165 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.53      |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.001      |
|    loss                 | 0.848      |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0444    |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33       |
|    ep_rew_mean     | 1.65     |
| time/              |          |
|    fps             | 166      |
|    iterations      | 274      |
|    time_elapsed    | 3361     |
|    total_timesteps | 561152   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4           |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 275         |
|    time_elapsed         | 3370        |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.107775524 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.001       |
|    loss                 | 0.196       |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0464     |
|    value_loss           | 1.15        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 3.43       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 276        |
|    time_elapsed         | 3380       |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.17287323 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.001      |
|    loss                 | 0.116      |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0417    |
|    value_loss           | 0.488      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.8       |
|    ep_rew_mean          | 2.68       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 277        |
|    time_elapsed         | 3390       |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.09731399 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.681     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0308    |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.24       |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.3      |
|    ep_rew_mean          | 2.37      |
| time/                   |           |
|    fps                  | 167       |
|    iterations           | 278       |
|    time_elapsed         | 3401      |
|    total_timesteps      | 569344    |
| train/                  |           |
|    approx_kl            | 0.1248261 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.776    |
|    explained_variance   | 0.834     |
|    learning_rate        | 0.001     |
|    loss                 | -0.033    |
|    n_updates            | 2770      |
|    policy_gradient_loss | -0.042    |
|    value_loss           | 0.225     |
---------------------------------------
Eval num_timesteps=570000, episode_reward=6.59 +/- 4.62
Episode length: 13.33 +/- 0.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 13.3        |
|    mean_reward          | 6.59        |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.081209674 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.708      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00505     |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0318     |
|    value_loss           | 0.258       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 3.97     |
| time/              |          |
|    fps             | 167      |
|    iterations      | 279      |
|    time_elapsed    | 3414     |
|    total_timesteps | 571392   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 4.06        |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 280         |
|    time_elapsed         | 3425        |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.063040935 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.585      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.001       |
|    loss                 | 0.097       |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0324     |
|    value_loss           | 0.265       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 3.52       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 281        |
|    time_elapsed         | 3437       |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.07581988 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.638     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0149    |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.321      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 3.43       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 282        |
|    time_elapsed         | 3448       |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.07622564 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.756     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.032     |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.246      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.3       |
|    ep_rew_mean          | 2.43       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 283        |
|    time_elapsed         | 3458       |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.12938517 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.694     |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.001      |
|    loss                 | -5.68e-05  |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.0424    |
|    value_loss           | 0.502      |
----------------------------------------
reached max steps=300
Eval num_timesteps=580000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.087229654 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.841      |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0186     |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0417     |
|    value_loss           | 0.291       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.2     |
|    ep_rew_mean     | 2.81     |
| time/              |          |
|    fps             | 167      |
|    iterations      | 284      |
|    time_elapsed    | 3469     |
|    total_timesteps | 581632   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 3.57       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 285        |
|    time_elapsed         | 3481       |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.07779461 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.659     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0335    |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.0292    |
|    value_loss           | 0.28       |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.6        |
|    ep_rew_mean          | 3.99        |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 286         |
|    time_elapsed         | 3494        |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.066850156 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.723      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.001       |
|    loss                 | -0.03       |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0266     |
|    value_loss           | 0.29        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 3.69       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 287        |
|    time_elapsed         | 3506       |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.08024303 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.649     |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.001      |
|    loss                 | 0.486      |
|    n_updates            | 2860       |
|    policy_gradient_loss | -0.0211    |
|    value_loss           | 0.658      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.9       |
|    ep_rew_mean          | 2.71       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 288        |
|    time_elapsed         | 3516       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.08455613 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.734     |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.001      |
|    loss                 | 0.223      |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.351      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=590000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.08467245 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.732     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00442   |
|    n_updates            | 2880       |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.232      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 3.16     |
| time/              |          |
|    fps             | 167      |
|    iterations      | 289      |
|    time_elapsed    | 3526     |
|    total_timesteps | 591872   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.3       |
|    ep_rew_mean          | 3.04       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 290        |
|    time_elapsed         | 3536       |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.07083734 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.783     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0555     |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0341    |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 4.35       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 291        |
|    time_elapsed         | 3545       |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.07163072 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.865     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0314    |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.0315    |
|    value_loss           | 0.193      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 3.46       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 292        |
|    time_elapsed         | 3555       |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.10555118 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.001      |
|    loss                 | 0.278      |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.287      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=600000, episode_reward=-2.92 +/- 15.61
Episode length: 59.33 +/- 64.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.3       |
|    mean_reward          | -2.92      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.08803637 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.719     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0159    |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.04      |
|    value_loss           | 0.232      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.4     |
|    ep_rew_mean     | 3.51     |
| time/              |          |
|    fps             | 168      |
|    iterations      | 293      |
|    time_elapsed    | 3566     |
|    total_timesteps | 600064   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.8        |
|    ep_rew_mean          | 0.69        |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 294         |
|    time_elapsed         | 3577        |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.098635375 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.768      |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.001       |
|    loss                 | 0.052       |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.0332     |
|    value_loss           | 0.23        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.3       |
|    ep_rew_mean          | 3.07       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 295        |
|    time_elapsed         | 3588       |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.06764505 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.971     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0496    |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0196    |
|    value_loss           | 0.146      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 4.43       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 296        |
|    time_elapsed         | 3598       |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.07251142 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0635    |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0384    |
|    value_loss           | 0.27       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 3.14       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 297        |
|    time_elapsed         | 3607       |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.07499363 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.68      |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0757     |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.233      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=610000, episode_reward=-6.05 +/- 17.05
Episode length: 58.33 +/- 64.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.3        |
|    mean_reward          | -6.05       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.073859304 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.728      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.001       |
|    loss                 | 0.101       |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0314     |
|    value_loss           | 0.279       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.2     |
|    ep_rew_mean     | 3.55     |
| time/              |          |
|    fps             | 168      |
|    iterations      | 298      |
|    time_elapsed    | 3618     |
|    total_timesteps | 610304   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 3.2        |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 299        |
|    time_elapsed         | 3628       |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.08092861 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.65      |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.001      |
|    loss                 | -0.0315    |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.232      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 2.45       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 300        |
|    time_elapsed         | 3638       |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.08981716 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.663     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | -0.026     |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.048     |
|    value_loss           | 0.182      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 4.08       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 301        |
|    time_elapsed         | 3647       |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.08648567 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.688     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0441    |
|    n_updates            | 3000       |
|    policy_gradient_loss | -0.0261    |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 3.07       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 302        |
|    time_elapsed         | 3658       |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.10484116 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.563     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0222     |
|    n_updates            | 3010       |
|    policy_gradient_loss | -0.0267    |
|    value_loss           | 0.248      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=620000, episode_reward=-4.38 +/- 14.71
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -4.38      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.10767225 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.057     |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.243      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 2.53     |
| time/              |          |
|    fps             | 169      |
|    iterations      | 303      |
|    time_elapsed    | 3668     |
|    total_timesteps | 620544   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 2.35       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 304        |
|    time_elapsed         | 3679       |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.06818076 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.624     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00149   |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.0305    |
|    value_loss           | 0.189      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26          |
|    ep_rew_mean          | 2.45        |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 305         |
|    time_elapsed         | 3690        |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.113964915 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.782      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0495      |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27          |
|    ep_rew_mean          | 2.23        |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 306         |
|    time_elapsed         | 3698        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.098710105 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.71       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0191      |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0343     |
|    value_loss           | 0.202       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 4.9        |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 307        |
|    time_elapsed         | 3708       |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.12510255 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.726     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.001      |
|    loss                 | 0.105      |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.033     |
|    value_loss           | 0.191      |
----------------------------------------
reached max steps=300
Eval num_timesteps=630000, episode_reward=-7.79 +/- 15.71
Episode length: 58.67 +/- 64.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -7.79      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.06453061 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.548     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0295    |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.0188    |
|    value_loss           | 0.272      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.2     |
|    ep_rew_mean     | 4.34     |
| time/              |          |
|    fps             | 169      |
|    iterations      | 308      |
|    time_elapsed    | 3718     |
|    total_timesteps | 630784   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 4.37       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 309        |
|    time_elapsed         | 3728       |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.07059609 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.533     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0104     |
|    n_updates            | 3080       |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.277      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 3.89       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 310        |
|    time_elapsed         | 3737       |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.07367038 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00371   |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 3.98       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 311        |
|    time_elapsed         | 3747       |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.08722991 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.641     |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0187    |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.0221    |
|    value_loss           | 0.266      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 2.63       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 312        |
|    time_elapsed         | 3756       |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.08282675 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0154    |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0216    |
|    value_loss           | 0.233      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=640000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.08099369 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.766     |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0304    |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.167      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 2.57     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 313      |
|    time_elapsed    | 3765     |
|    total_timesteps | 641024   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 3.75       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 314        |
|    time_elapsed         | 3774       |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.08737719 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.001      |
|    loss                 | 0.057      |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.0357    |
|    value_loss           | 0.213      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 4.43       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 315        |
|    time_elapsed         | 3784       |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.06661044 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.567     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0213    |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.0293    |
|    value_loss           | 0.198      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 3.81        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 316         |
|    time_elapsed         | 3793        |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.081836104 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.561      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0302      |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.366       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 2.97       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 317        |
|    time_elapsed         | 3804       |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.08728131 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0237     |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.228      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=650000, episode_reward=-2.99 +/- 19.22
Episode length: 59.67 +/- 63.88
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 59.7      |
|    mean_reward          | -2.99     |
| time/                   |           |
|    total_timesteps      | 650000    |
| train/                  |           |
|    approx_kl            | 0.0858142 |
|    clip_fraction        | 0.309     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.675    |
|    explained_variance   | 0.884     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0493   |
|    n_updates            | 3170      |
|    policy_gradient_loss | -0.034    |
|    value_loss           | 0.186     |
---------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.5     |
|    ep_rew_mean     | 2.86     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 318      |
|    time_elapsed    | 3813     |
|    total_timesteps | 651264   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 4.02       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 319        |
|    time_elapsed         | 3824       |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.12790728 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.729     |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0363    |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.05      |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 3.42        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 320         |
|    time_elapsed         | 3833        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.097620204 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.607      |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0644      |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 0.258       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 4.28       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 321        |
|    time_elapsed         | 3844       |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.12535688 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.785     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | -0.01      |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0265    |
|    value_loss           | 0.307      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.4        |
|    ep_rew_mean          | 3.6         |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 322         |
|    time_elapsed         | 3854        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.098271474 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.621      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0734      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0222     |
|    value_loss           | 0.275       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=660000, episode_reward=6.72 +/- 2.26
Episode length: 12.67 +/- 0.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.7        |
|    mean_reward          | 6.72        |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.085056454 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.62       |
|    explained_variance   | 0.463       |
|    learning_rate        | 0.001       |
|    loss                 | 0.56        |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0365     |
|    value_loss           | 0.938       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.7     |
|    ep_rew_mean     | 1.78     |
| time/              |          |
|    fps             | 171      |
|    iterations      | 323      |
|    time_elapsed    | 3865     |
|    total_timesteps | 661504   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.2      |
|    ep_rew_mean          | 2.44      |
| time/                   |           |
|    fps                  | 171       |
|    iterations           | 324       |
|    time_elapsed         | 3876      |
|    total_timesteps      | 663552    |
| train/                  |           |
|    approx_kl            | 0.1293957 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.705    |
|    explained_variance   | 0.665     |
|    learning_rate        | 0.001     |
|    loss                 | 0.343     |
|    n_updates            | 3230      |
|    policy_gradient_loss | -0.0453   |
|    value_loss           | 0.687     |
---------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.4        |
|    ep_rew_mean          | 3.93        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 325         |
|    time_elapsed         | 3887        |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.112171486 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.842      |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0544      |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.04       |
|    value_loss           | 0.352       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.7       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 326        |
|    time_elapsed         | 3898       |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.14044118 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0123     |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.278      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.9        |
|    ep_rew_mean          | 1.97        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 327         |
|    time_elapsed         | 3909        |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.079461545 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.725      |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.001       |
|    loss                 | 0.00615     |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.0392     |
|    value_loss           | 0.173       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=670000, episode_reward=-6.19 +/- 16.97
Episode length: 59.00 +/- 64.35
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 59        |
|    mean_reward          | -6.19     |
| time/                   |           |
|    total_timesteps      | 670000    |
| train/                  |           |
|    approx_kl            | 0.1881248 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.848    |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.001     |
|    loss                 | -0.0457   |
|    n_updates            | 3270      |
|    policy_gradient_loss | -0.0383   |
|    value_loss           | 0.132     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.9     |
|    ep_rew_mean     | 1.11     |
| time/              |          |
|    fps             | 171      |
|    iterations      | 328      |
|    time_elapsed    | 3921     |
|    total_timesteps | 671744   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.1        |
|    ep_rew_mean          | 1.38        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 329         |
|    time_elapsed         | 3931        |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.124056935 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.829      |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.001       |
|    loss                 | -0.05       |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.0431     |
|    value_loss           | 0.19        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 4.02       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 330        |
|    time_elapsed         | 3942       |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.08057219 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.781     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0175    |
|    n_updates            | 3290       |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.196      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 3.91        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 331         |
|    time_elapsed         | 3953        |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.084051795 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.706      |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.001       |
|    loss                 | -0.05       |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0271     |
|    value_loss           | 0.206       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 2.89       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 332        |
|    time_elapsed         | 3963       |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.06870502 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.647     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.001      |
|    loss                 | 0.021      |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.297      |
----------------------------------------
reached max steps=300
Eval num_timesteps=680000, episode_reward=-3.27 +/- 19.02
Episode length: 61.00 +/- 62.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61         |
|    mean_reward          | -3.27      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.07279532 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.808     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.001      |
|    loss                 | 0.19       |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.0246    |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | 2.98     |
| time/              |          |
|    fps             | 171      |
|    iterations      | 333      |
|    time_elapsed    | 3974     |
|    total_timesteps | 681984   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.3       |
|    ep_rew_mean          | 2.71       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 334        |
|    time_elapsed         | 3985       |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.07569629 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0305    |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.184      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 4.62       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 335        |
|    time_elapsed         | 3996       |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.08802103 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.892     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.001      |
|    loss                 | 0.013      |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0395    |
|    value_loss           | 0.17       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 3.72       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 336        |
|    time_elapsed         | 4007       |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.06860128 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.616     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0127    |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.0282    |
|    value_loss           | 0.246      |
----------------------------------------
reached max steps=300
Eval num_timesteps=690000, episode_reward=6.45 +/- 2.07
Episode length: 14.00 +/- 1.41
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 14        |
|    mean_reward          | 6.45      |
| time/                   |           |
|    total_timesteps      | 690000    |
| train/                  |           |
|    approx_kl            | 0.0868599 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.791    |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0488   |
|    n_updates            | 3360      |
|    policy_gradient_loss | -0.0452   |
|    value_loss           | 0.194     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 4.09     |
| time/              |          |
|    fps             | 171      |
|    iterations      | 337      |
|    time_elapsed    | 4018     |
|    total_timesteps | 690176   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 3.54       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 338        |
|    time_elapsed         | 4029       |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.08156183 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.278      |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.026     |
|    value_loss           | 0.284      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.4        |
|    ep_rew_mean          | 2.45        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 339         |
|    time_elapsed         | 4039        |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.089777954 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.702      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00432     |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.216       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.5        |
|    ep_rew_mean          | 3.52        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 340         |
|    time_elapsed         | 4050        |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.078934886 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.782      |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0135      |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0332     |
|    value_loss           | 0.135       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 3.63       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 341        |
|    time_elapsed         | 4060       |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.09633832 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.67      |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0923     |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.297      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=700000, episode_reward=6.45 +/- 2.07
Episode length: 14.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14         |
|    mean_reward          | 6.45       |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.13721925 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.651     |
|    explained_variance   | 0.259      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0142    |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.0391    |
|    value_loss           | 0.323      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.8     |
|    ep_rew_mean     | 3.29     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 342      |
|    time_elapsed    | 4070     |
|    total_timesteps | 700416   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 3.73        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 343         |
|    time_elapsed         | 4079        |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.097206816 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.698      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0275      |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0456     |
|    value_loss           | 0.207       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.2      |
|    ep_rew_mean          | 4.35      |
| time/                   |           |
|    fps                  | 172       |
|    iterations           | 344       |
|    time_elapsed         | 4089      |
|    total_timesteps      | 704512    |
| train/                  |           |
|    approx_kl            | 0.0854343 |
|    clip_fraction        | 0.286     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.576    |
|    explained_variance   | 0.883     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0335   |
|    n_updates            | 3430      |
|    policy_gradient_loss | -0.0285   |
|    value_loss           | 0.252     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 27.3     |
|    ep_rew_mean          | 2.6      |
| time/                   |          |
|    fps                  | 172      |
|    iterations           | 345      |
|    time_elapsed         | 4099     |
|    total_timesteps      | 706560   |
| train/                  |          |
|    approx_kl            | 0.082928 |
|    clip_fraction        | 0.272    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.659   |
|    explained_variance   | 0.894    |
|    learning_rate        | 0.001    |
|    loss                 | -0.029   |
|    n_updates            | 3440     |
|    policy_gradient_loss | -0.0252  |
|    value_loss           | 0.226    |
--------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.5      |
|    ep_rew_mean          | 3.07      |
| time/                   |           |
|    fps                  | 172       |
|    iterations           | 346       |
|    time_elapsed         | 4109      |
|    total_timesteps      | 708608    |
| train/                  |           |
|    approx_kl            | 0.0765146 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.741    |
|    explained_variance   | 0.859     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0249    |
|    n_updates            | 3450      |
|    policy_gradient_loss | -0.027    |
|    value_loss           | 0.275     |
---------------------------------------
reached max steps=300
Eval num_timesteps=710000, episode_reward=6.59 +/- 2.17
Episode length: 13.33 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.3       |
|    mean_reward          | 6.59       |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.08903158 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.646     |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.001      |
|    loss                 | -0.067     |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0437    |
|    value_loss           | 0.216      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 4.57     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 347      |
|    time_elapsed    | 4119     |
|    total_timesteps | 710656   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 4.38        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 348         |
|    time_elapsed         | 4128        |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.054780453 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0451      |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.0297     |
|    value_loss           | 0.22        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 3.31       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 349        |
|    time_elapsed         | 4142       |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.11659506 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.571     |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0314    |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.0326    |
|    value_loss           | 0.308      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.8        |
|    ep_rew_mean          | 2.72        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 350         |
|    time_elapsed         | 4154        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.084639505 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00865    |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0445     |
|    value_loss           | 0.237       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.2        |
|    ep_rew_mean          | 3.46        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 351         |
|    time_elapsed         | 4163        |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.085133664 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0211      |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0224     |
|    value_loss           | 0.24        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=720000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.09838694 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.694     |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00913   |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.161      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 5.33     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 352      |
|    time_elapsed    | 4174     |
|    total_timesteps | 720896   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 4.5        |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 353        |
|    time_elapsed         | 4183       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.08143673 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.471     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0921     |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0265    |
|    value_loss           | 0.265      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 4.57        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 354         |
|    time_elapsed         | 4192        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.076079905 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.001       |
|    loss                 | 0.113       |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.0197     |
|    value_loss           | 0.228       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 4.13       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 355        |
|    time_elapsed         | 4202       |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.08740564 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.428     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0116    |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0432    |
|    value_loss           | 0.228      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.7       |
|    ep_rew_mean          | 5.24       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 356        |
|    time_elapsed         | 4212       |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.09207532 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.516     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0149    |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.013     |
|    value_loss           | 0.193      |
----------------------------------------
reached max steps=300
Eval num_timesteps=730000, episode_reward=-4.45 +/- 18.07
Episode length: 58.67 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -4.45      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.08334014 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.437     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | 0.108      |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.0257    |
|    value_loss           | 0.225      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 3.19     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 357      |
|    time_elapsed    | 4222     |
|    total_timesteps | 731136   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 3.22       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 358        |
|    time_elapsed         | 4233       |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.08871434 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.598     |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.001      |
|    loss                 | 0.544      |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0338    |
|    value_loss           | 0.959      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.7       |
|    ep_rew_mean          | 3.73       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 359        |
|    time_elapsed         | 4243       |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.12875819 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0467     |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.0478    |
|    value_loss           | 0.549      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 3.88       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 360        |
|    time_elapsed         | 4253       |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.12628853 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.653     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0327     |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.0436     |
|    value_loss           | 0.225      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25          |
|    ep_rew_mean          | 2.62        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 361         |
|    time_elapsed         | 4263        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.114314936 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.616      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.001       |
|    loss                 | 0.102       |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0248     |
|    value_loss           | 0.256       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=740000, episode_reward=-6.60 +/- 16.63
Episode length: 61.00 +/- 62.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61         |
|    mean_reward          | -6.6       |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.08343588 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.671     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0238     |
|    n_updates            | 3610       |
|    policy_gradient_loss | -0.0264    |
|    value_loss           | 0.218      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 4.05     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 362      |
|    time_elapsed    | 4272     |
|    total_timesteps | 741376   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.2       |
|    ep_rew_mean          | 3.87       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 363        |
|    time_elapsed         | 4281       |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.08866568 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.596     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0135    |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.0262    |
|    value_loss           | 0.356      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 4.61       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 364        |
|    time_elapsed         | 4291       |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.07519351 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0574    |
|    n_updates            | 3630       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.237      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 26        |
|    ep_rew_mean          | 3.63      |
| time/                   |           |
|    fps                  | 173       |
|    iterations           | 365       |
|    time_elapsed         | 4300      |
|    total_timesteps      | 747520    |
| train/                  |           |
|    approx_kl            | 0.1131614 |
|    clip_fraction        | 0.293     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.545    |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.001     |
|    loss                 | 0.296     |
|    n_updates            | 3640      |
|    policy_gradient_loss | -0.0369   |
|    value_loss           | 0.535     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 5.4        |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 366        |
|    time_elapsed         | 4308       |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.11926568 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.652     |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.347      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=750000, episode_reward=-28.33 +/- 2.36
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -28.3      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.09680348 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.498     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0124     |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0304    |
|    value_loss           | 0.272      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 4.62     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 367      |
|    time_elapsed    | 4318     |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.9       |
|    ep_rew_mean          | 4.38       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 368        |
|    time_elapsed         | 4326       |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.09034914 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.66      |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0137    |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.303      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 5          |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 369        |
|    time_elapsed         | 4335       |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.10873431 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.671     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.001      |
|    loss                 | 0.126      |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0288    |
|    value_loss           | 0.303      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 4.49        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 370         |
|    time_elapsed         | 4347        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.099436104 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.651      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0765      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0287     |
|    value_loss           | 0.35        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 4.07       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 371        |
|    time_elapsed         | 4359       |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.11944859 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.673     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0306    |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0419    |
|    value_loss           | 0.251      |
----------------------------------------
reached max steps=300
Eval num_timesteps=760000, episode_reward=-4.38 +/- 14.71
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -4.38      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.09576017 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.783     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | 0.036      |
|    n_updates            | 3710       |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.233      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 4        |
| time/              |          |
|    fps             | 174      |
|    iterations      | 372      |
|    time_elapsed    | 4371     |
|    total_timesteps | 761856   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.6      |
|    ep_rew_mean          | 3.95      |
| time/                   |           |
|    fps                  | 174       |
|    iterations           | 373       |
|    time_elapsed         | 4381      |
|    total_timesteps      | 763904    |
| train/                  |           |
|    approx_kl            | 0.1041974 |
|    clip_fraction        | 0.283     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.583    |
|    explained_variance   | 0.861     |
|    learning_rate        | 0.001     |
|    loss                 | 0.198     |
|    n_updates            | 3720      |
|    policy_gradient_loss | -0.0264   |
|    value_loss           | 0.288     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 3          |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 374        |
|    time_elapsed         | 4396       |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.07534239 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.554     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0187    |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0257    |
|    value_loss           | 0.24       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.7        |
|    ep_rew_mean          | 3.69        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 375         |
|    time_elapsed         | 4410        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.115545124 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0648      |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.0361     |
|    value_loss           | 0.466       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=770000, episode_reward=-1.39 +/- 20.23
Episode length: 60.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60          |
|    mean_reward          | -1.39       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.095685616 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.109       |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.266       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 2.59     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 376      |
|    time_elapsed    | 4424     |
|    total_timesteps | 770048   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.6        |
|    ep_rew_mean          | 4.96        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 377         |
|    time_elapsed         | 4443        |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.083020784 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.781      |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0741     |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.0354     |
|    value_loss           | 0.238       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 4.32       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 378        |
|    time_elapsed         | 4457       |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.09595537 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.537     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.001      |
|    loss                 | 0.127      |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.021     |
|    value_loss           | 0.311      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 4.51        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 379         |
|    time_elapsed         | 4475        |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.075979345 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0453      |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.0315     |
|    value_loss           | 0.233       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.1        |
|    ep_rew_mean          | 6.08        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 380         |
|    time_elapsed         | 4491        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.115402274 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.536      |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | 0.297       |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.0342     |
|    value_loss           | 0.366       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=780000, episode_reward=-4.96 +/- 18.07
Episode length: 60.33 +/- 63.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.3       |
|    mean_reward          | -4.96      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.07906464 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.416     |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.001      |
|    loss                 | 0.02       |
|    n_updates            | 3800       |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.319      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 4.23     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 381      |
|    time_elapsed    | 4506     |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 5.78       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 382        |
|    time_elapsed         | 4522       |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.19529584 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.658     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0733     |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.261      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.1      |
|    ep_rew_mean          | 4.74      |
| time/                   |           |
|    fps                  | 172       |
|    iterations           | 383       |
|    time_elapsed         | 4536      |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.0895773 |
|    clip_fraction        | 0.259     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.494    |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0295    |
|    n_updates            | 3820      |
|    policy_gradient_loss | -0.0273   |
|    value_loss           | 0.371     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 4.46       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 384        |
|    time_elapsed         | 4555       |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.09916921 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.62      |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | 0.041      |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.033     |
|    value_loss           | 0.247      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 4.76        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 385         |
|    time_elapsed         | 4570        |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.085671425 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0112      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.32        |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=790000, episode_reward=-6.19 +/- 16.93
Episode length: 59.00 +/- 64.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 59          |
|    mean_reward          | -6.19       |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.092595674 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.614      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0258     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0288     |
|    value_loss           | 0.263       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 5.24     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 386      |
|    time_elapsed    | 4588     |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 4.96       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 387        |
|    time_elapsed         | 4606       |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.09605373 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.609     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.063     |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.247      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 4.12       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 388        |
|    time_elapsed         | 4624       |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.07079349 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.501     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00653    |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.0232    |
|    value_loss           | 0.266      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.5       |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 389        |
|    time_elapsed         | 4640       |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.07967735 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.674     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0537    |
|    n_updates            | 3880       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.194      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 4.76       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 390        |
|    time_elapsed         | 4655       |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.09620893 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.625     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00531    |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.214      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=800000, episode_reward=-18.96 +/- 15.61
Episode length: 104.67 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -19        |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.07273147 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.678     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.001      |
|    loss                 | 0.106      |
|    n_updates            | 3900       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.27       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 4.86     |
| time/              |          |
|    fps             | 171      |
|    iterations      | 391      |
|    time_elapsed    | 4670     |
|    total_timesteps | 800768   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 5.11       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 392        |
|    time_elapsed         | 4686       |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.08581607 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0246     |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.0313    |
|    value_loss           | 0.279      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 5.12        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 393         |
|    time_elapsed         | 4702        |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.082255274 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.481      |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.001       |
|    loss                 | 0.139       |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.0554     |
|    value_loss           | 0.342       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 4.39        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 394         |
|    time_elapsed         | 4718        |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.124588326 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.502      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00135    |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.0318     |
|    value_loss           | 0.199       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 4.15       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 395        |
|    time_elapsed         | 4749       |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.09034799 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00328    |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.234      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=810000, episode_reward=6.59 +/- 4.33
Episode length: 13.33 +/- 1.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.3       |
|    mean_reward          | 6.59       |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.08760953 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.62      |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0331    |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.185      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | 3.26     |
| time/              |          |
|    fps             | 169      |
|    iterations      | 396      |
|    time_elapsed    | 4778     |
|    total_timesteps | 811008   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.7       |
|    ep_rew_mean          | 3.31       |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 397        |
|    time_elapsed         | 4819       |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.09696081 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | 0.16       |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.18       |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.6       |
|    ep_rew_mean          | 4.03       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 398        |
|    time_elapsed         | 4856       |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.09873315 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0338    |
|    n_updates            | 3970       |
|    policy_gradient_loss | -0.037     |
|    value_loss           | 0.189      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.8       |
|    ep_rew_mean          | 1.8        |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 399        |
|    time_elapsed         | 4883       |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.10216847 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.635     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | -0.021     |
|    n_updates            | 3980       |
|    policy_gradient_loss | -0.0233    |
|    value_loss           | 0.236      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.75       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 400        |
|    time_elapsed         | 4907       |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.08220088 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.804     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0481     |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0215    |
|    value_loss           | 0.232      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=820000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.08572141 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.532     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000949  |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.0321    |
|    value_loss           | 0.269      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.7     |
|    ep_rew_mean     | 4.34     |
| time/              |          |
|    fps             | 166      |
|    iterations      | 401      |
|    time_elapsed    | 4927     |
|    total_timesteps | 821248   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.1       |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 402        |
|    time_elapsed         | 4946       |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.09942998 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.685     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.04      |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.148      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.11       |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 403        |
|    time_elapsed         | 4968       |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.07368253 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.731     |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.001      |
|    loss                 | 0.177      |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.0256    |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.7      |
|    ep_rew_mean          | 2.97      |
| time/                   |           |
|    fps                  | 165       |
|    iterations           | 404       |
|    time_elapsed         | 4988      |
|    total_timesteps      | 827392    |
| train/                  |           |
|    approx_kl            | 0.0766776 |
|    clip_fraction        | 0.244     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.681    |
|    explained_variance   | 0.925     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0397   |
|    n_updates            | 4030      |
|    policy_gradient_loss | -0.0249   |
|    value_loss           | 0.188     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 3.51       |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 405        |
|    time_elapsed         | 5012       |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.07304897 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.822     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0613     |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.212      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=830000, episode_reward=-6.19 +/- 16.97
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -6.19      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.12986585 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.685     |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.001      |
|    loss                 | -0.027     |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0539    |
|    value_loss           | 0.293      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 3.4      |
| time/              |          |
|    fps             | 164      |
|    iterations      | 406      |
|    time_elapsed    | 5040     |
|    total_timesteps | 831488   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 4.37       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 407        |
|    time_elapsed         | 5066       |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.10791834 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.716     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0054     |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.0205    |
|    value_loss           | 0.16       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.2       |
|    ep_rew_mean          | 3.25       |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 408        |
|    time_elapsed         | 5088       |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.09513016 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.63      |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.001      |
|    loss                 | 0.603      |
|    n_updates            | 4070       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.658      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.9       |
|    ep_rew_mean          | 3.08       |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 409        |
|    time_elapsed         | 5111       |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.14965844 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.737     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0157    |
|    n_updates            | 4080       |
|    policy_gradient_loss | -0.0386    |
|    value_loss           | 0.196      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 3.1        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 410        |
|    time_elapsed         | 5133       |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.07178558 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.748     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0202    |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0278    |
|    value_loss           | 0.172      |
----------------------------------------
reached max steps=300
Eval num_timesteps=840000, episode_reward=3.39 +/- 0.19
Episode length: 12.67 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 3.39       |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.09270855 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.68      |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0256     |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.211      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 3.35     |
| time/              |          |
|    fps             | 163      |
|    iterations      | 411      |
|    time_elapsed    | 5156     |
|    total_timesteps | 841728   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.9       |
|    ep_rew_mean          | 2.7        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 412        |
|    time_elapsed         | 5173       |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.08893429 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.769     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0698    |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.208      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.8       |
|    ep_rew_mean          | 3.35       |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 413        |
|    time_elapsed         | 5197       |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.09604296 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.742     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0423     |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.186      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.3        |
|    ep_rew_mean          | 4.17        |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 414         |
|    time_elapsed         | 5216        |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.069404036 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0218      |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.2         |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.16       |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 415        |
|    time_elapsed         | 5238       |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.09397495 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.627     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0589    |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.194      |
----------------------------------------
reached max steps=300
Eval num_timesteps=850000, episode_reward=-1.32 +/- 16.84
Episode length: 59.67 +/- 63.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.7       |
|    mean_reward          | -1.32      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.05549989 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.686     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00393    |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0276    |
|    value_loss           | 0.185      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 3.95     |
| time/              |          |
|    fps             | 162      |
|    iterations      | 416      |
|    time_elapsed    | 5258     |
|    total_timesteps | 851968   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 5.58       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 417        |
|    time_elapsed         | 5281       |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.08814162 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.604     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0301    |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.0331    |
|    value_loss           | 0.23       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 24.2     |
|    ep_rew_mean          | 3.5      |
| time/                   |          |
|    fps                  | 161      |
|    iterations           | 418      |
|    time_elapsed         | 5300     |
|    total_timesteps      | 856064   |
| train/                  |          |
|    approx_kl            | 0.0758   |
|    clip_fraction        | 0.233    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.541   |
|    explained_variance   | 0.861    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0283  |
|    n_updates            | 4170     |
|    policy_gradient_loss | -0.015   |
|    value_loss           | 0.345    |
--------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 4.87       |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 419        |
|    time_elapsed         | 5321       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.10008613 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.681     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00889   |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.188      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=860000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -7.65       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.078535035 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.593      |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.232       |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.0224     |
|    value_loss           | 0.333       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.9     |
|    ep_rew_mean     | 3.73     |
| time/              |          |
|    fps             | 161      |
|    iterations      | 420      |
|    time_elapsed    | 5340     |
|    total_timesteps | 860160   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 4.86       |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 421        |
|    time_elapsed         | 5367       |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.07975766 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0478    |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.229      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 4.66        |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 422         |
|    time_elapsed         | 5390        |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.115879856 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.618      |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0141      |
|    n_updates            | 4210        |
|    policy_gradient_loss | 0.00264     |
|    value_loss           | 0.301       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 4.55       |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 423        |
|    time_elapsed         | 5411       |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.12692451 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.588     |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00932   |
|    n_updates            | 4220       |
|    policy_gradient_loss | -0.0485    |
|    value_loss           | 0.218      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.4        |
|    ep_rew_mean          | 3.2         |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 424         |
|    time_elapsed         | 5430        |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.095021926 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.613      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0646     |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.024      |
|    value_loss           | 0.209       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=870000, episode_reward=8.18 +/- 3.75
Episode length: 13.67 +/- 1.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.7       |
|    mean_reward          | 8.18       |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.13592698 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.817     |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0371     |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0422    |
|    value_loss           | 0.201      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 2.95     |
| time/              |          |
|    fps             | 159      |
|    iterations      | 425      |
|    time_elapsed    | 5451     |
|    total_timesteps | 870400   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.9      |
|    ep_rew_mean          | 3.68      |
| time/                   |           |
|    fps                  | 159       |
|    iterations           | 426       |
|    time_elapsed         | 5472      |
|    total_timesteps      | 872448    |
| train/                  |           |
|    approx_kl            | 0.1004819 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.634    |
|    explained_variance   | 0.908     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0628   |
|    n_updates            | 4250      |
|    policy_gradient_loss | -0.0249   |
|    value_loss           | 0.205     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.06       |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 427        |
|    time_elapsed         | 5491       |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.09937388 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.636     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0644    |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.219      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 4.53       |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 428        |
|    time_elapsed         | 5512       |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.07723735 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.429     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00829   |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.0234    |
|    value_loss           | 0.311      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.7        |
|    ep_rew_mean          | 3.6         |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 429         |
|    time_elapsed         | 5532        |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.071174875 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.561      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0116      |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.0231     |
|    value_loss           | 0.217       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=880000, episode_reward=6.45 +/- 2.36
Episode length: 14.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 14          |
|    mean_reward          | 6.45        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.095159486 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.705      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.001       |
|    loss                 | 0.157       |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0234     |
|    value_loss           | 0.3         |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 4.32     |
| time/              |          |
|    fps             | 158      |
|    iterations      | 430      |
|    time_elapsed    | 5551     |
|    total_timesteps | 880640   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 3.03       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 431        |
|    time_elapsed         | 5570       |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.09332074 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.681     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00257   |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.0189    |
|    value_loss           | 0.276      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.3        |
|    ep_rew_mean          | 3.76        |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 432         |
|    time_elapsed         | 5594        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.106799036 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.696      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0115      |
|    n_updates            | 4310        |
|    policy_gradient_loss | -0.0292     |
|    value_loss           | 0.294       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 31.8      |
|    ep_rew_mean          | 2.38      |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 433       |
|    time_elapsed         | 5616      |
|    total_timesteps      | 886784    |
| train/                  |           |
|    approx_kl            | 0.0902726 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.671    |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0706   |
|    n_updates            | 4320      |
|    policy_gradient_loss | -0.0249   |
|    value_loss           | 0.201     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.5        |
|    ep_rew_mean          | 2.58        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 434         |
|    time_elapsed         | 5632        |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.083057225 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.749      |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.001       |
|    loss                 | 0.147       |
|    n_updates            | 4330        |
|    policy_gradient_loss | -0.0435     |
|    value_loss           | 0.795       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=890000, episode_reward=-6.19 +/- 16.97
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -6.19      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.12832819 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.755     |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.001      |
|    loss                 | 0.115      |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.366      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 4.27     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 435      |
|    time_elapsed    | 5651     |
|    total_timesteps | 890880   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.9        |
|    ep_rew_mean          | 3.24        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 436         |
|    time_elapsed         | 5669        |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.101297796 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0614     |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.239       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29         |
|    ep_rew_mean          | 3.18       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 437        |
|    time_elapsed         | 5690       |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.09103541 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.898     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.001      |
|    loss                 | 0.148      |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.0273    |
|    value_loss           | 0.302      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.1      |
|    ep_rew_mean          | 5.11      |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 438       |
|    time_elapsed         | 5710      |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.0865894 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.698    |
|    explained_variance   | 0.895     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0849    |
|    n_updates            | 4370      |
|    policy_gradient_loss | -0.0292   |
|    value_loss           | 0.278     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 3.43        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 439         |
|    time_elapsed         | 5732        |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.094827086 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.699      |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0307     |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0197     |
|    value_loss           | 0.278       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=900000, episode_reward=-2.92 +/- 15.61
Episode length: 59.33 +/- 64.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 59.3        |
|    mean_reward          | -2.92       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.080942154 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.825      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0199     |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.292       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 3.01     |
| time/              |          |
|    fps             | 156      |
|    iterations      | 440      |
|    time_elapsed    | 5752     |
|    total_timesteps | 901120   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 3.75       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 441        |
|    time_elapsed         | 5771       |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.07169085 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.876     |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0171    |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0236    |
|    value_loss           | 0.279      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.3        |
|    ep_rew_mean          | 3.94        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 442         |
|    time_elapsed         | 5796        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.091292165 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.738      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0844      |
|    n_updates            | 4410        |
|    policy_gradient_loss | -0.0269     |
|    value_loss           | 0.256       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 4.64       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 443        |
|    time_elapsed         | 5809       |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.09975472 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.786     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0128    |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.024     |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 2.6        |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 444        |
|    time_elapsed         | 5820       |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.08374405 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.721     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0253     |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.266      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=910000, episode_reward=-14.24 +/- 18.87
Episode length: 106.00 +/- 62.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 106        |
|    mean_reward          | -14.2      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.10517493 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.855     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0199    |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.197      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 4.21     |
| time/              |          |
|    fps             | 156      |
|    iterations      | 445      |
|    time_elapsed    | 5830     |
|    total_timesteps | 911360   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 3.77       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 446        |
|    time_elapsed         | 5840       |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.08353361 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.682     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.001      |
|    loss                 | 0.152      |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.373      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 5.41       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 447        |
|    time_elapsed         | 5850       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.09697766 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.603     |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0126    |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.0237    |
|    value_loss           | 0.283      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25        |
|    ep_rew_mean          | 4.41      |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 448       |
|    time_elapsed         | 5861      |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.0929592 |
|    clip_fraction        | 0.269     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.566    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.001     |
|    loss                 | 0.131     |
|    n_updates            | 4470      |
|    policy_gradient_loss | -0.0303   |
|    value_loss           | 0.254     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 4.59        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 449         |
|    time_elapsed         | 5872        |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.077700466 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0212      |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.0255     |
|    value_loss           | 0.233       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=920000, episode_reward=-2.85 +/- 19.29
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -2.85      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.12971045 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.584     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00758    |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.302      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 4.2      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 450      |
|    time_elapsed    | 5881     |
|    total_timesteps | 921600   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.5      |
|    ep_rew_mean          | 6.67      |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 451       |
|    time_elapsed         | 5891      |
|    total_timesteps      | 923648    |
| train/                  |           |
|    approx_kl            | 0.0793785 |
|    clip_fraction        | 0.266     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.561    |
|    explained_variance   | 0.874     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0568    |
|    n_updates            | 4500      |
|    policy_gradient_loss | -0.0274   |
|    value_loss           | 0.323     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28         |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 452        |
|    time_elapsed         | 5900       |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.09096085 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.379     |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0962     |
|    n_updates            | 4510       |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.295      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27          |
|    ep_rew_mean          | 4.05        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 453         |
|    time_elapsed         | 5910        |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.093014404 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.001       |
|    loss                 | 0.146       |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.427       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 4.59        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 454         |
|    time_elapsed         | 5918        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.105392344 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.6        |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.001       |
|    loss                 | 0.211       |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0395     |
|    value_loss           | 0.467       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=930000, episode_reward=-4.45 +/- 18.48
Episode length: 58.67 +/- 64.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.7        |
|    mean_reward          | -4.45       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.108365685 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.643      |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0458     |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.195       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26       |
|    ep_rew_mean     | 3.84     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 455      |
|    time_elapsed    | 5928     |
|    total_timesteps | 931840   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 4.89       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 456        |
|    time_elapsed         | 5936       |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.11963913 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0707     |
|    n_updates            | 4550       |
|    policy_gradient_loss | -0.0261    |
|    value_loss           | 0.224      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.5        |
|    ep_rew_mean          | 3.04        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 457         |
|    time_elapsed         | 5946        |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.100824445 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.632      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.001       |
|    loss                 | -0.015      |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.238       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 4.19       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 458        |
|    time_elapsed         | 5955       |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.08054288 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.682     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0244    |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.176      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=940000, episode_reward=-17.36 +/- 17.87
Episode length: 105.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 105         |
|    mean_reward          | -17.4       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.091043256 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.648      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0662     |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.0316     |
|    value_loss           | 0.184       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26       |
|    ep_rew_mean     | 3.36     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 459      |
|    time_elapsed    | 5967     |
|    total_timesteps | 940032   |
---------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.1      |
|    ep_rew_mean          | 3.48      |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 460       |
|    time_elapsed         | 5977      |
|    total_timesteps      | 942080    |
| train/                  |           |
|    approx_kl            | 0.0793488 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.7      |
|    explained_variance   | 0.938     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0385   |
|    n_updates            | 4590      |
|    policy_gradient_loss | -0.0266   |
|    value_loss           | 0.16      |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 4.26       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 461        |
|    time_elapsed         | 5987       |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.08624937 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.758     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0395    |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0286    |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 4.45       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 462        |
|    time_elapsed         | 5998       |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.06597109 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.619     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00612    |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.146      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 3.9        |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 463        |
|    time_elapsed         | 6012       |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.10045953 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.621     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0733    |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0482    |
|    value_loss           | 0.156      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=950000, episode_reward=-17.16 +/- 14.77
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.2      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.09856291 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.612     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0162    |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.179      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | 5.34     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 464      |
|    time_elapsed    | 6025     |
|    total_timesteps | 950272   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 4.57       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 465        |
|    time_elapsed         | 6039       |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.08575304 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.46      |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0708     |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.77       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 466        |
|    time_elapsed         | 6052       |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.06105874 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00491    |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.0178    |
|    value_loss           | 0.241      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.6       |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 467        |
|    time_elapsed         | 6062       |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.08346686 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.625     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0256    |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.291      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.3        |
|    ep_rew_mean          | 4.55        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 468         |
|    time_elapsed         | 6073        |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.079855114 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.758      |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0311     |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.0242     |
|    value_loss           | 0.222       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=960000, episode_reward=-16.77 +/- 20.87
Episode length: 105.33 +/- 63.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -16.8      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.08667869 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.702     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00132   |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.269      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.1     |
|    ep_rew_mean     | 3        |
| time/              |          |
|    fps             | 157      |
|    iterations      | 469      |
|    time_elapsed    | 6086     |
|    total_timesteps | 960512   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27          |
|    ep_rew_mean          | 3.23        |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 470         |
|    time_elapsed         | 6095        |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.081380434 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.807      |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00342     |
|    n_updates            | 4690        |
|    policy_gradient_loss | -0.0343     |
|    value_loss           | 0.249       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 3.58       |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 471        |
|    time_elapsed         | 6110       |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.12920617 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.682     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0168    |
|    n_updates            | 4700       |
|    policy_gradient_loss | -0.0421    |
|    value_loss           | 0.171      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 3.6        |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 472        |
|    time_elapsed         | 8302       |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.08805974 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.718     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0455     |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.211      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 5.51        |
| time/                   |             |
|    fps                  | 116         |
|    iterations           | 473         |
|    time_elapsed         | 8340        |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.099687055 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0293     |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.00662    |
|    value_loss           | 0.167       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=970000, episode_reward=-2.99 +/- 19.18
Episode length: 59.67 +/- 63.89
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 59.7      |
|    mean_reward          | -2.99     |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.0716507 |
|    clip_fraction        | 0.271     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.517    |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0129   |
|    n_updates            | 4730      |
|    policy_gradient_loss | -0.0293   |
|    value_loss           | 0.219     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 5.02     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 474      |
|    time_elapsed    | 8375     |
|    total_timesteps | 970752   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.3        |
|    ep_rew_mean          | 3.89        |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 475         |
|    time_elapsed         | 8407        |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.083201006 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.611      |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0311     |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0376     |
|    value_loss           | 0.306       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.89       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 476        |
|    time_elapsed         | 8433       |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.10514593 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.701     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.001      |
|    loss                 | 0.193      |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.269      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 5.09       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 477        |
|    time_elapsed         | 8464       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.06478347 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.466     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.001      |
|    loss                 | 0.115      |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.0188    |
|    value_loss           | 0.309      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 5.02       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 478        |
|    time_elapsed         | 8495       |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.08831998 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.557     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0236    |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.028     |
|    value_loss           | 0.179      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=980000, episode_reward=4.99 +/- 2.36
Episode length: 13.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 4.99       |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.10100298 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.497     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.142      |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0212    |
|    value_loss           | 0.201      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 4.68     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 479      |
|    time_elapsed    | 8527     |
|    total_timesteps | 980992   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.88        |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 480         |
|    time_elapsed         | 8564        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.060661234 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.464      |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00478     |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.23        |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.6      |
|    ep_rew_mean          | 5.27      |
| time/                   |           |
|    fps                  | 114       |
|    iterations           | 481       |
|    time_elapsed         | 8614      |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 0.1148729 |
|    clip_fraction        | 0.278     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.543    |
|    explained_variance   | 0.915     |
|    learning_rate        | 0.001     |
|    loss                 | -0.029    |
|    n_updates            | 4800      |
|    policy_gradient_loss | -0.0263   |
|    value_loss           | 0.205     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.2        |
|    ep_rew_mean          | 4.6         |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 482         |
|    time_elapsed         | 8653        |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.073183715 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.42       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0427      |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.026      |
|    value_loss           | 0.21        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 4.85       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 483        |
|    time_elapsed         | 8677       |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.08833037 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.62      |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0137     |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.222      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=3.39 +/- 0.19
Episode length: 12.67 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 3.39       |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.08228479 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.561     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00622   |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.0375    |
|    value_loss           | 0.216      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 5.61     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 484      |
|    time_elapsed    | 8710     |
|    total_timesteps | 991232   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.7       |
|    ep_rew_mean          | 4.67       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 485        |
|    time_elapsed         | 8740       |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.08675486 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.507     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | 0.01       |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.248      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 3.38       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 486        |
|    time_elapsed         | 8765       |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.08128108 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.561     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0203     |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.0146    |
|    value_loss           | 0.267      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.2       |
|    ep_rew_mean          | 2.91       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 487        |
|    time_elapsed         | 8792       |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.07621724 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.816     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0302    |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0203    |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 2.26       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 488        |
|    time_elapsed         | 8818       |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.09781836 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.703     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0764    |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0209    |
|    value_loss           | 0.162      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=1000000, episode_reward=-17.23 +/- 18.07
Episode length: 104.33 +/- 64.58
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 104       |
|    mean_reward          | -17.2     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.0809274 |
|    clip_fraction        | 0.312     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.73     |
|    explained_variance   | 0.923     |
|    learning_rate        | 0.001     |
|    loss                 | 0.121     |
|    n_updates            | 4880      |
|    policy_gradient_loss | -0.0313   |
|    value_loss           | 0.181     |
---------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.5     |
|    ep_rew_mean     | 4.7      |
| time/              |          |
|    fps             | 113      |
|    iterations      | 489      |
|    time_elapsed    | 8845     |
|    total_timesteps | 1001472  |
---------------------------------
