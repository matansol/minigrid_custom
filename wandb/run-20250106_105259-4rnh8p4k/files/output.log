Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000001F002F71510> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001F002F712A0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -33      |
| time/              |          |
|    fps             | 44       |
|    iterations      | 1        |
|    time_elapsed    | 46       |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -32         |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 2           |
|    time_elapsed         | 74          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011629351 |
|    clip_fraction        | 0.0669      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00293    |
|    learning_rate        | 0.001       |
|    loss                 | 0.00511     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0122     |
|    value_loss           | 0.424       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -31.7       |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 3           |
|    time_elapsed         | 103         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.016101139 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.119      |
|    learning_rate        | 0.001       |
|    loss                 | 0.395       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.303       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -31.7       |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 4           |
|    time_elapsed         | 133         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015553767 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.0202     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0153      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.222       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.016350368 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | -0.0807     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0789      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.273       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -31.5    |
| time/              |          |
|    fps             | 61       |
|    iterations      | 5        |
|    time_elapsed    | 166      |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -31.2       |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 6           |
|    time_elapsed         | 193         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.013449925 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.634      |
|    learning_rate        | 0.001       |
|    loss                 | 0.00949     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 0.109       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -30.9       |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 7           |
|    time_elapsed         | 222         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.014169648 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.245      |
|    learning_rate        | 0.001       |
|    loss                 | 0.106       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0114     |
|    value_loss           | 0.0803      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -30.8       |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 8           |
|    time_elapsed         | 252         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012911415 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.0903     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0668     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.07        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -30.1       |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 9           |
|    time_elapsed         | 281         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.028873231 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.221      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0129     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0226     |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.019366473 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.001       |
|    loss                 | -0.073      |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.0753      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -30.2    |
| time/              |          |
|    fps             | 64       |
|    iterations      | 10       |
|    time_elapsed    | 317      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -29.8       |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 11          |
|    time_elapsed         | 348         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.022590127 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.318      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0897     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.063       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 12          |
|    time_elapsed         | 380         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.019970179 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.119      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0213      |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.0781      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -29.2       |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 13          |
|    time_elapsed         | 410         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.028860364 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.0793     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0248      |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0241     |
|    value_loss           | 0.222       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -28.5      |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 14         |
|    time_elapsed         | 433        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03132441 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | -0.582     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0839    |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0194    |
|    value_loss           | 0.0998     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 30000      |
| train/                  |            |
|    approx_kl            | 0.03553476 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.178      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0491    |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.0121    |
|    value_loss           | 0.187      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -28.1    |
| time/              |          |
|    fps             | 66       |
|    iterations      | 15       |
|    time_elapsed    | 462      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -28.1       |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 16          |
|    time_elapsed         | 486         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.031901196 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.0116      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0128      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00779    |
|    value_loss           | 0.205       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -28         |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 17          |
|    time_elapsed         | 515         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.026841715 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | -0.327      |
|    learning_rate        | 0.001       |
|    loss                 | 0.16        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.113       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 141        |
|    ep_rew_mean          | -27        |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 18         |
|    time_elapsed         | 549        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.02583791 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | -0.721     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0449    |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.013     |
|    value_loss           | 0.1        |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 141         |
|    ep_rew_mean          | -27         |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 19          |
|    time_elapsed         | 579         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.020501371 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | -0.257      |
|    learning_rate        | 0.001       |
|    loss                 | 0.217       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.247       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.035168074 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | -0.263      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0205      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.123       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | -26.7    |
| time/              |          |
|    fps             | 66       |
|    iterations      | 20       |
|    time_elapsed    | 615      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 138         |
|    ep_rew_mean          | -26.3       |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 21          |
|    time_elapsed         | 648         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.024431292 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.0576      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0463     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0251     |
|    value_loss           | 0.117       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 138        |
|    ep_rew_mean          | -26.3      |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 22         |
|    time_elapsed         | 679        |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.02626717 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0596    |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.0166    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 129         |
|    ep_rew_mean          | -23.4       |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 23          |
|    time_elapsed         | 707         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.031303316 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0488     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0227     |
|    value_loss           | 0.0998      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 121         |
|    ep_rew_mean          | -21.1       |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 24          |
|    time_elapsed         | 735         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.038429294 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00156    |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0308     |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.04703029 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.76      |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.001      |
|    loss                 | 0.109      |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0278    |
|    value_loss           | 0.253      |
----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 115      |
|    ep_rew_mean     | -19.4    |
| time/              |          |
|    fps             | 66       |
|    iterations      | 25       |
|    time_elapsed    | 766      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 106        |
|    ep_rew_mean          | -16.9      |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 26         |
|    time_elapsed         | 795        |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.03748297 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.69      |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.001      |
|    loss                 | -0.067     |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.0266    |
|    value_loss           | 0.25       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 98.9        |
|    ep_rew_mean          | -15.4       |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 27          |
|    time_elapsed         | 822         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.045230664 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0521     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0244     |
|    value_loss           | 0.182       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 99.9       |
|    ep_rew_mean          | -15.7      |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 28         |
|    time_elapsed         | 850        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.04356664 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.63      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0415    |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 98.6        |
|    ep_rew_mean          | -15.6       |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 29          |
|    time_elapsed         | 880         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.036148403 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0454     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0171     |
|    value_loss           | 0.16        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.04020475 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.62      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.001      |
|    loss                 | 0.016      |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.00933   |
|    value_loss           | 0.173      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93       |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    fps             | 67       |
|    iterations      | 30       |
|    time_elapsed    | 905      |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 74.1       |
|    ep_rew_mean          | -9.97      |
| time/                   |            |
|    fps                  | 68         |
|    iterations           | 31         |
|    time_elapsed         | 928        |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.05531606 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.54      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0177     |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.0199    |
|    value_loss           | 0.156      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 65.1        |
|    ep_rew_mean          | -8.06       |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 32          |
|    time_elapsed         | 953         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.044303156 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00233     |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0189     |
|    value_loss           | 0.211       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.9       |
|    ep_rew_mean          | -5.34      |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 33         |
|    time_elapsed         | 976        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.06777876 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.46      |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0487    |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.02      |
|    value_loss           | 0.182      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | -1.83       |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 34          |
|    time_elapsed         | 1001        |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.045442544 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.001       |
|    loss                 | 0.153       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0194     |
|    value_loss           | 0.264       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-7.58 +/- 15.85
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -7.58      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.03747089 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00168    |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0145    |
|    value_loss           | 0.224      |
----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.6     |
|    ep_rew_mean     | -0.903   |
| time/              |          |
|    fps             | 69       |
|    iterations      | 35       |
|    time_elapsed    | 1025     |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.8       |
|    ep_rew_mean          | -0.332     |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 36         |
|    time_elapsed         | 1048       |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.05434444 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0249     |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0213    |
|    value_loss           | 0.277      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.1        |
|    ep_rew_mean          | -0.796      |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 37          |
|    time_elapsed         | 1073        |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.050158106 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0533      |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0254     |
|    value_loss           | 0.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.1        |
|    ep_rew_mean          | -0.431      |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 38          |
|    time_elapsed         | 1099        |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.045114204 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0534      |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0145     |
|    value_loss           | 0.149       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.5       |
|    ep_rew_mean          | -0.325     |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 39         |
|    time_elapsed         | 1127       |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.04306353 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0228    |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.0187    |
|    value_loss           | 0.254      |
----------------------------------------
reached max steps=300
Eval num_timesteps=80000, episode_reward=-7.51 +/- 15.90
Episode length: 57.33 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.3       |
|    mean_reward          | -7.51      |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.08118327 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.09      |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.001      |
|    loss                 | -0.01      |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.454      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.5     |
|    ep_rew_mean     | 0.582    |
| time/              |          |
|    fps             | 70       |
|    iterations      | 40       |
|    time_elapsed    | 1157     |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28         |
|    ep_rew_mean          | 0.845      |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 41         |
|    time_elapsed         | 1185       |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.06922876 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.989     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0346    |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.0237    |
|    value_loss           | 0.267      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.2        |
|    ep_rew_mean          | 1.1         |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 42          |
|    time_elapsed         | 1213        |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.068005614 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.97       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0332      |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0283     |
|    value_loss           | 0.239       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | -0.186      |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 43          |
|    time_elapsed         | 1240        |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.053038888 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.993      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0443     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0235     |
|    value_loss           | 0.167       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-7.51 +/- 15.90
Episode length: 57.33 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.3       |
|    mean_reward          | -7.51      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.05266761 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.975     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00689    |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0212    |
|    value_loss           | 0.254      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28       |
|    ep_rew_mean     | 0.483    |
| time/              |          |
|    fps             | 70       |
|    iterations      | 44       |
|    time_elapsed    | 1271     |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.7        |
|    ep_rew_mean          | 1.25        |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 45          |
|    time_elapsed         | 1299        |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.045208056 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.929      |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.001       |
|    loss                 | 0.191       |
|    n_updates            | 440         |
|    policy_gradient_loss | 0.00277     |
|    value_loss           | 0.35        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 1.49       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 46         |
|    time_elapsed         | 1329       |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.08323699 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.897     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.001      |
|    loss                 | 0.11       |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 0.205      |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 47         |
|    time_elapsed         | 1358       |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.06409141 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.837     |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0455    |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.5       |
|    ep_rew_mean          | 1.21       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 48         |
|    time_elapsed         | 1384       |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.07404146 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.954     |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.001      |
|    loss                 | 0.124      |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0361    |
|    value_loss           | 0.563      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.09012559 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.804     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | 0.154      |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0375    |
|    value_loss           | 0.285      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.3     |
|    ep_rew_mean     | -0.25    |
| time/              |          |
|    fps             | 70       |
|    iterations      | 49       |
|    time_elapsed    | 1415     |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.6       |
|    ep_rew_mean          | -1.92      |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 50         |
|    time_elapsed         | 1443       |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.11856499 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.869     |
|    explained_variance   | -0.281     |
|    learning_rate        | 0.001      |
|    loss                 | 0.294      |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0528    |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.2       |
|    ep_rew_mean          | 0.522      |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 51         |
|    time_elapsed         | 1471       |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.08547117 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.529      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00719    |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.577      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.8        |
|    ep_rew_mean          | 1.08        |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 52          |
|    time_elapsed         | 1498        |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.108821675 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.918      |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.001       |
|    loss                 | 0.11        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0322     |
|    value_loss           | 0.34        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.4       |
|    ep_rew_mean          | -0.794     |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 53         |
|    time_elapsed         | 1524       |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.06807193 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.947     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000881  |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=110000, episode_reward=4.60 +/- 1.22
Episode length: 11.67 +/- 0.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 11.7        |
|    mean_reward          | 4.6         |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.067947395 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0576     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0223     |
|    value_loss           | 0.18        |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 0.159    |
| time/              |          |
|    fps             | 71       |
|    iterations      | 54       |
|    time_elapsed    | 1553     |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.4      |
|    ep_rew_mean          | 0.734     |
| time/                   |           |
|    fps                  | 71        |
|    iterations           | 55        |
|    time_elapsed         | 1585      |
|    total_timesteps      | 112640    |
| train/                  |           |
|    approx_kl            | 0.0465044 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.03     |
|    explained_variance   | 0.901     |
|    learning_rate        | 0.001     |
|    loss                 | -0.00541  |
|    n_updates            | 540       |
|    policy_gradient_loss | -0.0213   |
|    value_loss           | 0.183     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 1.19        |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 56          |
|    time_elapsed         | 1613        |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.044037215 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.989      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0459      |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.134       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 1.71       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 57         |
|    time_elapsed         | 1640       |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.04752147 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.965     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0127    |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0272    |
|    value_loss           | 0.149      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 0.887      |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 58         |
|    time_elapsed         | 1669       |
|    total_timesteps      | 118784     |
| train/                  |            |
|    approx_kl            | 0.05589144 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.916     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0154     |
|    n_updates            | 570        |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 0.149      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-6.79 +/- 16.46
Episode length: 58.67 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -6.79      |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.04795014 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0727     |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.3     |
|    ep_rew_mean     | -0.0749  |
| time/              |          |
|    fps             | 71       |
|    iterations      | 59       |
|    time_elapsed    | 1698     |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 3.05       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 60         |
|    time_elapsed         | 1726       |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.06003073 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0476    |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.413      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.8      |
|    ep_rew_mean          | 2.45      |
| time/                   |           |
|    fps                  | 71        |
|    iterations           | 61        |
|    time_elapsed         | 1751      |
|    total_timesteps      | 124928    |
| train/                  |           |
|    approx_kl            | 0.0681424 |
|    clip_fraction        | 0.295     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.745    |
|    explained_variance   | 0.854     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0244    |
|    n_updates            | 600       |
|    policy_gradient_loss | -0.0375   |
|    value_loss           | 0.337     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 2.22       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 62         |
|    time_elapsed         | 1778       |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.09447775 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.753     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.001      |
|    loss                 | 0.016      |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.0429    |
|    value_loss           | 0.235      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.86       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 63         |
|    time_elapsed         | 1808       |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.06994135 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.69      |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00368    |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=130000, episode_reward=-6.65 +/- 16.55
Episode length: 58.00 +/- 65.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -6.65       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.066608965 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.813      |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0669     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0281     |
|    value_loss           | 0.124       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 2.08     |
| time/              |          |
|    fps             | 71       |
|    iterations      | 64       |
|    time_elapsed    | 1836     |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 2.38       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 65         |
|    time_elapsed         | 1863       |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.09316901 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0422     |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.0292    |
|    value_loss           | 0.2        |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 2.08        |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 66          |
|    time_elapsed         | 1889        |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.057856344 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0474      |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.141       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 2.89       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 67         |
|    time_elapsed         | 1918       |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.05618561 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.762     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.116      |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.197      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.4        |
|    ep_rew_mean          | 1.58        |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 68          |
|    time_elapsed         | 1946        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.077859774 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.739      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | -0.029      |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0428     |
|    value_loss           | 0.145       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=140000, episode_reward=4.39 +/- 1.39
Episode length: 12.67 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 4.39       |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.07704172 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.931     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | 0.11       |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0403    |
|    value_loss           | 0.226      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.731    |
| time/              |          |
|    fps             | 71       |
|    iterations      | 69       |
|    time_elapsed    | 1976     |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 0.967      |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 70         |
|    time_elapsed         | 1999       |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.09719961 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.994     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0111    |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.266      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.16       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 71         |
|    time_elapsed         | 2023       |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.08285545 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.843     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00567    |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.107      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.88       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 72         |
|    time_elapsed         | 2048       |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.06523361 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.765     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.001      |
|    loss                 | 0.161      |
|    n_updates            | 710        |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.133      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.16       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 73         |
|    time_elapsed         | 2067       |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.05991756 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.854     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0302    |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0338    |
|    value_loss           | 0.157      |
----------------------------------------
reached max steps=300
Eval num_timesteps=150000, episode_reward=-6.79 +/- 16.45
Episode length: 58.67 +/- 64.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.7        |
|    mean_reward          | -6.79       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.052697483 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0639      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0398     |
|    value_loss           | 0.219       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 2.35     |
| time/              |          |
|    fps             | 71       |
|    iterations      | 74       |
|    time_elapsed    | 2106     |
|    total_timesteps | 151552   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 1.64       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 75         |
|    time_elapsed         | 2134       |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.05876617 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.726     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00516    |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.0264    |
|    value_loss           | 0.192      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 3.25       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 76         |
|    time_elapsed         | 2167       |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.05237709 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.819     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0587    |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0226    |
|    value_loss           | 0.111      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.6        |
|    ep_rew_mean          | 2.17        |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 77          |
|    time_elapsed         | 2193        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.050826386 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0546      |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0243     |
|    value_loss           | 0.2         |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 2.99       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 78         |
|    time_elapsed         | 2222       |
|    total_timesteps      | 159744     |
| train/                  |            |
|    approx_kl            | 0.05088168 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.59      |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0653    |
|    n_updates            | 770        |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.198      |
----------------------------------------
Eval num_timesteps=160000, episode_reward=3.67 +/- 0.10
Episode length: 11.33 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.3       |
|    mean_reward          | 3.67       |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.06287677 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.692     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0386    |
|    n_updates            | 780        |
|    policy_gradient_loss | -0.0234    |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 1.62     |
| time/              |          |
|    fps             | 71       |
|    iterations      | 79       |
|    time_elapsed    | 2247     |
|    total_timesteps | 161792   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 0.911      |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 80         |
|    time_elapsed         | 2275       |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.06427464 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.939     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | 0.103      |
|    n_updates            | 790        |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.226      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.97       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 81         |
|    time_elapsed         | 2303       |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.08081567 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.898     |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.001      |
|    loss                 | -0.041     |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0456    |
|    value_loss           | 0.273      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 1.64       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 82         |
|    time_elapsed         | 2329       |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.06036398 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.767     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0295    |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 3.33       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 83         |
|    time_elapsed         | 2369       |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.06661151 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.86      |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0372    |
|    n_updates            | 820        |
|    policy_gradient_loss | -0.0379    |
|    value_loss           | 0.162      |
----------------------------------------
Eval num_timesteps=170000, episode_reward=3.67 +/- 0.10
Episode length: 11.33 +/- 0.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 11.3        |
|    mean_reward          | 3.67        |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.115895554 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0112      |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.7     |
|    ep_rew_mean     | 0.299    |
| time/              |          |
|    fps             | 71       |
|    iterations      | 84       |
|    time_elapsed    | 2400     |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.9       |
|    ep_rew_mean          | -2.84      |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 85         |
|    time_elapsed         | 2427       |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.07247139 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.967     |
|    explained_variance   | -0.243     |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0365    |
|    value_loss           | 0.869      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.5        |
|    ep_rew_mean          | -3.45       |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 86          |
|    time_elapsed         | 2453        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.075111866 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.979      |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.001       |
|    loss                 | 0.327       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0372     |
|    value_loss           | 0.566       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.7        |
|    ep_rew_mean          | -0.123      |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 87          |
|    time_elapsed         | 2477        |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.055152602 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.904      |
|    explained_variance   | 0.677       |
|    learning_rate        | 0.001       |
|    loss                 | 0.158       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.427       |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=4.53 +/- 1.42
Episode length: 12.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12          |
|    mean_reward          | 4.53        |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.076689065 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.893      |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0437      |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0425     |
|    value_loss           | 0.374       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 1.78     |
| time/              |          |
|    fps             | 71       |
|    iterations      | 88       |
|    time_elapsed    | 2503     |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 1.99       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 89         |
|    time_elapsed         | 2530       |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.07538828 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.846     |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0999     |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.0421    |
|    value_loss           | 0.346      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 2.74       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 90         |
|    time_elapsed         | 2555       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.07813103 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.796     |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.001      |
|    loss                 | 0.18       |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0439    |
|    value_loss           | 0.626      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 16.6      |
|    ep_rew_mean          | 3.35      |
| time/                   |           |
|    fps                  | 72        |
|    iterations           | 91        |
|    time_elapsed         | 2580      |
|    total_timesteps      | 186368    |
| train/                  |           |
|    approx_kl            | 0.0678306 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.65     |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.001     |
|    loss                 | 0.134     |
|    n_updates            | 900       |
|    policy_gradient_loss | -0.0478   |
|    value_loss           | 0.291     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 1.5        |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 92         |
|    time_elapsed         | 2604       |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.07090495 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.574     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.00328   |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.127      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=190000, episode_reward=-18.76 +/- 15.90
Episode length: 103.67 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.09156135 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.866     |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.001      |
|    loss                 | -0.067     |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0466    |
|    value_loss           | 0.126      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 2.64     |
| time/              |          |
|    fps             | 72       |
|    iterations      | 93       |
|    time_elapsed    | 2636     |
|    total_timesteps | 190464   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.1        |
|    ep_rew_mean          | 2.71        |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 94          |
|    time_elapsed         | 2661        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.056768492 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.625      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0762     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0219     |
|    value_loss           | 0.0957      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.9        |
|    ep_rew_mean          | 3.31        |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 95          |
|    time_elapsed         | 2687        |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.038316824 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0179     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 0.0689      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.9       |
|    ep_rew_mean          | 3.55       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 96         |
|    time_elapsed         | 2711       |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.05687189 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.507     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0213    |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.126      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 2.02        |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 97          |
|    time_elapsed         | 2737        |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.045382917 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.473      |
|    explained_variance   | 0.969       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0725     |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.064       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=200000, episode_reward=-7.51 +/- 15.90
Episode length: 57.33 +/- 65.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 57.3        |
|    mean_reward          | -7.51       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.054296806 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.632      |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0391     |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0234     |
|    value_loss           | 0.0703      |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 2.67     |
| time/              |          |
|    fps             | 72       |
|    iterations      | 98       |
|    time_elapsed    | 2765     |
|    total_timesteps | 200704   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.2       |
|    ep_rew_mean          | 3.19       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 99         |
|    time_elapsed         | 2790       |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.03019173 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.579     |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0336    |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.019     |
|    value_loss           | 0.0903     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.9        |
|    ep_rew_mean          | 3.31        |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 100         |
|    time_elapsed         | 2815        |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.042263523 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.519      |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0408     |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.022      |
|    value_loss           | 0.0549      |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 2.36        |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 101         |
|    time_elapsed         | 2838        |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.056430828 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.538      |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0321     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0285     |
|    value_loss           | 0.0782      |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 14.4       |
|    ep_rew_mean          | 3.61       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 102        |
|    time_elapsed         | 2864       |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.11027631 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.613     |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0317    |
|    n_updates            | 1010       |
|    policy_gradient_loss | -0.0489    |
|    value_loss           | 0.0801     |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=210000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.06787512 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0251    |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.022     |
|    value_loss           | 0.0481     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 2.81     |
| time/              |          |
|    fps             | 72       |
|    iterations      | 103      |
|    time_elapsed    | 2893     |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 2.89       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 104        |
|    time_elapsed         | 2919       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.07922739 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.744     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0358    |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.146      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.5        |
|    ep_rew_mean          | 2.91        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 105         |
|    time_elapsed         | 2943        |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.062945105 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.755      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0388     |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.044      |
|    value_loss           | 0.164       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.57       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 106        |
|    time_elapsed         | 2966       |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.06580308 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.662     |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.001      |
|    loss                 | 0.329      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.268      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.09       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 107        |
|    time_elapsed         | 2992       |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.08255073 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.736     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00834   |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 0.322      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=220000, episode_reward=-7.58 +/- 15.85
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -7.58      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.08173058 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.71      |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.001      |
|    loss                 | 0.0283     |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.0421    |
|    value_loss           | 0.203      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.1     |
|    ep_rew_mean     | 3.45     |
| time/              |          |
|    fps             | 73       |
|    iterations      | 108      |
|    time_elapsed    | 3022     |
|    total_timesteps | 221184   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 3.07       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 109        |
|    time_elapsed         | 3048       |
|    total_timesteps      | 223232     |
| train/                  |            |
|    approx_kl            | 0.08861169 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.607     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0541     |
|    n_updates            | 1080       |
|    policy_gradient_loss | -0.0271    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 2.27        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 110         |
|    time_elapsed         | 3070        |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.070845336 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.001       |
|    loss                 | 0.291       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.626       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.6       |
|    ep_rew_mean          | 3.67       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 111        |
|    time_elapsed         | 3094       |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.13864027 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.678     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00289    |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.0579    |
|    value_loss           | 0.345      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 1.99       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 112        |
|    time_elapsed         | 3122       |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.09345529 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | 0.00917    |
|    n_updates            | 1110       |
|    policy_gradient_loss | -0.0514    |
|    value_loss           | 0.166      |
----------------------------------------
Eval num_timesteps=230000, episode_reward=5.53 +/- 1.41
Episode length: 12.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 12        |
|    mean_reward          | 5.53      |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0952957 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.806    |
|    explained_variance   | 0.933     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0223   |
|    n_updates            | 1120      |
|    policy_gradient_loss | -0.0405   |
|    value_loss           | 0.121     |
---------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 3.29     |
| time/              |          |
|    fps             | 73       |
|    iterations      | 113      |
|    time_elapsed    | 3148     |
|    total_timesteps | 231424   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 3.05       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 114        |
|    time_elapsed         | 3173       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.05711921 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.557     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0597    |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.177      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 2.29       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 115        |
|    time_elapsed         | 3197       |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.06667973 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.569     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | 0.067      |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.102      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.5        |
|    ep_rew_mean          | 3.31        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 116         |
|    time_elapsed         | 3222        |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.078588456 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0329      |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 0.165       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.7       |
|    ep_rew_mean          | 1.69       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 117        |
|    time_elapsed         | 3248       |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.07718086 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.497     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00132    |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.0411    |
|    value_loss           | 0.122      |
----------------------------------------
Eval num_timesteps=240000, episode_reward=3.53 +/- 0.17
Episode length: 12.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12          |
|    mean_reward          | 3.53        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.088381715 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.782      |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0582     |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0401     |
|    value_loss           | 0.188       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 3.04     |
| time/              |          |
|    fps             | 73       |
|    iterations      | 118      |
|    time_elapsed    | 3274     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 2.12        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 119         |
|    time_elapsed         | 3299        |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.075460285 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.693      |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.001       |
|    loss                 | -0.028      |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0411     |
|    value_loss           | 0.202       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 2.23        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 120         |
|    time_elapsed         | 3321        |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.047384225 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.708      |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.001       |
|    loss                 | 0.222       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0365     |
|    value_loss           | 0.828       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.2        |
|    ep_rew_mean          | 3.13        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 121         |
|    time_elapsed         | 3347        |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.071389616 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0137     |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.562       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 2.91        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 122         |
|    time_elapsed         | 3374        |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.092965916 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.655      |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0638     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0428     |
|    value_loss           | 0.224       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=250000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -18.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.071374565 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0704      |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0431     |
|    value_loss           | 0.194       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 2.97     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 123      |
|    time_elapsed    | 3401     |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.7       |
|    ep_rew_mean          | 3.25       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 124        |
|    time_elapsed         | 3425       |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.07279924 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.626     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0493    |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.0446    |
|    value_loss           | 0.189      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 2.64       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 125        |
|    time_elapsed         | 3450       |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.06593981 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.553     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0731    |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.0403    |
|    value_loss           | 0.153      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 14         |
|    ep_rew_mean          | 3.63       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 126        |
|    time_elapsed         | 3477       |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.07256743 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.602     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0149    |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.0502    |
|    value_loss           | 0.102      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=260000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58         |
|    mean_reward          | -7.65      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.06232152 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.335     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0609    |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.102      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 2.54     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 127      |
|    time_elapsed    | 3503     |
|    total_timesteps | 260096   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 3.02       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 128        |
|    time_elapsed         | 3529       |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.09675615 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.547     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0194    |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.0495    |
|    value_loss           | 0.162      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.4       |
|    ep_rew_mean          | 3.01       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 129        |
|    time_elapsed         | 3551       |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.09008288 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.516     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0149    |
|    n_updates            | 1280       |
|    policy_gradient_loss | 0.00507    |
|    value_loss           | 0.125      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.3        |
|    ep_rew_mean          | 3.88        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 130         |
|    time_elapsed         | 3576        |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.063136436 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.42       |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00968     |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.185       |
|    value_loss           | 0.116       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.16       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 131        |
|    time_elapsed         | 3604       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.03757067 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.395     |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0474    |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.0192    |
|    value_loss           | 0.0602     |
----------------------------------------
reached max steps=300
Eval num_timesteps=270000, episode_reward=4.39 +/- 1.37
Episode length: 12.67 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 4.39       |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.06774996 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.449     |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0142    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.114      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 2.79     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 132      |
|    time_elapsed    | 3629     |
|    total_timesteps | 270336   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.4       |
|    ep_rew_mean          | 3.32       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 133        |
|    time_elapsed         | 3653       |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.06710589 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0473    |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.1        |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 2.33        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 134         |
|    time_elapsed         | 3676        |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.086375244 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.464      |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0739     |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0443     |
|    value_loss           | 0.0526      |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 1.93       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 135        |
|    time_elapsed         | 3711       |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.09466039 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.593     |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.001      |
|    loss                 | 0.154      |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.0491    |
|    value_loss           | 0.634      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.5       |
|    ep_rew_mean          | 3.62       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 136        |
|    time_elapsed         | 3739       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.09640698 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.001      |
|    loss                 | 0.401      |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0491    |
|    value_loss           | 0.472      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=-16.82 +/- 16.56
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -16.8       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.101752296 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.494      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0398     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0436     |
|    value_loss           | 0.181       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 3.02     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 137      |
|    time_elapsed    | 3766     |
|    total_timesteps | 280576   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.9       |
|    ep_rew_mean          | 3.53       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 138        |
|    time_elapsed         | 3790       |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.07956467 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.646     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0446     |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.0429    |
|    value_loss           | 0.132      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.1        |
|    ep_rew_mean          | 3.46        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 139         |
|    time_elapsed         | 3815        |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.066159785 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.441      |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0111     |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0432     |
|    value_loss           | 0.0892      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.37       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 140        |
|    time_elapsed         | 3842       |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.06583857 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.491     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0182     |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.11       |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.2        |
|    ep_rew_mean          | 3.63        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 141         |
|    time_elapsed         | 3869        |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.056583725 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.501      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0581     |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.0323     |
|    value_loss           | 0.114       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=290000, episode_reward=-18.96 +/- 15.61
Episode length: 104.67 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -19        |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.05064567 |
|    clip_fraction        | 0.196      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.413     |
|    explained_variance   | 0.957      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0389     |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0257    |
|    value_loss           | 0.0732     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 2.77     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 142      |
|    time_elapsed    | 3901     |
|    total_timesteps | 290816   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 15.3        |
|    ep_rew_mean          | 3.61        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 143         |
|    time_elapsed         | 3929        |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.056355715 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.614      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0509     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.0638      |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.4        |
|    ep_rew_mean          | 3.09        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 144         |
|    time_elapsed         | 3956        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.046653308 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.354      |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.001       |
|    loss                 | -0.054      |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0241     |
|    value_loss           | 0.061       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 14.2       |
|    ep_rew_mean          | 3.52       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 145        |
|    time_elapsed         | 3985       |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.07308644 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.428     |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0751    |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0417    |
|    value_loss           | 0.0385     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.2        |
|    ep_rew_mean          | 3.86        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 146         |
|    time_elapsed         | 4012        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.036452577 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.337      |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0431     |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.0407      |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=4.67 +/- 1.32
Episode length: 11.33 +/- 0.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 11.3        |
|    mean_reward          | 4.67        |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.048875596 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.272      |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0403     |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0251     |
|    value_loss           | 0.0591      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 14.4     |
|    ep_rew_mean     | 3.7      |
| time/              |          |
|    fps             | 74       |
|    iterations      | 147      |
|    time_elapsed    | 4043     |
|    total_timesteps | 301056   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 2.8        |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 148        |
|    time_elapsed         | 4071       |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.05683509 |
|    clip_fraction        | 0.0992     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.174     |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00812    |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.0144    |
|    value_loss           | 0.0929     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.28       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 149        |
|    time_elapsed         | 4098       |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.05411221 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.549     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.079     |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.0144    |
|    value_loss           | 0.107      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.9        |
|    ep_rew_mean          | 3.14        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 150         |
|    time_elapsed         | 4124        |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.072033525 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.402      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.001       |
|    loss                 | -0.097      |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.038      |
|    value_loss           | 0.118       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.7        |
|    ep_rew_mean          | 3.69        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 151         |
|    time_elapsed         | 4147        |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.061313696 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.467      |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0768     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0369     |
|    value_loss           | 0.112       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=310000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58         |
|    mean_reward          | -7.65      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.08960693 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.318     |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0656    |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.0567     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 14.8     |
|    ep_rew_mean     | 3.67     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 152      |
|    time_elapsed    | 4172     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.6        |
|    ep_rew_mean          | 3.27        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 153         |
|    time_elapsed         | 4201        |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.056789655 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.338      |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0718      |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0221     |
|    value_loss           | 0.15        |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 14.8      |
|    ep_rew_mean          | 3.83      |
| time/                   |           |
|    fps                  | 74        |
|    iterations           | 154       |
|    time_elapsed         | 4233      |
|    total_timesteps      | 315392    |
| train/                  |           |
|    approx_kl            | 0.0532506 |
|    clip_fraction        | 0.166     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.395    |
|    explained_variance   | 0.909     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0208    |
|    n_updates            | 1530      |
|    policy_gradient_loss | -0.0257   |
|    value_loss           | 0.26      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 2.95        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 155         |
|    time_elapsed         | 4261        |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.049750097 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.361      |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0128     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0209     |
|    value_loss           | 0.0437      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 1.62       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 156        |
|    time_elapsed         | 4285       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.07648658 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.556     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0826    |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0391    |
|    value_loss           | 0.145      |
----------------------------------------
Eval num_timesteps=320000, episode_reward=5.32 +/- 1.41
Episode length: 13.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 5.32       |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.08612909 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.749     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0551    |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.0269    |
|    value_loss           | 0.16       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.4     |
|    ep_rew_mean     | 2.92     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 157      |
|    time_elapsed    | 4314     |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 14.4       |
|    ep_rew_mean          | 4.09       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 158        |
|    time_elapsed         | 4342       |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.06453677 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.505     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | 0.021      |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.0321    |
|    value_loss           | 0.183      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.7      |
|    ep_rew_mean          | 1.84      |
| time/                   |           |
|    fps                  | 74        |
|    iterations           | 159       |
|    time_elapsed         | 4372      |
|    total_timesteps      | 325632    |
| train/                  |           |
|    approx_kl            | 0.0644961 |
|    clip_fraction        | 0.189     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.331    |
|    explained_variance   | 0.957     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0381   |
|    n_updates            | 1580      |
|    policy_gradient_loss | -0.0285   |
|    value_loss           | 0.0725    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.8        |
|    ep_rew_mean          | 3.18        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 160         |
|    time_elapsed         | 4399        |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.077032864 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.714      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0584     |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0364     |
|    value_loss           | 0.144       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 2.92       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 161        |
|    time_elapsed         | 4426       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.08943759 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.443     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0202     |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.139      |
----------------------------------------
Eval num_timesteps=330000, episode_reward=3.60 +/- 0.10
Episode length: 11.67 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.7       |
|    mean_reward          | 3.6        |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.06663756 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.491     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0179     |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0282    |
|    value_loss           | 0.17       |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 2.96     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 162      |
|    time_elapsed    | 4453     |
|    total_timesteps | 331776   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17          |
|    ep_rew_mean          | 3.05        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 163         |
|    time_elapsed         | 4480        |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.054636214 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.426      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0744     |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0262     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.2        |
|    ep_rew_mean          | 3.48        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 164         |
|    time_elapsed         | 4505        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.058433726 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.372      |
|    explained_variance   | 0.961       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0232     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0268     |
|    value_loss           | 0.0691      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.2       |
|    ep_rew_mean          | 3.65       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 165        |
|    time_elapsed         | 4530       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.05464136 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.465     |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0396    |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0232    |
|    value_loss           | 0.0642     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 3.18       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 166        |
|    time_elapsed         | 4558       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.05081719 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.4       |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00261    |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.0625     |
----------------------------------------
reached max steps=300
Eval num_timesteps=340000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -7.65       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.057009522 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.494      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0113     |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0276     |
|    value_loss           | 0.338       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 15.2     |
|    ep_rew_mean     | 3.72     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 167      |
|    time_elapsed    | 4584     |
|    total_timesteps | 342016   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 2.89       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 168        |
|    time_elapsed         | 4609       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.10762093 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.383     |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0674    |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0239    |
|    value_loss           | 0.327      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.46       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 169        |
|    time_elapsed         | 4639       |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.15266562 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.753     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0797     |
|    n_updates            | 1680       |
|    policy_gradient_loss | -0.00392   |
|    value_loss           | 0.291      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.4      |
|    ep_rew_mean          | 2.6       |
| time/                   |           |
|    fps                  | 74        |
|    iterations           | 170       |
|    time_elapsed         | 4679      |
|    total_timesteps      | 348160    |
| train/                  |           |
|    approx_kl            | 0.0876088 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.665    |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0158   |
|    n_updates            | 1690      |
|    policy_gradient_loss | -0.0366   |
|    value_loss           | 0.212     |
---------------------------------------
reached max steps=300
Eval num_timesteps=350000, episode_reward=-7.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -7.65       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.089062065 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.001       |
|    loss                 | -0.03       |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0258     |
|    value_loss           | 0.214       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 2.99     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 171      |
|    time_elapsed    | 4721     |
|    total_timesteps | 350208   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.4      |
|    ep_rew_mean          | 3.3       |
| time/                   |           |
|    fps                  | 74        |
|    iterations           | 172       |
|    time_elapsed         | 4756      |
|    total_timesteps      | 352256    |
| train/                  |           |
|    approx_kl            | 0.0954707 |
|    clip_fraction        | 0.275     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.557    |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0721    |
|    n_updates            | 1710      |
|    policy_gradient_loss | -0.0381   |
|    value_loss           | 0.227     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 2.42       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 173        |
|    time_elapsed         | 4790       |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.08015094 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.551     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0339     |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.174      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 3.07       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 174        |
|    time_elapsed         | 4819       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.07997687 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.588     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0735    |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0378    |
|    value_loss           | 0.242      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.8      |
|    ep_rew_mean          | 2.88      |
| time/                   |           |
|    fps                  | 73        |
|    iterations           | 175       |
|    time_elapsed         | 4848      |
|    total_timesteps      | 358400    |
| train/                  |           |
|    approx_kl            | 0.1022011 |
|    clip_fraction        | 0.285     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.551    |
|    explained_variance   | 0.92      |
|    learning_rate        | 0.001     |
|    loss                 | 0.0277    |
|    n_updates            | 1740      |
|    policy_gradient_loss | -0.0339   |
|    value_loss           | 0.176     |
---------------------------------------
reached max steps=300
Eval num_timesteps=360000, episode_reward=7.32 +/- 2.83
Episode length: 13.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 7.32       |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.09261651 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.644     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0553    |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.106      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.3     |
|    ep_rew_mean     | 3.19     |
| time/              |          |
|    fps             | 73       |
|    iterations      | 176      |
|    time_elapsed    | 4872     |
|    total_timesteps | 360448   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.1        |
|    ep_rew_mean          | 2           |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 177         |
|    time_elapsed         | 4898        |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.100749835 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | 0.018       |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0269     |
|    value_loss           | 0.126       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 2.48       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 178        |
|    time_elapsed         | 4925       |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.09405839 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0284     |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0379    |
|    value_loss           | 0.323      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.6        |
|    ep_rew_mean          | 2.06        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 179         |
|    time_elapsed         | 4951        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.067213774 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.632      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0666      |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0329     |
|    value_loss           | 0.219       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.24       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 180        |
|    time_elapsed         | 4976       |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.06838794 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.815     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0468     |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
Eval num_timesteps=370000, episode_reward=-7.58 +/- 15.85
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -7.58      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.05381961 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.745     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00552   |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.104      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 3.02     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 181      |
|    time_elapsed    | 5001     |
|    total_timesteps | 370688   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19          |
|    ep_rew_mean          | 2.87        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 182         |
|    time_elapsed         | 5027        |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.061178155 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0167     |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0297     |
|    value_loss           | 0.145       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.28       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 183        |
|    time_elapsed         | 5054       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.08266744 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.546     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0548    |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 0.0897     |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 15.9        |
|    ep_rew_mean          | 3.61        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 184         |
|    time_elapsed         | 5082        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.122806214 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0314     |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0333     |
|    value_loss           | 0.102       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.8        |
|    ep_rew_mean          | 2.92        |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 185         |
|    time_elapsed         | 5107        |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.061076388 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.433      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0373      |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0353     |
|    value_loss           | 0.0897      |
-----------------------------------------
Traceback (most recent call last):
  File "C:\Users\matan\master_thesis\minigrid_custom\minigrid_custom_train.py", line 358, in <module>
    if __name__ == "__main__":
  File "C:\Users\matan\master_thesis\minigrid_custom\minigrid_custom_train.py", line 310, in main
    print(next(model.policy.parameters()).device)  # Ensure using GPU, should print cuda:0
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\ppo\ppo.py", line 311, in learn
    return super().learn(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 336, in learn
    self.train()
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\ppo\ppo.py", line 275, in train
    loss.backward()
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\torch\_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\torch\autograd\__init__.py", line 347, in backward
    _engine_run_backward(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
