Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x0000021097A41510> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000021097A412A0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -30.7    |
| time/              |          |
|    fps             | 223      |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -30.9       |
| time/                   |             |
|    fps                  | 203         |
|    iterations           | 2           |
|    time_elapsed         | 20          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010677103 |
|    clip_fraction        | 0.0578      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00161    |
|    learning_rate        | 0.001       |
|    loss                 | -0.0284     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00789    |
|    value_loss           | 0.352       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -31.5      |
| time/                   |            |
|    fps                  | 195        |
|    iterations           | 3          |
|    time_elapsed         | 31         |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.00362548 |
|    clip_fraction        | 0.051      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.93      |
|    explained_variance   | 0.0285     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0275     |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.00985   |
|    value_loss           | 0.324      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -31.4       |
| time/                   |             |
|    fps                  | 186         |
|    iterations           | 4           |
|    time_elapsed         | 43          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.012399542 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.0854     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0806      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0117     |
|    value_loss           | 0.236       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.024891205 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.0527     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0492     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0193     |
|    value_loss           | 0.179       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -31.1    |
| time/              |          |
|    fps             | 180      |
|    iterations      | 5        |
|    time_elapsed    | 56       |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -30.6       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 6           |
|    time_elapsed         | 71          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.019819817 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.348      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0628     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.0434      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -30.1       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 7           |
|    time_elapsed         | 84          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.023533411 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.0054      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0737     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0238     |
|    value_loss           | 0.1         |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 149        |
|    ep_rew_mean          | -30        |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 8          |
|    time_elapsed         | 97         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.02424338 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.87      |
|    explained_variance   | -0.155     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0728    |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.0238    |
|    value_loss           | 0.0988     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 9           |
|    time_elapsed         | 109         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.029812748 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -0.355      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0651     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0319     |
|    value_loss           | 0.0871      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.03311339 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.00545    |
|    learning_rate        | 0.001      |
|    loss                 | -0.0906    |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.143      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -29.2    |
| time/              |          |
|    fps             | 165      |
|    iterations      | 10       |
|    time_elapsed    | 123      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -28.5       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 11          |
|    time_elapsed         | 135         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.040258978 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | -0.686      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0378      |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.019      |
|    value_loss           | 0.214       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -28.3       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 12          |
|    time_elapsed         | 147         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.032288037 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | -0.657      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0447     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0202     |
|    value_loss           | 0.0547      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -28.6       |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 13          |
|    time_elapsed         | 160         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.039367072 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.0167      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0308     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0169     |
|    value_loss           | 0.128       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 150        |
|    ep_rew_mean          | -28.9      |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 14         |
|    time_elapsed         | 172        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03074682 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.73      |
|    explained_variance   | -0.124     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0809     |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0197    |
|    value_loss           | 0.24       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.041292936 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | -0.952      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0142     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0289     |
|    value_loss           | 0.135       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -29      |
| time/              |          |
|    fps             | 164      |
|    iterations      | 15       |
|    time_elapsed    | 187      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -28.8       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 16          |
|    time_elapsed         | 200         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.046236567 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | -0.0913     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0137     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.195       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -29         |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 17          |
|    time_elapsed         | 223         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.045177065 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | -0.22       |
|    learning_rate        | 0.001       |
|    loss                 | -0.015      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0304     |
|    value_loss           | 0.128       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -28.5       |
| time/                   |             |
|    fps                  | 148         |
|    iterations           | 18          |
|    time_elapsed         | 247         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.045677863 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | -0.49       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0233     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.172       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -28         |
| time/                   |             |
|    fps                  | 143         |
|    iterations           | 19          |
|    time_elapsed         | 271         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.046039492 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | -0.173      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0899      |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.149       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-29.00 +/- 1.41
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -29         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.036844425 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | -0.577      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0305      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.142       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -27.5    |
| time/              |          |
|    fps             | 137      |
|    iterations      | 20       |
|    time_elapsed    | 297      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -26.8       |
| time/                   |             |
|    fps                  | 133         |
|    iterations           | 21          |
|    time_elapsed         | 321         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.047034763 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0866     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0255     |
|    value_loss           | 0.0679      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -26.5       |
| time/                   |             |
|    fps                  | 130         |
|    iterations           | 22          |
|    time_elapsed         | 346         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.040422827 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | -0.0716     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0157      |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0292     |
|    value_loss           | 0.116       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -26.3      |
| time/                   |            |
|    fps                  | 127        |
|    iterations           | 23         |
|    time_elapsed         | 370        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.03863005 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.66      |
|    explained_variance   | 0.103      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0517     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0216    |
|    value_loss           | 0.0931     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | -25.8       |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 24          |
|    time_elapsed         | 394         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.044431645 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0031     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.134       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-29.00 +/- 1.41
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -29        |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.03336979 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.294      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0518    |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0214    |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -25.4    |
| time/              |          |
|    fps             | 121      |
|    iterations      | 25       |
|    time_elapsed    | 421      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -25.6       |
| time/                   |             |
|    fps                  | 120         |
|    iterations           | 26          |
|    time_elapsed         | 442         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.037775688 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.301       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0671     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0268     |
|    value_loss           | 0.0948      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | -25.5       |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 27          |
|    time_elapsed         | 466         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.057176024 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | -0.227      |
|    learning_rate        | 0.001       |
|    loss                 | -0.00247    |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0153     |
|    value_loss           | 0.0971      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 145        |
|    ep_rew_mean          | -25.5      |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 28         |
|    time_elapsed         | 491        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.04927973 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0156    |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.077      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -25.4       |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 29          |
|    time_elapsed         | 514         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.049921103 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.349       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0117      |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.091       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.04962223 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.51      |
|    explained_variance   | 0.335      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0363    |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.0217    |
|    value_loss           | 0.0942     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -25.5    |
| time/              |          |
|    fps             | 113      |
|    iterations      | 30       |
|    time_elapsed    | 540      |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -25.3      |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 31         |
|    time_elapsed         | 564        |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.05308131 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.51      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00601    |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.0248    |
|    value_loss           | 0.0816     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -25.1       |
| time/                   |             |
|    fps                  | 111         |
|    iterations           | 32          |
|    time_elapsed         | 587         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.053364594 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0578     |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0228     |
|    value_loss           | 0.0953      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 142         |
|    ep_rew_mean          | -24.2       |
| time/                   |             |
|    fps                  | 110         |
|    iterations           | 33          |
|    time_elapsed         | 611         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.057197317 |
|    clip_fraction        | 0.433       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0118     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0229     |
|    value_loss           | 0.137       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 139        |
|    ep_rew_mean          | -23.4      |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 34         |
|    time_elapsed         | 635        |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.07088727 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.4       |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0428    |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0254    |
|    value_loss           | 0.108      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.06924215 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0813    |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0179    |
|    value_loss           | 0.116      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | -23.4    |
| time/              |          |
|    fps             | 108      |
|    iterations      | 35       |
|    time_elapsed    | 660      |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 133        |
|    ep_rew_mean          | -22        |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 36         |
|    time_elapsed         | 684        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.04638631 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0874    |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0208    |
|    value_loss           | 0.0775     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 131        |
|    ep_rew_mean          | -21.4      |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 37         |
|    time_elapsed         | 707        |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.05890234 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0144    |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0214    |
|    value_loss           | 0.138      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 129         |
|    ep_rew_mean          | -20.9       |
| time/                   |             |
|    fps                  | 106         |
|    iterations           | 38          |
|    time_elapsed         | 730         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.056691065 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0186      |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 0.105       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 123        |
|    ep_rew_mean          | -19.4      |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 39         |
|    time_elapsed         | 754        |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.07108968 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0287    |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.105      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=80000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.08314843 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0775    |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -14.5    |
| time/              |          |
|    fps             | 105      |
|    iterations      | 40       |
|    time_elapsed    | 779      |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.6        |
|    ep_rew_mean          | -12.8       |
| time/                   |             |
|    fps                  | 104         |
|    iterations           | 41          |
|    time_elapsed         | 803         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.060880847 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0252      |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0303     |
|    value_loss           | 0.215       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.8        |
|    ep_rew_mean          | -9.52       |
| time/                   |             |
|    fps                  | 104         |
|    iterations           | 42          |
|    time_elapsed         | 826         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.082142875 |
|    clip_fraction        | 0.472       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.29       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0587     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.109       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80.1       |
|    ep_rew_mean          | -8.41      |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 43         |
|    time_elapsed         | 850        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.06405425 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0953     |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0272    |
|    value_loss           | 0.173      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-29.67 +/- 0.47
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -29.7       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.073074214 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.001       |
|    loss                 | 0.101       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0287     |
|    value_loss           | 0.178       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74       |
|    ep_rew_mean     | -7.4     |
| time/              |          |
|    fps             | 102      |
|    iterations      | 44       |
|    time_elapsed    | 876      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 65.1       |
|    ep_rew_mean          | -5.48      |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 45         |
|    time_elapsed         | 900        |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.06292313 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.24      |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0339    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.191      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.4        |
|    ep_rew_mean          | -4.34       |
| time/                   |             |
|    fps                  | 101         |
|    iterations           | 46          |
|    time_elapsed         | 924         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.067132846 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0386     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.14        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 58.6       |
|    ep_rew_mean          | -4.01      |
| time/                   |            |
|    fps                  | 101        |
|    iterations           | 47         |
|    time_elapsed         | 948        |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.09394626 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0232    |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.022     |
|    value_loss           | 0.181      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.1       |
|    ep_rew_mean          | -2.75      |
| time/                   |            |
|    fps                  | 101        |
|    iterations           | 48         |
|    time_elapsed         | 972        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.07076071 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0148    |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-6.92 +/- 15.61
Episode length: 59.33 +/- 64.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 59.3        |
|    mean_reward          | -6.92       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.068369016 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0639     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0303     |
|    value_loss           | 0.183       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.4     |
|    ep_rew_mean     | -0.571   |
| time/              |          |
|    fps             | 100      |
|    iterations      | 49       |
|    time_elapsed    | 997      |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.1       |
|    ep_rew_mean          | 0.0682     |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 50         |
|    time_elapsed         | 1020       |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.10579444 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0567    |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.158      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37         |
|    ep_rew_mean          | 0.426      |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 51         |
|    time_elapsed         | 1043       |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.06515713 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0201    |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.0257    |
|    value_loss           | 0.162      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.3        |
|    ep_rew_mean          | 2.17        |
| time/                   |             |
|    fps                  | 99          |
|    iterations           | 52          |
|    time_elapsed         | 1068        |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.075395316 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.997      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.001       |
|    loss                 | 0.035       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0323     |
|    value_loss           | 0.183       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.3        |
|    ep_rew_mean          | 1.97        |
| time/                   |             |
|    fps                  | 99          |
|    iterations           | 53          |
|    time_elapsed         | 1094        |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.082058206 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.847      |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0316     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0405     |
|    value_loss           | 0.228       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=110000, episode_reward=5.16 +/- 1.34
Episode length: 17.00 +/- 4.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 17         |
|    mean_reward          | 5.16       |
| time/                   |            |
|    total_timesteps      | 110000     |
| train/                  |            |
|    approx_kl            | 0.10364759 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.825     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0158    |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.224      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.7     |
|    ep_rew_mean     | 2.2      |
| time/              |          |
|    fps             | 98       |
|    iterations      | 54       |
|    time_elapsed    | 1119     |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.8        |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 55         |
|    time_elapsed         | 1145       |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.10505439 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.742     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0232    |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.0377    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 2.35       |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 56         |
|    time_elapsed         | 1170       |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.06837383 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.751     |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0249    |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0476    |
|    value_loss           | 0.181      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 2.55       |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 57         |
|    time_elapsed         | 1196       |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.08878956 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.59      |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.001      |
|    loss                 | -0.0309    |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0382    |
|    value_loss           | 0.169      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 2.43       |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 58         |
|    time_elapsed         | 1222       |
|    total_timesteps      | 118784     |
| train/                  |            |
|    approx_kl            | 0.08394108 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.618     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0399    |
|    n_updates            | 570        |
|    policy_gradient_loss | -0.0316    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-6.26 +/- 16.83
Episode length: 59.33 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.3       |
|    mean_reward          | -6.26      |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.09895612 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.558     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0105    |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.127      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 1.49     |
| time/              |          |
|    fps             | 96       |
|    iterations      | 59       |
|    time_elapsed    | 1246     |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 3.38       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 60         |
|    time_elapsed         | 1271       |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.07193866 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.697     |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0131     |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.0413    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 3.58       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 61         |
|    time_elapsed         | 1294       |
|    total_timesteps      | 124928     |
| train/                  |            |
|    approx_kl            | 0.11419897 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.538     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.017     |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.0278    |
|    value_loss           | 0.143      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.2        |
|    ep_rew_mean          | 3.16        |
| time/                   |             |
|    fps                  | 96          |
|    iterations           | 62          |
|    time_elapsed         | 1318        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.076433435 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.549      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0169      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0344     |
|    value_loss           | 0.15        |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 3.2         |
| time/                   |             |
|    fps                  | 96          |
|    iterations           | 63          |
|    time_elapsed         | 1343        |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.084003404 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.635      |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.001       |
|    loss                 | 0.111       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0306     |
|    value_loss           | 0.202       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=130000, episode_reward=-18.56 +/- 16.18
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.6      |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.09198128 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.627     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | -0.063     |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.149      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25       |
|    ep_rew_mean     | 2.64     |
| time/              |          |
|    fps             | 95       |
|    iterations      | 64       |
|    time_elapsed    | 1368     |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 2.77       |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 65         |
|    time_elapsed         | 1393       |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.10342352 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0132    |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.0386    |
|    value_loss           | 0.15       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 66         |
|    time_elapsed         | 1421       |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.08884197 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.6       |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0412     |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0397    |
|    value_loss           | 0.155      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 3.62       |
| time/                   |            |
|    fps                  | 94         |
|    iterations           | 67         |
|    time_elapsed         | 1447       |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.06872837 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.598     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0211     |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.125      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 3.23        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 68          |
|    time_elapsed         | 1470        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.071596265 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.544      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0271     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0308     |
|    value_loss           | 0.108       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=140000, episode_reward=-6.39 +/- 16.73
Episode length: 60.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60          |
|    mean_reward          | -6.39       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.101438984 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.662      |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0229     |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0391     |
|    value_loss           | 0.14        |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 3.06     |
| time/              |          |
|    fps             | 94       |
|    iterations      | 69       |
|    time_elapsed    | 1495     |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.1      |
|    ep_rew_mean          | 3.01      |
| time/                   |           |
|    fps                  | 94        |
|    iterations           | 70        |
|    time_elapsed         | 1518      |
|    total_timesteps      | 143360    |
| train/                  |           |
|    approx_kl            | 0.0768456 |
|    clip_fraction        | 0.279     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.581    |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.001     |
|    loss                 | 0.00599   |
|    n_updates            | 690       |
|    policy_gradient_loss | -0.0298   |
|    value_loss           | 0.209     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 3.12       |
| time/                   |            |
|    fps                  | 94         |
|    iterations           | 71         |
|    time_elapsed         | 1542       |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.09040874 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.642     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0487    |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.122      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 3.92        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 72          |
|    time_elapsed         | 1565        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.101468466 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.583      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0352     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0293     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.1        |
|    ep_rew_mean          | 2.27        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 73          |
|    time_elapsed         | 1590        |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.113501936 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.506      |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00159     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0434     |
|    value_loss           | 0.119       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=150000, episode_reward=4.44 +/- 0.96
Episode length: 15.67 +/- 2.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.7       |
|    mean_reward          | 4.44       |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.08152369 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.766     |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.001      |
|    loss                 | 0.779      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.0261    |
|    value_loss           | 0.553      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 3.38     |
| time/              |          |
|    fps             | 93       |
|    iterations      | 74       |
|    time_elapsed    | 1615     |
|    total_timesteps | 151552   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 3.14       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 75         |
|    time_elapsed         | 1641       |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.10632211 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0296    |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.123      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.1       |
|    ep_rew_mean          | 1.74       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 76         |
|    time_elapsed         | 1668       |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.20561795 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.744     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0581    |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0359    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 3.14       |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 77         |
|    time_elapsed         | 1696       |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.11384601 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.82      |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00685   |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 3.53        |
| time/                   |             |
|    fps                  | 92          |
|    iterations           | 78          |
|    time_elapsed         | 1723        |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.069202036 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0177     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0345     |
|    value_loss           | 0.114       |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=5.66 +/- 1.54
Episode length: 13.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 13          |
|    mean_reward          | 5.66        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.070974976 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.63       |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00846    |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0314     |
|    value_loss           | 0.128       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 4.45     |
| time/              |          |
|    fps             | 92       |
|    iterations      | 79       |
|    time_elapsed    | 1749     |
|    total_timesteps | 161792   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.9        |
|    ep_rew_mean          | 3.4         |
| time/                   |             |
|    fps                  | 92          |
|    iterations           | 80          |
|    time_elapsed         | 1776        |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.064686745 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.494      |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0211     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.028      |
|    value_loss           | 0.156       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.4      |
|    ep_rew_mean          | 3.8       |
| time/                   |           |
|    fps                  | 92        |
|    iterations           | 81        |
|    time_elapsed         | 1802      |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.1156809 |
|    clip_fraction        | 0.335     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.612    |
|    explained_variance   | 0.908     |
|    learning_rate        | 0.001     |
|    loss                 | -0.104    |
|    n_updates            | 800       |
|    policy_gradient_loss | -0.0483   |
|    value_loss           | 0.113     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 3.5        |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 82         |
|    time_elapsed         | 1827       |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.10194744 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.44      |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0354    |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 3.14        |
| time/                   |             |
|    fps                  | 91          |
|    iterations           | 83          |
|    time_elapsed         | 1851        |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.054529384 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.564      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0224     |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0212     |
|    value_loss           | 0.0901      |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=4.32 +/- 1.12
Episode length: 13.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 4.32       |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.11426811 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0815    |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 4.2      |
| time/              |          |
|    fps             | 91       |
|    iterations      | 84       |
|    time_elapsed    | 1875     |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 3.79       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 85         |
|    time_elapsed         | 1899       |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.07443359 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | 0.031      |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0215    |
|    value_loss           | 0.104      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 16.2      |
|    ep_rew_mean          | 4.41      |
| time/                   |           |
|    fps                  | 91        |
|    iterations           | 86        |
|    time_elapsed         | 1923      |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0842733 |
|    clip_fraction        | 0.249     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.486    |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0464   |
|    n_updates            | 850       |
|    policy_gradient_loss | -0.0357   |
|    value_loss           | 0.121     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 3.45       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 87         |
|    time_elapsed         | 1943       |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.06501742 |
|    clip_fraction        | 0.223      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.421     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0636    |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.0902     |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=180000, episode_reward=3.72 +/- 0.43
Episode length: 12.67 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 3.72       |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.10787189 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.577     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0608    |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0371    |
|    value_loss           | 0.0815     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 3.43     |
| time/              |          |
|    fps             | 91       |
|    iterations      | 88       |
|    time_elapsed    | 1968     |
|    total_timesteps | 180224   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 2.91       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 89         |
|    time_elapsed         | 1993       |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.08308481 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0809    |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.0243    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 3.85       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 90         |
|    time_elapsed         | 2017       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.10078849 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.589     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0354    |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0482    |
|    value_loss           | 0.073      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 4.31        |
| time/                   |             |
|    fps                  | 91          |
|    iterations           | 91          |
|    time_elapsed         | 2040        |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.063587666 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.496      |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0233     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.0754      |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 4.01      |
| time/                   |           |
|    fps                  | 91        |
|    iterations           | 92        |
|    time_elapsed         | 2063      |
|    total_timesteps      | 188416    |
| train/                  |           |
|    approx_kl            | 0.1379236 |
|    clip_fraction        | 0.25      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.458    |
|    explained_variance   | 0.885     |
|    learning_rate        | 0.001     |
|    loss                 | 0.121     |
|    n_updates            | 910       |
|    policy_gradient_loss | -0.0297   |
|    value_loss           | 0.147     |
---------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=190000, episode_reward=-16.89 +/- 14.29
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -16.9      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.07871251 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.505     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0088    |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.123      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 4.65     |
| time/              |          |
|    fps             | 91       |
|    iterations      | 93       |
|    time_elapsed    | 2089     |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.04        |
| time/                   |             |
|    fps                  | 91          |
|    iterations           | 94          |
|    time_elapsed         | 2114        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.082020365 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.441      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0185     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 0.113       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 4.42       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 95         |
|    time_elapsed         | 2137       |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.09394096 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.599     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0767    |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.108      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 3.4        |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 96         |
|    time_elapsed         | 2160       |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.08075303 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0513     |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.172      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.6       |
|    ep_rew_mean          | 2.62       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 97         |
|    time_elapsed         | 2184       |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.08494821 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.718     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0394     |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.363      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=200000, episode_reward=-28.67 +/- 1.89
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -28.7      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.09378784 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.797     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.061     |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0331    |
|    value_loss           | 0.189      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 4.8      |
| time/              |          |
|    fps             | 90       |
|    iterations      | 98       |
|    time_elapsed    | 2208     |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 4.74       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 99         |
|    time_elapsed         | 2231       |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.07976752 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.487     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0437    |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.0389    |
|    value_loss           | 0.158      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.5        |
|    ep_rew_mean          | 4.41        |
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 100         |
|    time_elapsed         | 2251        |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.105785646 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.498      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0268     |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0381     |
|    value_loss           | 0.175       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 4.14       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 101        |
|    time_elapsed         | 2274       |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.10737606 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.491     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0492    |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.037     |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 4.71       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 102        |
|    time_elapsed         | 2299       |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.14135003 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.553     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00802   |
|    n_updates            | 1010       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.111      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=210000, episode_reward=-17.49 +/- 14.88
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -17.5       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.086046994 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.504      |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0235     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0373     |
|    value_loss           | 0.0929      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.3     |
|    ep_rew_mean     | 4.76     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 103      |
|    time_elapsed    | 2323     |
|    total_timesteps | 210944   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 4.13       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 104        |
|    time_elapsed         | 2346       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.06606771 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.375     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.045     |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.0835     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.05       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 105        |
|    time_elapsed         | 2369       |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.07984476 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.579     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0476     |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.0966     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 4.44       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 106        |
|    time_elapsed         | 2392       |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.09625921 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.655     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0883    |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0452    |
|    value_loss           | 0.141      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 4.36       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 107        |
|    time_elapsed         | 2415       |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.11396589 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.522     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0612    |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.0385    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=220000, episode_reward=-16.56 +/- 14.77
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -16.6      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.09079444 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.512     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0992     |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.529      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 4.18     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 108      |
|    time_elapsed    | 2440     |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 4.26        |
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 109         |
|    time_elapsed         | 2463        |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.095898084 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.592      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0455     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0378     |
|    value_loss           | 0.185       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 3.89       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 110        |
|    time_elapsed         | 2486       |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.07337693 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0664     |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0421    |
|    value_loss           | 0.138      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 4.7        |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 111        |
|    time_elapsed         | 2510       |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.10090004 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.638     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0215    |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.0574    |
|    value_loss           | 0.137      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.1      |
|    ep_rew_mean          | 4.87      |
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 112       |
|    time_elapsed         | 2532      |
|    total_timesteps      | 229376    |
| train/                  |           |
|    approx_kl            | 0.1141751 |
|    clip_fraction        | 0.259     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.446    |
|    explained_variance   | 0.904     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0551   |
|    n_updates            | 1110      |
|    policy_gradient_loss | -0.0397   |
|    value_loss           | 0.141     |
---------------------------------------
reached max steps=300
Eval num_timesteps=230000, episode_reward=-4.85 +/- 17.82
Episode length: 59.00 +/- 64.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 59          |
|    mean_reward          | -4.85       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.092729755 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.409      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0999      |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0394     |
|    value_loss           | 0.147       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 4.84     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 113      |
|    time_elapsed    | 2557     |
|    total_timesteps | 231424   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 4.89       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 114        |
|    time_elapsed         | 2580       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.09576388 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.385     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | 1.83e-05   |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0379    |
|    value_loss           | 0.136      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 3.74       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 115        |
|    time_elapsed         | 2603       |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.09087594 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.442     |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0319    |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0272    |
|    value_loss           | 0.087      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 3.95        |
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 116         |
|    time_elapsed         | 2627        |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.052438457 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.41       |
|    explained_variance   | 0.37        |
|    learning_rate        | 0.001       |
|    loss                 | 0.379       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 1.17        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 4.34       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 117        |
|    time_elapsed         | 2650       |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.09392299 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.587     |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0936     |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.655      |
----------------------------------------
Eval num_timesteps=240000, episode_reward=6.98 +/- 2.52
Episode length: 14.67 +/- 2.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.7       |
|    mean_reward          | 6.98       |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.11067452 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.677     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0985    |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0431    |
|    value_loss           | 0.185      |
----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 4.24     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 118      |
|    time_elapsed    | 2673     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.2      |
|    ep_rew_mean          | 4.17      |
| time/                   |           |
|    fps                  | 90        |
|    iterations           | 119       |
|    time_elapsed         | 2697      |
|    total_timesteps      | 243712    |
| train/                  |           |
|    approx_kl            | 0.1065748 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.644    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0167   |
|    n_updates            | 1180      |
|    policy_gradient_loss | -0.0474   |
|    value_loss           | 0.188     |
---------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.1        |
|    ep_rew_mean          | 3.74        |
| time/                   |             |
|    fps                  | 90          |
|    iterations           | 120         |
|    time_elapsed         | 2720        |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.108349614 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.668      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0208      |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.151       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 121        |
|    time_elapsed         | 2744       |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.10308761 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.671     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00436   |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.0467    |
|    value_loss           | 0.172      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 4.02       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 122        |
|    time_elapsed         | 2769       |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.08607243 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.638     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0501    |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0432    |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
Eval num_timesteps=250000, episode_reward=-5.73 +/- 17.17
Episode length: 60.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -5.73      |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.09906978 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0136    |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0466    |
|    value_loss           | 0.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.3     |
|    ep_rew_mean     | 4.63     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 123      |
|    time_elapsed    | 2795     |
|    total_timesteps | 251904   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 4.5        |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 124        |
|    time_elapsed         | 2820       |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.08279699 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0342    |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.0412    |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 5.21       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 125        |
|    time_elapsed         | 2846       |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.08996491 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0516    |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.116      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.4        |
|    ep_rew_mean          | 5.03        |
| time/                   |             |
|    fps                  | 89          |
|    iterations           | 126         |
|    time_elapsed         | 2870        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.054650135 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.401      |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0382      |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0307     |
|    value_loss           | 0.109       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=260000, episode_reward=-18.29 +/- 15.85
Episode length: 104.67 +/- 64.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 105         |
|    mean_reward          | -18.3       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.081984505 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.348      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0281     |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0355     |
|    value_loss           | 0.113       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 4.43     |
| time/              |          |
|    fps             | 89       |
|    iterations      | 127      |
|    time_elapsed    | 2895     |
|    total_timesteps | 260096   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.4      |
|    ep_rew_mean          | 4.62      |
| time/                   |           |
|    fps                  | 89        |
|    iterations           | 128       |
|    time_elapsed         | 2920      |
|    total_timesteps      | 262144    |
| train/                  |           |
|    approx_kl            | 0.0907023 |
|    clip_fraction        | 0.286     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.492    |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0198   |
|    n_updates            | 1270      |
|    policy_gradient_loss | -0.0375   |
|    value_loss           | 0.124     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 4.13       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 129        |
|    time_elapsed         | 2944       |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.06139588 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.471     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0486    |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.0728     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 3.92       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 130        |
|    time_elapsed         | 2969       |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.08210157 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.538     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.0283    |
|    value_loss           | 0.178      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 4.25       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 131        |
|    time_elapsed         | 2996       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.08072065 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.583     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0925    |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.0845     |
----------------------------------------
reached max steps=300
Eval num_timesteps=270000, episode_reward=6.58 +/- 0.41
Episode length: 15.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15         |
|    mean_reward          | 6.58       |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.14710695 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.49      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0827    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0628    |
|    value_loss           | 0.107      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 4.45     |
| time/              |          |
|    fps             | 89       |
|    iterations      | 132      |
|    time_elapsed    | 3028     |
|    total_timesteps | 270336   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 4.76       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 133        |
|    time_elapsed         | 3060       |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.06426331 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0279    |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.0261    |
|    value_loss           | 0.065      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 5.18       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 134        |
|    time_elapsed         | 3123       |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.08443819 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.407     |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0133     |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.0279    |
|    value_loss           | 0.074      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.2      |
|    ep_rew_mean          | 4.15      |
| time/                   |           |
|    fps                  | 87        |
|    iterations           | 135       |
|    time_elapsed         | 3151      |
|    total_timesteps      | 276480    |
| train/                  |           |
|    approx_kl            | 0.0676684 |
|    clip_fraction        | 0.185     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.312    |
|    explained_variance   | 0.95      |
|    learning_rate        | 0.001     |
|    loss                 | 0.0812    |
|    n_updates            | 1340      |
|    policy_gradient_loss | -0.0292   |
|    value_loss           | 0.0877    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.7       |
|    ep_rew_mean          | 5.1        |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 136        |
|    time_elapsed         | 3175       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.09743796 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.509     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | -0.094     |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0526    |
|    value_loss           | 0.103      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=-5.06 +/- 17.69
Episode length: 60.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60          |
|    mean_reward          | -5.06       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.081656866 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.35       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0289     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0297     |
|    value_loss           | 0.0876      |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 3.87     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 137      |
|    time_elapsed    | 3200     |
|    total_timesteps | 280576   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.4      |
|    ep_rew_mean          | 4.93      |
| time/                   |           |
|    fps                  | 87        |
|    iterations           | 138       |
|    time_elapsed         | 3223      |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0655926 |
|    clip_fraction        | 0.256     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.533    |
|    explained_variance   | 0.865     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0203    |
|    n_updates            | 1370      |
|    policy_gradient_loss | -0.0318   |
|    value_loss           | 0.349     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 4.39       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 139        |
|    time_elapsed         | 3248       |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.13111061 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.42      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0701    |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.142      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 4.53       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 140        |
|    time_elapsed         | 3271       |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.11414632 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0436    |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 4.47       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 141        |
|    time_elapsed         | 3295       |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.07833142 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.463     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0539    |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.131      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=3.99 +/- 0.47
Episode length: 13.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 3.99       |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.12204715 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.492     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0466    |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0527    |
|    value_loss           | 0.105      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 4.75     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 142      |
|    time_elapsed    | 3319     |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.2       |
|    ep_rew_mean          | 5.05       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 143        |
|    time_elapsed         | 3343       |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.09505531 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.477     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00722   |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.0876     |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 3.95        |
| time/                   |             |
|    fps                  | 87          |
|    iterations           | 144         |
|    time_elapsed         | 3365        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.084755324 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.285      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00506    |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.032      |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 4.32       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 145        |
|    time_elapsed         | 3389       |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.09606116 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.441     |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0726    |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0577    |
|    value_loss           | 0.093      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 5.46       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 146        |
|    time_elapsed         | 3412       |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.06709579 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.382     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | 0.041      |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.0979     |
----------------------------------------
reached max steps=300
Eval num_timesteps=300000, episode_reward=-6.13 +/- 16.89
Episode length: 60.33 +/- 63.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.3       |
|    mean_reward          | -6.13      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.07629217 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.295     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00383    |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.121      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.1     |
|    ep_rew_mean     | 5.53     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 147      |
|    time_elapsed    | 3441     |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.6        |
|    ep_rew_mean          | 5.21        |
| time/                   |             |
|    fps                  | 87          |
|    iterations           | 148         |
|    time_elapsed         | 3468        |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.088337004 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.327      |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0124      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0336     |
|    value_loss           | 0.166       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.56       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 149        |
|    time_elapsed         | 3493       |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.10509919 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.342     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0145    |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.0435    |
|    value_loss           | 0.141      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 5.4        |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 150        |
|    time_elapsed         | 3521       |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.12596615 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.418     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0845    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.182      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17         |
|    ep_rew_mean          | 5.24       |
| time/                   |            |
|    fps                  | 86         |
|    iterations           | 151        |
|    time_elapsed         | 3566       |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.08501309 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0357    |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.135      |
----------------------------------------
reached max steps=300
Eval num_timesteps=310000, episode_reward=-7.59 +/- 15.85
Episode length: 59.33 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.3       |
|    mean_reward          | -7.59      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.06977821 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.334     |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0455    |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.086      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 4.88     |
| time/              |          |
|    fps             | 86       |
|    iterations      | 152      |
|    time_elapsed    | 3619     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 4.34        |
| time/                   |             |
|    fps                  | 85          |
|    iterations           | 153         |
|    time_elapsed         | 3678        |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.068210706 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.421      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0504     |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0442     |
|    value_loss           | 0.0989      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 4.13       |
| time/                   |            |
|    fps                  | 84         |
|    iterations           | 154        |
|    time_elapsed         | 3731       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.07971926 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.541     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0106    |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 3.98       |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 155        |
|    time_elapsed         | 3793       |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.07802613 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.503     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0414    |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 4.43       |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 156        |
|    time_elapsed         | 3848       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.07238689 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00557    |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0279    |
|    value_loss           | 0.104      |
----------------------------------------
Eval num_timesteps=320000, episode_reward=8.58 +/- 1.60
Episode length: 15.00 +/- 1.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15         |
|    mean_reward          | 8.58       |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.10271984 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00316    |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.0345    |
|    value_loss           | 0.101      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 4.81     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 157      |
|    time_elapsed    | 3901     |
|    total_timesteps | 321536   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 4.55       |
| time/                   |            |
|    fps                  | 81         |
|    iterations           | 158        |
|    time_elapsed         | 3954       |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.07758516 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.492     |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.001      |
|    loss                 | 0.574      |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.515      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.4        |
|    ep_rew_mean          | 4.96        |
| time/                   |             |
|    fps                  | 81          |
|    iterations           | 159         |
|    time_elapsed         | 4010        |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.112679005 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.421      |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0624      |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0524     |
|    value_loss           | 0.305       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.4       |
|    ep_rew_mean          | 5.57       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 160        |
|    time_elapsed         | 4067       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.14547494 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.379     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0613    |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0613    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 4.81       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 161        |
|    time_elapsed         | 4123       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.10636101 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.295     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0448    |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.0739     |
----------------------------------------
Eval num_timesteps=330000, episode_reward=3.45 +/- 0.62
Episode length: 14.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 14          |
|    mean_reward          | 3.45        |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.088112846 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.486      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0156     |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 0.102       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 5.18     |
| time/              |          |
|    fps             | 79       |
|    iterations      | 162      |
|    time_elapsed    | 4179     |
|    total_timesteps | 331776   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.3      |
|    ep_rew_mean          | 5         |
| time/                   |           |
|    fps                  | 78        |
|    iterations           | 163       |
|    time_elapsed         | 4231      |
|    total_timesteps      | 333824    |
| train/                  |           |
|    approx_kl            | 0.0791105 |
|    clip_fraction        | 0.235     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.45     |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0629   |
|    n_updates            | 1620      |
|    policy_gradient_loss | -0.0384   |
|    value_loss           | 0.0786    |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 4.73       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 164        |
|    time_elapsed         | 4274       |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.08641826 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.409     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00923   |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.147      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 4.45       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 165        |
|    time_elapsed         | 4299       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.08572952 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.522     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | 0.144      |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.13       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 5.13       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 166        |
|    time_elapsed         | 4326       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.09378263 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0445     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.473      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=6.91 +/- 1.27
Episode length: 15.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15         |
|    mean_reward          | 6.91       |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.12229973 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.438     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00192   |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.0574    |
|    value_loss           | 0.183      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | 3.47     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 167      |
|    time_elapsed    | 4352     |
|    total_timesteps | 342016   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 4.25       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 168        |
|    time_elapsed         | 4377       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.09204911 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.767     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0786    |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0437    |
|    value_loss           | 0.186      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.5        |
|    ep_rew_mean          | 4.29        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 169         |
|    time_elapsed         | 4402        |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.090139985 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.609      |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0151      |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0376     |
|    value_loss           | 0.126       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 4.25       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 170        |
|    time_elapsed         | 4426       |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.07472164 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | 0.311      |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0456    |
|    value_loss           | 0.347      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=350000, episode_reward=-5.52 +/- 17.31
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -5.52      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.10243246 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.648     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0248     |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0559    |
|    value_loss           | 0.258      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.5     |
|    ep_rew_mean     | 4.66     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 171      |
|    time_elapsed    | 4452     |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 4.83       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 172        |
|    time_elapsed         | 4476       |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.12753803 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0487    |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0603    |
|    value_loss           | 0.167      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.1      |
|    ep_rew_mean          | 3.91      |
| time/                   |           |
|    fps                  | 78        |
|    iterations           | 173       |
|    time_elapsed         | 4500      |
|    total_timesteps      | 354304    |
| train/                  |           |
|    approx_kl            | 0.3065518 |
|    clip_fraction        | 0.29      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.476    |
|    explained_variance   | 0.883     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0292    |
|    n_updates            | 1720      |
|    policy_gradient_loss | -0.051    |
|    value_loss           | 0.138     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 4.49       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 174        |
|    time_elapsed         | 4524       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.07456258 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.613     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0667    |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 4.52       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 175        |
|    time_elapsed         | 4548       |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.06720004 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.568     |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0358    |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.0745     |
----------------------------------------
reached max steps=300
Eval num_timesteps=360000, episode_reward=-4.45 +/- 15.41
Episode length: 58.67 +/- 64.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -4.45      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.13157481 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.485     |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.001      |
|    loss                 | 0.209      |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0399    |
|    value_loss           | 0.346      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 5.38     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 176      |
|    time_elapsed    | 4573     |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 5.29        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 177         |
|    time_elapsed         | 4601        |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.098145664 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.438      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0158     |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0429     |
|    value_loss           | 0.172       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 4.3         |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 178         |
|    time_elapsed         | 4627        |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.090180054 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.481      |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0259      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.143       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 4.66       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 179        |
|    time_elapsed         | 4654       |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.10441169 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.607     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0666    |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.000635  |
|    value_loss           | 0.0915     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.3       |
|    ep_rew_mean          | 3.43       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 180        |
|    time_elapsed         | 4682       |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.07438734 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0861    |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0378    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
Eval num_timesteps=370000, episode_reward=-6.92 +/- 16.32
Episode length: 59.33 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.3       |
|    mean_reward          | -6.92      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.09549442 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0535    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 0.103      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 4.66     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 181      |
|    time_elapsed    | 4714     |
|    total_timesteps | 370688   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.26       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 182        |
|    time_elapsed         | 4740       |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.12412089 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0456    |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.126      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 4.14       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 183        |
|    time_elapsed         | 4769       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.11407217 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | 0.138      |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.135      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.05       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 184        |
|    time_elapsed         | 4797       |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.14570612 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.624     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0795    |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0446    |
|    value_loss           | 0.0939     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 5.28       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 185        |
|    time_elapsed         | 4824       |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.09070414 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.401     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0109    |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.122      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=380000, episode_reward=-17.89 +/- 17.12
Episode length: 104.33 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -17.9      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.09840992 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.395     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0582    |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 4.79     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 186      |
|    time_elapsed    | 4857     |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 5.16       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 187        |
|    time_elapsed         | 4881       |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.07970446 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0406     |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0418    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 4.99       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 188        |
|    time_elapsed         | 4911       |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.08924036 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.33      |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0327    |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.0819     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.4       |
|    ep_rew_mean          | 5.36       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 189        |
|    time_elapsed         | 4938       |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.08650376 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.418     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0579     |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.1        |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 5.11       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 190        |
|    time_elapsed         | 4962       |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.07527196 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.32      |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0449     |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0341    |
|    value_loss           | 0.0906     |
----------------------------------------
reached max steps=300
Eval num_timesteps=390000, episode_reward=9.03 +/- 0.69
Episode length: 17.67 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 17.7       |
|    mean_reward          | 9.03       |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.08815439 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.415     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0188     |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0425    |
|    value_loss           | 0.0854     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 5.75     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 191      |
|    time_elapsed    | 4986     |
|    total_timesteps | 391168   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.8        |
|    ep_rew_mean          | 5.81        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 192         |
|    time_elapsed         | 5011        |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.075782984 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.391      |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0234     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.105       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 5.6        |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 193        |
|    time_elapsed         | 5035       |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.07659769 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.326     |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0188    |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.0634     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 4.13       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 194        |
|    time_elapsed         | 5059       |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.08019954 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.304     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0257     |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.241      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 5.28       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 195        |
|    time_elapsed         | 5083       |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.12680063 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.543     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0428     |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.103      |
----------------------------------------
reached max steps=300
Eval num_timesteps=400000, episode_reward=-5.07 +/- 17.63
Episode length: 61.67 +/- 62.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61.7       |
|    mean_reward          | -5.07      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.10328535 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.41      |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0545    |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.0701     |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 4.15     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 196      |
|    time_elapsed    | 5109     |
|    total_timesteps | 401408   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 5.17       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 197        |
|    time_elapsed         | 5133       |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.10835937 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.531     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0155    |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.0331    |
|    value_loss           | 0.0994     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 4.48       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 198        |
|    time_elapsed         | 5158       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.08526768 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00566    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0297    |
|    value_loss           | 0.0955     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 5.33       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 199        |
|    time_elapsed         | 5182       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07874259 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.022     |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.0735     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.7      |
|    ep_rew_mean          | 5.22      |
| time/                   |           |
|    fps                  | 78        |
|    iterations           | 200       |
|    time_elapsed         | 5204      |
|    total_timesteps      | 409600    |
| train/                  |           |
|    approx_kl            | 0.0954806 |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.379    |
|    explained_variance   | 0.948     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0469   |
|    n_updates            | 1990      |
|    policy_gradient_loss | -0.0384   |
|    value_loss           | 0.0916    |
---------------------------------------
Eval num_timesteps=410000, episode_reward=5.71 +/- 0.99
Episode length: 14.33 +/- 1.89
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 14.3      |
|    mean_reward          | 5.71      |
| time/                   |           |
|    total_timesteps      | 410000    |
| train/                  |           |
|    approx_kl            | 0.1549712 |
|    clip_fraction        | 0.224     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.325    |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0382   |
|    n_updates            | 2000      |
|    policy_gradient_loss | -0.0283   |
|    value_loss           | 0.0877    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.1     |
|    ep_rew_mean     | 5.7      |
| time/              |          |
|    fps             | 78       |
|    iterations      | 201      |
|    time_elapsed    | 5228     |
|    total_timesteps | 411648   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.2      |
|    ep_rew_mean          | 5.73      |
| time/                   |           |
|    fps                  | 78        |
|    iterations           | 202       |
|    time_elapsed         | 5252      |
|    total_timesteps      | 413696    |
| train/                  |           |
|    approx_kl            | 0.0827229 |
|    clip_fraction        | 0.18      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.262    |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0278   |
|    n_updates            | 2010      |
|    policy_gradient_loss | -0.0291   |
|    value_loss           | 0.0905    |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 5.54       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 203        |
|    time_elapsed         | 5275       |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.22884637 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.305     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0297    |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.042     |
|    value_loss           | 0.0993     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.3        |
|    ep_rew_mean          | 5.78        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 204         |
|    time_elapsed         | 5300        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.112259045 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.303      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | -0.024      |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0332     |
|    value_loss           | 0.0702      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.12       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 205        |
|    time_elapsed         | 5324       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.11053763 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.234     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0605    |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0243    |
|    value_loss           | 0.101      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=420000, episode_reward=-17.03 +/- 16.27
Episode length: 105.00 +/- 63.64
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 105       |
|    mean_reward          | -17       |
| time/                   |           |
|    total_timesteps      | 420000    |
| train/                  |           |
|    approx_kl            | 0.0861307 |
|    clip_fraction        | 0.258     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.386    |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0908    |
|    n_updates            | 2050      |
|    policy_gradient_loss | -0.0401   |
|    value_loss           | 0.429     |
---------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 4.59     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 206      |
|    time_elapsed    | 5350     |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 5.15        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 207         |
|    time_elapsed         | 5374        |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.105165005 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.348      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.001       |
|    loss                 | 0.108       |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0435     |
|    value_loss           | 0.263       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.6       |
|    ep_rew_mean          | 6.01       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 208        |
|    time_elapsed         | 5398       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.15157995 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.3       |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0132    |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0397    |
|    value_loss           | 0.157      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 4.11       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 209        |
|    time_elapsed         | 5422       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.08845958 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.259     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0488    |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0235    |
|    value_loss           | 0.0952     |
----------------------------------------
reached max steps=300
Eval num_timesteps=430000, episode_reward=-2.86 +/- 19.41
Episode length: 60.67 +/- 63.19
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.7       |
|    mean_reward          | -2.86      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.10076127 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0127     |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.0392    |
|    value_loss           | 0.0656     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 5.17     |
| time/              |          |
|    fps             | 78       |
|    iterations      | 210      |
|    time_elapsed    | 5446     |
|    total_timesteps | 430080   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 4.36        |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 211         |
|    time_elapsed         | 5471        |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.096347764 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.352      |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0218      |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.0834      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.7        |
|    ep_rew_mean          | 6.23        |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 212         |
|    time_elapsed         | 5495        |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.094638705 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0428     |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0349     |
|    value_loss           | 0.0547      |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 4.3        |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 213        |
|    time_elapsed         | 5519       |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.12016467 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.253     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0433    |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 0.0858     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 4.88       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 214        |
|    time_elapsed         | 5542       |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.06395869 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.628     |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.001      |
|    loss                 | 0.36       |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.813      |
----------------------------------------
reached max steps=300
Eval num_timesteps=440000, episode_reward=-2.79 +/- 12.88
Episode length: 58.67 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -2.79      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.10191086 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.531     |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.001      |
|    loss                 | 0.239      |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0532    |
|    value_loss           | 0.625      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.6     |
|    ep_rew_mean     | 4.37     |
| time/              |          |
|    fps             | 79       |
|    iterations      | 215      |
|    time_elapsed    | 5566     |
|    total_timesteps | 440320   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 4.08       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 216        |
|    time_elapsed         | 5591       |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.11830007 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.637     |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0935     |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0548    |
|    value_loss           | 0.531      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 4.05       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 217        |
|    time_elapsed         | 5600       |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.13098484 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.65      |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0784    |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0584    |
|    value_loss           | 0.206      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 5.31        |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 218         |
|    time_elapsed         | 5609        |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.124993004 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.001       |
|    loss                 | -0.074      |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0507     |
|    value_loss           | 0.151       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 5.82       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 219        |
|    time_elapsed         | 5618       |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.08196832 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.468     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0438     |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.146      |
----------------------------------------
reached max steps=300
Eval num_timesteps=450000, episode_reward=-4.73 +/- 17.88
Episode length: 60.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -4.73      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.11621387 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.402     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0377    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 5.29     |
| time/              |          |
|    fps             | 80       |
|    iterations      | 220      |
|    time_elapsed    | 5626     |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 5.24       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 221        |
|    time_elapsed         | 5635       |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.09369075 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.518     |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.001      |
|    loss                 | 0.18       |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0493    |
|    value_loss           | 0.468      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 4.88       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 222        |
|    time_elapsed         | 5649       |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.14132245 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.413     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | 0.219      |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0513    |
|    value_loss           | 0.335      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 4.01       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 223        |
|    time_elapsed         | 5662       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.16034842 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.566     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | 0.205      |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0469    |
|    value_loss           | 0.219      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 4.67       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 224        |
|    time_elapsed         | 5673       |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.11921099 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.703     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.038     |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0419    |
|    value_loss           | 0.142      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=460000, episode_reward=-15.89 +/- 14.50
Episode length: 104.33 +/- 64.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -15.9       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.106680825 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.564      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0332      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.119       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 5.16     |
| time/              |          |
|    fps             | 81       |
|    iterations      | 225      |
|    time_elapsed    | 5687     |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.22       |
| time/                   |            |
|    fps                  | 81         |
|    iterations           | 226        |
|    time_elapsed         | 5699       |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.07821799 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.53      |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0323    |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.0396    |
|    value_loss           | 0.153      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 5.56       |
| time/                   |            |
|    fps                  | 81         |
|    iterations           | 227        |
|    time_elapsed         | 5713       |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.10070434 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.415     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0162    |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.119      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21        |
|    ep_rew_mean          | 4.91      |
| time/                   |           |
|    fps                  | 81        |
|    iterations           | 228       |
|    time_elapsed         | 5724      |
|    total_timesteps      | 466944    |
| train/                  |           |
|    approx_kl            | 0.0859575 |
|    clip_fraction        | 0.249     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.411    |
|    explained_variance   | 0.927     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0321   |
|    n_updates            | 2270      |
|    policy_gradient_loss | -0.0329   |
|    value_loss           | 0.131     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 5.35       |
| time/                   |            |
|    fps                  | 81         |
|    iterations           | 229        |
|    time_elapsed         | 5737       |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.10021058 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.457     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | 0.109      |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0411    |
|    value_loss           | 0.139      |
----------------------------------------
reached max steps=300
Eval num_timesteps=470000, episode_reward=-7.45 +/- 15.95
Episode length: 58.67 +/- 64.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -7.45      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.10140918 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.398     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0668    |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.0866     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18       |
|    ep_rew_mean     | 5.42     |
| time/              |          |
|    fps             | 81       |
|    iterations      | 230      |
|    time_elapsed    | 5750     |
|    total_timesteps | 471040   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 4.69       |
| time/                   |            |
|    fps                  | 82         |
|    iterations           | 231        |
|    time_elapsed         | 5764       |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.09371416 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.334     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0329    |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.0438    |
|    value_loss           | 0.1        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 5.53       |
| time/                   |            |
|    fps                  | 82         |
|    iterations           | 232        |
|    time_elapsed         | 5775       |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.11182697 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.489     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0761    |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.104      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 5.62       |
| time/                   |            |
|    fps                  | 82         |
|    iterations           | 233        |
|    time_elapsed         | 5788       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.09685795 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.365     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0207    |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0338    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 5.41       |
| time/                   |            |
|    fps                  | 82         |
|    iterations           | 234        |
|    time_elapsed         | 5801       |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.08758874 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.391     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0536    |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.071      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=7.51 +/- 1.69
Episode length: 15.33 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 7.51       |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.09287977 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.372     |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0723    |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0415    |
|    value_loss           | 0.0833     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.4     |
|    ep_rew_mean     | 5.35     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 235      |
|    time_elapsed    | 5815     |
|    total_timesteps | 481280   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 4.75        |
| time/                   |             |
|    fps                  | 82          |
|    iterations           | 236         |
|    time_elapsed         | 5831        |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.111072645 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.335      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0224      |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0555     |
|    value_loss           | 0.0673      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.6       |
|    ep_rew_mean          | 5.36       |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 237        |
|    time_elapsed         | 5844       |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.08643885 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.461     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0633    |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0371    |
|    value_loss           | 0.0777     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 4.9        |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 238        |
|    time_elapsed         | 5856       |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.07256036 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.224     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0629    |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.095      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 5.28       |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 239        |
|    time_elapsed         | 5868       |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.09433135 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.295     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0386    |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0404    |
|    value_loss           | 0.179      |
----------------------------------------
reached max steps=300
Eval num_timesteps=490000, episode_reward=4.46 +/- 1.32
Episode length: 12.33 +/- 0.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.3        |
|    mean_reward          | 4.46        |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.091671534 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.309      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0119     |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 5.38     |
| time/              |          |
|    fps             | 83       |
|    iterations      | 240      |
|    time_elapsed    | 5881     |
|    total_timesteps | 491520   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 4.9        |
| time/                   |            |
|    fps                  | 83         |
|    iterations           | 241        |
|    time_elapsed         | 5893       |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.07551467 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.437     |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.001      |
|    loss                 | 0.278      |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0416    |
|    value_loss           | 0.649      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 19.9     |
|    ep_rew_mean          | 5.33     |
| time/                   |          |
|    fps                  | 83       |
|    iterations           | 242      |
|    time_elapsed         | 5906     |
|    total_timesteps      | 495616   |
| train/                  |          |
|    approx_kl            | 0.120755 |
|    clip_fraction        | 0.348    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.432   |
|    explained_variance   | 0.842    |
|    learning_rate        | 0.001    |
|    loss                 | 0.0828   |
|    n_updates            | 2410     |
|    policy_gradient_loss | -0.0597  |
|    value_loss           | 0.305    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 5.13       |
| time/                   |            |
|    fps                  | 84         |
|    iterations           | 243        |
|    time_elapsed         | 5918       |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.12934637 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.451     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0389    |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.0467    |
|    value_loss           | 0.131      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 5.17       |
| time/                   |            |
|    fps                  | 84         |
|    iterations           | 244        |
|    time_elapsed         | 5929       |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.12426347 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0244    |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0458    |
|    value_loss           | 0.138      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=7.44 +/- 2.37
Episode length: 15.67 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.7       |
|    mean_reward          | 7.44       |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.12592177 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.44      |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.072      |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0456    |
|    value_loss           | 0.147      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 5.44     |
| time/              |          |
|    fps             | 84       |
|    iterations      | 245      |
|    time_elapsed    | 5942     |
|    total_timesteps | 501760   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.51        |
| time/                   |             |
|    fps                  | 84          |
|    iterations           | 246         |
|    time_elapsed         | 5954        |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.082840085 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.389      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0155     |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.118       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 4.78       |
| time/                   |            |
|    fps                  | 84         |
|    iterations           | 247        |
|    time_elapsed         | 5967       |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.11074473 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.439     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0429    |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0374    |
|    value_loss           | 0.144      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 5           |
| time/                   |             |
|    fps                  | 84          |
|    iterations           | 248         |
|    time_elapsed         | 5978        |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.109979704 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.506      |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.001       |
|    loss                 | -0.085      |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0366     |
|    value_loss           | 0.0916      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 5.26       |
| time/                   |            |
|    fps                  | 85         |
|    iterations           | 249        |
|    time_elapsed         | 5991       |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.09397231 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.482     |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.001      |
|    loss                 | 0.183      |
|    n_updates            | 2480       |
|    policy_gradient_loss | -0.0484    |
|    value_loss           | 0.555      |
----------------------------------------
reached max steps=300
Eval num_timesteps=510000, episode_reward=-6.47 +/- 16.64
Episode length: 62.00 +/- 62.25
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 62        |
|    mean_reward          | -6.47     |
| time/                   |           |
|    total_timesteps      | 510000    |
| train/                  |           |
|    approx_kl            | 0.0827941 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.475    |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.001     |
|    loss                 | 0.288     |
|    n_updates            | 2490      |
|    policy_gradient_loss | -0.0599   |
|    value_loss           | 0.392     |
---------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 4.52     |
| time/              |          |
|    fps             | 85       |
|    iterations      | 250      |
|    time_elapsed    | 6005     |
|    total_timesteps | 512000   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 5.15       |
| time/                   |            |
|    fps                  | 85         |
|    iterations           | 251        |
|    time_elapsed         | 6016       |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.14944744 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0537     |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0511    |
|    value_loss           | 0.297      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.2       |
|    ep_rew_mean          | 4.19       |
| time/                   |            |
|    fps                  | 85         |
|    iterations           | 252        |
|    time_elapsed         | 6029       |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.15145144 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.449     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0639    |
|    n_updates            | 2510       |
|    policy_gradient_loss | -0.0361    |
|    value_loss           | 0.127      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 4.92        |
| time/                   |             |
|    fps                  | 85          |
|    iterations           | 253         |
|    time_elapsed         | 6042        |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.111290365 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.608      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0834     |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0443     |
|    value_loss           | 0.0984      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=520000, episode_reward=6.65 +/- 0.41
Episode length: 14.67 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.7       |
|    mean_reward          | 6.65       |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.10038544 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.433     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0485    |
|    n_updates            | 2530       |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.102      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 4.25     |
| time/              |          |
|    fps             | 85       |
|    iterations      | 254      |
|    time_elapsed    | 6053     |
|    total_timesteps | 520192   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 4.79       |
| time/                   |            |
|    fps                  | 86         |
|    iterations           | 255        |
|    time_elapsed         | 6063       |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.12354802 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.593     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0543    |
|    n_updates            | 2540       |
|    policy_gradient_loss | -0.0451    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 5.37       |
| time/                   |            |
|    fps                  | 86         |
|    iterations           | 256        |
|    time_elapsed         | 6072       |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.11184247 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.434     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000237  |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.146      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 4.82        |
| time/                   |             |
|    fps                  | 86          |
|    iterations           | 257         |
|    time_elapsed         | 6082        |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.084476605 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.464      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0429     |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 0.113       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 5.44       |
| time/                   |            |
|    fps                  | 86         |
|    iterations           | 258        |
|    time_elapsed         | 6091       |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.16755232 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.429     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0105     |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.0523    |
|    value_loss           | 0.193      |
----------------------------------------
reached max steps=300
Eval num_timesteps=530000, episode_reward=-5.39 +/- 17.46
Episode length: 60.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60          |
|    mean_reward          | -5.39       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.088281035 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.413      |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0457     |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.0781      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 5.68     |
| time/              |          |
|    fps             | 86       |
|    iterations      | 259      |
|    time_elapsed    | 6106     |
|    total_timesteps | 530432   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 5.23       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 260        |
|    time_elapsed         | 6116       |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.11682834 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.359     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0228    |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.111      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 5.45       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 261        |
|    time_elapsed         | 6129       |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.11363132 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0266    |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.0366    |
|    value_loss           | 0.108      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 5.48       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 262        |
|    time_elapsed         | 6141       |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.08679698 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.275     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00396    |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.028     |
|    value_loss           | 0.0942     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 4.99       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 263        |
|    time_elapsed         | 6155       |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.08869893 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.279     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0329    |
|    n_updates            | 2620       |
|    policy_gradient_loss | -0.0435    |
|    value_loss           | 0.0863     |
----------------------------------------
reached max steps=300
Eval num_timesteps=540000, episode_reward=-6.08 +/- 16.25
Episode length: 63.33 +/- 61.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 63.3       |
|    mean_reward          | -6.08      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.11074804 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.43      |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0703    |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.0749     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 5.44     |
| time/              |          |
|    fps             | 87       |
|    iterations      | 264      |
|    time_elapsed    | 6167     |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 5.48       |
| time/                   |            |
|    fps                  | 87         |
|    iterations           | 265        |
|    time_elapsed         | 6180       |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.13423894 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.305     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0335    |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0513    |
|    value_loss           | 0.165      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.7      |
|    ep_rew_mean          | 5.63      |
| time/                   |           |
|    fps                  | 87        |
|    iterations           | 266       |
|    time_elapsed         | 6192      |
|    total_timesteps      | 544768    |
| train/                  |           |
|    approx_kl            | 0.1699518 |
|    clip_fraction        | 0.215     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.285    |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0638   |
|    n_updates            | 2650      |
|    policy_gradient_loss | 0.19      |
|    value_loss           | 0.107     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 5.07       |
| time/                   |            |
|    fps                  | 88         |
|    iterations           | 267        |
|    time_elapsed         | 6203       |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.09417021 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.324     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00658   |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0233    |
|    value_loss           | 0.07       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.45       |
| time/                   |            |
|    fps                  | 88         |
|    iterations           | 268        |
|    time_elapsed         | 6215       |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.09137691 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.443     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0141     |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.259      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=550000, episode_reward=-16.29 +/- 15.34
Episode length: 104.67 +/- 64.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -16.3      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.13239062 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.415     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.03      |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0477    |
|    value_loss           | 0.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 5.33     |
| time/              |          |
|    fps             | 88       |
|    iterations      | 269      |
|    time_elapsed    | 6225     |
|    total_timesteps | 550912   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 4.67       |
| time/                   |            |
|    fps                  | 88         |
|    iterations           | 270        |
|    time_elapsed         | 6238       |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.14164662 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.448     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0632    |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.043     |
|    value_loss           | 0.164      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 4.95       |
| time/                   |            |
|    fps                  | 88         |
|    iterations           | 271        |
|    time_elapsed         | 6250       |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.15682639 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.482     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0407    |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 4.43       |
| time/                   |            |
|    fps                  | 88         |
|    iterations           | 272        |
|    time_elapsed         | 6261       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.12681516 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.452     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0465    |
|    n_updates            | 2710       |
|    policy_gradient_loss | -0.0432    |
|    value_loss           | 0.131      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.1        |
|    ep_rew_mean          | 5.37        |
| time/                   |             |
|    fps                  | 89          |
|    iterations           | 273         |
|    time_elapsed         | 6271        |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.104144424 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.477      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0585     |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.0297     |
|    value_loss           | 0.0783      |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=560000, episode_reward=6.31 +/- 1.81
Episode length: 14.67 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.7       |
|    mean_reward          | 6.31       |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.10148319 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.368     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0502    |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.0795     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 5.04     |
| time/              |          |
|    fps             | 89       |
|    iterations      | 274      |
|    time_elapsed    | 6285     |
|    total_timesteps | 561152   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 5.48       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 275        |
|    time_elapsed         | 6296       |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.12877485 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.38      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0455    |
|    n_updates            | 2740       |
|    policy_gradient_loss | -0.016     |
|    value_loss           | 0.108      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 4.26       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 276        |
|    time_elapsed         | 6306       |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.09691153 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.389     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00059    |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.124      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 5.61       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 277        |
|    time_elapsed         | 6315       |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.15361807 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.485     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0734    |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0502    |
|    value_loss           | 0.0713     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 4.83       |
| time/                   |            |
|    fps                  | 89         |
|    iterations           | 278        |
|    time_elapsed         | 6326       |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.10535973 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.285     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | -0.028     |
|    n_updates            | 2770       |
|    policy_gradient_loss | -0.0402    |
|    value_loss           | 0.0952     |
----------------------------------------
Eval num_timesteps=570000, episode_reward=6.04 +/- 2.17
Episode length: 16.00 +/- 1.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 16         |
|    mean_reward          | 6.04       |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.23149091 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.337     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0877    |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.0418    |
|    value_loss           | 0.067      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 5.87     |
| time/              |          |
|    fps             | 90       |
|    iterations      | 279      |
|    time_elapsed    | 6337     |
|    total_timesteps | 571392   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 5.83       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 280        |
|    time_elapsed         | 6349       |
|    total_timesteps      | 573440     |
| train/                  |            |
|    approx_kl            | 0.09064414 |
|    clip_fraction        | 0.156      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.223     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.042     |
|    n_updates            | 2790       |
|    policy_gradient_loss | -0.0256    |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.36       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 281        |
|    time_elapsed         | 6359       |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.15436992 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.277     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0143    |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.0411    |
|    value_loss           | 0.0981     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.14       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 282        |
|    time_elapsed         | 6369       |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.09979674 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.307     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0196    |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0357    |
|    value_loss           | 0.136      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 6.08       |
| time/                   |            |
|    fps                  | 90         |
|    iterations           | 283        |
|    time_elapsed         | 6379       |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.12056321 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.335     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0289     |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.0352    |
|    value_loss           | 0.178      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=5.65 +/- 2.31
Episode length: 14.67 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.7       |
|    mean_reward          | 5.65       |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.14543313 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.314     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00488    |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.0401    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 5.87     |
| time/              |          |
|    fps             | 91       |
|    iterations      | 284      |
|    time_elapsed    | 6391     |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 5.7        |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 285        |
|    time_elapsed         | 6399       |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.13089454 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.361     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0364    |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.0341    |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.7        |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 286        |
|    time_elapsed         | 6409       |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.11569475 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.335     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0107    |
|    n_updates            | 2850       |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.143      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 4.55       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 287        |
|    time_elapsed         | 6418       |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.13121629 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.498     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0169    |
|    n_updates            | 2860       |
|    policy_gradient_loss | -0.0307    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 4.74       |
| time/                   |            |
|    fps                  | 91         |
|    iterations           | 288        |
|    time_elapsed         | 6427       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.12306994 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.498     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00148   |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.048     |
|    value_loss           | 0.118      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=7.17 +/- 2.86
Episode length: 15.33 +/- 2.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 7.17       |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.11751368 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | 0.045      |
|    n_updates            | 2880       |
|    policy_gradient_loss | -0.0304    |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 4.94     |
| time/              |          |
|    fps             | 91       |
|    iterations      | 289      |
|    time_elapsed    | 6435     |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 5.77       |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 290        |
|    time_elapsed         | 6444       |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.10150136 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.347     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0347     |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0307    |
|    value_loss           | 0.0846     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 5.52       |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 291        |
|    time_elapsed         | 6453       |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.12944293 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.31      |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0252    |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.036     |
|    value_loss           | 0.139      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 4.98       |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 292        |
|    time_elapsed         | 6462       |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.10046292 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.339     |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0685    |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.0359    |
|    value_loss           | 0.0736     |
----------------------------------------
reached max steps=300
Eval num_timesteps=600000, episode_reward=5.31 +/- 2.15
Episode length: 14.67 +/- 2.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 14.7        |
|    mean_reward          | 5.31        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.096256256 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.473      |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.001       |
|    loss                 | 0.422       |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.0393     |
|    value_loss           | 0.592       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.8     |
|    ep_rew_mean     | 5.04     |
| time/              |          |
|    fps             | 92       |
|    iterations      | 293      |
|    time_elapsed    | 6475     |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 5.4        |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 294        |
|    time_elapsed         | 6485       |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.12529446 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.471     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.001      |
|    loss                 | 0.194      |
|    n_updates            | 2930       |
|    policy_gradient_loss | -0.0486    |
|    value_loss           | 0.406      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 5.2        |
| time/                   |            |
|    fps                  | 92         |
|    iterations           | 295        |
|    time_elapsed         | 6497       |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.15392405 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.492     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0285     |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0497    |
|    value_loss           | 0.205      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 4.9        |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 296        |
|    time_elapsed         | 6507       |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.13573861 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.491     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0607    |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0435    |
|    value_loss           | 0.0994     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 5.17       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 297        |
|    time_elapsed         | 6518       |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.13034199 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.541     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000535  |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.289      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=610000, episode_reward=-1.46 +/- 15.23
Episode length: 60.33 +/- 63.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.3       |
|    mean_reward          | -1.46      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.11639692 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.587     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.107     |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0468    |
|    value_loss           | 0.101      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.3     |
|    ep_rew_mean     | 4.56     |
| time/              |          |
|    fps             | 93       |
|    iterations      | 298      |
|    time_elapsed    | 6528     |
|    total_timesteps | 610304   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 4.46       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 299        |
|    time_elapsed         | 6542       |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.12592733 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.583     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0356     |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0416    |
|    value_loss           | 0.136      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 4.98       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 300        |
|    time_elapsed         | 6554       |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.13882706 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.565     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0766    |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.0428    |
|    value_loss           | 0.106      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 5.27       |
| time/                   |            |
|    fps                  | 93         |
|    iterations           | 301        |
|    time_elapsed         | 6565       |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.09594099 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | 0.117      |
|    n_updates            | 3000       |
|    policy_gradient_loss | -0.0402    |
|    value_loss           | 0.14       |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 4.58        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 302         |
|    time_elapsed         | 6576        |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.095382646 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.449      |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0319     |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0246     |
|    value_loss           | 0.102       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=620000, episode_reward=-3.53 +/- 18.84
Episode length: 60.67 +/- 63.19
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60.7       |
|    mean_reward          | -3.53      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.12857963 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.494     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0321    |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.0378    |
|    value_loss           | 0.149      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 4.62     |
| time/              |          |
|    fps             | 94       |
|    iterations      | 303      |
|    time_elapsed    | 6587     |
|    total_timesteps | 620544   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 5.31       |
| time/                   |            |
|    fps                  | 94         |
|    iterations           | 304        |
|    time_elapsed         | 6597       |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.13426998 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.552     |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0445     |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.0534    |
|    value_loss           | 0.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 5.39       |
| time/                   |            |
|    fps                  | 94         |
|    iterations           | 305        |
|    time_elapsed         | 6607       |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.08932927 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.444     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0397    |
|    n_updates            | 3040       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.0802     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.8        |
|    ep_rew_mean          | 5.96        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 306         |
|    time_elapsed         | 6617        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.119788885 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.377      |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0106     |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 0.0911      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.6        |
|    ep_rew_mean          | 5.55        |
| time/                   |             |
|    fps                  | 94          |
|    iterations           | 307         |
|    time_elapsed         | 6626        |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.099641144 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.269      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0451     |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0297     |
|    value_loss           | 0.102       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=630000, episode_reward=6.96 +/- 1.52
Episode length: 18.00 +/- 4.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18          |
|    mean_reward          | 6.96        |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.115560755 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.365      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0504     |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.168       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 5.81     |
| time/              |          |
|    fps             | 95       |
|    iterations      | 308      |
|    time_elapsed    | 6636     |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 5.3        |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 309        |
|    time_elapsed         | 6646       |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.08716893 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.385     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00242   |
|    n_updates            | 3080       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.116      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 5.85       |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 310        |
|    time_elapsed         | 6656       |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.12681238 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.361     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0419    |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0378    |
|    value_loss           | 0.188      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 4.2        |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 311        |
|    time_elapsed         | 6667       |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.10378313 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.33      |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0203    |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.107      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 5.83       |
| time/                   |            |
|    fps                  | 95         |
|    iterations           | 312        |
|    time_elapsed         | 6677       |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.08336027 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.001      |
|    loss                 | 0.306      |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0359    |
|    value_loss           | 0.415      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=640000, episode_reward=-17.49 +/- 14.88
Episode length: 104.00 +/- 65.05
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 104       |
|    mean_reward          | -17.5     |
| time/                   |           |
|    total_timesteps      | 640000    |
| train/                  |           |
|    approx_kl            | 0.1852389 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.421    |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0432   |
|    n_updates            | 3120      |
|    policy_gradient_loss | -0.0577   |
|    value_loss           | 0.213     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 4.31     |
| time/              |          |
|    fps             | 95       |
|    iterations      | 313      |
|    time_elapsed    | 6688     |
|    total_timesteps | 641024   |
---------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.1      |
|    ep_rew_mean          | 4.89      |
| time/                   |           |
|    fps                  | 96        |
|    iterations           | 314       |
|    time_elapsed         | 6697      |
|    total_timesteps      | 643072    |
| train/                  |           |
|    approx_kl            | 0.2196975 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.534    |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0863   |
|    n_updates            | 3130      |
|    policy_gradient_loss | -0.0406   |
|    value_loss           | 0.183     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 4.98       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 315        |
|    time_elapsed         | 6706       |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.13608116 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.474     |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0112     |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.045     |
|    value_loss           | 0.193      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 5.54       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 316        |
|    time_elapsed         | 6716       |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.08643536 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.442     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00955   |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 5.42       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 317        |
|    time_elapsed         | 6728       |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.10441023 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.356     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0603    |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0386    |
|    value_loss           | 0.105      |
----------------------------------------
reached max steps=300
Eval num_timesteps=650000, episode_reward=-4.80 +/- 15.70
Episode length: 60.33 +/- 63.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60.3        |
|    mean_reward          | -4.8        |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.095711455 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.396      |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0516     |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0308     |
|    value_loss           | 0.0948      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 5.57     |
| time/              |          |
|    fps             | 96       |
|    iterations      | 318      |
|    time_elapsed    | 6738     |
|    total_timesteps | 651264   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 4.26       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 319        |
|    time_elapsed         | 6749       |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.09254101 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.358     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0209    |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.104      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 4.58       |
| time/                   |            |
|    fps                  | 96         |
|    iterations           | 320        |
|    time_elapsed         | 6758       |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.10920578 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.455     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0342    |
|    n_updates            | 3190       |
|    policy_gradient_loss | -0.0381    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.8      |
|    ep_rew_mean          | 4.83      |
| time/                   |           |
|    fps                  | 97        |
|    iterations           | 321       |
|    time_elapsed         | 6768      |
|    total_timesteps      | 657408    |
| train/                  |           |
|    approx_kl            | 0.5563899 |
|    clip_fraction        | 0.265     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.446    |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0643   |
|    n_updates            | 3200      |
|    policy_gradient_loss | -0.0485   |
|    value_loss           | 0.0753    |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 4.6        |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 322        |
|    time_elapsed         | 6778       |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.09140236 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.517     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0544    |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.0904     |
----------------------------------------
Eval num_timesteps=660000, episode_reward=5.66 +/- 2.47
Episode length: 13.00 +/- 0.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 13          |
|    mean_reward          | 5.66        |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.114644915 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.498      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0449     |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0338     |
|    value_loss           | 0.127       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 5.61     |
| time/              |          |
|    fps             | 97       |
|    iterations      | 323      |
|    time_elapsed    | 6789     |
|    total_timesteps | 661504   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.7      |
|    ep_rew_mean          | 4.95      |
| time/                   |           |
|    fps                  | 97        |
|    iterations           | 324       |
|    time_elapsed         | 6799      |
|    total_timesteps      | 663552    |
| train/                  |           |
|    approx_kl            | 0.1373964 |
|    clip_fraction        | 0.237     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.33     |
|    explained_variance   | 0.913     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0557   |
|    n_updates            | 3230      |
|    policy_gradient_loss | -0.0423   |
|    value_loss           | 0.0881    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 6.16       |
| time/                   |            |
|    fps                  | 97         |
|    iterations           | 325        |
|    time_elapsed         | 6809       |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.10775347 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.426     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.00908   |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0214    |
|    value_loss           | 0.0794     |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.7      |
|    ep_rew_mean          | 5.52      |
| time/                   |           |
|    fps                  | 97        |
|    iterations           | 326       |
|    time_elapsed         | 6822      |
|    total_timesteps      | 667648    |
| train/                  |           |
|    approx_kl            | 0.0900127 |
|    clip_fraction        | 0.166     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.239    |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0358   |
|    n_updates            | 3250      |
|    policy_gradient_loss | -0.0301   |
|    value_loss           | 0.105     |
---------------------------------------
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 18.1     |
|    ep_rew_mean          | 6.23     |
| time/                   |          |
|    fps                  | 97       |
|    iterations           | 327      |
|    time_elapsed         | 6838     |
|    total_timesteps      | 669696   |
| train/                  |          |
|    approx_kl            | 0.083638 |
|    clip_fraction        | 0.192    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.349   |
|    explained_variance   | 0.934    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0194  |
|    n_updates            | 3260     |
|    policy_gradient_loss | -0.0272  |
|    value_loss           | 0.101    |
--------------------------------------
reached max steps=300
Eval num_timesteps=670000, episode_reward=-4.85 +/- 17.82
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -4.85      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.09361499 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.305     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0214    |
|    n_updates            | 3270       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.0913     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 5.24     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 328      |
|    time_elapsed    | 6852     |
|    total_timesteps | 671744   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.7      |
|    ep_rew_mean          | 4.82      |
| time/                   |           |
|    fps                  | 98        |
|    iterations           | 329       |
|    time_elapsed         | 6867      |
|    total_timesteps      | 673792    |
| train/                  |           |
|    approx_kl            | 0.1462222 |
|    clip_fraction        | 0.223     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.376    |
|    explained_variance   | 0.947     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0185    |
|    n_updates            | 3280      |
|    policy_gradient_loss | -0.0331   |
|    value_loss           | 0.0965    |
---------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 4.94        |
| time/                   |             |
|    fps                  | 98          |
|    iterations           | 330         |
|    time_elapsed         | 6883        |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.105211064 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.502      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0553     |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.041      |
|    value_loss           | 0.0945      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 5.78       |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 331        |
|    time_elapsed         | 6896       |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.09876484 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.437     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0711     |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 5.39       |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 332        |
|    time_elapsed         | 6911       |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.08948149 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.292     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0115    |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.136      |
----------------------------------------
Eval num_timesteps=680000, episode_reward=6.24 +/- 2.22
Episode length: 15.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15         |
|    mean_reward          | 6.24       |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.09248825 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.408     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.00525   |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.0394    |
|    value_loss           | 0.0817     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 4.94     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 333      |
|    time_elapsed    | 6924     |
|    total_timesteps | 681984   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 5.45       |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 334        |
|    time_elapsed         | 6937       |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.16819654 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.316     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0237    |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.0752     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.78       |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 335        |
|    time_elapsed         | 6949       |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.12840918 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.359     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0329     |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0403    |
|    value_loss           | 0.0898     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 4.61       |
| time/                   |            |
|    fps                  | 98         |
|    iterations           | 336        |
|    time_elapsed         | 6962       |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.11770516 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.316     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0209     |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.0371    |
|    value_loss           | 0.182      |
----------------------------------------
Eval num_timesteps=690000, episode_reward=4.99 +/- 0.94
Episode length: 13.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 4.99       |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.13046649 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.464     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0643    |
|    n_updates            | 3360       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.107      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.5     |
|    ep_rew_mean     | 5.54     |
| time/              |          |
|    fps             | 98       |
|    iterations      | 337      |
|    time_elapsed    | 6974     |
|    total_timesteps | 690176   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 5.27       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 338        |
|    time_elapsed         | 6986       |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.11824575 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.316     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0657     |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.128      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.51       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 339        |
|    time_elapsed         | 7000       |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.12916635 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.369     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0841    |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.0457    |
|    value_loss           | 0.187      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.99       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 340        |
|    time_elapsed         | 7012       |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.13203053 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.303     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0164     |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.201      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 5.66       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 341        |
|    time_elapsed         | 7025       |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.17641392 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.428     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0296    |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.138      |
----------------------------------------
reached max steps=300
Eval num_timesteps=700000, episode_reward=4.85 +/- 1.87
Episode length: 13.67 +/- 2.36
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 13.7      |
|    mean_reward          | 4.85      |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.0968798 |
|    clip_fraction        | 0.208     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.316    |
|    explained_variance   | 0.931     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0297   |
|    n_updates            | 3410      |
|    policy_gradient_loss | -0.0276   |
|    value_loss           | 0.13      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.1     |
|    ep_rew_mean     | 4.42     |
| time/              |          |
|    fps             | 99       |
|    iterations      | 342      |
|    time_elapsed    | 7038     |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 5.54       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 343        |
|    time_elapsed         | 7051       |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.17558263 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.422     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.014     |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.0422    |
|    value_loss           | 0.215      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.85       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 344        |
|    time_elapsed         | 7064       |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.10664578 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.336     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00354    |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.0396    |
|    value_loss           | 0.238      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.45       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 345        |
|    time_elapsed         | 7077       |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.20991687 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.474     |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0218    |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.0473    |
|    value_loss           | 0.203      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 4.05       |
| time/                   |            |
|    fps                  | 99         |
|    iterations           | 346        |
|    time_elapsed         | 7090       |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.11108996 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.38      |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0354    |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.147      |
----------------------------------------
Eval num_timesteps=710000, episode_reward=6.18 +/- 2.12
Episode length: 13.67 +/- 1.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.7       |
|    mean_reward          | 6.18       |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.08824503 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.609     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0386    |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0209    |
|    value_loss           | 0.106      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.3     |
|    ep_rew_mean     | 4.43     |
| time/              |          |
|    fps             | 100      |
|    iterations      | 347      |
|    time_elapsed    | 7102     |
|    total_timesteps | 710656   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 5.29       |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 348        |
|    time_elapsed         | 7115       |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.14215343 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.464     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0505     |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.0404    |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.71        |
| time/                   |             |
|    fps                  | 100         |
|    iterations           | 349         |
|    time_elapsed         | 7125        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.113094985 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.385      |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.001       |
|    loss                 | -0.056      |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0303     |
|    value_loss           | 0.1         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.2       |
|    ep_rew_mean          | 5.55       |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 350        |
|    time_elapsed         | 7136       |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.14126316 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.421     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0472    |
|    n_updates            | 3490       |
|    policy_gradient_loss | -0.0416    |
|    value_loss           | 0.123      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 4.95        |
| time/                   |             |
|    fps                  | 100         |
|    iterations           | 351         |
|    time_elapsed         | 7148        |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.102480024 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.301      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0337      |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.0867      |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=720000, episode_reward=9.17 +/- 1.87
Episode length: 15.33 +/- 1.25
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 15.3      |
|    mean_reward          | 9.17      |
| time/                   |           |
|    total_timesteps      | 720000    |
| train/                  |           |
|    approx_kl            | 0.1280333 |
|    clip_fraction        | 0.226     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.415    |
|    explained_variance   | 0.928     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0502   |
|    n_updates            | 3510      |
|    policy_gradient_loss | -0.0086   |
|    value_loss           | 0.12      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 4.93     |
| time/              |          |
|    fps             | 100      |
|    iterations      | 352      |
|    time_elapsed    | 7160     |
|    total_timesteps | 720896   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 5.05       |
| time/                   |            |
|    fps                  | 100        |
|    iterations           | 353        |
|    time_elapsed         | 7171       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.10310727 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.504     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0518    |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.0903     |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18          |
|    ep_rew_mean          | 5.49        |
| time/                   |             |
|    fps                  | 100         |
|    iterations           | 354         |
|    time_elapsed         | 7182        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.109562814 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.424      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00572    |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.0319     |
|    value_loss           | 0.117       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.8       |
|    ep_rew_mean          | 6.14       |
| time/                   |            |
|    fps                  | 101        |
|    iterations           | 355        |
|    time_elapsed         | 7192       |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.10093381 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.334     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0424    |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 4.8        |
| time/                   |            |
|    fps                  | 101        |
|    iterations           | 356        |
|    time_elapsed         | 7204       |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.09572905 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.241     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0391    |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.0382    |
|    value_loss           | 0.0887     |
----------------------------------------
Eval num_timesteps=730000, episode_reward=6.71 +/- 0.32
Episode length: 14.33 +/- 1.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.3       |
|    mean_reward          | 6.71       |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.12289127 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0226     |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.0308    |
|    value_loss           | 0.0833     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.4     |
|    ep_rew_mean     | 5.85     |
| time/              |          |
|    fps             | 101      |
|    iterations      | 357      |
|    time_elapsed    | 7216     |
|    total_timesteps | 731136   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.1      |
|    ep_rew_mean          | 5.48      |
| time/                   |           |
|    fps                  | 101       |
|    iterations           | 358       |
|    time_elapsed         | 7226      |
|    total_timesteps      | 733184    |
| train/                  |           |
|    approx_kl            | 0.1015898 |
|    clip_fraction        | 0.171     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.282    |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0486   |
|    n_updates            | 3570      |
|    policy_gradient_loss | -0.0274   |
|    value_loss           | 0.105     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 5.18        |
| time/                   |             |
|    fps                  | 101         |
|    iterations           | 359         |
|    time_elapsed         | 7237        |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.106604576 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.325      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0351     |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.0401     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 4.95       |
| time/                   |            |
|    fps                  | 101        |
|    iterations           | 360        |
|    time_elapsed         | 7250       |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.13811684 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.39      |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0212     |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.159      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 4.33        |
| time/                   |             |
|    fps                  | 101         |
|    iterations           | 361         |
|    time_elapsed         | 7261        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.123267464 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.417      |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0823     |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0373     |
|    value_loss           | 0.0759      |
-----------------------------------------
reached max steps=300
Eval num_timesteps=740000, episode_reward=-6.33 +/- 16.94
Episode length: 61.33 +/- 62.70
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 61.3      |
|    mean_reward          | -6.33     |
| time/                   |           |
|    total_timesteps      | 740000    |
| train/                  |           |
|    approx_kl            | 0.1543161 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.542    |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0768   |
|    n_updates            | 3610      |
|    policy_gradient_loss | -0.0274   |
|    value_loss           | 0.0772    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.8     |
|    ep_rew_mean     | 5.64     |
| time/              |          |
|    fps             | 101      |
|    iterations      | 362      |
|    time_elapsed    | 7273     |
|    total_timesteps | 741376   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 4.72       |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 363        |
|    time_elapsed         | 7283       |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.11027207 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.281     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00436   |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.0773     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 3.99       |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 364        |
|    time_elapsed         | 7295       |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.11004427 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0577    |
|    n_updates            | 3630       |
|    policy_gradient_loss | -0.049     |
|    value_loss           | 0.0941     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 5.83       |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 365        |
|    time_elapsed         | 7304       |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.09973681 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.558     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0179     |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.0271    |
|    value_loss           | 0.0839     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.1      |
|    ep_rew_mean          | 6.29      |
| time/                   |           |
|    fps                  | 102       |
|    iterations           | 366       |
|    time_elapsed         | 7313      |
|    total_timesteps      | 749568    |
| train/                  |           |
|    approx_kl            | 0.1527019 |
|    clip_fraction        | 0.154     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.282    |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0166   |
|    n_updates            | 3650      |
|    policy_gradient_loss | -0.0136   |
|    value_loss           | 0.0895    |
---------------------------------------
reached max steps=300
Eval num_timesteps=750000, episode_reward=-4.39 +/- 17.41
Episode length: 60.00 +/- 63.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60          |
|    mean_reward          | -4.39       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.095714346 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.262      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0331     |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.0816      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 5.07     |
| time/              |          |
|    fps             | 102      |
|    iterations      | 367      |
|    time_elapsed    | 7322     |
|    total_timesteps | 751616   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 4.75       |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 368        |
|    time_elapsed         | 7330       |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.14004979 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.371     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00282   |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.212      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 5.33       |
| time/                   |            |
|    fps                  | 102        |
|    iterations           | 369        |
|    time_elapsed         | 7339       |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.14558724 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.475     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0635    |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.0996     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 5.5        |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 370        |
|    time_elapsed         | 7348       |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.15264714 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.439     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0663    |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.0417    |
|    value_loss           | 0.113      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.4       |
|    ep_rew_mean          | 5.53       |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 371        |
|    time_elapsed         | 7357       |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.10473233 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.339     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0331    |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0326    |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
Eval num_timesteps=760000, episode_reward=-2.20 +/- 15.42
Episode length: 60.67 +/- 63.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60.7        |
|    mean_reward          | -2.2        |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.099572465 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.239      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0414      |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.0833      |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 4.8      |
| time/              |          |
|    fps             | 103      |
|    iterations      | 372      |
|    time_elapsed    | 7365     |
|    total_timesteps | 761856   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19        |
|    ep_rew_mean          | 5.17      |
| time/                   |           |
|    fps                  | 103       |
|    iterations           | 373       |
|    time_elapsed         | 7374      |
|    total_timesteps      | 763904    |
| train/                  |           |
|    approx_kl            | 0.6226901 |
|    clip_fraction        | 0.286     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.381    |
|    explained_variance   | 0.922     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0102    |
|    n_updates            | 3720      |
|    policy_gradient_loss | -0.0374   |
|    value_loss           | 0.132     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 5.05       |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 374        |
|    time_elapsed         | 7383       |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.07360606 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.329     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0324    |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 4.9        |
| time/                   |            |
|    fps                  | 103        |
|    iterations           | 375        |
|    time_elapsed         | 7391       |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.09949182 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.349     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0152    |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.0823     |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=770000, episode_reward=6.31 +/- 1.71
Episode length: 14.67 +/- 1.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 14.7        |
|    mean_reward          | 6.31        |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.107180074 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.421      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00572    |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0246     |
|    value_loss           | 0.121       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 4.89     |
| time/              |          |
|    fps             | 104      |
|    iterations      | 376      |
|    time_elapsed    | 7400     |
|    total_timesteps | 770048   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 5.15       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 377        |
|    time_elapsed         | 7409       |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.07984972 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.412     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.001      |
|    loss                 | -0.015     |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.0297    |
|    value_loss           | 0.0866     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 6.17       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 378        |
|    time_elapsed         | 7418       |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.08706091 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.379     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0202    |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.0262    |
|    value_loss           | 0.096      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 5.55       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 379        |
|    time_elapsed         | 7426       |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.12482368 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.288     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0236     |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.105      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 5.08       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 380        |
|    time_elapsed         | 7435       |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.14645952 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.343     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0448    |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.0255    |
|    value_loss           | 0.0929     |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=780000, episode_reward=5.39 +/- 2.63
Episode length: 12.67 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 5.39       |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.10186456 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.419     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.001      |
|    loss                 | 0.106      |
|    n_updates            | 3800       |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 4.63     |
| time/              |          |
|    fps             | 104      |
|    iterations      | 381      |
|    time_elapsed    | 7444     |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 5.42       |
| time/                   |            |
|    fps                  | 104        |
|    iterations           | 382        |
|    time_elapsed         | 7453       |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.14583151 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.503     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0528    |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0334    |
|    value_loss           | 0.19       |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 5.3        |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 383        |
|    time_elapsed         | 7462       |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.16174515 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.333     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0619    |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.122      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 5.18       |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 384        |
|    time_elapsed         | 7471       |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.10271696 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.457     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0169    |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.0348    |
|    value_loss           | 0.0889     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 5.83       |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 385        |
|    time_elapsed         | 7480       |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.11438681 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.363     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0319     |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.0398    |
|    value_loss           | 0.159      |
----------------------------------------
reached max steps=300
Eval num_timesteps=790000, episode_reward=7.78 +/- 0.94
Episode length: 14.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14         |
|    mean_reward          | 7.78       |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.09561436 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.336     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0462    |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.0288    |
|    value_loss           | 0.105      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 5.22     |
| time/              |          |
|    fps             | 105      |
|    iterations      | 386      |
|    time_elapsed    | 7489     |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 5.16       |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 387        |
|    time_elapsed         | 7497       |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.15000314 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.431     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0578    |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.122      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 5.04       |
| time/                   |            |
|    fps                  | 105        |
|    iterations           | 388        |
|    time_elapsed         | 7506       |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.14312522 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.451     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0313    |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.141      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.8      |
|    ep_rew_mean          | 5.89      |
| time/                   |           |
|    fps                  | 105       |
|    iterations           | 389       |
|    time_elapsed         | 7516      |
|    total_timesteps      | 796672    |
| train/                  |           |
|    approx_kl            | 0.0885128 |
|    clip_fraction        | 0.236     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.419    |
|    explained_variance   | 0.957     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0398   |
|    n_updates            | 3880      |
|    policy_gradient_loss | -0.0318   |
|    value_loss           | 0.067     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 5.47       |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 390        |
|    time_elapsed         | 7524       |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.12121733 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.285     |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0495    |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=800000, episode_reward=-6.92 +/- 15.61
Episode length: 59.33 +/- 64.12
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 59.3     |
|    mean_reward          | -6.92    |
| time/                   |          |
|    total_timesteps      | 800000   |
| train/                  |          |
|    approx_kl            | 0.096837 |
|    clip_fraction        | 0.217    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.433   |
|    explained_variance   | 0.953    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0323  |
|    n_updates            | 3900     |
|    policy_gradient_loss | -0.0288  |
|    value_loss           | 0.0823   |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 5.51     |
| time/              |          |
|    fps             | 106      |
|    iterations      | 391      |
|    time_elapsed    | 7534     |
|    total_timesteps | 800768   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 4.53       |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 392        |
|    time_elapsed         | 7542       |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.08404945 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.477     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0144    |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 5.6        |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 393        |
|    time_elapsed         | 7551       |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.10330029 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.402     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0058    |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.042     |
|    value_loss           | 0.331      |
----------------------------------------
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 21.1     |
|    ep_rew_mean          | 5.09     |
| time/                   |          |
|    fps                  | 106      |
|    iterations           | 394      |
|    time_elapsed         | 7559     |
|    total_timesteps      | 806912   |
| train/                  |          |
|    approx_kl            | 0.12196  |
|    clip_fraction        | 0.304    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.444   |
|    explained_variance   | 0.91     |
|    learning_rate        | 0.001    |
|    loss                 | 0.0117   |
|    n_updates            | 3930     |
|    policy_gradient_loss | -0.0487  |
|    value_loss           | 0.122    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.52       |
| time/                   |            |
|    fps                  | 106        |
|    iterations           | 395        |
|    time_elapsed         | 7568       |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.11679455 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.412     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0471    |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 0.126      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=5.78 +/- 2.41
Episode length: 14.00 +/- 1.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14         |
|    mean_reward          | 5.78       |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.08059049 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.394     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0449    |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.0961     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 5.16     |
| time/              |          |
|    fps             | 107      |
|    iterations      | 396      |
|    time_elapsed    | 7577     |
|    total_timesteps | 811008   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 5.18        |
| time/                   |             |
|    fps                  | 107         |
|    iterations           | 397         |
|    time_elapsed         | 7585        |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.110307105 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.343      |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.001       |
|    loss                 | -0.016      |
|    n_updates            | 3960        |
|    policy_gradient_loss | 0.00202     |
|    value_loss           | 0.148       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 5.92       |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 398        |
|    time_elapsed         | 7594       |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.07099676 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.385     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0575    |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.00582    |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 4.86        |
| time/                   |             |
|    fps                  | 107         |
|    iterations           | 399         |
|    time_elapsed         | 7603        |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.079616204 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.294      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0203      |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.0247     |
|    value_loss           | 0.103       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 5.35       |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 400        |
|    time_elapsed         | 7613       |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.11406116 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.4       |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00124   |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.0802     |
----------------------------------------
reached max steps=300
Eval num_timesteps=820000, episode_reward=7.51 +/- 1.42
Episode length: 15.33 +/- 1.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 15.3        |
|    mean_reward          | 7.51        |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.093256176 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.39       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0543     |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.042      |
|    value_loss           | 0.0993      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 5.4      |
| time/              |          |
|    fps             | 107      |
|    iterations      | 401      |
|    time_elapsed    | 7623     |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19          |
|    ep_rew_mean          | 5.8         |
| time/                   |             |
|    fps                  | 107         |
|    iterations           | 402         |
|    time_elapsed         | 7632        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.107299685 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.358      |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0145     |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.03       |
|    value_loss           | 0.119       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 5.09       |
| time/                   |            |
|    fps                  | 107        |
|    iterations           | 403        |
|    time_elapsed         | 7642       |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.08529265 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.286     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | -0.046     |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.0231    |
|    value_loss           | 0.0982     |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.7      |
|    ep_rew_mean          | 4.74      |
| time/                   |           |
|    fps                  | 108       |
|    iterations           | 404       |
|    time_elapsed         | 7652      |
|    total_timesteps      | 827392    |
| train/                  |           |
|    approx_kl            | 0.0814565 |
|    clip_fraction        | 0.229     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.44     |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.00545  |
|    n_updates            | 4030      |
|    policy_gradient_loss | -0.0306   |
|    value_loss           | 0.118     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 4.27       |
| time/                   |            |
|    fps                  | 108        |
|    iterations           | 405        |
|    time_elapsed         | 7662       |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.11834427 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.456     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00395   |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0439    |
|    value_loss           | 0.0755     |
----------------------------------------
Eval num_timesteps=830000, episode_reward=6.84 +/- 1.47
Episode length: 15.33 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 6.84       |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.11726586 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.492     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0691    |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0393    |
|    value_loss           | 0.0943     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.1     |
|    ep_rew_mean     | 5.78     |
| time/              |          |
|    fps             | 108      |
|    iterations      | 406      |
|    time_elapsed    | 7671     |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 5.84       |
| time/                   |            |
|    fps                  | 108        |
|    iterations           | 407        |
|    time_elapsed         | 7682       |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.09768987 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.322     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0457    |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.143      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 6.23       |
| time/                   |            |
|    fps                  | 108        |
|    iterations           | 408        |
|    time_elapsed         | 7692       |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.07585657 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.333     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0464     |
|    n_updates            | 4070       |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.123      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 5.35        |
| time/                   |             |
|    fps                  | 108         |
|    iterations           | 409         |
|    time_elapsed         | 7704        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.112372905 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.276      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0132     |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0324     |
|    value_loss           | 0.12        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 4.48       |
| time/                   |            |
|    fps                  | 108        |
|    iterations           | 410        |
|    time_elapsed         | 7713       |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.10261831 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.348     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0436    |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0391    |
|    value_loss           | 0.102      |
----------------------------------------
Eval num_timesteps=840000, episode_reward=6.31 +/- 0.32
Episode length: 14.67 +/- 1.25
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 14.7      |
|    mean_reward          | 6.31      |
| time/                   |           |
|    total_timesteps      | 840000    |
| train/                  |           |
|    approx_kl            | 0.1396904 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.454    |
|    explained_variance   | 0.77      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0807   |
|    n_updates            | 4100      |
|    policy_gradient_loss | -0.0678   |
|    value_loss           | 0.123     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.8     |
|    ep_rew_mean     | 6.39     |
| time/              |          |
|    fps             | 108      |
|    iterations      | 411      |
|    time_elapsed    | 7724     |
|    total_timesteps | 841728   |
---------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.1      |
|    ep_rew_mean          | 4.91      |
| time/                   |           |
|    fps                  | 109       |
|    iterations           | 412       |
|    time_elapsed         | 7735      |
|    total_timesteps      | 843776    |
| train/                  |           |
|    approx_kl            | 0.0852565 |
|    clip_fraction        | 0.162     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.224    |
|    explained_variance   | 0.949     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0293   |
|    n_updates            | 4110      |
|    policy_gradient_loss | -0.0321   |
|    value_loss           | 0.0788    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 5.98       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 413        |
|    time_elapsed         | 7745       |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.07410915 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.471     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0136     |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0405    |
|    value_loss           | 0.246      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 5.17       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 414        |
|    time_elapsed         | 7755       |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.13971664 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.335     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0683     |
|    n_updates            | 4130       |
|    policy_gradient_loss | -0.0397    |
|    value_loss           | 0.333      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 5.06       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 415        |
|    time_elapsed         | 7765       |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.12715372 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.406     |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.001      |
|    loss                 | -0.00704   |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0427    |
|    value_loss           | 0.215      |
----------------------------------------
Eval num_timesteps=850000, episode_reward=7.25 +/- 1.32
Episode length: 13.33 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.3       |
|    mean_reward          | 7.25       |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.11776518 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.495     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0231    |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.0956     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 4.78     |
| time/              |          |
|    fps             | 109      |
|    iterations      | 416      |
|    time_elapsed    | 7775     |
|    total_timesteps | 851968   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.2      |
|    ep_rew_mean          | 5.4       |
| time/                   |           |
|    fps                  | 109       |
|    iterations           | 417       |
|    time_elapsed         | 7785      |
|    total_timesteps      | 854016    |
| train/                  |           |
|    approx_kl            | 0.1463598 |
|    clip_fraction        | 0.304     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.457    |
|    explained_variance   | 0.928     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0785   |
|    n_updates            | 4160      |
|    policy_gradient_loss | -0.0448   |
|    value_loss           | 0.137     |
---------------------------------------
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 22       |
|    ep_rew_mean          | 4.87     |
| time/                   |          |
|    fps                  | 109      |
|    iterations           | 418      |
|    time_elapsed         | 7794     |
|    total_timesteps      | 856064   |
| train/                  |          |
|    approx_kl            | 0.102408 |
|    clip_fraction        | 0.264    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.389   |
|    explained_variance   | 0.944    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0201  |
|    n_updates            | 4170     |
|    policy_gradient_loss | -0.0436  |
|    value_loss           | 0.0966   |
--------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 5.13       |
| time/                   |            |
|    fps                  | 109        |
|    iterations           | 419        |
|    time_elapsed         | 7803       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.09257319 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.443     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0293    |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.00164    |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=860000, episode_reward=-5.06 +/- 17.15
Episode length: 60.00 +/- 63.69
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -5.06      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.09356996 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.386     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0512    |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 5.92     |
| time/              |          |
|    fps             | 110      |
|    iterations      | 420      |
|    time_elapsed    | 7812     |
|    total_timesteps | 860160   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 5.32       |
| time/                   |            |
|    fps                  | 110        |
|    iterations           | 421        |
|    time_elapsed         | 7821       |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.07442023 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.303     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0499    |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0238    |
|    value_loss           | 0.087      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 5.6        |
| time/                   |            |
|    fps                  | 110        |
|    iterations           | 422        |
|    time_elapsed         | 7830       |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.12295021 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.321     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0215     |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.151      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 4.68        |
| time/                   |             |
|    fps                  | 110         |
|    iterations           | 423         |
|    time_elapsed         | 7839        |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.084763095 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.41       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0147     |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.0353     |
|    value_loss           | 0.0895      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 5.08        |
| time/                   |             |
|    fps                  | 110         |
|    iterations           | 424         |
|    time_elapsed         | 7848        |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.120335676 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.495      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0237     |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.128       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=870000, episode_reward=8.04 +/- 1.14
Episode length: 16.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 16         |
|    mean_reward          | 8.04       |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.11327881 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.408     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00974    |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 4.93     |
| time/              |          |
|    fps             | 110      |
|    iterations      | 425      |
|    time_elapsed    | 7857     |
|    total_timesteps | 870400   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.6        |
|    ep_rew_mean          | 4.68        |
| time/                   |             |
|    fps                  | 110         |
|    iterations           | 426         |
|    time_elapsed         | 7866        |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.091069594 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.45       |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0478     |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.0289     |
|    value_loss           | 0.125       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 4.99        |
| time/                   |             |
|    fps                  | 111         |
|    iterations           | 427         |
|    time_elapsed         | 7875        |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.123629875 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.441      |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.001       |
|    loss                 | -0.069      |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.0526     |
|    value_loss           | 0.12        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 6.06       |
| time/                   |            |
|    fps                  | 111        |
|    iterations           | 428        |
|    time_elapsed         | 7883       |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.09511342 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.408     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0365    |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.0261    |
|    value_loss           | 0.0796     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 5.42       |
| time/                   |            |
|    fps                  | 111        |
|    iterations           | 429        |
|    time_elapsed         | 7893       |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.09442893 |
|    clip_fraction        | 0.166      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.232     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0115    |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.0817     |
----------------------------------------
Eval num_timesteps=880000, episode_reward=6.84 +/- 0.49
Episode length: 15.33 +/- 1.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 6.84       |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.08261337 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.313     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.056     |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.118      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.9     |
|    ep_rew_mean     | 6.24     |
| time/              |          |
|    fps             | 111      |
|    iterations      | 430      |
|    time_elapsed    | 7901     |
|    total_timesteps | 880640   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 5.55       |
| time/                   |            |
|    fps                  | 111        |
|    iterations           | 431        |
|    time_elapsed         | 7910       |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.08389836 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.269     |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0353     |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.0925     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.1        |
|    ep_rew_mean          | 5.88        |
| time/                   |             |
|    fps                  | 111         |
|    iterations           | 432         |
|    time_elapsed         | 7919        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.088212974 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.296      |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0734      |
|    n_updates            | 4310        |
|    policy_gradient_loss | -0.0261     |
|    value_loss           | 0.116       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.9        |
|    ep_rew_mean          | 5.62        |
| time/                   |             |
|    fps                  | 111         |
|    iterations           | 433         |
|    time_elapsed         | 7928        |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.115413025 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.266      |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0561     |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0333     |
|    value_loss           | 0.0868      |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.4      |
|    ep_rew_mean          | 5.75      |
| time/                   |           |
|    fps                  | 111       |
|    iterations           | 434       |
|    time_elapsed         | 7937      |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 0.0817368 |
|    clip_fraction        | 0.174     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.262    |
|    explained_variance   | 0.939     |
|    learning_rate        | 0.001     |
|    loss                 | -0.019    |
|    n_updates            | 4330      |
|    policy_gradient_loss | -0.0347   |
|    value_loss           | 0.106     |
---------------------------------------
reached max steps=300
Eval num_timesteps=890000, episode_reward=-3.93 +/- 18.44
Episode length: 61.00 +/- 62.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 61          |
|    mean_reward          | -3.93       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.080130026 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.328      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0213      |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.0265     |
|    value_loss           | 0.111       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 5.59     |
| time/              |          |
|    fps             | 112      |
|    iterations      | 435      |
|    time_elapsed    | 7946     |
|    total_timesteps | 890880   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.2       |
|    ep_rew_mean          | 3.91       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 436        |
|    time_elapsed         | 7954       |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.10679002 |
|    clip_fraction        | 0.223      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.331     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0572     |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.183      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 4.93       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 437        |
|    time_elapsed         | 7963       |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.13624468 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.484     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0157     |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.103      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 4.32       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 438        |
|    time_elapsed         | 7971       |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.08553929 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.396     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0585    |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.0993     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 5.74       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 439        |
|    time_elapsed         | 7980       |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.10695234 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.407     |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0118    |
|    n_updates            | 4380       |
|    policy_gradient_loss | -0.0563    |
|    value_loss           | 0.164      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=5.78 +/- 1.14
Episode length: 14.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14         |
|    mean_reward          | 5.78       |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.10840986 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.259     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0312    |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0411    |
|    value_loss           | 0.0984     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17       |
|    ep_rew_mean     | 6.62     |
| time/              |          |
|    fps             | 112      |
|    iterations      | 440      |
|    time_elapsed    | 7989     |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 5.72       |
| time/                   |            |
|    fps                  | 112        |
|    iterations           | 441        |
|    time_elapsed         | 7998       |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.09750538 |
|    clip_fraction        | 0.144      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.195     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0223    |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.023     |
|    value_loss           | 0.111      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 5.33       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 442        |
|    time_elapsed         | 8007       |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.10244542 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.247     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0424    |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 5          |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 443        |
|    time_elapsed         | 8015       |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.09083504 |
|    clip_fraction        | 0.166      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.272     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0129     |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.0323    |
|    value_loss           | 0.0971     |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.7      |
|    ep_rew_mean          | 5.25      |
| time/                   |           |
|    fps                  | 113       |
|    iterations           | 444       |
|    time_elapsed         | 8024      |
|    total_timesteps      | 909312    |
| train/                  |           |
|    approx_kl            | 0.1219932 |
|    clip_fraction        | 0.243     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.381    |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0618   |
|    n_updates            | 4430      |
|    policy_gradient_loss | -0.0353   |
|    value_loss           | 0.107     |
---------------------------------------
Eval num_timesteps=910000, episode_reward=6.17 +/- 0.19
Episode length: 15.33 +/- 2.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 6.17       |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.12423508 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.352     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0129     |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 5.95     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 445      |
|    time_elapsed    | 8032     |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 5.71       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 446        |
|    time_elapsed         | 8041       |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.10259465 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.327     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000346  |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.118      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 5.92       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 447        |
|    time_elapsed         | 8050       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.11361287 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.295     |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0664    |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 4.55       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 448        |
|    time_elapsed         | 8059       |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.12513188 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.271     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0332     |
|    n_updates            | 4470       |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.112      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 5.76       |
| time/                   |            |
|    fps                  | 113        |
|    iterations           | 449        |
|    time_elapsed         | 8068       |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.12323609 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.377     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.001      |
|    loss                 | -0.051     |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.188      |
----------------------------------------
reached max steps=300
Eval num_timesteps=920000, episode_reward=-5.85 +/- 15.72
Episode length: 59.00 +/- 64.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -5.85      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.13649707 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.266     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0225    |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.033     |
|    value_loss           | 0.0911     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 5.47     |
| time/              |          |
|    fps             | 114      |
|    iterations      | 450      |
|    time_elapsed    | 8077     |
|    total_timesteps | 921600   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.2        |
|    ep_rew_mean          | 5.62        |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 451         |
|    time_elapsed         | 8086        |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.103628054 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.339      |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0158     |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0334     |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.8      |
|    ep_rew_mean          | 5.03      |
| time/                   |           |
|    fps                  | 114       |
|    iterations           | 452       |
|    time_elapsed         | 8095      |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.0710392 |
|    clip_fraction        | 0.166     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.272    |
|    explained_variance   | 0.946     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0356    |
|    n_updates            | 4510      |
|    policy_gradient_loss | -0.0218   |
|    value_loss           | 0.108     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 6          |
| time/                   |            |
|    fps                  | 114        |
|    iterations           | 453        |
|    time_elapsed         | 8104       |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.11033247 |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.396     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0306    |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.105      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 4.98        |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 454         |
|    time_elapsed         | 8113        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.095367044 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.32       |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0222      |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.0939      |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=6.38 +/- 0.41
Episode length: 14.33 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.3       |
|    mean_reward          | 6.38       |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.14711323 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.422     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00309   |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.0472    |
|    value_loss           | 0.207      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.7     |
|    ep_rew_mean     | 5.86     |
| time/              |          |
|    fps             | 114      |
|    iterations      | 455      |
|    time_elapsed    | 8122     |
|    total_timesteps | 931840   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.9      |
|    ep_rew_mean          | 5.24      |
| time/                   |           |
|    fps                  | 114       |
|    iterations           | 456       |
|    time_elapsed         | 8131      |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 0.1621244 |
|    clip_fraction        | 0.207     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.257    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0132    |
|    n_updates            | 4550      |
|    policy_gradient_loss | -0.044    |
|    value_loss           | 0.205     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 4.4        |
| time/                   |            |
|    fps                  | 114        |
|    iterations           | 457        |
|    time_elapsed         | 8139       |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.16613194 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.404     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0412    |
|    n_updates            | 4560       |
|    policy_gradient_loss | -0.0426    |
|    value_loss           | 0.128      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 5.26       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 458        |
|    time_elapsed         | 8148       |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.12639336 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.481     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0426    |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=940000, episode_reward=-5.74 +/- 17.34
Episode length: 61.67 +/- 62.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61.7       |
|    mean_reward          | -5.74      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.11204755 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.389     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00335    |
|    n_updates            | 4580       |
|    policy_gradient_loss | -0.0273    |
|    value_loss           | 0.0962     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 5.11     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 459      |
|    time_elapsed    | 8157     |
|    total_timesteps | 940032   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 4.72        |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 460         |
|    time_elapsed         | 8166        |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.120525256 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.433      |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0765     |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.122       |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.2      |
|    ep_rew_mean          | 5.24      |
| time/                   |           |
|    fps                  | 115       |
|    iterations           | 461       |
|    time_elapsed         | 8175      |
|    total_timesteps      | 944128    |
| train/                  |           |
|    approx_kl            | 0.1214637 |
|    clip_fraction        | 0.261     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.423    |
|    explained_variance   | 0.94      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0259   |
|    n_updates            | 4600      |
|    policy_gradient_loss | -0.0366   |
|    value_loss           | 0.106     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 5.08       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 462        |
|    time_elapsed         | 8184       |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.10592265 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.411     |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0421    |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.0317    |
|    value_loss           | 0.0781     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 5.16       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 463        |
|    time_elapsed         | 8194       |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.09315405 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.405     |
|    explained_variance   | 0.542      |
|    learning_rate        | 0.001      |
|    loss                 | 0.153      |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0451    |
|    value_loss           | 0.867      |
----------------------------------------
Eval num_timesteps=950000, episode_reward=4.52 +/- 1.30
Episode length: 13.67 +/- 0.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.7       |
|    mean_reward          | 4.52       |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.27979863 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.396     |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0469     |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.0453    |
|    value_loss           | 0.433      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 4.78     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 464      |
|    time_elapsed    | 8203     |
|    total_timesteps | 950272   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 4.33       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 465        |
|    time_elapsed         | 8212       |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.16075586 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0473    |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0475    |
|    value_loss           | 0.163      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 5.3        |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 466        |
|    time_elapsed         | 8220       |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.15705824 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.555     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0329    |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.0399    |
|    value_loss           | 0.119      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 5.04       |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 467        |
|    time_elapsed         | 8229       |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.18034995 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.426     |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.001      |
|    loss                 | 0.208      |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.052     |
|    value_loss           | 0.836      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 3.51       |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 468        |
|    time_elapsed         | 8238       |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.15431899 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.479     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0459     |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.0438    |
|    value_loss           | 0.167      |
----------------------------------------
reached max steps=300
Eval num_timesteps=960000, episode_reward=-3.73 +/- 15.79
Episode length: 60.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -3.73      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.14408047 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.718     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0498    |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.0459    |
|    value_loss           | 0.137      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22       |
|    ep_rew_mean     | 5.06     |
| time/              |          |
|    fps             | 116      |
|    iterations      | 469      |
|    time_elapsed    | 8248     |
|    total_timesteps | 960512   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.3       |
|    ep_rew_mean          | 3.37       |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 470        |
|    time_elapsed         | 8257       |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.13038191 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.539     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0686    |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.0389    |
|    value_loss           | 0.126      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.6      |
|    ep_rew_mean          | 5.05      |
| time/                   |           |
|    fps                  | 116       |
|    iterations           | 471       |
|    time_elapsed         | 8265      |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 0.0839207 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.691    |
|    explained_variance   | 0.701     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0546    |
|    n_updates            | 4700      |
|    policy_gradient_loss | -0.0218   |
|    value_loss           | 0.545     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 4.52       |
| time/                   |            |
|    fps                  | 116        |
|    iterations           | 472        |
|    time_elapsed         | 8274       |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.13550842 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.441     |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0944     |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.0597    |
|    value_loss           | 0.397      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.6      |
|    ep_rew_mean          | 3.24      |
| time/                   |           |
|    fps                  | 116       |
|    iterations           | 473       |
|    time_elapsed         | 8283      |
|    total_timesteps      | 968704    |
| train/                  |           |
|    approx_kl            | 0.1877559 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.556    |
|    explained_variance   | 0.868     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0155    |
|    n_updates            | 4720      |
|    policy_gradient_loss | -0.0453   |
|    value_loss           | 0.237     |
---------------------------------------
reached max steps=300
Eval num_timesteps=970000, episode_reward=-5.28 +/- 17.78
Episode length: 62.67 +/- 61.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 62.7       |
|    mean_reward          | -5.28      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.13297361 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0819    |
|    n_updates            | 4730       |
|    policy_gradient_loss | -0.0437    |
|    value_loss           | 0.105      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 5.18     |
| time/              |          |
|    fps             | 117      |
|    iterations      | 474      |
|    time_elapsed    | 8292     |
|    total_timesteps | 970752   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.1      |
|    ep_rew_mean          | 5.8       |
| time/                   |           |
|    fps                  | 117       |
|    iterations           | 475       |
|    time_elapsed         | 8301      |
|    total_timesteps      | 972800    |
| train/                  |           |
|    approx_kl            | 0.0879401 |
|    clip_fraction        | 0.275     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.471    |
|    explained_variance   | 0.934     |
|    learning_rate        | 0.001     |
|    loss                 | -0.037    |
|    n_updates            | 4740      |
|    policy_gradient_loss | -0.0424   |
|    value_loss           | 0.114     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 5.22       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 476        |
|    time_elapsed         | 8309       |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.10027742 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.383     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0298     |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.029     |
|    value_loss           | 0.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 4.79       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 477        |
|    time_elapsed         | 8318       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.10074903 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.533     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0202     |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.0335    |
|    value_loss           | 0.204      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.19       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 478        |
|    time_elapsed         | 8327       |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.14776999 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0418    |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.243      |
----------------------------------------
Eval num_timesteps=980000, episode_reward=6.24 +/- 0.62
Episode length: 15.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15         |
|    mean_reward          | 6.24       |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.10577932 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.417     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00355   |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.108      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 5.18     |
| time/              |          |
|    fps             | 117      |
|    iterations      | 479      |
|    time_elapsed    | 8336     |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 5.97       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 480        |
|    time_elapsed         | 8344       |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.11632662 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0227    |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.0404    |
|    value_loss           | 0.156      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 5.38       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 481        |
|    time_elapsed         | 8353       |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.11460883 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.413     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00751    |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 4.64       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 482        |
|    time_elapsed         | 8362       |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.11104606 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.495     |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.001      |
|    loss                 | 0.479      |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.0486    |
|    value_loss           | 0.495      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 4.54       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 483        |
|    time_elapsed         | 8372       |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.12625718 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.525     |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0856     |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.0554    |
|    value_loss           | 0.372      |
----------------------------------------
reached max steps=300
Eval num_timesteps=990000, episode_reward=8.17 +/- 2.22
Episode length: 15.33 +/- 1.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 15.3       |
|    mean_reward          | 8.17       |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.11558874 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.529     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0189     |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.0565    |
|    value_loss           | 0.204      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 4.96     |
| time/              |          |
|    fps             | 118      |
|    iterations      | 484      |
|    time_elapsed    | 8382     |
|    total_timesteps | 991232   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 5.52       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 485        |
|    time_elapsed         | 8393       |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.10138972 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.433     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0226    |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.174      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 5.25       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 486        |
|    time_elapsed         | 8404       |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.10523977 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.35      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00687   |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.117      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 5.38       |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 487        |
|    time_elapsed         | 8415       |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.09394355 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.469     |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0824    |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.0763     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.7        |
|    ep_rew_mean          | 5.62        |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 488         |
|    time_elapsed         | 8425        |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.089667454 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.356      |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0883      |
|    n_updates            | 4870        |
|    policy_gradient_loss | -0.0281     |
|    value_loss           | 0.0984      |
-----------------------------------------
Eval num_timesteps=1000000, episode_reward=6.04 +/- 0.69
Episode length: 16.00 +/- 2.45
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 16         |
|    mean_reward          | 6.04       |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.06847309 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.285     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0257    |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.0953     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 5.66     |
| time/              |          |
|    fps             | 118      |
|    iterations      | 489      |
|    time_elapsed    | 8436     |
|    total_timesteps | 1001472  |
---------------------------------
