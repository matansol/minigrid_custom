Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000002452BD11540> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000002452BD112D0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -32      |
| time/              |          |
|    fps             | 52       |
|    iterations      | 1        |
|    time_elapsed    | 38       |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -33.7       |
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 2           |
|    time_elapsed         | 79          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.013296132 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00285    |
|    learning_rate        | 0.001       |
|    loss                 | 0.25        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0096     |
|    value_loss           | 0.495       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -32.6       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 3           |
|    time_elapsed         | 128         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.015482202 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.0181     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0375     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0153     |
|    value_loss           | 0.291       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -31.8       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 4           |
|    time_elapsed         | 180         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015752744 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.354      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0293     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00986    |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.028075166 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.0943     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0404     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0234     |
|    value_loss           | 0.0632      |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -31.3    |
| time/              |          |
|    fps             | 43       |
|    iterations      | 5        |
|    time_elapsed    | 233      |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30.8       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 6           |
|    time_elapsed         | 286         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.022066377 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | -0.123      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0197     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.0874      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30.5       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 7           |
|    time_elapsed         | 337         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.025505029 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.144      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0693     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0245     |
|    value_loss           | 0.0539      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30.2       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 8           |
|    time_elapsed         | 385         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.022685366 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.001       |
|    loss                 | 0.051       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0217     |
|    value_loss           | 0.0898      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -29.4       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 9           |
|    time_elapsed         | 432         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.027502319 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | -0.0537     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0527     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0302     |
|    value_loss           | 0.171       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.03297837 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.85      |
|    explained_variance   | -0.0953    |
|    learning_rate        | 0.001      |
|    loss                 | 0.0242     |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0268    |
|    value_loss           | 0.247      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -29      |
| time/              |          |
|    fps             | 42       |
|    iterations      | 10       |
|    time_elapsed    | 482      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 148        |
|    ep_rew_mean          | -28.7      |
| time/                   |            |
|    fps                  | 42         |
|    iterations           | 11         |
|    time_elapsed         | 527        |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.03744252 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | -1.23      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0462    |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.0303    |
|    value_loss           | 0.131      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -28.4       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 12          |
|    time_elapsed         | 575         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.037752695 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -0.176      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0267     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0264     |
|    value_loss           | 0.252       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -28.5       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 13          |
|    time_elapsed         | 621         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.038816914 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -0.24       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0717     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0192     |
|    value_loss           | 0.166       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | -28.6      |
| time/                   |            |
|    fps                  | 43         |
|    iterations           | 14         |
|    time_elapsed         | 666        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03434852 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.81      |
|    explained_variance   | -0.539     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0222    |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0254    |
|    value_loss           | 0.0939     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.034684613 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | -0.729      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0862     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0216     |
|    value_loss           | 0.0906      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -28.4    |
| time/              |          |
|    fps             | 42       |
|    iterations      | 15       |
|    time_elapsed    | 716      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -28.2       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 16          |
|    time_elapsed         | 763         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.049781047 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | -0.166      |
|    learning_rate        | 0.001       |
|    loss                 | -0.079      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0282     |
|    value_loss           | 0.146       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 144       |
|    ep_rew_mean          | -27.6     |
| time/                   |           |
|    fps                  | 42        |
|    iterations           | 17        |
|    time_elapsed         | 813       |
|    total_timesteps      | 34816     |
| train/                  |           |
|    approx_kl            | 0.0429293 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.8      |
|    explained_variance   | -0.244    |
|    learning_rate        | 0.001     |
|    loss                 | 0.0073    |
|    n_updates            | 160       |
|    policy_gradient_loss | -0.0266   |
|    value_loss           | 0.118     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 144        |
|    ep_rew_mean          | -27.4      |
| time/                   |            |
|    fps                  | 42         |
|    iterations           | 18         |
|    time_elapsed         | 863        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.04527312 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.78      |
|    explained_variance   | -0.106     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0562     |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.278      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -27.6       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 19          |
|    time_elapsed         | 915         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.045220442 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.0348      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0522     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0274     |
|    value_loss           | 0.215       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.047336582 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | -0.281      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0488     |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0276     |
|    value_loss           | 0.0792      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -27.5    |
| time/              |          |
|    fps             | 42       |
|    iterations      | 20       |
|    time_elapsed    | 969      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -27.5       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 21          |
|    time_elapsed         | 1018        |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.039184213 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | -0.0351     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0431     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.107       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | -27.1       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 22          |
|    time_elapsed         | 1069        |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.045835968 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | -0.538      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0017      |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0177     |
|    value_loss           | 0.0834      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 139         |
|    ep_rew_mean          | -26         |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 23          |
|    time_elapsed         | 1118        |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.040756803 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.346       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0441     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0268     |
|    value_loss           | 0.0656      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 138         |
|    ep_rew_mean          | -25.7       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 24          |
|    time_elapsed         | 1171        |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.044895373 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.001       |
|    loss                 | -0.0761     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0301     |
|    value_loss           | 0.199       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.04839845 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.74      |
|    explained_variance   | 0.371      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00386   |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | -25.3    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 25       |
|    time_elapsed    | 1223     |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 127        |
|    ep_rew_mean          | -22.6      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 26         |
|    time_elapsed         | 1269       |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.03152458 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.72      |
|    explained_variance   | 0.0566     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0396     |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.0153    |
|    value_loss           | 0.102      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 117        |
|    ep_rew_mean          | -19.8      |
| time/                   |            |
|    fps                  | 42         |
|    iterations           | 27         |
|    time_elapsed         | 1315       |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.04116126 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.67      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0467    |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.0325    |
|    value_loss           | 0.16       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 107        |
|    ep_rew_mean          | -17.4      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 28         |
|    time_elapsed         | 1367       |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.04360839 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.62      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00998    |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | -16.8       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 29          |
|    time_elapsed         | 1418        |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.049755152 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0416     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.134       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.052043986 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.001       |
|    loss                 | -0.023      |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0299     |
|    value_loss           | 0.105       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.1     |
|    ep_rew_mean     | -14.7    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 30       |
|    time_elapsed    | 1473     |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 88.1       |
|    ep_rew_mean          | -12.9      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 31         |
|    time_elapsed         | 1520       |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.03847155 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.53      |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0764    |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.0195    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 89.2       |
|    ep_rew_mean          | -13.4      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 32         |
|    time_elapsed         | 1565       |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.04749492 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.51      |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0341    |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0242    |
|    value_loss           | 0.199      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.3        |
|    ep_rew_mean          | -11.4       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 33          |
|    time_elapsed         | 1609        |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.059248056 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0563     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.021      |
|    value_loss           | 0.0914      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 73.2        |
|    ep_rew_mean          | -9.97       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 34          |
|    time_elapsed         | 1655        |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.043321025 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0795     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.015      |
|    value_loss           | 0.0955      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.04621096 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.38      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0257    |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0179    |
|    value_loss           | 0.138      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.8     |
|    ep_rew_mean     | -7.83    |
| time/              |          |
|    fps             | 42       |
|    iterations      | 35       |
|    time_elapsed    | 1704     |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 65.6        |
|    ep_rew_mean          | -8.28       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 36          |
|    time_elapsed         | 1759        |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.041388527 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0255     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 0.243       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 63.4      |
|    ep_rew_mean          | -7.69     |
| time/                   |           |
|    fps                  | 41        |
|    iterations           | 37        |
|    time_elapsed         | 1806      |
|    total_timesteps      | 75776     |
| train/                  |           |
|    approx_kl            | 0.0658288 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.46     |
|    explained_variance   | 0.833     |
|    learning_rate        | 0.001     |
|    loss                 | -0.078    |
|    n_updates            | 360       |
|    policy_gradient_loss | -0.0187   |
|    value_loss           | 0.146     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.9        |
|    ep_rew_mean          | -7.11       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 38          |
|    time_elapsed         | 1854        |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.044209972 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00609     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0202     |
|    value_loss           | 0.135       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 53.9        |
|    ep_rew_mean          | -5.23       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 39          |
|    time_elapsed         | 1901        |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.041940086 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0468     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00974    |
|    value_loss           | 0.128       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=80000, episode_reward=-6.58 +/- 16.60
Episode length: 57.67 +/- 65.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 57.7        |
|    mean_reward          | -6.58       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.048862554 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0464      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0306     |
|    value_loss           | 0.164       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 54.3     |
|    ep_rew_mean     | -4.98    |
| time/              |          |
|    fps             | 42       |
|    iterations      | 40       |
|    time_elapsed    | 1950     |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 55.5        |
|    ep_rew_mean          | -5.32       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 41          |
|    time_elapsed         | 1996        |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.053772494 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0225     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 0.122       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59          |
|    ep_rew_mean          | -6.08       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 42          |
|    time_elapsed         | 2043        |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.053515643 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0581     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0237     |
|    value_loss           | 0.139       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.5       |
|    ep_rew_mean          | -4.02      |
| time/                   |            |
|    fps                  | 42         |
|    iterations           | 43         |
|    time_elapsed         | 2091       |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.04751303 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0444    |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0103    |
|    value_loss           | 0.101      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-17.82 +/- 17.22
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -17.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.044120137 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0539      |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0212     |
|    value_loss           | 0.207       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48.5     |
|    ep_rew_mean     | -3.52    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 44       |
|    time_elapsed    | 2145     |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 52.8        |
|    ep_rew_mean          | -4.48       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 45          |
|    time_elapsed         | 2212        |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.047385097 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0237     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 52.5        |
|    ep_rew_mean          | -4.37       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 46          |
|    time_elapsed         | 2262        |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.060006604 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.001       |
|    loss                 | 0.061       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0175     |
|    value_loss           | 0.127       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.1        |
|    ep_rew_mean          | -4.48       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 47          |
|    time_elapsed         | 2313        |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.086858705 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0848      |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0263     |
|    value_loss           | 0.344       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 58.4       |
|    ep_rew_mean          | -5.17      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 48         |
|    time_elapsed         | 2358       |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.09213902 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0236    |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.418      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-18.42 +/- 15.67
Episode length: 103.67 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.4      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.06933629 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.42      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0445     |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0295    |
|    value_loss           | 0.237      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 61.2     |
|    ep_rew_mean     | -5.72    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 49       |
|    time_elapsed    | 2401     |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 64         |
|    ep_rew_mean          | -6.4       |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 50         |
|    time_elapsed         | 2452       |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.05445421 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.38      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0601    |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 0.217      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.2        |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 51          |
|    time_elapsed         | 2505        |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.045776915 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0098      |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.148       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 55.7        |
|    ep_rew_mean          | -4.71       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 52          |
|    time_elapsed         | 2548        |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.056390762 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0453      |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0347     |
|    value_loss           | 0.177       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.7        |
|    ep_rew_mean          | -1.45       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 53          |
|    time_elapsed         | 2592        |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.038547043 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0311      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0239     |
|    value_loss           | 0.154       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=110000, episode_reward=-6.91 +/- 15.62
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -6.91      |
| time/                   |            |
|    total_timesteps      | 110000     |
| train/                  |            |
|    approx_kl            | 0.05885448 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.14      |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.001      |
|    loss                 | -0.023     |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.207      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.5     |
|    ep_rew_mean     | -1.56    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 54       |
|    time_elapsed    | 2642     |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49          |
|    ep_rew_mean          | -2.93       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 55          |
|    time_elapsed         | 2688        |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.061488725 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.001       |
|    loss                 | 0.106       |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0266     |
|    value_loss           | 0.601       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.4       |
|    ep_rew_mean          | -3.56      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 56         |
|    time_elapsed         | 2735       |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.06687395 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.001      |
|    loss                 | 0.235      |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0316    |
|    value_loss           | 0.577      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.3       |
|    ep_rew_mean          | -1.99      |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 57         |
|    time_elapsed         | 2781       |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.07782552 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.22      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.001      |
|    loss                 | -0.067     |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.9       |
|    ep_rew_mean          | -0.837     |
| time/                   |            |
|    fps                  | 41         |
|    iterations           | 58         |
|    time_elapsed         | 2828       |
|    total_timesteps      | 118784     |
| train/                  |            |
|    approx_kl            | 0.07452136 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0352     |
|    n_updates            | 570        |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.225      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-18.42 +/- 15.67
Episode length: 103.67 +/- 65.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -18.4       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.083694436 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0355     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0407     |
|    value_loss           | 0.133       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.5     |
|    ep_rew_mean     | -1.63    |
| time/              |          |
|    fps             | 41       |
|    iterations      | 59       |
|    time_elapsed    | 2889     |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.2        |
|    ep_rew_mean          | -0.397      |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 60          |
|    time_elapsed         | 2940        |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.068399906 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0333     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0392     |
|    value_loss           | 0.179       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.9        |
|    ep_rew_mean          | 1.59        |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 61          |
|    time_elapsed         | 2989        |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.054876044 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.89       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0479      |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.175       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.5        |
|    ep_rew_mean          | 0.829       |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 62          |
|    time_elapsed         | 3040        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.082023434 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.894      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0584     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0354     |
|    value_loss           | 0.131       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.2       |
|    ep_rew_mean          | 1.97       |
| time/                   |            |
|    fps                  | 42         |
|    iterations           | 63         |
|    time_elapsed         | 3064       |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.06723777 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.937     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0341    |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.0317    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=130000, episode_reward=-18.76 +/- 15.90
Episode length: 103.67 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.06434928 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.847     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.001      |
|    loss                 | 0.132      |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.26       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 2.94     |
| time/              |          |
|    fps             | 42       |
|    iterations      | 64       |
|    time_elapsed    | 3093     |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.9        |
|    ep_rew_mean          | 2.28        |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 65          |
|    time_elapsed         | 3114        |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.106066726 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.726      |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.001       |
|    loss                 | 0.000451    |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.311       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 26.7      |
|    ep_rew_mean          | 1.63      |
| time/                   |           |
|    fps                  | 43        |
|    iterations           | 66        |
|    time_elapsed         | 3141      |
|    total_timesteps      | 135168    |
| train/                  |           |
|    approx_kl            | 0.0783319 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.833    |
|    explained_variance   | 0.892     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0141    |
|    n_updates            | 650       |
|    policy_gradient_loss | -0.0471   |
|    value_loss           | 0.2       |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 1.97       |
| time/                   |            |
|    fps                  | 43         |
|    iterations           | 67         |
|    time_elapsed         | 3166       |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.09060983 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.828     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0252    |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.0425    |
|    value_loss           | 0.18       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 2.54       |
| time/                   |            |
|    fps                  | 43         |
|    iterations           | 68         |
|    time_elapsed         | 3192       |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.08516155 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.876     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0485    |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.0242    |
|    value_loss           | 0.135      |
----------------------------------------
reached max steps=300
Eval num_timesteps=140000, episode_reward=-6.38 +/- 16.72
Episode length: 58.33 +/- 64.82
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 58.3      |
|    mean_reward          | -6.38     |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0770024 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.756    |
|    explained_variance   | 0.93      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0102   |
|    n_updates            | 680       |
|    policy_gradient_loss | -0.0348   |
|    value_loss           | 0.117     |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.2     |
|    ep_rew_mean     | 3.6      |
| time/              |          |
|    fps             | 43       |
|    iterations      | 69       |
|    time_elapsed    | 3217     |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.9        |
|    ep_rew_mean          | 1.29        |
| time/                   |             |
|    fps                  | 44          |
|    iterations           | 70          |
|    time_elapsed         | 3242        |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.056104757 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0445     |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0307     |
|    value_loss           | 0.109       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.2       |
|    ep_rew_mean          | 0.555      |
| time/                   |            |
|    fps                  | 44         |
|    iterations           | 71         |
|    time_elapsed         | 3257       |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.14134541 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.934     |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.001      |
|    loss                 | 0.058      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0316    |
|    value_loss           | 0.407      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.3        |
|    ep_rew_mean          | 1.96        |
| time/                   |             |
|    fps                  | 44          |
|    iterations           | 72          |
|    time_elapsed         | 3284        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.093775965 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.775      |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00341    |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0348     |
|    value_loss           | 0.344       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 3.29       |
| time/                   |            |
|    fps                  | 45         |
|    iterations           | 73         |
|    time_elapsed         | 3309       |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.19825079 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.761     |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0186    |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.404      |
----------------------------------------
Eval num_timesteps=150000, episode_reward=4.00 +/- 0.37
Episode length: 11.33 +/- 0.47
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 11.3      |
|    mean_reward          | 4         |
| time/                   |           |
|    total_timesteps      | 150000    |
| train/                  |           |
|    approx_kl            | 0.0927344 |
|    clip_fraction        | 0.285     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.599    |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0784    |
|    n_updates            | 730       |
|    policy_gradient_loss | -0.0422   |
|    value_loss           | 0.188     |
---------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 2.44     |
| time/              |          |
|    fps             | 45       |
|    iterations      | 74       |
|    time_elapsed    | 3335     |
|    total_timesteps | 151552   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 2.53       |
| time/                   |            |
|    fps                  | 45         |
|    iterations           | 75         |
|    time_elapsed         | 3361       |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.07609815 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.769     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00656   |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.154      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 2.04       |
| time/                   |            |
|    fps                  | 45         |
|    iterations           | 76         |
|    time_elapsed         | 3388       |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.07800767 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.732     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0211    |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.143      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | -0.0535     |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 77          |
|    time_elapsed         | 3415        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.081290625 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.863      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0512     |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0343     |
|    value_loss           | 0.137       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.73       |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 78         |
|    time_elapsed         | 3443       |
|    total_timesteps      | 159744     |
| train/                  |            |
|    approx_kl            | 0.07239145 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.09      |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | 0.202      |
|    n_updates            | 770        |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.163      |
----------------------------------------
reached max steps=300
Eval num_timesteps=160000, episode_reward=-6.51 +/- 14.49
Episode length: 57.33 +/- 65.53
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 57.3      |
|    mean_reward          | -6.51     |
| time/                   |           |
|    total_timesteps      | 160000    |
| train/                  |           |
|    approx_kl            | 0.0765253 |
|    clip_fraction        | 0.294     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.68     |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.001     |
|    loss                 | 0.0395    |
|    n_updates            | 780       |
|    policy_gradient_loss | -0.0326   |
|    value_loss           | 0.216     |
---------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.3     |
|    ep_rew_mean     | 2.46     |
| time/              |          |
|    fps             | 46       |
|    iterations      | 79       |
|    time_elapsed    | 3471     |
|    total_timesteps | 161792   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.85       |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 80         |
|    time_elapsed         | 3491       |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.06937359 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.746     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0049     |
|    n_updates            | 790        |
|    policy_gradient_loss | -0.0349    |
|    value_loss           | 0.137      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 2.29       |
| time/                   |            |
|    fps                  | 47         |
|    iterations           | 81         |
|    time_elapsed         | 3516       |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.07159455 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.662     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0165     |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19          |
|    ep_rew_mean          | 3.09        |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 82          |
|    time_elapsed         | 3542        |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.061641898 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.774      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0496     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.102       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 2.43        |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 83          |
|    time_elapsed         | 3568        |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.060380764 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.582      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0547     |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.162       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=170000, episode_reward=-17.49 +/- 14.95
Episode length: 104.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -17.5       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.059713412 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.742      |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0658     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0196     |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.3     |
|    ep_rew_mean     | 1.51     |
| time/              |          |
|    fps             | 47       |
|    iterations      | 84       |
|    time_elapsed    | 3596     |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 1.07       |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 85         |
|    time_elapsed         | 3623       |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.06555466 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.89      |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0456    |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.0967     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 1.75       |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 86         |
|    time_elapsed         | 3648       |
|    total_timesteps      | 176128     |
| train/                  |            |
|    approx_kl            | 0.06939057 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.913     |
|    explained_variance   | 0.525      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0174     |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.818      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 2.82       |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 87         |
|    time_elapsed         | 3673       |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.09976543 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.848     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0458     |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.244      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=180000, episode_reward=-18.82 +/- 15.81
Episode length: 104.00 +/- 65.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -18.8      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.08778497 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.836     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.11      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0475    |
|    value_loss           | 0.144      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.1     |
|    ep_rew_mean     | 0.748    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 88       |
|    time_elapsed    | 3701     |
|    total_timesteps | 180224   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 42.5        |
|    ep_rew_mean          | -0.809      |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 89          |
|    time_elapsed         | 3719        |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.065694615 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.001       |
|    loss                 | 0.166       |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0453     |
|    value_loss           | 0.706       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.1       |
|    ep_rew_mean          | -1.59      |
| time/                   |            |
|    fps                  | 49         |
|    iterations           | 90         |
|    time_elapsed         | 3741       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.08043447 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.001      |
|    loss                 | 0.435      |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0527    |
|    value_loss           | 0.529      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.5        |
|    ep_rew_mean          | -0.415      |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 91          |
|    time_elapsed         | 3767        |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.087307036 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0235     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0438     |
|    value_loss           | 0.191       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.26       |
| time/                   |            |
|    fps                  | 49         |
|    iterations           | 92         |
|    time_elapsed         | 3794       |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.09278597 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.898     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0364     |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.0534    |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
Eval num_timesteps=190000, episode_reward=-5.38 +/- 17.52
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -5.38      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.07242756 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0216    |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0468    |
|    value_loss           | 0.175      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.5     |
|    ep_rew_mean     | 1.56     |
| time/              |          |
|    fps             | 49       |
|    iterations      | 93       |
|    time_elapsed    | 3820     |
|    total_timesteps | 190464   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 1.65       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 94         |
|    time_elapsed         | 3847       |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.08588524 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.882     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0308    |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.0474    |
|    value_loss           | 0.169      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.9       |
|    ep_rew_mean          | 2.15       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 95         |
|    time_elapsed         | 3874       |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.07153761 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.875     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0535    |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0458    |
|    value_loss           | 0.17       |
----------------------------------------
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 25       |
|    ep_rew_mean          | 1.85     |
| time/                   |          |
|    fps                  | 50       |
|    iterations           | 96       |
|    time_elapsed         | 3898     |
|    total_timesteps      | 196608   |
| train/                  |          |
|    approx_kl            | 0.091602 |
|    clip_fraction        | 0.36     |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.779   |
|    explained_variance   | 0.91     |
|    learning_rate        | 0.001    |
|    loss                 | 0.0212   |
|    n_updates            | 950      |
|    policy_gradient_loss | -0.0425  |
|    value_loss           | 0.122    |
--------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 2.23       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 97         |
|    time_elapsed         | 3923       |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.06294373 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.828     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0276    |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.0893     |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=200000, episode_reward=4.92 +/- 1.42
Episode length: 13.33 +/- 1.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.3       |
|    mean_reward          | 4.92       |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.07293327 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.743     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0479    |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0411    |
|    value_loss           | 0.102      |
----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.5     |
|    ep_rew_mean     | 1.68     |
| time/              |          |
|    fps             | 50       |
|    iterations      | 98       |
|    time_elapsed    | 3951     |
|    total_timesteps | 200704   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.2       |
|    ep_rew_mean          | 1.61       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 99         |
|    time_elapsed         | 3976       |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.06770742 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00761   |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.042     |
|    value_loss           | 0.255      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.8       |
|    ep_rew_mean          | 3.94       |
| time/                   |            |
|    fps                  | 51         |
|    iterations           | 100        |
|    time_elapsed         | 4001       |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.07832135 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0578    |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0407    |
|    value_loss           | 0.0918     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 3.15       |
| time/                   |            |
|    fps                  | 51         |
|    iterations           | 101        |
|    time_elapsed         | 4028       |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.07244395 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.43      |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.014     |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.108      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.4       |
|    ep_rew_mean          | 3.57       |
| time/                   |            |
|    fps                  | 51         |
|    iterations           | 102        |
|    time_elapsed         | 4053       |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.08007659 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0571    |
|    n_updates            | 1010       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.0872     |
----------------------------------------
reached max steps=300
Eval num_timesteps=210000, episode_reward=-7.51 +/- 15.90
Episode length: 57.33 +/- 65.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 57.3        |
|    mean_reward          | -7.51       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.063311145 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.443      |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0234     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0371     |
|    value_loss           | 0.0966      |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 2.79     |
| time/              |          |
|    fps             | 51       |
|    iterations      | 103      |
|    time_elapsed    | 4072     |
|    total_timesteps | 210944   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 2.49       |
| time/                   |            |
|    fps                  | 51         |
|    iterations           | 104        |
|    time_elapsed         | 4096       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.06234838 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0171    |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.0405    |
|    value_loss           | 0.125      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 2.26       |
| time/                   |            |
|    fps                  | 52         |
|    iterations           | 105        |
|    time_elapsed         | 4121       |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.07298459 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.746     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0346    |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.2       |
|    ep_rew_mean          | 2.44       |
| time/                   |            |
|    fps                  | 52         |
|    iterations           | 106        |
|    time_elapsed         | 4147       |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.07672441 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.723     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0801     |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0394    |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.1        |
|    ep_rew_mean          | 1.16        |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 107         |
|    time_elapsed         | 4173        |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.075771466 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.786      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0157      |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0377     |
|    value_loss           | 0.18        |
-----------------------------------------
reached max steps=300
Eval num_timesteps=220000, episode_reward=3.72 +/- 0.66
Episode length: 12.67 +/- 1.70
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 12.7      |
|    mean_reward          | 3.72      |
| time/                   |           |
|    total_timesteps      | 220000    |
| train/                  |           |
|    approx_kl            | 0.0902919 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.871    |
|    explained_variance   | 0.92      |
|    learning_rate        | 0.001     |
|    loss                 | -0.0888   |
|    n_updates            | 1070      |
|    policy_gradient_loss | -0.0413   |
|    value_loss           | 0.107     |
---------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.3     |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    fps             | 52       |
|    iterations      | 108      |
|    time_elapsed    | 4193     |
|    total_timesteps | 221184   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 3.32        |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 109         |
|    time_elapsed         | 4217        |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.070982516 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.918      |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0775     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0383     |
|    value_loss           | 0.145       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 2.8        |
| time/                   |            |
|    fps                  | 53         |
|    iterations           | 110        |
|    time_elapsed         | 4243       |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.05363961 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.636     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0347    |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.9        |
|    ep_rew_mean          | 3.12        |
| time/                   |             |
|    fps                  | 53          |
|    iterations           | 111         |
|    time_elapsed         | 4262        |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.062499322 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00644    |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.036      |
|    value_loss           | 0.116       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 2.61        |
| time/                   |             |
|    fps                  | 53          |
|    iterations           | 112         |
|    time_elapsed         | 4289        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.064160526 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.653      |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0662     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0352     |
|    value_loss           | 0.128       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=5.72 +/- 2.81
Episode length: 12.67 +/- 2.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.7       |
|    mean_reward          | 5.72       |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.11963913 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.722     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | -0.051     |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.0532    |
|    value_loss           | 0.235      |
----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 2.43     |
| time/              |          |
|    fps             | 53       |
|    iterations      | 113      |
|    time_elapsed    | 4316     |
|    total_timesteps | 231424   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.2        |
|    ep_rew_mean          | 2.69        |
| time/                   |             |
|    fps                  | 53          |
|    iterations           | 114         |
|    time_elapsed         | 4344        |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.096877016 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.643      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0342     |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0356     |
|    value_loss           | 0.121       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 3.71       |
| time/                   |            |
|    fps                  | 53         |
|    iterations           | 115        |
|    time_elapsed         | 4372       |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.08301462 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.696     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0212    |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0405    |
|    value_loss           | 0.0913     |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 3.05        |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 116         |
|    time_elapsed         | 4398        |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.054314457 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.518      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0729     |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0296     |
|    value_loss           | 0.114       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 2.82       |
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 117        |
|    time_elapsed         | 4425       |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.08604643 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.625     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0503    |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.0503    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
Eval num_timesteps=240000, episode_reward=4.53 +/- 1.12
Episode length: 12.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12         |
|    mean_reward          | 4.53       |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.07336386 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.669     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0753    |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0389    |
|    value_loss           | 0.188      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.4     |
|    ep_rew_mean     | 2.3      |
| time/              |          |
|    fps             | 54       |
|    iterations      | 118      |
|    time_elapsed    | 4454     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 3.61       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 119        |
|    time_elapsed         | 4842       |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.05980697 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.748     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.03      |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.0325    |
|    value_loss           | 0.174      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 3.07       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 120        |
|    time_elapsed         | 4868       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.08925159 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.653     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0542    |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.0441    |
|    value_loss           | 0.102      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 2.39       |
| time/                   |            |
|    fps                  | 50         |
|    iterations           | 121        |
|    time_elapsed         | 4878       |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.06695995 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.734     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0373    |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.389      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 1.65        |
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 122         |
|    time_elapsed         | 4890        |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.104264945 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.797      |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0683      |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0542     |
|    value_loss           | 0.323       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=250000, episode_reward=-18.76 +/- 15.90
Episode length: 103.67 +/- 65.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | -18.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.089003965 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.88       |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00587     |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0469     |
|    value_loss           | 0.18        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.3     |
|    ep_rew_mean     | 1.33     |
| time/              |          |
|    fps             | 51       |
|    iterations      | 123      |
|    time_elapsed    | 4901     |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 1.95       |
| time/                   |            |
|    fps                  | 51         |
|    iterations           | 124        |
|    time_elapsed         | 4911       |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.08379273 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.94      |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.001      |
|    loss                 | 0.189      |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.0382    |
|    value_loss           | 0.311      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.6      |
|    ep_rew_mean          | 1.52      |
| time/                   |           |
|    fps                  | 52        |
|    iterations           | 125       |
|    time_elapsed         | 4921      |
|    total_timesteps      | 256000    |
| train/                  |           |
|    approx_kl            | 0.0993419 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.797    |
|    explained_variance   | 0.864     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0512   |
|    n_updates            | 1240      |
|    policy_gradient_loss | -0.0443   |
|    value_loss           | 0.211     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 3.1         |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 126         |
|    time_elapsed         | 4932        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.083928935 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.89       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0339     |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0445     |
|    value_loss           | 0.147       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=260000, episode_reward=-6.59 +/- 16.59
Episode length: 59.33 +/- 64.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.3       |
|    mean_reward          | -6.59      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.06965816 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.704     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0357    |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0469    |
|    value_loss           | 0.101      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 2.41     |
| time/              |          |
|    fps             | 52       |
|    iterations      | 127      |
|    time_elapsed    | 4944     |
|    total_timesteps | 260096   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.9        |
|    ep_rew_mean          | 1.73        |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 128         |
|    time_elapsed         | 4958        |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.076943874 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.793      |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0668     |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.0444     |
|    value_loss           | 0.103       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 2.75       |
| time/                   |            |
|    fps                  | 53         |
|    iterations           | 129        |
|    time_elapsed         | 4970       |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.07735945 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.852     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00301   |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.0444    |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 53         |
|    iterations           | 130        |
|    time_elapsed         | 4984       |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.08617021 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.703     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0293    |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.0443    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.6       |
|    ep_rew_mean          | 2.66       |
| time/                   |            |
|    fps                  | 53         |
|    iterations           | 131        |
|    time_elapsed         | 5005       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.07322968 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.678     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0209    |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.0422    |
|    value_loss           | 0.162      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=270000, episode_reward=-6.65 +/- 15.81
Episode length: 58.00 +/- 65.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58          |
|    mean_reward          | -6.65       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.072164744 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.847      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0278      |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0377     |
|    value_loss           | 0.188       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 2.48     |
| time/              |          |
|    fps             | 53       |
|    iterations      | 132      |
|    time_elapsed    | 5023     |
|    total_timesteps | 270336   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 2.77       |
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 133        |
|    time_elapsed         | 5035       |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.07497371 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.725     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0356     |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.0499    |
|    value_loss           | 0.162      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 3.47       |
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 134        |
|    time_elapsed         | 5046       |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.14483017 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.705     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0216     |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.043     |
|    value_loss           | 0.233      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 3.04       |
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 135        |
|    time_elapsed         | 5056       |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.07990377 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.07      |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.0357    |
|    value_loss           | 0.134      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.4       |
|    ep_rew_mean          | 2.1        |
| time/                   |            |
|    fps                  | 54         |
|    iterations           | 136        |
|    time_elapsed         | 5066       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.08985202 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.792     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | 0.136      |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.043     |
|    value_loss           | 0.174      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=-5.66 +/- 15.15
Episode length: 59.67 +/- 63.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.7       |
|    mean_reward          | -5.66      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.09652259 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.904     |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0308    |
|    n_updates            | 1360       |
|    policy_gradient_loss | -0.0493    |
|    value_loss           | 0.195      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.3     |
|    ep_rew_mean     | 2.93     |
| time/              |          |
|    fps             | 55       |
|    iterations      | 137      |
|    time_elapsed    | 5077     |
|    total_timesteps | 280576   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 3.06        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 138         |
|    time_elapsed         | 5087        |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.086553544 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.753      |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0347      |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0413     |
|    value_loss           | 0.205       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.6        |
|    ep_rew_mean          | 2.85        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 139         |
|    time_elapsed         | 5097        |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.085315324 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.751      |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0507     |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0404     |
|    value_loss           | 0.15        |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 3.29        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 140         |
|    time_elapsed         | 5108        |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.107133724 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.707      |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0637     |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0458     |
|    value_loss           | 0.124       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 2.98       |
| time/                   |            |
|    fps                  | 56         |
|    iterations           | 141        |
|    time_elapsed         | 5118       |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.07439944 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.648     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0548    |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.0926     |
----------------------------------------
reached max steps=300
Eval num_timesteps=290000, episode_reward=-7.12 +/- 16.18
Episode length: 58.67 +/- 64.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -7.12      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.09255164 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.713     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0499     |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.428      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 3.52     |
| time/              |          |
|    fps             | 56       |
|    iterations      | 142      |
|    time_elapsed    | 5129     |
|    total_timesteps | 290816   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 3.01       |
| time/                   |            |
|    fps                  | 56         |
|    iterations           | 143        |
|    time_elapsed         | 5140       |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.07884964 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.579     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0357    |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0418    |
|    value_loss           | 0.313      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 3.02       |
| time/                   |            |
|    fps                  | 57         |
|    iterations           | 144        |
|    time_elapsed         | 5150       |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.09937398 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.7       |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0458     |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0414    |
|    value_loss           | 0.117      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 3.79        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 145         |
|    time_elapsed         | 5160        |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.079272844 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.801      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0487     |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0379     |
|    value_loss           | 0.144       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.3        |
|    ep_rew_mean          | 2.92        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 146         |
|    time_elapsed         | 5171        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.119216464 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.625      |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.001       |
|    loss                 | -0.011      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0383     |
|    value_loss           | 0.126       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=300000, episode_reward=-7.99 +/- 15.56
Episode length: 59.67 +/- 63.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59.7       |
|    mean_reward          | -7.99      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.09362437 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.689     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0799    |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0454    |
|    value_loss           | 0.111      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 3.91     |
| time/              |          |
|    fps             | 58       |
|    iterations      | 147      |
|    time_elapsed    | 5182     |
|    total_timesteps | 301056   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 3.45       |
| time/                   |            |
|    fps                  | 58         |
|    iterations           | 148        |
|    time_elapsed         | 5192       |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.09242286 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.592     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0307    |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.0429    |
|    value_loss           | 0.0865     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.6        |
|    ep_rew_mean          | 2.45        |
| time/                   |             |
|    fps                  | 58          |
|    iterations           | 149         |
|    time_elapsed         | 5202        |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.100815736 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0557     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0442     |
|    value_loss           | 0.132       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.6       |
|    ep_rew_mean          | 2.48       |
| time/                   |            |
|    fps                  | 58         |
|    iterations           | 150        |
|    time_elapsed         | 5212       |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.08851244 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.771     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00423    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0315    |
|    value_loss           | 0.124      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.2        |
|    ep_rew_mean          | 2.94        |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 151         |
|    time_elapsed         | 5223        |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.095601164 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.763      |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0424     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0417     |
|    value_loss           | 0.163       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=310000, episode_reward=-6.38 +/- 16.02
Episode length: 58.33 +/- 64.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -6.38      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.10126212 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.823     |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0422     |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0448    |
|    value_loss           | 0.184      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.3     |
|    ep_rew_mean     | 1.39     |
| time/              |          |
|    fps             | 59       |
|    iterations      | 152      |
|    time_elapsed    | 5234     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 3.46       |
| time/                   |            |
|    fps                  | 59         |
|    iterations           | 153        |
|    time_elapsed         | 5244       |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.10348921 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.882     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0276     |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.0408    |
|    value_loss           | 0.216      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 3.13       |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 154        |
|    time_elapsed         | 5255       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.10334793 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.689     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0032     |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0442    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 2.99       |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 155        |
|    time_elapsed         | 5266       |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.10310578 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0431    |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.0502    |
|    value_loss           | 0.168      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 3.67       |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 156        |
|    time_elapsed         | 5279       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.09763324 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.678     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0364    |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0349    |
|    value_loss           | 0.137      |
----------------------------------------
reached max steps=300
Eval num_timesteps=320000, episode_reward=-4.39 +/- 16.15
Episode length: 60.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -4.39      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.09817834 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.657     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0688    |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.037     |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 3        |
| time/              |          |
|    fps             | 60       |
|    iterations      | 157      |
|    time_elapsed    | 5292     |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 3.44       |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 158        |
|    time_elapsed         | 5304       |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.08880797 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.737     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0461    |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.0459    |
|    value_loss           | 0.11       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.2        |
|    ep_rew_mean          | 2.35        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 159         |
|    time_elapsed         | 5315        |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.091102764 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.629      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0399     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0339     |
|    value_loss           | 0.124       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 3.7        |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 160        |
|    time_elapsed         | 5326       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.09241563 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.771     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0625    |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.133      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.1       |
|    ep_rew_mean          | 2.17       |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 161        |
|    time_elapsed         | 5337       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.10836387 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.553     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00314   |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.042     |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
Eval num_timesteps=330000, episode_reward=-6.52 +/- 16.66
Episode length: 59.00 +/- 64.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -6.52      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.09274587 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.793     |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0714    |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0351    |
|    value_loss           | 0.167      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 3.73     |
| time/              |          |
|    fps             | 62       |
|    iterations      | 162      |
|    time_elapsed    | 5348     |
|    total_timesteps | 331776   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 3.09       |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 163        |
|    time_elapsed         | 5359       |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.09535612 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.561     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0581     |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0431    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 3.53       |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 164        |
|    time_elapsed         | 5371       |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.13113213 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.723     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0452    |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.0485    |
|    value_loss           | 0.113      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 3.56       |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 165        |
|    time_elapsed         | 5381       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.08108965 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.665     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | -0.04      |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.211      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.7      |
|    ep_rew_mean          | 3.93      |
| time/                   |           |
|    fps                  | 63        |
|    iterations           | 166       |
|    time_elapsed         | 5392      |
|    total_timesteps      | 339968    |
| train/                  |           |
|    approx_kl            | 0.0993862 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.564    |
|    explained_variance   | 0.934     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0512   |
|    n_updates            | 1650      |
|    policy_gradient_loss | -0.0413   |
|    value_loss           | 0.0862    |
---------------------------------------
reached max steps=300
Eval num_timesteps=340000, episode_reward=-5.39 +/- 17.48
Episode length: 60.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | -5.39      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.07723081 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.571     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0689    |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.139      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 3.91     |
| time/              |          |
|    fps             | 63       |
|    iterations      | 167      |
|    time_elapsed    | 5402     |
|    total_timesteps | 342016   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 3.81       |
| time/                   |            |
|    fps                  | 63         |
|    iterations           | 168        |
|    time_elapsed         | 5412       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.10363123 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.656     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0467    |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.00273    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 3.16       |
| time/                   |            |
|    fps                  | 63         |
|    iterations           | 169        |
|    time_elapsed         | 5423       |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.07856907 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.57      |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0474    |
|    n_updates            | 1680       |
|    policy_gradient_loss | -0.0355    |
|    value_loss           | 0.132      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 3.77       |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 170        |
|    time_elapsed         | 5433       |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.07451779 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.562     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | 0.632      |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0372    |
|    value_loss           | 0.181      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=350000, episode_reward=-5.19 +/- 14.73
Episode length: 59.00 +/- 64.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 59         |
|    mean_reward          | -5.19      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.06970554 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.52      |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0777    |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.126      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 3.43     |
| time/              |          |
|    fps             | 64       |
|    iterations      | 171      |
|    time_elapsed    | 5443     |
|    total_timesteps | 350208   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 2.91       |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 172        |
|    time_elapsed         | 5454       |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.07046595 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.572     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00177   |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0331    |
|    value_loss           | 0.169      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 3.95       |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 173        |
|    time_elapsed         | 5464       |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.09188762 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.608     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0438    |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.121      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.6      |
|    ep_rew_mean          | 3.69      |
| time/                   |           |
|    fps                  | 65        |
|    iterations           | 174       |
|    time_elapsed         | 5474      |
|    total_timesteps      | 356352    |
| train/                  |           |
|    approx_kl            | 0.0894945 |
|    clip_fraction        | 0.277     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.541    |
|    explained_variance   | 0.909     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0206   |
|    n_updates            | 1730      |
|    policy_gradient_loss | -0.0397   |
|    value_loss           | 0.161     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 2.05       |
| time/                   |            |
|    fps                  | 65         |
|    iterations           | 175        |
|    time_elapsed         | 5484       |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.10817556 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.592     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0118    |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.108      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=360000, episode_reward=-14.70 +/- 15.33
Episode length: 105.00 +/- 63.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 105        |
|    mean_reward          | -14.7      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.07995491 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.656     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0253     |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0292    |
|    value_loss           | 0.141      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 3.87     |
| time/              |          |
|    fps             | 65       |
|    iterations      | 176      |
|    time_elapsed    | 5495     |
|    total_timesteps | 360448   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 3.14       |
| time/                   |            |
|    fps                  | 65         |
|    iterations           | 177        |
|    time_elapsed         | 5505       |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.09505083 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.489     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.079     |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0381    |
|    value_loss           | 0.0959     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 3.98       |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 178        |
|    time_elapsed         | 5515       |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.08755873 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.525     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0665    |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0405    |
|    value_loss           | 0.373      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 3.77       |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 179        |
|    time_elapsed         | 5525       |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.11715385 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.504     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0876    |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.0416    |
|    value_loss           | 0.171      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.6        |
|    ep_rew_mean          | 2.25        |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 180         |
|    time_elapsed         | 5536        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.104434535 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.598      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.001       |
|    loss                 | -0.037      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0393     |
|    value_loss           | 0.126       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=370000, episode_reward=-5.58 +/- 15.19
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -5.58      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.11155829 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.668     |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0461    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0391    |
|    value_loss           | 0.414      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.3     |
|    ep_rew_mean     | 2.71     |
| time/              |          |
|    fps             | 66       |
|    iterations      | 181      |
|    time_elapsed    | 5546     |
|    total_timesteps | 370688   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 3.53       |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 182        |
|    time_elapsed         | 5557       |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.11197314 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.647     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0943    |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0384    |
|    value_loss           | 0.14       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.1        |
|    ep_rew_mean          | 2.43        |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 183         |
|    time_elapsed         | 5567        |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.109366596 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.585      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0822     |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0411     |
|    value_loss           | 0.101       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 3.43       |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 184        |
|    time_elapsed         | 5577       |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.07726391 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.792     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0423    |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0246    |
|    value_loss           | 0.106      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 185        |
|    time_elapsed         | 5588       |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.07828947 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.623     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00604    |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=380000, episode_reward=3.67 +/- 0.10
Episode length: 11.33 +/- 0.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.3       |
|    mean_reward          | 3.67       |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.10570883 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.646     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00609   |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.161      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.3     |
|    ep_rew_mean     | 2.6      |
| time/              |          |
|    fps             | 68       |
|    iterations      | 186      |
|    time_elapsed    | 5598     |
|    total_timesteps | 380928   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.6       |
|    ep_rew_mean          | 3.05       |
| time/                   |            |
|    fps                  | 68         |
|    iterations           | 187        |
|    time_elapsed         | 5608       |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.07562251 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.743     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0667     |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0328    |
|    value_loss           | 0.125      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 4.3        |
| time/                   |            |
|    fps                  | 68         |
|    iterations           | 188        |
|    time_elapsed         | 5618       |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.07488698 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.699     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0691     |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.0402    |
|    value_loss           | 0.141      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.5        |
|    ep_rew_mean          | 3.5         |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 189         |
|    time_elapsed         | 5629        |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.109186195 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00553    |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.168       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 3.56        |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 190         |
|    time_elapsed         | 5640        |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.106418476 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.605      |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0614      |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.14        |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=390000, episode_reward=-5.45 +/- 15.25
Episode length: 58.67 +/- 64.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.7       |
|    mean_reward          | -5.45      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.09597214 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.6       |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0539    |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.0967     |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 2.43     |
| time/              |          |
|    fps             | 69       |
|    iterations      | 191      |
|    time_elapsed    | 5652     |
|    total_timesteps | 391168   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 2.79       |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 192        |
|    time_elapsed         | 5664       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.10037266 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.684     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0217    |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.0404    |
|    value_loss           | 0.35       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 3.59       |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 193        |
|    time_elapsed         | 5676       |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.10620685 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.614     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0204     |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.198      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 24.6     |
|    ep_rew_mean          | 3.28     |
| time/                   |          |
|    fps                  | 69       |
|    iterations           | 194      |
|    time_elapsed         | 5687     |
|    total_timesteps      | 397312   |
| train/                  |          |
|    approx_kl            | 0.104139 |
|    clip_fraction        | 0.275    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.58    |
|    explained_variance   | 0.908    |
|    learning_rate        | 0.001    |
|    loss                 | 0.0194   |
|    n_updates            | 1930     |
|    policy_gradient_loss | -0.0352  |
|    value_loss           | 0.14     |
--------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 3.97       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 195        |
|    time_elapsed         | 5698       |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.09212114 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.638     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0287    |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
Eval num_timesteps=400000, episode_reward=6.78 +/- 0.18
Episode length: 14.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14         |
|    mean_reward          | 6.78       |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.10098244 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.599     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0224    |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.135      |
----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 3.73     |
| time/              |          |
|    fps             | 70       |
|    iterations      | 196      |
|    time_elapsed    | 5710     |
|    total_timesteps | 401408   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.9      |
|    ep_rew_mean          | 3.5       |
| time/                   |           |
|    fps                  | 70        |
|    iterations           | 197       |
|    time_elapsed         | 5721      |
|    total_timesteps      | 403456    |
| train/                  |           |
|    approx_kl            | 0.1198137 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.57     |
|    explained_variance   | 0.843     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0314   |
|    n_updates            | 1960      |
|    policy_gradient_loss | -0.0394   |
|    value_loss           | 0.18      |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 4.28       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 198        |
|    time_elapsed         | 5732       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.10255826 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0466    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.179      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 3.52       |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 199        |
|    time_elapsed         | 5743       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.11149353 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.504     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0617    |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.138      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 3.09       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 200        |
|    time_elapsed         | 5755       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.12004333 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.602     |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.001      |
|    loss                 | 0.144      |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.784      |
----------------------------------------
reached max steps=300
Eval num_timesteps=410000, episode_reward=-7.05 +/- 15.52
Episode length: 58.33 +/- 64.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 58.3       |
|    mean_reward          | -7.05      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.15937804 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0335    |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0599    |
|    value_loss           | 0.207      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 3.92     |
| time/              |          |
|    fps             | 71       |
|    iterations      | 201      |
|    time_elapsed    | 5766     |
|    total_timesteps | 411648   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 3.79       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 202        |
|    time_elapsed         | 5777       |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.15913162 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.494     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.001      |
|    loss                 | 0.166      |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.0484    |
|    value_loss           | 0.317      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 3.19       |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 203        |
|    time_elapsed         | 5787       |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.12005368 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0706    |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.0232    |
|    value_loss           | 0.162      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.8       |
|    ep_rew_mean          | 2.36       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 204        |
|    time_elapsed         | 5798       |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.11627692 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.656     |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00533    |
|    n_updates            | 2030       |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.312      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 3.2        |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 205        |
|    time_elapsed         | 5808       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.13546535 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.001      |
|    loss                 | 0.029      |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0465    |
|    value_loss           | 0.374      |
----------------------------------------
Eval num_timesteps=420000, episode_reward=5.70 +/- 1.80
Episode length: 16.00 +/- 3.56
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 16       |
|    mean_reward          | 5.7      |
| time/                   |          |
|    total_timesteps      | 420000   |
| train/                  |          |
|    approx_kl            | 0.300547 |
|    clip_fraction        | 0.383    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.623   |
|    explained_variance   | 0.854    |
|    learning_rate        | 0.001    |
|    loss                 | 0.0912   |
|    n_updates            | 2050     |
|    policy_gradient_loss | 0.168    |
|    value_loss           | 0.218    |
--------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 2.87     |
| time/              |          |
|    fps             | 72       |
|    iterations      | 206      |
|    time_elapsed    | 5819     |
|    total_timesteps | 421888   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 3.62       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 207        |
|    time_elapsed         | 5829       |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.14101416 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.752     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00814   |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.211      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.5       |
|    ep_rew_mean          | 2.57       |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 208        |
|    time_elapsed         | 5839       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.11011184 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.619     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0155    |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0424    |
|    value_loss           | 0.133      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 2.82       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 209        |
|    time_elapsed         | 5850       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.14635736 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.713     |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0646    |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=430000, episode_reward=-5.74 +/- 15.07
Episode length: 61.67 +/- 62.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 61.7        |
|    mean_reward          | -5.74       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.107673645 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.731      |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0516     |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0389     |
|    value_loss           | 0.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 2.49     |
| time/              |          |
|    fps             | 73       |
|    iterations      | 210      |
|    time_elapsed    | 5861     |
|    total_timesteps | 430080   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.1       |
|    ep_rew_mean          | 2.64       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 211        |
|    time_elapsed         | 5871       |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.13008472 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.705     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0956    |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.2       |
|    ep_rew_mean          | 2.36       |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 212        |
|    time_elapsed         | 5881       |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.12683064 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.665     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | 0.103      |
|    n_updates            | 2110       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26          |
|    ep_rew_mean          | 3.3         |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 213         |
|    time_elapsed         | 5893        |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.122071005 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0553     |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0243     |
|    value_loss           | 0.141       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 2.33       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 214        |
|    time_elapsed         | 5903       |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.11048266 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.56      |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0919    |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0438    |
|    value_loss           | 0.11       |
----------------------------------------
reached max steps=300
Eval num_timesteps=440000, episode_reward=5.66 +/- 0.80
Episode length: 13.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 5.66       |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.09725945 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00727   |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0429    |
|    value_loss           | 0.148      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 3.96     |
| time/              |          |
|    fps             | 74       |
|    iterations      | 215      |
|    time_elapsed    | 5914     |
|    total_timesteps | 440320   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 4.19       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 216        |
|    time_elapsed         | 5924       |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.08323482 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.021     |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0277    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 3.22       |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 217        |
|    time_elapsed         | 5934       |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.08206868 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.495     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | 0.02       |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 3.52       |
| time/                   |            |
|    fps                  | 75         |
|    iterations           | 218        |
|    time_elapsed         | 5945       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.09269862 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.634     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0828    |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.116      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 4.23        |
| time/                   |             |
|    fps                  | 75          |
|    iterations           | 219         |
|    time_elapsed         | 5955        |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.106921166 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0802     |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0363     |
|    value_loss           | 0.146       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=450000, episode_reward=-7.58 +/- 15.85
Episode length: 57.67 +/- 65.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.7       |
|    mean_reward          | -7.58      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.11702365 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00746   |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0414    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 3.6      |
| time/              |          |
|    fps             | 75       |
|    iterations      | 220      |
|    time_elapsed    | 5966     |
|    total_timesteps | 450560   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.5       |
|    ep_rew_mean          | 2.44       |
| time/                   |            |
|    fps                  | 75         |
|    iterations           | 221        |
|    time_elapsed         | 5976       |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.08266197 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.718     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0813    |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0401    |
|    value_loss           | 0.116      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 3.37       |
| time/                   |            |
|    fps                  | 75         |
|    iterations           | 222        |
|    time_elapsed         | 5986       |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.10483191 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.753     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | -0.073     |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.118      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 3.67       |
| time/                   |            |
|    fps                  | 76         |
|    iterations           | 223        |
|    time_elapsed         | 5997       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.10827135 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.523     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0136    |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0277    |
|    value_loss           | 0.145      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.9       |
|    ep_rew_mean          | 2.45       |
| time/                   |            |
|    fps                  | 76         |
|    iterations           | 224        |
|    time_elapsed         | 6007       |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.10485159 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.524     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.018     |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0259    |
|    value_loss           | 0.172      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=460000, episode_reward=-14.42 +/- 12.84
Episode length: 103.67 +/- 65.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 104        |
|    mean_reward          | -14.4      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.24039447 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.763     |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.001      |
|    loss                 | -0.064     |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.182      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 4.33     |
| time/              |          |
|    fps             | 76       |
|    iterations      | 225      |
|    time_elapsed    | 6018     |
|    total_timesteps | 460800   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 3.91       |
| time/                   |            |
|    fps                  | 76         |
|    iterations           | 226        |
|    time_elapsed         | 6029       |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.12316107 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.484     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00286    |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.0398    |
|    value_loss           | 0.194      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 4.74        |
| time/                   |             |
|    fps                  | 76          |
|    iterations           | 227         |
|    time_elapsed         | 6039        |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.099061266 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.653      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00703    |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0355     |
|    value_loss           | 0.17        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.7      |
|    ep_rew_mean          | 4.15      |
| time/                   |           |
|    fps                  | 77        |
|    iterations           | 228       |
|    time_elapsed         | 6049      |
|    total_timesteps      | 466944    |
| train/                  |           |
|    approx_kl            | 0.1015691 |
|    clip_fraction        | 0.276     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.495    |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0283   |
|    n_updates            | 2270      |
|    policy_gradient_loss | -0.0357   |
|    value_loss           | 0.164     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 3.79       |
| time/                   |            |
|    fps                  | 77         |
|    iterations           | 229        |
|    time_elapsed         | 6059       |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.09854031 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.556     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0177     |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.196      |
----------------------------------------
reached max steps=300
Eval num_timesteps=470000, episode_reward=-6.74 +/- 16.48
Episode length: 61.67 +/- 62.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 61.7       |
|    mean_reward          | -6.74      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.14580092 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.563     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0815    |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0463    |
|    value_loss           | 0.117      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 3.58     |
| time/              |          |
|    fps             | 77       |
|    iterations      | 230      |
|    time_elapsed    | 6069     |
|    total_timesteps | 471040   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 3.46       |
| time/                   |            |
|    fps                  | 77         |
|    iterations           | 231        |
|    time_elapsed         | 6079       |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.13364795 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.548     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.001      |
|    loss                 | 0.00378    |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.141      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.6       |
|    ep_rew_mean          | 2.78       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 232        |
|    time_elapsed         | 6089       |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.09977784 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.697     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0393    |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.109      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 3.69       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 233        |
|    time_elapsed         | 6100       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.08773666 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.001      |
|    loss                 | 0.326      |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.81       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 3.69       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 234        |
|    time_elapsed         | 6110       |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.13289285 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.639     |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.001      |
|    loss                 | 0.363      |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0476    |
|    value_loss           | 0.56       |
----------------------------------------
reached max steps=300
Eval num_timesteps=480000, episode_reward=5.32 +/- 1.42
Episode length: 13.00 +/- 0.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13         |
|    mean_reward          | 5.32       |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.15417887 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0537    |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.046     |
|    value_loss           | 0.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 3.5      |
| time/              |          |
|    fps             | 78       |
|    iterations      | 235      |
|    time_elapsed    | 6121     |
|    total_timesteps | 481280   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 3.45       |
| time/                   |            |
|    fps                  | 78         |
|    iterations           | 236        |
|    time_elapsed         | 6132       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.11458667 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.732     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0384     |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.0414    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 3.87        |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 237         |
|    time_elapsed         | 6141        |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.091962084 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.661      |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0556     |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.039      |
|    value_loss           | 0.16        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 3.49       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 238        |
|    time_elapsed         | 6151       |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.15168333 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.552     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0432    |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 3.85        |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 239         |
|    time_elapsed         | 6161        |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.095939286 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.601      |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00576     |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0285     |
|    value_loss           | 0.21        |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=4.52 +/- 0.80
Episode length: 13.67 +/- 2.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.7       |
|    mean_reward          | 4.52       |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.10873254 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.558     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0753     |
|    n_updates            | 2390       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.154      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 4.23     |
| time/              |          |
|    fps             | 79       |
|    iterations      | 240      |
|    time_elapsed    | 6171     |
|    total_timesteps | 491520   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 4.21       |
| time/                   |            |
|    fps                  | 79         |
|    iterations           | 241        |
|    time_elapsed         | 6181       |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.10647753 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.001      |
|    loss                 | -0.00491   |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.171      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 3.77       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 242        |
|    time_elapsed         | 6191       |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.13333891 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.414     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0574    |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.109      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 3.99        |
| time/                   |             |
|    fps                  | 80          |
|    iterations           | 243         |
|    time_elapsed         | 6201        |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.086238235 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0115     |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0275     |
|    value_loss           | 0.121       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.9       |
|    ep_rew_mean          | 2.53       |
| time/                   |            |
|    fps                  | 80         |
|    iterations           | 244        |
|    time_elapsed         | 6211       |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.08671625 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.597     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0666    |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0284    |
|    value_loss           | 0.369      |
----------------------------------------
reached max steps=300
Eval num_timesteps=500000, episode_reward=-5.51 +/- 13.07
Episode length: 57.33 +/- 65.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 57.3        |
|    mean_reward          | -5.51       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.118278414 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.001       |
|    loss                 | 0.034       |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.477       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 4.66     |
| time/              |          |
|    fps             | 80       |
|    iterations      | 245      |
|    time_elapsed    | 6222     |
|    total_timesteps | 501760   |
---------------------------------
