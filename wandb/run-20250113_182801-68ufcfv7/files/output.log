Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x00000218659F7400> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000021866D91360>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -33.6    |
| time/              |          |
|    fps             | 133      |
|    iterations      | 1        |
|    time_elapsed    | 15       |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -32.8       |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.013454217 |
|    clip_fraction        | 0.0868      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00488    |
|    learning_rate        | 0.001       |
|    loss                 | -0.0175     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.395       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -31.6       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.014492661 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | -0.11       |
|    learning_rate        | 0.001       |
|    loss                 | 0.14        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.017      |
|    value_loss           | 0.232       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -31         |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 4           |
|    time_elapsed         | 49          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.012416583 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | -0.0826     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0579     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.221       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.02 +/- 0.04
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.014924878 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.365      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0343     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0187     |
|    value_loss           | 0.114       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -30.6    |
| time/              |          |
|    fps             | 158      |
|    iterations      | 5        |
|    time_elapsed    | 64       |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 150        |
|    ep_rew_mean          | -30.3      |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 6          |
|    time_elapsed         | 76         |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.02276314 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.88      |
|    explained_variance   | -0.621     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0818    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.0725     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30.2       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 7           |
|    time_elapsed         | 88          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.023601534 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -0.428      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0114     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.114       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30.1       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 8           |
|    time_elapsed         | 100         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.025147066 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -1.63       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0993     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0291     |
|    value_loss           | 0.0514      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -29.4       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 9           |
|    time_elapsed         | 113         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.029364098 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.0941     |
|    learning_rate        | 0.001       |
|    loss                 | -0.098      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.023      |
|    value_loss           | 0.116       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.026842492 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -1.95       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0863     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.0293      |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -29.4    |
| time/              |          |
|    fps             | 161      |
|    iterations      | 10       |
|    time_elapsed    | 126      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -30         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 11          |
|    time_elapsed         | 138         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.029607635 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | -0.0663     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0957     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0277     |
|    value_loss           | 0.129       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 150        |
|    ep_rew_mean          | -30.2      |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 12         |
|    time_elapsed         | 149        |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.03321038 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.84      |
|    explained_variance   | -0.342     |
|    learning_rate        | 0.001      |
|    loss                 | 0.331      |
|    n_updates            | 110        |
|    policy_gradient_loss | -0.0304    |
|    value_loss           | 0.279      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 150        |
|    ep_rew_mean          | -30.4      |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 13         |
|    time_elapsed         | 161        |
|    total_timesteps      | 26624      |
| train/                  |            |
|    approx_kl            | 0.03805674 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | -1.03      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0194     |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.0368    |
|    value_loss           | 0.0878     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 149        |
|    ep_rew_mean          | -30        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 14         |
|    time_elapsed         | 173        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03042673 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | -0.152     |
|    learning_rate        | 0.001      |
|    loss                 | 0.105      |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.263      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 30000      |
| train/                  |            |
|    approx_kl            | 0.03775724 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | -0.683     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0128     |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.0347    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -29.8    |
| time/              |          |
|    fps             | 163      |
|    iterations      | 15       |
|    time_elapsed    | 187      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 16          |
|    time_elapsed         | 198         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.043417357 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.517      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0677     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0304     |
|    value_loss           | 0.189       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 17          |
|    time_elapsed         | 210         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.032569077 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | -0.198      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0385     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.025      |
|    value_loss           | 0.269       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 145        |
|    ep_rew_mean          | -28.5      |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 18         |
|    time_elapsed         | 221        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.04158207 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.76      |
|    explained_variance   | -0.706     |
|    learning_rate        | 0.001      |
|    loss                 | -0.123     |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0361    |
|    value_loss           | 0.126      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -28.7       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 19          |
|    time_elapsed         | 233         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.035024628 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | -0.191      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0348      |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0291     |
|    value_loss           | 0.357       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-30.04 +/- 0.08
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.04728251 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.7       |
|    explained_variance   | -0.691     |
|    learning_rate        | 0.001      |
|    loss                 | 0.102      |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -27.9    |
| time/              |          |
|    fps             | 166      |
|    iterations      | 20       |
|    time_elapsed    | 246      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 143        |
|    ep_rew_mean          | -28.4      |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 21         |
|    time_elapsed         | 258        |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.04478905 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.73      |
|    explained_variance   | -0.32      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0731    |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0251    |
|    value_loss           | 0.201      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | -28.4       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 22          |
|    time_elapsed         | 270         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.039315857 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | -0.248      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0878     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0315     |
|    value_loss           | 0.236       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 143        |
|    ep_rew_mean          | -28.2      |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 23         |
|    time_elapsed         | 282        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.03929241 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.74      |
|    explained_variance   | -0.387     |
|    learning_rate        | 0.001      |
|    loss                 | -0.011     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0278    |
|    value_loss           | 0.189      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 144        |
|    ep_rew_mean          | -28.3      |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 24         |
|    time_elapsed         | 294        |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.04372756 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.75      |
|    explained_variance   | -0.0763    |
|    learning_rate        | 0.001      |
|    loss                 | -0.11      |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.122      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.04095619 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.73      |
|    explained_variance   | -0.254     |
|    learning_rate        | 0.001      |
|    loss                 | 0.161      |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0153    |
|    value_loss           | 0.212      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -28.1    |
| time/              |          |
|    fps             | 166      |
|    iterations      | 25       |
|    time_elapsed    | 307      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 145        |
|    ep_rew_mean          | -27.6      |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 26         |
|    time_elapsed         | 318        |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.04858287 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.72      |
|    explained_variance   | -0.141     |
|    learning_rate        | 0.001      |
|    loss                 | 0.0536     |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.0253    |
|    value_loss           | 0.201      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 146       |
|    ep_rew_mean          | -27.9     |
| time/                   |           |
|    fps                  | 167       |
|    iterations           | 27        |
|    time_elapsed         | 329       |
|    total_timesteps      | 55296     |
| train/                  |           |
|    approx_kl            | 0.0445593 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.7      |
|    explained_variance   | -0.109    |
|    learning_rate        | 0.001     |
|    loss                 | -0.0515   |
|    n_updates            | 260       |
|    policy_gradient_loss | -0.0358   |
|    value_loss           | 0.157     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -27.3       |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 28          |
|    time_elapsed         | 340         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.034391537 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | -0.326      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0832     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0213     |
|    value_loss           | 0.111       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -26.6       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 29          |
|    time_elapsed         | 350         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.034291174 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | -0.282      |
|    learning_rate        | 0.001       |
|    loss                 | 0.0381      |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.03       |
|    value_loss           | 0.354       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.04134547 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.69      |
|    explained_variance   | 0.0433     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0228    |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.265      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -26.8    |
| time/              |          |
|    fps             | 169      |
|    iterations      | 30       |
|    time_elapsed    | 363      |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | -25.6       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 31          |
|    time_elapsed         | 373         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.045824565 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | -0.638      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0563     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0417     |
|    value_loss           | 0.21        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | -26.2       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 32          |
|    time_elapsed         | 383         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.047150973 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | 0.0874      |
|    learning_rate        | 0.001       |
|    loss                 | 0.128       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.339       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | -26.3       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 33          |
|    time_elapsed         | 394         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.052730575 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.66       |
|    explained_variance   | -1.32       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00291     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.148       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 138        |
|    ep_rew_mean          | -25.3      |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 34         |
|    time_elapsed         | 405        |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.04609142 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.63      |
|    explained_variance   | 0.0762     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0864    |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0286    |
|    value_loss           | 0.17       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.045935653 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | -0.0938     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0545     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0302     |
|    value_loss           | 0.241       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | -25.6    |
| time/              |          |
|    fps             | 171      |
|    iterations      | 35       |
|    time_elapsed    | 417      |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 139         |
|    ep_rew_mean          | -25.3       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 36          |
|    time_elapsed         | 427         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.057442386 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | -0.143      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0863     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 0.152       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 136         |
|    ep_rew_mean          | -24.6       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 37          |
|    time_elapsed         | 438         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.055916138 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.114       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0282     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0321     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 137        |
|    ep_rew_mean          | -24.7      |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 38         |
|    time_elapsed         | 448        |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.04753644 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.63      |
|    explained_variance   | 0.0318     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0676    |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.0293    |
|    value_loss           | 0.152      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 132         |
|    ep_rew_mean          | -22.5       |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 39          |
|    time_elapsed         | 458         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.050138228 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0141     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0308     |
|    value_loss           | 0.173       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=80000, episode_reward=-30.04 +/- 0.08
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.05489973 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.27       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0313     |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0392    |
|    value_loss           | 0.267      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | -21.7    |
| time/              |          |
|    fps             | 174      |
|    iterations      | 40       |
|    time_elapsed    | 470      |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | -19.2       |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 41          |
|    time_elapsed         | 480         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.053317208 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.001       |
|    loss                 | 0.21        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.277       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 107         |
|    ep_rew_mean          | -16.6       |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 42          |
|    time_elapsed         | 491         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.064665124 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0371     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.209       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 99.5        |
|    ep_rew_mean          | -15.2       |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 43          |
|    time_elapsed         | 501         |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.049372084 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0332     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0328     |
|    value_loss           | 0.231       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-29.22 +/- 1.61
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -29.2      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.05738393 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.52      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0872    |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.162      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 89.3     |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    fps             | 175      |
|    iterations      | 44       |
|    time_elapsed    | 513      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.9        |
|    ep_rew_mean          | -12.1       |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 45          |
|    time_elapsed         | 524         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.054337487 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0505     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0374     |
|    value_loss           | 0.189       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 86.7       |
|    ep_rew_mean          | -12.9      |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 46         |
|    time_elapsed         | 534        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.05135014 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.5       |
|    explained_variance   | 0.529      |
|    learning_rate        | 0.001      |
|    loss                 | 0.17       |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.0281    |
|    value_loss           | 0.298      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.9        |
|    ep_rew_mean          | -14.3       |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 47          |
|    time_elapsed         | 544         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.049396984 |
|    clip_fraction        | 0.461       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0137     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0361     |
|    value_loss           | 0.131       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 91.6       |
|    ep_rew_mean          | -14        |
| time/                   |            |
|    fps                  | 177        |
|    iterations           | 48         |
|    time_elapsed         | 554        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.04593511 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0561    |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.123      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-23.34 +/- 13.33
Episode length: 122.60 +/- 54.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 123         |
|    mean_reward          | -23.3       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.041631296 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.661       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0183     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.22        |
-----------------------------------------
New best mean reward!
Traceback (most recent call last):
  File "C:\Users\matan\master_thesis\minigrid_custom\minigrid_custom_train.py", line 359, in <module>
    main()
  File "C:\Users\matan\master_thesis\minigrid_custom\minigrid_custom_train.py", line 311, in main
    model.learn(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\ppo\ppo.py", line 311, in learn
    return super().learn(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 323, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 224, in collect_rollouts
    if not callback.on_step():
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py", line 114, in on_step
    return self._on_step()
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py", line 223, in _on_step
    continue_training = callback.on_step() and continue_training
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py", line 114, in on_step
    return self._on_step()
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\integration\sb3\sb3.py", line 136, in _on_step
    self.save_model()
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\integration\sb3\sb3.py", line 145, in save_model
    wandb.save(self.path, base_path=self.model_save_path)
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\sdk\wandb_run.py", line 392, in wrapper_fn
    return func(self, *args, **kwargs)
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\sdk\wandb_run.py", line 382, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\sdk\wandb_run.py", line 1963, in save
    return self._save(
  File "C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\wandb\sdk\wandb_run.py", line 2022, in _save
    target_path.symlink_to(source_path)
  File "C:\Users\matan\anaconda3\envs\master_env\lib\pathlib.py", line 1255, in symlink_to
    self._accessor.symlink(target, self, target_is_directory)
OSError: [WinError 1314] A required privilege is not held by the client: 'C:\\Users\\matan\\master_thesis\\minigrid_custom\\models\\wandb_models\\-0.1,4,-0.1,-4,0.2\\model.zip' -> 'C:\\Users\\matan\\master_thesis\\minigrid_custom\\wandb\\run-20250113_182801-68ufcfv7\\files\\model.zip'
