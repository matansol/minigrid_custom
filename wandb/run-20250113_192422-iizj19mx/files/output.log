Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000002188DA515A0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000002188DA51330>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -32.4    |
| time/              |          |
|    fps             | 248      |
|    iterations      | 1        |
|    time_elapsed    | 8        |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 146          |
|    ep_rew_mean          | -31.4        |
| time/                   |              |
|    fps                  | 208          |
|    iterations           | 2            |
|    time_elapsed         | 19           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0060654487 |
|    clip_fraction        | 0.0362       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | -0.00586     |
|    learning_rate        | 0.001        |
|    loss                 | 0.276        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00475     |
|    value_loss           | 0.284        |
------------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -31.3       |
| time/                   |             |
|    fps                  | 200         |
|    iterations           | 3           |
|    time_elapsed         | 30          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012863409 |
|    clip_fraction        | 0.0747      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.00742     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0417     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.262       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -31         |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 4           |
|    time_elapsed         | 44          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.013491378 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | -0.0749     |
|    learning_rate        | 0.001       |
|    loss                 | -0.0257     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.281       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.017790075 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | -0.143      |
|    learning_rate        | 0.001       |
|    loss                 | 0.145       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 0.2         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -30.8    |
| time/              |          |
|    fps             | 163      |
|    iterations      | 5        |
|    time_elapsed    | 62       |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -30.7       |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 6           |
|    time_elapsed         | 77          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.023904812 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.105      |
|    learning_rate        | 0.001       |
|    loss                 | 0.00218     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0249     |
|    value_loss           | 0.164       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -30.1       |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 7           |
|    time_elapsed         | 91          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.022048958 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.772      |
|    learning_rate        | 0.001       |
|    loss                 | 0.211       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.122       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -28.8       |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 8           |
|    time_elapsed         | 104         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.025606444 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.1         |
|    learning_rate        | 0.001       |
|    loss                 | -0.034      |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0219     |
|    value_loss           | 0.0981      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 140        |
|    ep_rew_mean          | -27.3      |
| time/                   |            |
|    fps                  | 150        |
|    iterations           | 9          |
|    time_elapsed         | 122        |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.02176902 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.83      |
|    explained_variance   | 0.0755     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0371    |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.0191    |
|    value_loss           | 0.203      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-23.34 +/- 13.33
Episode length: 122.60 +/- 54.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 123         |
|    mean_reward          | -23.3       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.025921073 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.21        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0256     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0204     |
|    value_loss           | 0.157       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | -25.3    |
| time/              |          |
|    fps             | 144      |
|    iterations      | 10       |
|    time_elapsed    | 141      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 120        |
|    ep_rew_mean          | -21.8      |
| time/                   |            |
|    fps                  | 143        |
|    iterations           | 11         |
|    time_elapsed         | 157        |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.02489832 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.81      |
|    explained_variance   | 0.192      |
|    learning_rate        | 0.001      |
|    loss                 | 0.123      |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.357      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 101         |
|    ep_rew_mean          | -17.1       |
| time/                   |             |
|    fps                  | 143         |
|    iterations           | 12          |
|    time_elapsed         | 171         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.029321434 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0618     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0347     |
|    value_loss           | 0.214       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 95.8        |
|    ep_rew_mean          | -15.7       |
| time/                   |             |
|    fps                  | 145         |
|    iterations           | 13          |
|    time_elapsed         | 183         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.037995063 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.001       |
|    loss                 | 0.164       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0282     |
|    value_loss           | 0.367       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 85.9       |
|    ep_rew_mean          | -12.9      |
| time/                   |            |
|    fps                  | 146        |
|    iterations           | 14         |
|    time_elapsed         | 195        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.03440787 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.75      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.001      |
|    loss                 | -0.054     |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0256    |
|    value_loss           | 0.159      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-15.75 +/- 17.50
Episode length: 94.60 +/- 67.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 94.6        |
|    mean_reward          | -15.7       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.045291953 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0209      |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0287     |
|    value_loss           | 0.238       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.5     |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    fps             | 147      |
|    iterations      | 15       |
|    time_elapsed    | 208      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 77.8        |
|    ep_rew_mean          | -10.6       |
| time/                   |             |
|    fps                  | 149         |
|    iterations           | 16          |
|    time_elapsed         | 219         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.038920663 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.001       |
|    loss                 | 0.151       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0245     |
|    value_loss           | 0.185       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 69.5       |
|    ep_rew_mean          | -8.59      |
| time/                   |            |
|    fps                  | 150        |
|    iterations           | 17         |
|    time_elapsed         | 231        |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.04178979 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.59      |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0258     |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0223    |
|    value_loss           | 0.222      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.7       |
|    ep_rew_mean          | -4.91      |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 18         |
|    time_elapsed         | 243        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.05064988 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.54      |
|    explained_variance   | 0.437      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0115    |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0295    |
|    value_loss           | 0.33       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.2        |
|    ep_rew_mean          | -4.78       |
| time/                   |             |
|    fps                  | 152         |
|    iterations           | 19          |
|    time_elapsed         | 254         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.048607573 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.001       |
|    loss                 | 0.122       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0311     |
|    value_loss           | 0.314       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-23.31 +/- 13.37
Episode length: 122.40 +/- 55.20
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 122      |
|    mean_reward          | -23.3    |
| time/                   |          |
|    total_timesteps      | 40000    |
| train/                  |          |
|    approx_kl            | 0.041905 |
|    clip_fraction        | 0.331    |
|    clip_range           | 0.2      |
|    entropy_loss         | -1.47    |
|    explained_variance   | 0.533    |
|    learning_rate        | 0.001    |
|    loss                 | 0.0211   |
|    n_updates            | 190      |
|    policy_gradient_loss | -0.0201  |
|    value_loss           | 0.248    |
--------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.7     |
|    ep_rew_mean     | -3.22    |
| time/              |          |
|    fps             | 152      |
|    iterations      | 20       |
|    time_elapsed    | 268      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.5       |
|    ep_rew_mean          | -1.27      |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 21         |
|    time_elapsed         | 280        |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.04875441 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0471     |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0133    |
|    value_loss           | 0.325      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.7        |
|    ep_rew_mean          | -2.07       |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 22          |
|    time_elapsed         | 292         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.056820154 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.001       |
|    loss                 | 0.137       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0248     |
|    value_loss           | 0.333       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 49         |
|    ep_rew_mean          | -4.07      |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 23         |
|    time_elapsed         | 303        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.05726859 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00552    |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.00902   |
|    value_loss           | 0.234      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.2        |
|    ep_rew_mean          | -4.52       |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 24          |
|    time_elapsed         | 313         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.048833117 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0177     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0205     |
|    value_loss           | 0.21        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-23.25 +/- 13.49
Episode length: 122.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 122        |
|    mean_reward          | -23.3      |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.06151601 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0367    |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.024     |
|    value_loss           | 0.242      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 51.2     |
|    ep_rew_mean     | -4.1     |
| time/              |          |
|    fps             | 157      |
|    iterations      | 25       |
|    time_elapsed    | 326      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 49.9       |
|    ep_rew_mean          | -3.88      |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 26         |
|    time_elapsed         | 336        |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.06687564 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0111    |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.021     |
|    value_loss           | 0.269      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 58.2        |
|    ep_rew_mean          | -5.87       |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 27          |
|    time_elapsed         | 346         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.055685103 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0593     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0196     |
|    value_loss           | 0.136       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 59.7       |
|    ep_rew_mean          | -6.23      |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 28         |
|    time_elapsed         | 355        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.04953519 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.001      |
|    loss                 | 0.188      |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.015     |
|    value_loss           | 0.185      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.3        |
|    ep_rew_mean          | -5.48       |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 29          |
|    time_elapsed         | 366         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.050290756 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | -0.027      |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0211     |
|    value_loss           | 0.143       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-9.06 +/- 17.16
Episode length: 67.00 +/- 67.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67         |
|    mean_reward          | -9.06      |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.05055812 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0534    |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.0297    |
|    value_loss           | 0.144      |
----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.5     |
|    ep_rew_mean     | -2.82    |
| time/              |          |
|    fps             | 162      |
|    iterations      | 30       |
|    time_elapsed    | 379      |
|    total_timesteps | 61440    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.9       |
|    ep_rew_mean          | -2.94      |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 31         |
|    time_elapsed         | 391        |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.09002924 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.001      |
|    loss                 | 2.23       |
|    n_updates            | 300        |
|    policy_gradient_loss | 0.0999     |
|    value_loss           | 0.173      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.4       |
|    ep_rew_mean          | -3.75      |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 32         |
|    time_elapsed         | 402        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.06602375 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0321    |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0179    |
|    value_loss           | 0.158      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43.5       |
|    ep_rew_mean          | -3.01      |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 33         |
|    time_elapsed         | 411        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.05787185 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0448     |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.019     |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.5        |
|    ep_rew_mean          | -3.48       |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 34          |
|    time_elapsed         | 421         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.055219393 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0532     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.206       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-9.06 +/- 17.14
Episode length: 67.00 +/- 67.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67         |
|    mean_reward          | -9.06      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.05342425 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0227    |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0244    |
|    value_loss           | 0.104      |
----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50.8     |
|    ep_rew_mean     | -5.03    |
| time/              |          |
|    fps             | 165      |
|    iterations      | 35       |
|    time_elapsed    | 433      |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.2        |
|    ep_rew_mean          | -5.02       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 36          |
|    time_elapsed         | 443         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.051656324 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.001       |
|    loss                 | -0.041      |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0187     |
|    value_loss           | 0.184       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.1       |
|    ep_rew_mean          | -2.6       |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 37         |
|    time_elapsed         | 453        |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.06894641 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0453    |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0374    |
|    value_loss           | 0.227      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.7        |
|    ep_rew_mean          | -0.444      |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 38          |
|    time_elapsed         | 464         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.050219133 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.001       |
|    loss                 | 0.298       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0217     |
|    value_loss           | 0.357       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.6        |
|    ep_rew_mean          | -1.03       |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 39          |
|    time_elapsed         | 474         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.058482252 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0638     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0247     |
|    value_loss           | 0.198       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=80000, episode_reward=-23.25 +/- 13.49
Episode length: 122.20 +/- 55.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 122         |
|    mean_reward          | -23.3       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.052867442 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0569     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.124       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.7     |
|    ep_rew_mean     | 0.0687   |
| time/              |          |
|    fps             | 168      |
|    iterations      | 40       |
|    time_elapsed    | 485      |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.9        |
|    ep_rew_mean          | -0.341      |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 41          |
|    time_elapsed         | 496         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.053303026 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.99       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0313      |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0232     |
|    value_loss           | 0.231       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.5        |
|    ep_rew_mean          | -0.584      |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 42          |
|    time_elapsed         | 507         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.053796493 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0051      |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0309     |
|    value_loss           | 0.134       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.2       |
|    ep_rew_mean          | -0.468     |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 43         |
|    time_elapsed         | 518        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.05681876 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0263     |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.029     |
|    value_loss           | 0.223      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-2.27 +/- 11.86
Episode length: 39.00 +/- 55.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39          |
|    mean_reward          | -2.27       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.039900452 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.001       |
|    loss                 | 0.271       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0218     |
|    value_loss           | 0.262       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.5     |
|    ep_rew_mean     | -1.09    |
| time/              |          |
|    fps             | 170      |
|    iterations      | 44       |
|    time_elapsed    | 528      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.8       |
|    ep_rew_mean          | -1.57      |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 45         |
|    time_elapsed         | 538        |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.09967632 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.09      |
|    explained_variance   | 0.543      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0196    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.262      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.4       |
|    ep_rew_mean          | -1.61      |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 46         |
|    time_elapsed         | 548        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.06681541 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0351     |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.174      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.9       |
|    ep_rew_mean          | -0.24      |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 47         |
|    time_elapsed         | 559        |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.05106466 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | 0.208      |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.253      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.3        |
|    ep_rew_mean          | 0.102       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 48          |
|    time_elapsed         | 569         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.063905075 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0262     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0307     |
|    value_loss           | 0.402       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.4       |
|    mean_reward          | -16.5      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.06609458 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.001      |
|    loss                 | 0.179      |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0325    |
|    value_loss           | 0.549      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.8     |
|    ep_rew_mean     | -1.05    |
| time/              |          |
|    fps             | 172      |
|    iterations      | 49       |
|    time_elapsed    | 580      |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.5       |
|    ep_rew_mean          | -2.04      |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 50         |
|    time_elapsed         | 591        |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.06453706 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.001      |
|    loss                 | 0.116      |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0303    |
|    value_loss           | 0.257      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41.4        |
|    ep_rew_mean          | -2.15       |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 51          |
|    time_elapsed         | 602         |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.060756646 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0133     |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.242       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 42.2        |
|    ep_rew_mean          | -2.27       |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 52          |
|    time_elapsed         | 612         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.046883777 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0353     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0274     |
|    value_loss           | 0.17        |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | -1.38       |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 53          |
|    time_elapsed         | 623         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.038799312 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0394      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.212       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=110000, episode_reward=-23.27 +/- 13.50
Episode length: 122.20 +/- 55.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 122         |
|    mean_reward          | -23.3       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.055764142 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0153     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0332     |
|    value_loss           | 0.236       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.7     |
|    ep_rew_mean     | -1.24    |
| time/              |          |
|    fps             | 174      |
|    iterations      | 54       |
|    time_elapsed    | 634      |
|    total_timesteps | 110592   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | -1.27       |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 55          |
|    time_elapsed         | 644         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.057635702 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.13       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00597    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0248     |
|    value_loss           | 0.2         |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.7       |
|    ep_rew_mean          | -0.0701    |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 56         |
|    time_elapsed         | 654        |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.06379916 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.11      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00953    |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.215      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.4        |
|    ep_rew_mean          | 0.82        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 57          |
|    time_elapsed         | 665         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.065566294 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0626     |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0325     |
|    value_loss           | 0.196       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.4        |
|    ep_rew_mean          | 0.229       |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 58          |
|    time_elapsed         | 675         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.055561118 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.948      |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0591     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.036      |
|    value_loss           | 0.175       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.4       |
|    mean_reward          | -16.5      |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.06416784 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.03      |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0281    |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.0334    |
|    value_loss           | 0.223      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31       |
|    ep_rew_mean     | -0.175   |
| time/              |          |
|    fps             | 175      |
|    iterations      | 59       |
|    time_elapsed    | 687      |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.3       |
|    ep_rew_mean          | -0.72      |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 60         |
|    time_elapsed         | 697        |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.05351404 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.001      |
|    loss                 | -0.036     |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.036     |
|    value_loss           | 0.175      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.5       |
|    ep_rew_mean          | 0.345      |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 61         |
|    time_elapsed         | 706        |
|    total_timesteps      | 124928     |
| train/                  |            |
|    approx_kl            | 0.06340852 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0568     |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.0413    |
|    value_loss           | 0.209      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | -1.17       |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 62          |
|    time_elapsed         | 716         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.055593967 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.987      |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0498     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0446     |
|    value_loss           | 0.188       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 37.4      |
|    ep_rew_mean          | -1.27     |
| time/                   |           |
|    fps                  | 177       |
|    iterations           | 63        |
|    time_elapsed         | 726       |
|    total_timesteps      | 129024    |
| train/                  |           |
|    approx_kl            | 0.0556902 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.972    |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0215   |
|    n_updates            | 620       |
|    policy_gradient_loss | -0.0344   |
|    value_loss           | 0.266     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=130000, episode_reward=-22.51 +/- 13.06
Episode length: 122.40 +/- 55.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 122        |
|    mean_reward          | -22.5      |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.05499576 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0516    |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0222    |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.5     |
|    ep_rew_mean     | 0.382    |
| time/              |          |
|    fps             | 177      |
|    iterations      | 64       |
|    time_elapsed    | 738      |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 0.239      |
| time/                   |            |
|    fps                  | 177        |
|    iterations           | 65         |
|    time_elapsed         | 749        |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.04448663 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.919     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0114     |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.289      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 2.76        |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 66          |
|    time_elapsed         | 761         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.059295468 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.905      |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0605      |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0325     |
|    value_loss           | 0.224       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.7      |
|    ep_rew_mean          | 1.2       |
| time/                   |           |
|    fps                  | 177       |
|    iterations           | 67        |
|    time_elapsed         | 771       |
|    total_timesteps      | 137216    |
| train/                  |           |
|    approx_kl            | 0.0385162 |
|    clip_fraction        | 0.254     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.775    |
|    explained_variance   | 0.823     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0474   |
|    n_updates            | 660       |
|    policy_gradient_loss | -0.024    |
|    value_loss           | 0.298     |
---------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.6        |
|    ep_rew_mean          | 1.12        |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 68          |
|    time_elapsed         | 782         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.058979295 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.926      |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0206     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0417     |
|    value_loss           | 0.205       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=140000, episode_reward=-9.99 +/- 16.34
Episode length: 67.60 +/- 67.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 67.6        |
|    mean_reward          | -9.99       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.060879845 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.875      |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00911    |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 0.279       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.1     |
|    ep_rew_mean     | 0.449    |
| time/              |          |
|    fps             | 178      |
|    iterations      | 69       |
|    time_elapsed    | 793      |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.1       |
|    ep_rew_mean          | -0.139     |
| time/                   |            |
|    fps                  | 178        |
|    iterations           | 70         |
|    time_elapsed         | 804        |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.07239831 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.915     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0708     |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.235      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.2        |
|    ep_rew_mean          | 0.598       |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 71          |
|    time_elapsed         | 815         |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.061730947 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.001       |
|    loss                 | -0.116      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0363     |
|    value_loss           | 0.181       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 2.36        |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 72          |
|    time_elapsed         | 826         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.057550304 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.842      |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0118     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0333     |
|    value_loss           | 0.267       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 2.14        |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 73          |
|    time_elapsed         | 837         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.044943675 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.836      |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0112      |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0296     |
|    value_loss           | 0.323       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=150000, episode_reward=-8.30 +/- 17.77
Episode length: 67.20 +/- 67.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 67.2        |
|    mean_reward          | -8.3        |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.046294313 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.777      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0723      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0284     |
|    value_loss           | 0.233       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 1.18     |
| time/              |          |
|    fps             | 178      |
|    iterations      | 74       |
|    time_elapsed    | 848      |
|    total_timesteps | 151552   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 2.18       |
| time/                   |            |
|    fps                  | 178        |
|    iterations           | 75         |
|    time_elapsed         | 859        |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.07087144 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.91      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | 0.159      |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.0426    |
|    value_loss           | 0.26       |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 1.99        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 76          |
|    time_elapsed         | 869         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.063059136 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.718      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0474     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0373     |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 2.21        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 77          |
|    time_elapsed         | 879         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.047850408 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.805      |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0421     |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0303     |
|    value_loss           | 0.207       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 2.29       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 78         |
|    time_elapsed         | 889        |
|    total_timesteps      | 159744     |
| train/                  |            |
|    approx_kl            | 0.05003143 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.798     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.001      |
|    loss                 | 0.163      |
|    n_updates            | 770        |
|    policy_gradient_loss | -0.0306    |
|    value_loss           | 0.341      |
----------------------------------------
Eval num_timesteps=160000, episode_reward=5.83 +/- 3.10
Episode length: 12.20 +/- 0.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.2        |
|    mean_reward          | 5.83        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.060012102 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0142      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0364     |
|    value_loss           | 0.271       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 2.88     |
| time/              |          |
|    fps             | 179      |
|    iterations      | 79       |
|    time_elapsed    | 900      |
|    total_timesteps | 161792   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 2.38        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 80          |
|    time_elapsed         | 911         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.045845084 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.642      |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0627     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0284     |
|    value_loss           | 0.237       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 1.95       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 81         |
|    time_elapsed         | 921        |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.03542218 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.743     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.001      |
|    loss                 | 0.382      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.284      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 2.87       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 82         |
|    time_elapsed         | 932        |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.06529462 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.809     |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0529    |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0404    |
|    value_loss           | 0.295      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.4      |
|    ep_rew_mean          | 1.55      |
| time/                   |           |
|    fps                  | 180       |
|    iterations           | 83        |
|    time_elapsed         | 943       |
|    total_timesteps      | 169984    |
| train/                  |           |
|    approx_kl            | 0.0502294 |
|    clip_fraction        | 0.265     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.662    |
|    explained_variance   | 0.813     |
|    learning_rate        | 0.001     |
|    loss                 | 0.00645   |
|    n_updates            | 820       |
|    policy_gradient_loss | -0.0343   |
|    value_loss           | 0.307     |
---------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=170000, episode_reward=-8.24 +/- 17.82
Episode length: 67.00 +/- 67.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67         |
|    mean_reward          | -8.24      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.07365279 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.863     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0532    |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.0464    |
|    value_loss           | 0.227      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 2.49     |
| time/              |          |
|    fps             | 180      |
|    iterations      | 84       |
|    time_elapsed    | 954      |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 1.76        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 85          |
|    time_elapsed         | 965         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.045484543 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.766      |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0726      |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0295     |
|    value_loss           | 0.341       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 1.05       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 86         |
|    time_elapsed         | 976        |
|    total_timesteps      | 176128     |
| train/                  |            |
|    approx_kl            | 0.06890032 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.854     |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.001      |
|    loss                 | 0.14       |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.0395    |
|    value_loss           | 0.397      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.1       |
|    ep_rew_mean          | 0.822      |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 87         |
|    time_elapsed         | 988        |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.05475793 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.902     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0333     |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0349    |
|    value_loss           | 0.293      |
----------------------------------------
reached max steps=300
Eval num_timesteps=180000, episode_reward=-3.16 +/- 13.42
Episode length: 39.40 +/- 55.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.4       |
|    mean_reward          | -3.16      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.06061209 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.973     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0262     |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0357    |
|    value_loss           | 0.235      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 2.09     |
| time/              |          |
|    fps             | 180      |
|    iterations      | 88       |
|    time_elapsed    | 999      |
|    total_timesteps | 180224   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.4        |
|    ep_rew_mean          | 1.65        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 89          |
|    time_elapsed         | 1010        |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.085730046 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.72       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0809     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0373     |
|    value_loss           | 0.318       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 2.19       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 90         |
|    time_elapsed         | 1021       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.06861573 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.949     |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00533    |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0349    |
|    value_loss           | 0.244      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.5       |
|    ep_rew_mean          | 0.945      |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 91         |
|    time_elapsed         | 1032       |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.07420358 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.881     |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0353     |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.412      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.61       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 92         |
|    time_elapsed         | 1044       |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.07609968 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0149     |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.359      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=190000, episode_reward=-9.00 +/- 17.20
Episode length: 66.80 +/- 67.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 66.8       |
|    mean_reward          | -9         |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.05464407 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.744     |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0228    |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0392    |
|    value_loss           | 0.363      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 2.64     |
| time/              |          |
|    fps             | 180      |
|    iterations      | 93       |
|    time_elapsed    | 1057     |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 2.51       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 94         |
|    time_elapsed         | 1068       |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.06024316 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.737     |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0741    |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.0399    |
|    value_loss           | 0.252      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.7        |
|    ep_rew_mean          | 1.19        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 95          |
|    time_elapsed         | 1079        |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.051988184 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.706      |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00132     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0373     |
|    value_loss           | 0.355       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 2.2         |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 96          |
|    time_elapsed         | 1090        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.057033207 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.965      |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.001       |
|    loss                 | -0.011      |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0324     |
|    value_loss           | 0.342       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 2.38       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 97         |
|    time_elapsed         | 1103       |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.05653649 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.81      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0421     |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.0382    |
|    value_loss           | 0.323      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=200000, episode_reward=-15.75 +/- 17.50
Episode length: 94.60 +/- 67.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.6       |
|    mean_reward          | -15.7      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.07093482 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.736     |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0356    |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.19       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 2.55     |
| time/              |          |
|    fps             | 179      |
|    iterations      | 98       |
|    time_elapsed    | 1115     |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 2.2         |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 99          |
|    time_elapsed         | 1126        |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.061781727 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.758      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0106     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.03       |
|    value_loss           | 0.214       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 1.77        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 100         |
|    time_elapsed         | 1137        |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.070223704 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.806      |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.001       |
|    loss                 | 0.191       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0379     |
|    value_loss           | 0.255       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 2.01        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 101         |
|    time_elapsed         | 1149        |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.067049414 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.861      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0718     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0315     |
|    value_loss           | 0.196       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 2.02        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 102         |
|    time_elapsed         | 1160        |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.051977113 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.853      |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00214     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0389     |
|    value_loss           | 0.275       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=210000, episode_reward=-9.76 +/- 16.53
Episode length: 66.60 +/- 68.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 66.6       |
|    mean_reward          | -9.76      |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.06928299 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0215     |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0412    |
|    value_loss           | 0.226      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 2.48     |
| time/              |          |
|    fps             | 179      |
|    iterations      | 103      |
|    time_elapsed    | 1173     |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 2.13        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 104         |
|    time_elapsed         | 1186        |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.048650376 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.804      |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.001       |
|    loss                 | 0.135       |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0348     |
|    value_loss           | 0.273       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 2.12       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 105        |
|    time_elapsed         | 1197       |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.06317724 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.848     |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0104    |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0415    |
|    value_loss           | 0.319      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 2.33       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 106        |
|    time_elapsed         | 1208       |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.06397978 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.851     |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.001      |
|    loss                 | 0.157      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.306      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 2.34        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 107         |
|    time_elapsed         | 1220        |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.070838355 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.706      |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0181      |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0415     |
|    value_loss           | 0.283       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=220000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.059204128 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.74       |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0668      |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0352     |
|    value_loss           | 0.164       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 2.94     |
| time/              |          |
|    fps             | 179      |
|    iterations      | 108      |
|    time_elapsed    | 1232     |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 2.42        |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 109         |
|    time_elapsed         | 1242        |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.065031186 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0416     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.036      |
|    value_loss           | 0.284       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.19       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 110        |
|    time_elapsed         | 1253       |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.06425381 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.721     |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0187     |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.393      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 2.01       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 111        |
|    time_elapsed         | 1264       |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.06787354 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.623     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0437    |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.245      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 3.01       |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 112        |
|    time_elapsed         | 1275       |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.05378712 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.727     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.001      |
|    loss                 | 0.000378   |
|    n_updates            | 1110       |
|    policy_gradient_loss | -0.0252    |
|    value_loss           | 0.265      |
----------------------------------------
reached max steps=300
Eval num_timesteps=230000, episode_reward=-2.30 +/- 13.93
Episode length: 39.20 +/- 55.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.2       |
|    mean_reward          | -2.3       |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.05305146 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.661     |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0409    |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.0307    |
|    value_loss           | 0.255      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 2.69     |
| time/              |          |
|    fps             | 180      |
|    iterations      | 113      |
|    time_elapsed    | 1285     |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 2.52       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 114        |
|    time_elapsed         | 1295       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.04944463 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.736     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00651   |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0317    |
|    value_loss           | 0.233      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.62       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 115        |
|    time_elapsed         | 1306       |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.05147099 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.757     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.001      |
|    loss                 | 0.113      |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0315    |
|    value_loss           | 0.199      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 2.1        |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 116        |
|    time_elapsed         | 1316       |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.05748348 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.845     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.133      |
|    n_updates            | 1150       |
|    policy_gradient_loss | -0.0323    |
|    value_loss           | 0.234      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.8        |
|    ep_rew_mean          | 2.81        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 117         |
|    time_elapsed         | 1326        |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.065996066 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0747     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0366     |
|    value_loss           | 0.241       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=240000, episode_reward=-16.73 +/- 16.29
Episode length: 95.20 +/- 67.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 95.2       |
|    mean_reward          | -16.7      |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.05623363 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.597     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0616     |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0376    |
|    value_loss           | 0.252      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 2.58     |
| time/              |          |
|    fps             | 180      |
|    iterations      | 118      |
|    time_elapsed    | 1337     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.1        |
|    ep_rew_mean          | 2.45        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 119         |
|    time_elapsed         | 1349        |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.061063066 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.753      |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0753     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0365     |
|    value_loss           | 0.257       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.3        |
|    ep_rew_mean          | 3.35        |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 120         |
|    time_elapsed         | 1360        |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.070096515 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.606      |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0356     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0371     |
|    value_loss           | 0.229       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 2.67       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 121        |
|    time_elapsed         | 1371       |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.04520543 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.581     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0427    |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.332      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 2.5        |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 122        |
|    time_elapsed         | 1382       |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.06769679 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.603     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0466     |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.31       |
----------------------------------------
Eval num_timesteps=250000, episode_reward=4.31 +/- 1.63
Episode length: 11.80 +/- 0.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.8       |
|    mean_reward          | 4.31       |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.07659471 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.754     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0724    |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.268      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 2.6      |
| time/              |          |
|    fps             | 180      |
|    iterations      | 123      |
|    time_elapsed    | 1393     |
|    total_timesteps | 251904   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.1      |
|    ep_rew_mean          | 1.9       |
| time/                   |           |
|    fps                  | 180       |
|    iterations           | 124       |
|    time_elapsed         | 1403      |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.0655731 |
|    clip_fraction        | 0.309     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.702    |
|    explained_variance   | 0.663     |
|    learning_rate        | 0.001     |
|    loss                 | 0.572     |
|    n_updates            | 1230      |
|    policy_gradient_loss | -0.0375   |
|    value_loss           | 0.776     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 2.95       |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 125        |
|    time_elapsed         | 1414       |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.09238531 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.747     |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.001      |
|    loss                 | -0.014     |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.0399    |
|    value_loss           | 0.486      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 1.13        |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 126         |
|    time_elapsed         | 1425        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.075062394 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.702      |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.001       |
|    loss                 | 0.164       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.037      |
|    value_loss           | 0.397       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=260000, episode_reward=-8.30 +/- 17.78
Episode length: 67.20 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.2       |
|    mean_reward          | -8.3       |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.07281312 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.889     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.001      |
|    loss                 | -0.03      |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0378    |
|    value_loss           | 0.218      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.8     |
|    ep_rew_mean     | -0.56    |
| time/              |          |
|    fps             | 181      |
|    iterations      | 127      |
|    time_elapsed    | 1436     |
|    total_timesteps | 260096   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 2.64       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 128        |
|    time_elapsed         | 1447       |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.07251477 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0481     |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.0363    |
|    value_loss           | 0.169      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 2.43        |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 129         |
|    time_elapsed         | 1457        |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.062499058 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.758      |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.001       |
|    loss                 | 0.136       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.036      |
|    value_loss           | 0.324       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.5        |
|    ep_rew_mean          | 1.79        |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 130         |
|    time_elapsed         | 1467        |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.054529652 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.733      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.001       |
|    loss                 | 0.124       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0301     |
|    value_loss           | 0.196       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.37       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 131        |
|    time_elapsed         | 1478       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.06482819 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.778     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0663    |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.205      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=270000, episode_reward=-22.47 +/- 13.20
Episode length: 122.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 122        |
|    mean_reward          | -22.5      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.06435034 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.77      |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00864    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0339    |
|    value_loss           | 0.256      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 1.85     |
| time/              |          |
|    fps             | 181      |
|    iterations      | 132      |
|    time_elapsed    | 1489     |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.5        |
|    ep_rew_mean          | 3.18        |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 133         |
|    time_elapsed         | 1501        |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.065100506 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.795      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0627      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0317     |
|    value_loss           | 0.258       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 2.29       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 134        |
|    time_elapsed         | 1511       |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.06577879 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.651     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0057    |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.0338    |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 1.93        |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 135         |
|    time_elapsed         | 1522        |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.073048115 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0259     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.032      |
|    value_loss           | 0.28        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 2.97       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 136        |
|    time_elapsed         | 1532       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.07152895 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.768     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.001      |
|    loss                 | 0.224      |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.033     |
|    value_loss           | 0.206      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=-2.40 +/- 13.89
Episode length: 39.60 +/- 55.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39.6        |
|    mean_reward          | -2.4        |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.053857774 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0465     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0302     |
|    value_loss           | 0.252       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 1.65     |
| time/              |          |
|    fps             | 181      |
|    iterations      | 137      |
|    time_elapsed    | 1544     |
|    total_timesteps | 280576   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 2.11       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 138        |
|    time_elapsed         | 1554       |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.15506572 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.757     |
|    explained_variance   | 0.311      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0548     |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.00746   |
|    value_loss           | 0.695      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 139        |
|    time_elapsed         | 1564       |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.07490829 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.763     |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.001      |
|    loss                 | 0.015      |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0432    |
|    value_loss           | 0.476      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 2.4        |
| time/                   |            |
|    fps                  | 181        |
|    iterations           | 140        |
|    time_elapsed         | 1575       |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.06515481 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.655     |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.001      |
|    loss                 | 0.122      |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.0439    |
|    value_loss           | 0.284      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 1.81       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 141        |
|    time_elapsed         | 1585       |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.06593469 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.767     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0484    |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.295      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=290000, episode_reward=-16.59 +/- 16.43
Episode length: 94.80 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.8       |
|    mean_reward          | -16.6      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.06605053 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.793     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0765    |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.246      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 2.65     |
| time/              |          |
|    fps             | 182      |
|    iterations      | 142      |
|    time_elapsed    | 1597     |
|    total_timesteps | 290816   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 2.02       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 143        |
|    time_elapsed         | 1608       |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.07049093 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.697     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0183    |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.289      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.7      |
|    ep_rew_mean          | 2.4       |
| time/                   |           |
|    fps                  | 182       |
|    iterations           | 144       |
|    time_elapsed         | 1619      |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0606282 |
|    clip_fraction        | 0.296     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.772    |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.001     |
|    loss                 | 0.00105   |
|    n_updates            | 1430      |
|    policy_gradient_loss | -0.0287   |
|    value_loss           | 0.275     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 2.13       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 145        |
|    time_elapsed         | 1630       |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.06564635 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.723     |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.001      |
|    loss                 | 0.116      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0388    |
|    value_loss           | 0.298      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 2.41        |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 146         |
|    time_elapsed         | 1641        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.053313106 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.724      |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0159      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0386     |
|    value_loss           | 0.202       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=300000, episode_reward=-1.58 +/- 14.37
Episode length: 39.40 +/- 55.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.4       |
|    mean_reward          | -1.58      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.05704016 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.673     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0218    |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0387    |
|    value_loss           | 0.224      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 3.2      |
| time/              |          |
|    fps             | 182      |
|    iterations      | 147      |
|    time_elapsed    | 1651     |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 2.33       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 148        |
|    time_elapsed         | 1662       |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.04992444 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.641     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0523    |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.0279    |
|    value_loss           | 0.27       |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.1      |
|    ep_rew_mean          | 2.22      |
| time/                   |           |
|    fps                  | 182       |
|    iterations           | 149       |
|    time_elapsed         | 1673      |
|    total_timesteps      | 305152    |
| train/                  |           |
|    approx_kl            | 0.0635511 |
|    clip_fraction        | 0.293     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.74     |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.001     |
|    loss                 | 0.042     |
|    n_updates            | 1480      |
|    policy_gradient_loss | -0.0353   |
|    value_loss           | 0.237     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 2.37       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 150        |
|    time_elapsed         | 1683       |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.06711907 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.767     |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0294    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.229      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.1        |
|    ep_rew_mean          | 3.03        |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 151         |
|    time_elapsed         | 1693        |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.050002746 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0127      |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0351     |
|    value_loss           | 0.241       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=310000, episode_reward=-9.21 +/- 17.05
Episode length: 67.60 +/- 67.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.6       |
|    mean_reward          | -9.21      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.05479616 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.591     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.001      |
|    loss                 | -0.00829   |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 2.54     |
| time/              |          |
|    fps             | 182      |
|    iterations      | 152      |
|    time_elapsed    | 1704     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 2.45        |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 153         |
|    time_elapsed         | 1714        |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.050894536 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.646      |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0319      |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 0.286       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 2.48       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 154        |
|    time_elapsed         | 1724       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.10280125 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.65      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0498    |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.04      |
|    value_loss           | 0.205      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 2.69       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 155        |
|    time_elapsed         | 1735       |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.06769788 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.665     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0977     |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.0299    |
|    value_loss           | 0.305      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.25       |
| time/                   |            |
|    fps                  | 182        |
|    iterations           | 156        |
|    time_elapsed         | 1745       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.06599595 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.69      |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0136     |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0322    |
|    value_loss           | 0.309      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=320000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.4       |
|    mean_reward          | -16.5      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.06451507 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.753     |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | 0.025      |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.0298    |
|    value_loss           | 0.252      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 1.69     |
| time/              |          |
|    fps             | 182      |
|    iterations      | 157      |
|    time_elapsed    | 1757     |
|    total_timesteps | 321536   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.9        |
|    ep_rew_mean          | 2.05        |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 158         |
|    time_elapsed         | 1768        |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.058729306 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.787      |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0273      |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0315     |
|    value_loss           | 0.269       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 2.27       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 159        |
|    time_elapsed         | 1778       |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.06936983 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.784     |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.0357    |
|    value_loss           | 0.252      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 2.82        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 160         |
|    time_elapsed         | 1788        |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.066393286 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.782      |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0451     |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.259       |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.4      |
|    ep_rew_mean          | 2.99      |
| time/                   |           |
|    fps                  | 183       |
|    iterations           | 161       |
|    time_elapsed         | 1799      |
|    total_timesteps      | 329728    |
| train/                  |           |
|    approx_kl            | 0.0626442 |
|    clip_fraction        | 0.27      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.71     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.001     |
|    loss                 | 0.306     |
|    n_updates            | 1600      |
|    policy_gradient_loss | -0.0269   |
|    value_loss           | 0.339     |
---------------------------------------
reached max steps=300
Eval num_timesteps=330000, episode_reward=-3.18 +/- 13.41
Episode length: 39.40 +/- 55.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.4       |
|    mean_reward          | -3.18      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.05498466 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.632     |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0449    |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0355    |
|    value_loss           | 0.373      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 2.26     |
| time/              |          |
|    fps             | 183      |
|    iterations      | 162      |
|    time_elapsed    | 1809     |
|    total_timesteps | 331776   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 2.55       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 163        |
|    time_elapsed         | 1820       |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.10736209 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.684     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0635    |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.257      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24          |
|    ep_rew_mean          | 1.76        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 164         |
|    time_elapsed         | 1830        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.077325694 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.633      |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0315      |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0406     |
|    value_loss           | 0.3         |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 2.53       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 165        |
|    time_elapsed         | 1840       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.09260792 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0187     |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0446    |
|    value_loss           | 0.375      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 2.83       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 166        |
|    time_elapsed         | 1851       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.06956041 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.567     |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0368     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0465    |
|    value_loss           | 0.249      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=340000, episode_reward=-16.61 +/- 16.40
Episode length: 94.80 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.8       |
|    mean_reward          | -16.6      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.05319576 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.587     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | 0.039      |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.029     |
|    value_loss           | 0.21       |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 2.13     |
| time/              |          |
|    fps             | 183      |
|    iterations      | 167      |
|    time_elapsed    | 1862     |
|    total_timesteps | 342016   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2.01       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 168        |
|    time_elapsed         | 1872       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.07113175 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.758     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.001      |
|    loss                 | 0.111      |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0438    |
|    value_loss           | 0.274      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.6        |
|    ep_rew_mean          | 3.05        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 169         |
|    time_elapsed         | 1883        |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.052402794 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.693      |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.001       |
|    loss                 | 0.149       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.024      |
|    value_loss           | 0.215       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26         |
|    ep_rew_mean          | 1.15       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 170        |
|    time_elapsed         | 1893       |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.06077175 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.621     |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00378   |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0313    |
|    value_loss           | 0.338      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=350000, episode_reward=-8.26 +/- 16.22
Episode length: 67.00 +/- 67.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 67          |
|    mean_reward          | -8.26       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.060420197 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.92       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.001       |
|    loss                 | 0.034       |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0381     |
|    value_loss           | 0.374       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 1.45     |
| time/              |          |
|    fps             | 183      |
|    iterations      | 171      |
|    time_elapsed    | 1905     |
|    total_timesteps | 350208   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.78       |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 172        |
|    time_elapsed         | 1917       |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.10047744 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.764     |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.001      |
|    loss                 | 0.187      |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0371    |
|    value_loss           | 0.505      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.9        |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 173        |
|    time_elapsed         | 1927       |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.10486309 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.779     |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.001      |
|    loss                 | 0.203      |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0424    |
|    value_loss           | 0.262      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 2          |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 174        |
|    time_elapsed         | 1938       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.06936855 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.807     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.001      |
|    loss                 | -0.053     |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0334    |
|    value_loss           | 0.231      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.8        |
|    ep_rew_mean          | 1.79        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 175         |
|    time_elapsed         | 1949        |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.059168503 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.776      |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0198     |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0262     |
|    value_loss           | 0.206       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=360000, episode_reward=4.92 +/- 1.72
Episode length: 12.60 +/- 1.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.6       |
|    mean_reward          | 4.92       |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.09562017 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.808     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0474    |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0321    |
|    value_loss           | 0.249      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.7     |
|    ep_rew_mean     | 1.95     |
| time/              |          |
|    fps             | 183      |
|    iterations      | 176      |
|    time_elapsed    | 1959     |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.6        |
|    ep_rew_mean          | 2.77        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 177         |
|    time_elapsed         | 1970        |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.072193176 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.811      |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0181     |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0347     |
|    value_loss           | 0.292       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 2.5        |
| time/                   |            |
|    fps                  | 183        |
|    iterations           | 178        |
|    time_elapsed         | 1981       |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.07181696 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.641     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0652    |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0397    |
|    value_loss           | 0.266      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 2.52        |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 179         |
|    time_elapsed         | 1992        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.084107846 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0464     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0422     |
|    value_loss           | 0.242       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 1.55        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 180         |
|    time_elapsed         | 2002        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.078734666 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.725      |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0482      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0346     |
|    value_loss           | 0.322       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=370000, episode_reward=-9.88 +/- 16.47
Episode length: 67.00 +/- 67.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67         |
|    mean_reward          | -9.88      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.05948548 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.794     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0875    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0384    |
|    value_loss           | 0.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 3.13     |
| time/              |          |
|    fps             | 184      |
|    iterations      | 181      |
|    time_elapsed    | 2014     |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.2        |
|    ep_rew_mean          | 3.24        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 182         |
|    time_elapsed         | 2024        |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.061680112 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.623      |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00264    |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0328     |
|    value_loss           | 0.226       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 2.32       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 183        |
|    time_elapsed         | 2034       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.07403891 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0331    |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.303      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.6      |
|    ep_rew_mean          | 2.79      |
| time/                   |           |
|    fps                  | 184       |
|    iterations           | 184       |
|    time_elapsed         | 2045      |
|    total_timesteps      | 376832    |
| train/                  |           |
|    approx_kl            | 0.0655116 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.737    |
|    explained_variance   | 0.838     |
|    learning_rate        | 0.001     |
|    loss                 | 0.101     |
|    n_updates            | 1830      |
|    policy_gradient_loss | -0.029    |
|    value_loss           | 0.31      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 2.44       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 185        |
|    time_elapsed         | 2055       |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.06585631 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0667     |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.029     |
|    value_loss           | 0.272      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=380000, episode_reward=-1.58 +/- 14.32
Episode length: 39.60 +/- 55.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.6       |
|    mean_reward          | -1.58      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.06113652 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.644     |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0326     |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0239    |
|    value_loss           | 0.307      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 2.33     |
| time/              |          |
|    fps             | 184      |
|    iterations      | 186      |
|    time_elapsed    | 2065     |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 2.56       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 187        |
|    time_elapsed         | 2076       |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.08340949 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.798     |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.001      |
|    loss                 | -0.03      |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0283    |
|    value_loss           | 0.268      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 2.15        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 188         |
|    time_elapsed         | 2086        |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.076747194 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.697      |
|    explained_variance   | 0.677       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0998      |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.0397     |
|    value_loss           | 0.56        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 2.55       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 189        |
|    time_elapsed         | 2097       |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.09185366 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.716     |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0107     |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.0422    |
|    value_loss           | 0.355      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 3.01       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 190        |
|    time_elapsed         | 2108       |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.09243926 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.631     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0614     |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0386    |
|    value_loss           | 0.195      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=4.21 +/- 1.69
Episode length: 12.40 +/- 1.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.4       |
|    mean_reward          | 4.21       |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.08086045 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.55      |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0369     |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0318    |
|    value_loss           | 0.262      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.9     |
|    ep_rew_mean     | 3.51     |
| time/              |          |
|    fps             | 184      |
|    iterations      | 191      |
|    time_elapsed    | 2119     |
|    total_timesteps | 391168   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 2.28        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 192         |
|    time_elapsed         | 2130        |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.074089706 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.563      |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0344     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0314     |
|    value_loss           | 0.276       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 2.74        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 193         |
|    time_elapsed         | 2141        |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.059508644 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.001       |
|    loss                 | 0.126       |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0345     |
|    value_loss           | 0.332       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 3.22       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 194        |
|    time_elapsed         | 2151       |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.08242106 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.625     |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0483    |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.0383    |
|    value_loss           | 0.312      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 3.09       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 195        |
|    time_elapsed         | 2161       |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.08067122 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.001      |
|    loss                 | 0.196      |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.315      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=400000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 94.4        |
|    mean_reward          | -16.5       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.076932825 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.001       |
|    loss                 | 0.00899     |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0332     |
|    value_loss           | 0.326       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 2.9      |
| time/              |          |
|    fps             | 184      |
|    iterations      | 196      |
|    time_elapsed    | 2172     |
|    total_timesteps | 401408   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 2.63        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 197         |
|    time_elapsed         | 2183        |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.086569145 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.673      |
|    explained_variance   | 0.812       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0274      |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.0318     |
|    value_loss           | 0.339       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 2.67       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 198        |
|    time_elapsed         | 2193       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.08552355 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.704     |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0525    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0276    |
|    value_loss           | 0.357      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 2.01        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 199         |
|    time_elapsed         | 2204        |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.082325205 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.634      |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0346      |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0269     |
|    value_loss           | 0.271       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 1.71       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 200        |
|    time_elapsed         | 2215       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.09564155 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.796     |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0669    |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0384    |
|    value_loss           | 0.257      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=410000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.4       |
|    mean_reward          | -16.5      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.09152499 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.722     |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0499     |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0448    |
|    value_loss           | 0.316      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.3     |
|    ep_rew_mean     | 2.21     |
| time/              |          |
|    fps             | 184      |
|    iterations      | 201      |
|    time_elapsed    | 2227     |
|    total_timesteps | 411648   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.9      |
|    ep_rew_mean          | 3.39      |
| time/                   |           |
|    fps                  | 184       |
|    iterations           | 202       |
|    time_elapsed         | 2238      |
|    total_timesteps      | 413696    |
| train/                  |           |
|    approx_kl            | 0.0631598 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.563    |
|    explained_variance   | 0.806     |
|    learning_rate        | 0.001     |
|    loss                 | -0.000889 |
|    n_updates            | 2010      |
|    policy_gradient_loss | -0.0375   |
|    value_loss           | 0.272     |
---------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 2.3         |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 203         |
|    time_elapsed         | 2249        |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.064688824 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.474      |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0278      |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0314     |
|    value_loss           | 0.364       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.6        |
|    ep_rew_mean          | 3.12        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 204         |
|    time_elapsed         | 2260        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.089996815 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.615      |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0289     |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 0.263       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 1.79       |
| time/                   |            |
|    fps                  | 184        |
|    iterations           | 205        |
|    time_elapsed         | 2271       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.07309021 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.52      |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.001      |
|    loss                 | -0.005     |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0246    |
|    value_loss           | 0.294      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=420000, episode_reward=-9.41 +/- 16.89
Episode length: 68.40 +/- 66.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 68.4       |
|    mean_reward          | -9.41      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.07360588 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.583     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.001      |
|    loss                 | 0.053      |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0241    |
|    value_loss           | 0.267      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 2.68     |
| time/              |          |
|    fps             | 184      |
|    iterations      | 206      |
|    time_elapsed    | 2282     |
|    total_timesteps | 421888   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 2.28        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 207         |
|    time_elapsed         | 2293        |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.057468385 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.569      |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0291     |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0339     |
|    value_loss           | 0.347       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.8        |
|    ep_rew_mean          | 1.47        |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 208         |
|    time_elapsed         | 2303        |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.089286186 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0471      |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0298     |
|    value_loss           | 0.232       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 2.49       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 209        |
|    time_elapsed         | 2313       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.07316866 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.811     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0368    |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0233    |
|    value_loss           | 0.251      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=430000, episode_reward=4.35 +/- 1.60
Episode length: 11.80 +/- 0.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.8       |
|    mean_reward          | 4.35       |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.06559713 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.634     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0273    |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.313      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 2.1      |
| time/              |          |
|    fps             | 185      |
|    iterations      | 210      |
|    time_elapsed    | 2323     |
|    total_timesteps | 430080   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.86       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 211        |
|    time_elapsed         | 2334       |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.10624273 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.001      |
|    loss                 | 0.242      |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0499    |
|    value_loss           | 0.331      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 2.59       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 212        |
|    time_elapsed         | 2345       |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.08241367 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.631     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0445    |
|    n_updates            | 2110       |
|    policy_gradient_loss | -0.0423    |
|    value_loss           | 0.229      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 2          |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 213        |
|    time_elapsed         | 2356       |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.08303182 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.604     |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00708    |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0288    |
|    value_loss           | 0.365      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.6        |
|    ep_rew_mean          | 3.04        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 214         |
|    time_elapsed         | 2367        |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.104947425 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.629      |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00929    |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0432     |
|    value_loss           | 0.408       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=440000, episode_reward=-9.04 +/- 17.16
Episode length: 67.00 +/- 67.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67         |
|    mean_reward          | -9.04      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.07212001 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.542     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.001      |
|    loss                 | 0.362      |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0343    |
|    value_loss           | 0.274      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.3     |
|    ep_rew_mean     | 3.23     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 215      |
|    time_elapsed    | 2378     |
|    total_timesteps | 440320   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 2.62        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 216         |
|    time_elapsed         | 2389        |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.056999624 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.543      |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0057      |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0324     |
|    value_loss           | 0.251       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 2.58       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 217        |
|    time_elapsed         | 2399       |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.07585872 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0338     |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.323      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 3.44       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 218        |
|    time_elapsed         | 2410       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.07717227 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.606     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0773     |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.0269    |
|    value_loss           | 0.236      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 3.29       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 219        |
|    time_elapsed         | 2421       |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.05395989 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.49      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0604    |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0301    |
|    value_loss           | 0.323      |
----------------------------------------
Eval num_timesteps=450000, episode_reward=4.98 +/- 3.07
Episode length: 12.60 +/- 1.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.6       |
|    mean_reward          | 4.98       |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.06634525 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.47      |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0487    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0258    |
|    value_loss           | 0.219      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.3     |
|    ep_rew_mean     | 3.28     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 220      |
|    time_elapsed    | 2432     |
|    total_timesteps | 450560   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17         |
|    ep_rew_mean          | 3.32       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 221        |
|    time_elapsed         | 2443       |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.06987326 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.515     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.001      |
|    loss                 | 0.711      |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0369    |
|    value_loss           | 0.37       |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.3        |
|    ep_rew_mean          | 2.78        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 222         |
|    time_elapsed         | 2454        |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.057037987 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.473      |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0161     |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0375     |
|    value_loss           | 0.318       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 2.67       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 223        |
|    time_elapsed         | 2464       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.08171819 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.564     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0401    |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0244    |
|    value_loss           | 0.279      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 2.71        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 224         |
|    time_elapsed         | 2475        |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.083399475 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.638      |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.001       |
|    loss                 | 0.153       |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.0215     |
|    value_loss           | 0.289       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=460000, episode_reward=-3.07 +/- 13.46
Episode length: 39.00 +/- 55.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39          |
|    mean_reward          | -3.07       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.090570584 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.653      |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0104      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0326     |
|    value_loss           | 0.429       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.1     |
|    ep_rew_mean     | 3.35     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 225      |
|    time_elapsed    | 2486     |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.8        |
|    ep_rew_mean          | 3.2         |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 226         |
|    time_elapsed         | 2497        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.095507964 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.49       |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0867      |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.031      |
|    value_loss           | 0.382       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.8       |
|    ep_rew_mean          | 3.12       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 227        |
|    time_elapsed         | 2507       |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.07985112 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.414     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0288    |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.0309    |
|    value_loss           | 0.298      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 2.28       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 228        |
|    time_elapsed         | 2518       |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.06286765 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.481     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0375     |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.299      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 2.58       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 229        |
|    time_elapsed         | 2528       |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.08273151 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.735     |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0717     |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 0.253      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=470000, episode_reward=-3.26 +/- 13.37
Episode length: 39.80 +/- 55.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.8       |
|    mean_reward          | -3.26      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.07702142 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0919     |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0223    |
|    value_loss           | 0.27       |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 1.26     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 230      |
|    time_elapsed    | 2539     |
|    total_timesteps | 471040   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.8      |
|    ep_rew_mean          | 2.99      |
| time/                   |           |
|    fps                  | 185       |
|    iterations           | 231       |
|    time_elapsed         | 2550      |
|    total_timesteps      | 473088    |
| train/                  |           |
|    approx_kl            | 0.0963588 |
|    clip_fraction        | 0.324     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.774    |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0892   |
|    n_updates            | 2300      |
|    policy_gradient_loss | -0.0413   |
|    value_loss           | 0.185     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 2.3         |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 232         |
|    time_elapsed         | 2560        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.078115754 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.5        |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0573      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.311       |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 2.55       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 233        |
|    time_elapsed         | 2571       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.40324953 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.594     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0513    |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0304    |
|    value_loss           | 0.279      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 3.02        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 234         |
|    time_elapsed         | 2581        |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.102269575 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.531      |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0826     |
|    n_updates            | 2330        |
|    policy_gradient_loss | 0.00248     |
|    value_loss           | 0.202       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=480000, episode_reward=-16.63 +/- 16.38
Episode length: 94.80 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.8       |
|    mean_reward          | -16.6      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.09957929 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.535     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.001      |
|    loss                 | 0.266      |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0239    |
|    value_loss           | 0.379      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 2.98     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 235      |
|    time_elapsed    | 2593     |
|    total_timesteps | 481280   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 2.89       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 236        |
|    time_elapsed         | 2604       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.06871546 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.538     |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0429    |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.0192    |
|    value_loss           | 0.311      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 17.3      |
|    ep_rew_mean          | 2.95      |
| time/                   |           |
|    fps                  | 185       |
|    iterations           | 237       |
|    time_elapsed         | 2615      |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 0.0633293 |
|    clip_fraction        | 0.2       |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.452    |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.001     |
|    loss                 | 0.139     |
|    n_updates            | 2360      |
|    policy_gradient_loss | -0.0192   |
|    value_loss           | 0.245     |
---------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.2        |
|    ep_rew_mean          | 3.08        |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 238         |
|    time_elapsed         | 2625        |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.065139435 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.457      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0519      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0272     |
|    value_loss           | 0.244       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 3.27       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 239        |
|    time_elapsed         | 2636       |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.07786469 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0446    |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0423    |
|    value_loss           | 0.251      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=3.38 +/- 0.56
Episode length: 12.60 +/- 2.73
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.6        |
|    mean_reward          | 3.38        |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.069079384 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.42       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.001       |
|    loss                 | 0.013       |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.283       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.7     |
|    ep_rew_mean     | 3.31     |
| time/              |          |
|    fps             | 185      |
|    iterations      | 240      |
|    time_elapsed    | 2647     |
|    total_timesteps | 491520   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 2.56       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 241        |
|    time_elapsed         | 2657       |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.06808562 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0293    |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0283    |
|    value_loss           | 0.281      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 2.2         |
| time/                   |             |
|    fps                  | 185         |
|    iterations           | 242         |
|    time_elapsed         | 2667        |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.094859436 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.541      |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.001       |
|    loss                 | 0.133       |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0282     |
|    value_loss           | 0.254       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 3.11       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 243        |
|    time_elapsed         | 2678       |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.07211665 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.68      |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.001      |
|    loss                 | 0.238      |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.0239    |
|    value_loss           | 0.235      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.09       |
| time/                   |            |
|    fps                  | 185        |
|    iterations           | 244        |
|    time_elapsed         | 2688       |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.07754931 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.592     |
|    explained_variance   | 0.82       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0693     |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.025     |
|    value_loss           | 0.362      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=500000, episode_reward=-3.30 +/- 13.35
Episode length: 40.00 +/- 55.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40         |
|    mean_reward          | -3.3       |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.07388739 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0187    |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.234      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 2.2      |
| time/              |          |
|    fps             | 185      |
|    iterations      | 245      |
|    time_elapsed    | 2699     |
|    total_timesteps | 501760   |
---------------------------------
