Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
Observation space: Dict('image': Box(0, 255, (3, 7, 7), uint8))
cuda:0
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000002111DB6A500> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000211176DA980>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.grid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.grid` for environment variables or `env.get_wrapper_attr('grid')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.front_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.front_pos` for environment variables or `env.get_wrapper_attr('front_pos')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actions` for environment variables or `env.get_wrapper_attr('actions')` that will search the reminding wrappers.[0m
  logger.warn(
C:\Users\matan\anaconda3\envs\master_env\lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.[0m
  logger.warn(
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -35.3    |
| time/              |          |
|    fps             | 170      |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 2048     |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | -32.7        |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0143193565 |
|    clip_fraction        | 0.0771       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | -0.00297     |
|    learning_rate        | 0.001        |
|    loss                 | 0.121        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0122      |
|    value_loss           | 0.713        |
------------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 148        |
|    ep_rew_mean          | -32.1      |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 3          |
|    time_elapsed         | 34         |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.00823611 |
|    clip_fraction        | 0.0639     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.0723     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0129    |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.00905   |
|    value_loss           | 0.418      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 149        |
|    ep_rew_mean          | -31.2      |
| time/                   |            |
|    fps                  | 177        |
|    iterations           | 4          |
|    time_elapsed         | 46         |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01262924 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.91      |
|    explained_variance   | -0.0177    |
|    learning_rate        | 0.001      |
|    loss                 | 0.156      |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0143    |
|    value_loss           | 0.227      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=10000, episode_reward=-30.02 +/- 0.04
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.015785854 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | -0.0842     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0126      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.158       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -30.6    |
| time/              |          |
|    fps             | 172      |
|    iterations      | 5        |
|    time_elapsed    | 59       |
|    total_timesteps | 10240    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -30.7       |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 6           |
|    time_elapsed         | 70          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.016541269 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | -0.178      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0789     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.181       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -30.5       |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 7           |
|    time_elapsed         | 82          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.025612012 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.482      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0387     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00816    |
|    value_loss           | 0.174       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -30         |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 8           |
|    time_elapsed         | 94          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.023460045 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.0298      |
|    learning_rate        | 0.001       |
|    loss                 | 0.239       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0207     |
|    value_loss           | 0.281       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -29.8       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 9           |
|    time_elapsed         | 106         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.025690936 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | -0.435      |
|    learning_rate        | 0.001       |
|    loss                 | 0.00437     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0236     |
|    value_loss           | 0.175       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=20000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.027603311 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -0.234      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0602     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0227     |
|    value_loss           | 0.161       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -29.2    |
| time/              |          |
|    fps             | 169      |
|    iterations      | 10       |
|    time_elapsed    | 120      |
|    total_timesteps | 20480    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | -29.3       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 11          |
|    time_elapsed         | 131         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.023322247 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | -0.267      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0733     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0213     |
|    value_loss           | 0.126       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -28.8       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 12          |
|    time_elapsed         | 143         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.029795129 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | -0.205      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0618     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.0957      |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -28.9       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 13          |
|    time_elapsed         | 155         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.024518993 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.00916     |
|    learning_rate        | 0.001       |
|    loss                 | 0.0264      |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.021      |
|    value_loss           | 0.191       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | -27.9       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 14          |
|    time_elapsed         | 167         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.035078462 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | -0.342      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0422     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0285     |
|    value_loss           | 0.25        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=30000, episode_reward=-30.00 +/- 0.00
Episode length: 150.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 150        |
|    mean_reward          | -30        |
| time/                   |            |
|    total_timesteps      | 30000      |
| train/                  |            |
|    approx_kl            | 0.03714615 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.71      |
|    explained_variance   | -0.339     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0417    |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.212      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | -26.5    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 15       |
|    time_elapsed    | 182      |
|    total_timesteps | 30720    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 140        |
|    ep_rew_mean          | -26.2      |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 16         |
|    time_elapsed         | 193        |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.03818246 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.71      |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0777     |
|    n_updates            | 150        |
|    policy_gradient_loss | -0.0242    |
|    value_loss           | 0.307      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 127         |
|    ep_rew_mean          | -23         |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 17          |
|    time_elapsed         | 205         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.044173457 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | -0.419      |
|    learning_rate        | 0.001       |
|    loss                 | -0.0724     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0283     |
|    value_loss           | 0.211       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 122         |
|    ep_rew_mean          | -21.6       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 18          |
|    time_elapsed         | 217         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.038780995 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0572     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0244     |
|    value_loss           | 0.425       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 115         |
|    ep_rew_mean          | -19         |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 19          |
|    time_elapsed         | 228         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.044671744 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.116       |
|    learning_rate        | 0.001       |
|    loss                 | 0.203       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0288     |
|    value_loss           | 0.255       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=40000, episode_reward=-29.20 +/- 1.60
Episode length: 150.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 150         |
|    mean_reward          | -29.2       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.058489505 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.001       |
|    loss                 | -0.045      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0328     |
|    value_loss           | 0.228       |
-----------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 108      |
|    ep_rew_mean     | -17.1    |
| time/              |          |
|    fps             | 169      |
|    iterations      | 20       |
|    time_elapsed    | 242      |
|    total_timesteps | 40960    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 99.7       |
|    ep_rew_mean          | -14.5      |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 21         |
|    time_elapsed         | 253        |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.05817816 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.59      |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0407    |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0243    |
|    value_loss           | 0.352      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 98.7        |
|    ep_rew_mean          | -14.1       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 22          |
|    time_elapsed         | 265         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.062686056 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0419      |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 0.194       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 83.1        |
|    ep_rew_mean          | -10.5       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 23          |
|    time_elapsed         | 277         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.049035244 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.001       |
|    loss                 | 0.146       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0237     |
|    value_loss           | 0.27        |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 76.4       |
|    ep_rew_mean          | -9.2       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 24         |
|    time_elapsed         | 288        |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.05378026 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.49      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0217    |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0248    |
|    value_loss           | 0.287      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=50000, episode_reward=-16.51 +/- 16.53
Episode length: 94.40 +/- 68.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 94.4        |
|    mean_reward          | -16.5       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.050836753 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.626       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0086      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0199     |
|    value_loss           | 0.303       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.9     |
|    ep_rew_mean     | -6.07    |
| time/              |          |
|    fps             | 169      |
|    iterations      | 25       |
|    time_elapsed    | 301      |
|    total_timesteps | 51200    |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.8       |
|    ep_rew_mean          | -3.34      |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 26         |
|    time_elapsed         | 312        |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.06796631 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0924     |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.031     |
|    value_loss           | 0.276      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.2        |
|    ep_rew_mean          | -3.91       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 27          |
|    time_elapsed         | 323         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.061785303 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0356     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0291     |
|    value_loss           | 0.286       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.5        |
|    ep_rew_mean          | -3.26       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 28          |
|    time_elapsed         | 334         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.060877003 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0562      |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.243       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.4       |
|    ep_rew_mean          | -0.132     |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 29         |
|    time_elapsed         | 346        |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 0.06150295 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.21      |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.001      |
|    loss                 | 0.107      |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.0295    |
|    value_loss           | 0.304      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=60000, episode_reward=-23.25 +/- 13.49
Episode length: 122.20 +/- 55.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 122         |
|    mean_reward          | -23.3       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.059324466 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0235      |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0282     |
|    value_loss           | 0.306       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.7     |
|    ep_rew_mean     | 0.929    |
| time/              |          |
|    fps             | 171      |
|    iterations      | 30       |
|    time_elapsed    | 358      |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 2.01       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 31         |
|    time_elapsed         | 369        |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.07174124 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.903     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0604    |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.285      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.92       |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 32         |
|    time_elapsed         | 381        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.07704378 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.81      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.001      |
|    loss                 | 0.167      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0293    |
|    value_loss           | 0.26       |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 2.72       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 33         |
|    time_elapsed         | 392        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.08753143 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.783     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.001      |
|    loss                 | 0.231      |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.00437   |
|    value_loss           | 0.268      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 2.99       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 34         |
|    time_elapsed         | 403        |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.07419765 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0526    |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0276    |
|    value_loss           | 0.221      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=70000, episode_reward=-16.65 +/- 16.39
Episode length: 94.80 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.8       |
|    mean_reward          | -16.6      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.11053556 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.681     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0229    |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0179    |
|    value_loss           | 0.199      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 3.08     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 35       |
|    time_elapsed    | 416      |
|    total_timesteps | 71680    |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.24       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 36         |
|    time_elapsed         | 427        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.09337911 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.591     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | 0.104      |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0273    |
|    value_loss           | 0.153      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 2.3        |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 37         |
|    time_elapsed         | 439        |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.10076263 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.644     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0253     |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0152    |
|    value_loss           | 0.182      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.4       |
|    ep_rew_mean          | 3.34       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 38         |
|    time_elapsed         | 450        |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.08100936 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.531     |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.001      |
|    loss                 | 0.601      |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.0158    |
|    value_loss           | 0.345      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 2.5        |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 39         |
|    time_elapsed         | 462        |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.11274865 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0252    |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.13       |
----------------------------------------
reached max steps=300
Eval num_timesteps=80000, episode_reward=-2.38 +/- 13.88
Episode length: 39.40 +/- 55.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.4       |
|    mean_reward          | -2.38      |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.09091995 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.722     |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00519    |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.237      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 2.71     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 40       |
|    time_elapsed    | 474      |
|    total_timesteps | 81920    |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.4        |
|    ep_rew_mean          | 3.1         |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 41          |
|    time_elapsed         | 486         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.098117575 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.526      |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0247     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0339     |
|    value_loss           | 0.188       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.3       |
|    ep_rew_mean          | 3.83       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 42         |
|    time_elapsed         | 497        |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.11542075 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0164    |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0236    |
|    value_loss           | 0.152      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 3.13       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 43         |
|    time_elapsed         | 509        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.08959897 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.481     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00967   |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0215    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=90000, episode_reward=-9.92 +/- 16.39
Episode length: 67.20 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.2       |
|    mean_reward          | -9.92      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.12073372 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0658     |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0266    |
|    value_loss           | 0.611      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.5     |
|    ep_rew_mean     | 3.07     |
| time/              |          |
|    fps             | 172      |
|    iterations      | 44       |
|    time_elapsed    | 521      |
|    total_timesteps | 90112    |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 2.81       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 45         |
|    time_elapsed         | 533        |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.11206463 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0573    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.0236    |
|    value_loss           | 0.239      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.3       |
|    ep_rew_mean          | 2.64       |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 46         |
|    time_elapsed         | 544        |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.09203164 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.677     |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0214     |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.0227    |
|    value_loss           | 0.643      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.2        |
|    ep_rew_mean          | 2.64        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 47          |
|    time_elapsed         | 556         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.100815386 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.805      |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0141      |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0312     |
|    value_loss           | 0.345       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24        |
|    ep_rew_mean          | 2.3       |
| time/                   |           |
|    fps                  | 173       |
|    iterations           | 48        |
|    time_elapsed         | 567       |
|    total_timesteps      | 98304     |
| train/                  |           |
|    approx_kl            | 0.0898214 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.769    |
|    explained_variance   | 0.798     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0636    |
|    n_updates            | 470       |
|    policy_gradient_loss | -0.0379   |
|    value_loss           | 0.312     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=100000, episode_reward=-1.68 +/- 14.30
Episode length: 39.80 +/- 55.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.8       |
|    mean_reward          | -1.68      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.12319335 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.71      |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0298    |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0294    |
|    value_loss           | 0.293      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 2.54     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 49       |
|    time_elapsed    | 579      |
|    total_timesteps | 100352   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 2.47       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 50         |
|    time_elapsed         | 591        |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.11438859 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.651     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0663    |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0247    |
|    value_loss           | 0.161      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 3.24       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 51         |
|    time_elapsed         | 602        |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.08648834 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | 0.244      |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.027     |
|    value_loss           | 0.275      |
----------------------------------------
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 21.8     |
|    ep_rew_mean          | 3.01     |
| time/                   |          |
|    fps                  | 173      |
|    iterations           | 52       |
|    time_elapsed         | 614      |
|    total_timesteps      | 106496   |
| train/                  |          |
|    approx_kl            | 0.077159 |
|    clip_fraction        | 0.25     |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.619   |
|    explained_variance   | 0.926    |
|    learning_rate        | 0.001    |
|    loss                 | -0.0215  |
|    n_updates            | 510      |
|    policy_gradient_loss | -0.0213  |
|    value_loss           | 0.135    |
--------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.8        |
|    ep_rew_mean          | 3.76        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 53          |
|    time_elapsed         | 625         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.056043293 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0172      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0211     |
|    value_loss           | 0.243       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=110000, episode_reward=-14.58 +/- 19.16
Episode length: 96.60 +/- 65.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 96.6       |
|    mean_reward          | -14.6      |
| time/                   |            |
|    total_timesteps      | 110000     |
| train/                  |            |
|    approx_kl            | 0.08087092 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.001      |
|    loss                 | 0.00892    |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.0385    |
|    value_loss           | 0.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 3.07     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 54       |
|    time_elapsed    | 638      |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 3.22       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 55         |
|    time_elapsed         | 649        |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.07899866 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.676     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0167     |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.0276    |
|    value_loss           | 0.207      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 3.45       |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 56         |
|    time_elapsed         | 660        |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.07922964 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.596     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00111   |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.114      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16         |
|    ep_rew_mean          | 3.8        |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 57         |
|    time_elapsed         | 671        |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.10321753 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.463     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0609    |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0359    |
|    value_loss           | 0.0646     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 14.4      |
|    ep_rew_mean          | 4.14      |
| time/                   |           |
|    fps                  | 173       |
|    iterations           | 58        |
|    time_elapsed         | 683       |
|    total_timesteps      | 118784    |
| train/                  |           |
|    approx_kl            | 0.0669566 |
|    clip_fraction        | 0.231     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.464    |
|    explained_variance   | 0.937     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0519   |
|    n_updates            | 570       |
|    policy_gradient_loss | -0.00413  |
|    value_loss           | 0.0917    |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=120000, episode_reward=-14.99 +/- 16.85
Episode length: 94.80 +/- 67.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 94.8        |
|    mean_reward          | -15         |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.051836453 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.372      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0495     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0253     |
|    value_loss           | 0.159       |
-----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 3.06     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 59       |
|    time_elapsed    | 696      |
|    total_timesteps | 120832   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 15.5        |
|    ep_rew_mean          | 4.3         |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 60          |
|    time_elapsed         | 707         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.111144595 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.54       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0117     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0431     |
|    value_loss           | 0.208       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.8        |
|    ep_rew_mean          | 3.89        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 61          |
|    time_elapsed         | 719         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.080278724 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.407      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0471     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0385     |
|    value_loss           | 0.112       |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 2.7         |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 62          |
|    time_elapsed         | 730         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.050281495 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.322      |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0326     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0334     |
|    value_loss           | 0.0788      |
-----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.5        |
|    ep_rew_mean          | 3.66        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 63          |
|    time_elapsed         | 742         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.111424044 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.521      |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.001       |
|    loss                 | 0.557       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0433     |
|    value_loss           | 0.697       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=130000, episode_reward=3.65 +/- 0.10
Episode length: 11.40 +/- 0.49
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 11.4      |
|    mean_reward          | 3.65      |
| time/                   |           |
|    total_timesteps      | 130000    |
| train/                  |           |
|    approx_kl            | 0.1268457 |
|    clip_fraction        | 0.296     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.524    |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.001     |
|    loss                 | -0.00102  |
|    n_updates            | 630       |
|    policy_gradient_loss | -0.0259   |
|    value_loss           | 0.296     |
---------------------------------------
New best mean reward!
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.1     |
|    ep_rew_mean     | 2.55     |
| time/              |          |
|    fps             | 173      |
|    iterations      | 64       |
|    time_elapsed    | 753      |
|    total_timesteps | 131072   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.2        |
|    ep_rew_mean          | 3.74        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 65          |
|    time_elapsed         | 765         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.064638026 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.767      |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0943      |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.0211      |
|    value_loss           | 0.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 3.42       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 66         |
|    time_elapsed         | 776        |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.06956151 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.514     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0534     |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0271    |
|    value_loss           | 0.209      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 1.63       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 67         |
|    time_elapsed         | 788        |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.06669251 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.585     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0954     |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.328      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26         |
|    ep_rew_mean          | 1.9        |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 68         |
|    time_elapsed         | 800        |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.08775875 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.926     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.001      |
|    loss                 | -0.057     |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.0413    |
|    value_loss           | 0.164      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=140000, episode_reward=-9.27 +/- 16.98
Episode length: 67.80 +/- 67.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.8       |
|    mean_reward          | -9.27      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.12903342 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.851     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0544     |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0346    |
|    value_loss           | 0.176      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 2.73     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 69       |
|    time_elapsed    | 812      |
|    total_timesteps | 141312   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 2.23       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 70         |
|    time_elapsed         | 823        |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.05262167 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.778     |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00852   |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.0233    |
|    value_loss           | 0.157      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 2.83       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 71         |
|    time_elapsed         | 834        |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.06686618 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.809     |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.001      |
|    loss                 | 0.263      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0362    |
|    value_loss           | 0.645      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24        |
|    ep_rew_mean          | 3.12      |
| time/                   |           |
|    fps                  | 174       |
|    iterations           | 72        |
|    time_elapsed         | 846       |
|    total_timesteps      | 147456    |
| train/                  |           |
|    approx_kl            | 0.0789507 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.684    |
|    explained_variance   | 0.779     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0476   |
|    n_updates            | 710       |
|    policy_gradient_loss | -0.044    |
|    value_loss           | 0.413     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 3.96       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 73         |
|    time_elapsed         | 857        |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.08576535 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.751     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0367    |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.32       |
----------------------------------------
Eval num_timesteps=150000, episode_reward=5.01 +/- 1.78
Episode length: 12.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12.4       |
|    mean_reward          | 5.01       |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.07205429 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.685     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0242    |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.0327    |
|    value_loss           | 0.206      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 3.09     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 74       |
|    time_elapsed    | 869      |
|    total_timesteps | 151552   |
---------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 2.83      |
| time/                   |           |
|    fps                  | 174       |
|    iterations           | 75        |
|    time_elapsed         | 881       |
|    total_timesteps      | 153600    |
| train/                  |           |
|    approx_kl            | 0.0923229 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.641    |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.001     |
|    loss                 | -0.0441   |
|    n_updates            | 740       |
|    policy_gradient_loss | -0.0416   |
|    value_loss           | 0.183     |
---------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.6        |
|    ep_rew_mean          | 3.84        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 76          |
|    time_elapsed         | 892         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.059308928 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0324      |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0438     |
|    value_loss           | 0.13        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 3.74       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 77         |
|    time_elapsed         | 904        |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.05374032 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.484     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0706    |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0231    |
|    value_loss           | 0.112      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.9        |
|    ep_rew_mean          | 3.78        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 78          |
|    time_elapsed         | 915         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.049728874 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | -0.062      |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.148       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=160000, episode_reward=-2.52 +/- 13.81
Episode length: 40.00 +/- 55.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40         |
|    mean_reward          | -2.52      |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.06329461 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0592    |
|    n_updates            | 780        |
|    policy_gradient_loss | -0.0326    |
|    value_loss           | 0.125      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.2     |
|    ep_rew_mean     | 3.81     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 79       |
|    time_elapsed    | 927      |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 2.9         |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 80          |
|    time_elapsed         | 939         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.060517427 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00312     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0319     |
|    value_loss           | 0.223       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 3.79       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 81         |
|    time_elapsed         | 950        |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.08522178 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.67      |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0349    |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0412    |
|    value_loss           | 0.255      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.2        |
|    ep_rew_mean          | 4.23        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 82          |
|    time_elapsed         | 961         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.083168134 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.607      |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0364     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0358     |
|    value_loss           | 0.223       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.7        |
|    ep_rew_mean          | 2.69        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 83          |
|    time_elapsed         | 972         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.103654355 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.499      |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0696      |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0349     |
|    value_loss           | 0.206       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=170000, episode_reward=-8.45 +/- 17.68
Episode length: 67.80 +/- 67.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.8       |
|    mean_reward          | -8.45      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.11506764 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.575     |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.001      |
|    loss                 | 0.149      |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.0406    |
|    value_loss           | 0.673      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 2.73     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 84       |
|    time_elapsed    | 984      |
|    total_timesteps | 172032   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 3.39       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 85         |
|    time_elapsed         | 996        |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.09767634 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.641     |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0488    |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0277    |
|    value_loss           | 0.274      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 3.01        |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 86          |
|    time_elapsed         | 1008        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.078306966 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.605      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0152     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0325     |
|    value_loss           | 0.145       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.3       |
|    ep_rew_mean          | 4.56       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 87         |
|    time_elapsed         | 1019       |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.05550717 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.613     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0403    |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0175    |
|    value_loss           | 0.288      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=180000, episode_reward=-9.99 +/- 16.34
Episode length: 67.60 +/- 67.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.6       |
|    mean_reward          | -9.99      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.06414144 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0243    |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.235      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 3.52     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 88       |
|    time_elapsed    | 1031     |
|    total_timesteps | 180224   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 2.52       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 89         |
|    time_elapsed         | 1043       |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.07447418 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.647     |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0355    |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.313      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 3.21       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 90         |
|    time_elapsed         | 1054       |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.07589347 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.681     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0426    |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0458    |
|    value_loss           | 0.143      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 3.48       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 91         |
|    time_elapsed         | 1065       |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.08929956 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.578     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | 0.177      |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.0336    |
|    value_loss           | 0.121      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 4          |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 92         |
|    time_elapsed         | 1077       |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.07366826 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.001      |
|    loss                 | 0.739      |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.0272    |
|    value_loss           | 0.955      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=190000, episode_reward=-7.48 +/- 18.54
Episode length: 67.20 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.2       |
|    mean_reward          | -7.48      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.08622681 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.494     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0315     |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0332    |
|    value_loss           | 0.298      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.1     |
|    ep_rew_mean     | 3.96     |
| time/              |          |
|    fps             | 174      |
|    iterations      | 93       |
|    time_elapsed    | 1089     |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 3.38       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 94         |
|    time_elapsed         | 1100       |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.07428434 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.6       |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0579     |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.0341    |
|    value_loss           | 0.292      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 3.36       |
| time/                   |            |
|    fps                  | 174        |
|    iterations           | 95         |
|    time_elapsed         | 1111       |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.08468824 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.604     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.049     |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0365    |
|    value_loss           | 0.152      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.1        |
|    ep_rew_mean          | 4.12        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 96          |
|    time_elapsed         | 1122        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.049851425 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.621      |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0867      |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.209       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.6        |
|    ep_rew_mean          | 3.89        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 97          |
|    time_elapsed         | 1134        |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.062754385 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.485      |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.001       |
|    loss                 | 0.061       |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0371     |
|    value_loss           | 0.423       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=200000, episode_reward=-2.50 +/- 13.83
Episode length: 40.00 +/- 55.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40         |
|    mean_reward          | -2.5       |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.06938018 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.418     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.001      |
|    loss                 | 0.462      |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0321    |
|    value_loss           | 0.46       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.8     |
|    ep_rew_mean     | 3.52     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 98       |
|    time_elapsed    | 1145     |
|    total_timesteps | 200704   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 2.9        |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 99         |
|    time_elapsed         | 1157       |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.06384735 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.524     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0476    |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.168      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 2.6        |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 100        |
|    time_elapsed         | 1168       |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.07158269 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0832    |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0513    |
|    value_loss           | 0.173      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 2.74        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 101         |
|    time_elapsed         | 1179        |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.058358237 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0687     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0289     |
|    value_loss           | 0.122       |
-----------------------------------------
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 16.7     |
|    ep_rew_mean          | 3.57     |
| time/                   |          |
|    fps                  | 175      |
|    iterations           | 102      |
|    time_elapsed         | 1191     |
|    total_timesteps      | 208896   |
| train/                  |          |
|    approx_kl            | 0.05163  |
|    clip_fraction        | 0.272    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.658   |
|    explained_variance   | 0.92     |
|    learning_rate        | 0.001    |
|    loss                 | 0.175    |
|    n_updates            | 1010     |
|    policy_gradient_loss | -0.028   |
|    value_loss           | 0.187    |
--------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=210000, episode_reward=-9.14 +/- 17.10
Episode length: 67.40 +/- 67.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.4       |
|    mean_reward          | -9.14      |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.06472364 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.429     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.001      |
|    loss                 | -0.032     |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.107      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 3.61     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 103      |
|    time_elapsed    | 1203     |
|    total_timesteps | 210944   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.2       |
|    ep_rew_mean          | 3.93       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 104        |
|    time_elapsed         | 1214       |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.51409864 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.474     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0891    |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.065     |
|    value_loss           | 0.0948     |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 3.53       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 105        |
|    time_elapsed         | 1226       |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.06515589 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.458     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.00551   |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0254    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 3.54       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 106        |
|    time_elapsed         | 1237       |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.07865863 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0466    |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0236    |
|    value_loss           | 0.116      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.2        |
|    ep_rew_mean          | 3.87        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 107         |
|    time_elapsed         | 1249        |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.051338486 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.49       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0336     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0305     |
|    value_loss           | 0.107       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=220000, episode_reward=-9.94 +/- 16.38
Episode length: 67.20 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.2       |
|    mean_reward          | -9.94      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.07331067 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.43      |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0348     |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.0264    |
|    value_loss           | 0.142      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 3.51     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 108      |
|    time_elapsed    | 1262     |
|    total_timesteps | 221184   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 4.04       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 109        |
|    time_elapsed         | 1273       |
|    total_timesteps      | 223232     |
| train/                  |            |
|    approx_kl            | 0.07402998 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.509     |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00416    |
|    n_updates            | 1080       |
|    policy_gradient_loss | -0.0228    |
|    value_loss           | 0.0979     |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 3.48       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 110        |
|    time_elapsed         | 1285       |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.06066698 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.434     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0705    |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0507    |
|    value_loss           | 0.0882     |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.6        |
|    ep_rew_mean          | 3.53        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 111         |
|    time_elapsed         | 1296        |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.048840597 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.478      |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0683     |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0281     |
|    value_loss           | 0.0774      |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 15.7        |
|    ep_rew_mean          | 3.72        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 112         |
|    time_elapsed         | 1308        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.048373207 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.446      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | -0.0701     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0408     |
|    value_loss           | 0.0953      |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=230000, episode_reward=-7.61 +/- 16.76
Episode length: 67.60 +/- 67.28
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 67.6      |
|    mean_reward          | -7.61     |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0818167 |
|    clip_fraction        | 0.23      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.478    |
|    explained_variance   | 0.964     |
|    learning_rate        | 0.001     |
|    loss                 | 0.00657   |
|    n_updates            | 1120      |
|    policy_gradient_loss | -0.0269   |
|    value_loss           | 0.0651    |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 2.15     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 113      |
|    time_elapsed    | 1320     |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 3.23       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 114        |
|    time_elapsed         | 1331       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.17585665 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.786     |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00123   |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0613    |
|    value_loss           | 0.198      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.6      |
|    ep_rew_mean          | 3.63      |
| time/                   |           |
|    fps                  | 175       |
|    iterations           | 115       |
|    time_elapsed         | 1343      |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.0753669 |
|    clip_fraction        | 0.316     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.636    |
|    explained_variance   | 0.882     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0248    |
|    n_updates            | 1140      |
|    policy_gradient_loss | -0.0411   |
|    value_loss           | 0.181     |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 3.49       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 116        |
|    time_elapsed         | 1354       |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.07034465 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.637     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0622     |
|    n_updates            | 1150       |
|    policy_gradient_loss | -0.0422    |
|    value_loss           | 0.199      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.7      |
|    ep_rew_mean          | 3.53      |
| time/                   |           |
|    fps                  | 175       |
|    iterations           | 117       |
|    time_elapsed         | 1366      |
|    total_timesteps      | 239616    |
| train/                  |           |
|    approx_kl            | 0.0621082 |
|    clip_fraction        | 0.264     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.565    |
|    explained_variance   | 0.938     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0588    |
|    n_updates            | 1160      |
|    policy_gradient_loss | -0.0399   |
|    value_loss           | 0.112     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=240000, episode_reward=-14.95 +/- 16.91
Episode length: 94.60 +/- 67.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.6       |
|    mean_reward          | -14.9      |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.09527036 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.614     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00796    |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.176      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.4     |
|    ep_rew_mean     | 3.85     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 118      |
|    time_elapsed    | 1378     |
|    total_timesteps | 241664   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.1       |
|    ep_rew_mean          | 3.93       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 119        |
|    time_elapsed         | 1390       |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.06364852 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.486     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.044     |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.04      |
|    value_loss           | 0.127      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.2       |
|    ep_rew_mean          | 3.94       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 120        |
|    time_elapsed         | 1401       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.07798733 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0265    |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.0335    |
|    value_loss           | 0.102      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.1        |
|    ep_rew_mean          | 3.87        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 121         |
|    time_elapsed         | 1413        |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.047398172 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.506      |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0651     |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0282     |
|    value_loss           | 0.0967      |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 4.32       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 122        |
|    time_elapsed         | 1424       |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.05543316 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.467     |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00616   |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0216    |
|    value_loss           | 0.0776     |
----------------------------------------
Eval num_timesteps=250000, episode_reward=4.08 +/- 1.44
Episode length: 12.60 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.6        |
|    mean_reward          | 4.08        |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.060613077 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.442      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00987     |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0335     |
|    value_loss           | 0.209       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17       |
|    ep_rew_mean     | 4.16     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 123      |
|    time_elapsed    | 1436     |
|    total_timesteps | 251904   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.3       |
|    ep_rew_mean          | 4.02       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 124        |
|    time_elapsed         | 1447       |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.10999543 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.493     |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0128    |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.0636    |
|    value_loss           | 0.2        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.7       |
|    ep_rew_mean          | 3.8        |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 125        |
|    time_elapsed         | 1458       |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.07265502 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.426     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0814    |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.017     |
|    value_loss           | 0.107      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17.2        |
|    ep_rew_mean          | 3.73        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 126         |
|    time_elapsed         | 1470        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.053280093 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.371      |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0439      |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0311     |
|    value_loss           | 0.116       |
-----------------------------------------
reached max steps=300
Eval num_timesteps=260000, episode_reward=4.35 +/- 1.60
Episode length: 11.80 +/- 0.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 11.8       |
|    mean_reward          | 4.35       |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.07473208 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.416     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0509    |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.151      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.2     |
|    ep_rew_mean     | 3.57     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 127      |
|    time_elapsed    | 1481     |
|    total_timesteps | 260096   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 3.68       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 128        |
|    time_elapsed         | 1492       |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.04724498 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.494     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0132    |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.0354    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
reached max steps=300
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 19.4     |
|    ep_rew_mean          | 2.96     |
| time/                   |          |
|    fps                  | 175      |
|    iterations           | 129      |
|    time_elapsed         | 1504     |
|    total_timesteps      | 264192   |
| train/                  |          |
|    approx_kl            | 0.1182   |
|    clip_fraction        | 0.249    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.531   |
|    explained_variance   | 0.712    |
|    learning_rate        | 0.001    |
|    loss                 | -0.00763 |
|    n_updates            | 1280     |
|    policy_gradient_loss | -0.0523  |
|    value_loss           | 0.201    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 3.47       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 130        |
|    time_elapsed         | 1515       |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.14623177 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.584     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0595    |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.052     |
|    value_loss           | 0.0878     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.1       |
|    ep_rew_mean          | 4.53       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 131        |
|    time_elapsed         | 1526       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.06689805 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.455     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.012     |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.032     |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
Eval num_timesteps=270000, episode_reward=4.29 +/- 1.63
Episode length: 12.00 +/- 0.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 12         |
|    mean_reward          | 4.29       |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.04609695 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.337     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0298    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0171    |
|    value_loss           | 0.126      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 3.7      |
| time/              |          |
|    fps             | 175      |
|    iterations      | 132      |
|    time_elapsed    | 1538     |
|    total_timesteps | 270336   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.3        |
|    ep_rew_mean          | 4.32        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 133         |
|    time_elapsed         | 1549        |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.058719564 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.582      |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.001       |
|    loss                 | 0.035       |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0324     |
|    value_loss           | 0.234       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.4        |
|    ep_rew_mean          | 3.9         |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 134         |
|    time_elapsed         | 1560        |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.055990294 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.418      |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.001       |
|    loss                 | -0.035      |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0341     |
|    value_loss           | 0.111       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18          |
|    ep_rew_mean          | 3.8         |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 135         |
|    time_elapsed         | 1571        |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.055839293 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.405      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0334     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0345     |
|    value_loss           | 0.207       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 3.33        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 136         |
|    time_elapsed         | 1582        |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.053993084 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.546      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.001       |
|    loss                 | -6.34e-05   |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0273     |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=280000, episode_reward=0.66 +/- 15.62
Episode length: 40.20 +/- 54.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 40.2        |
|    mean_reward          | 0.659       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.051697463 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.566      |
|    explained_variance   | 0.626       |
|    learning_rate        | 0.001       |
|    loss                 | 0.221       |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0379     |
|    value_loss           | 0.799       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.1     |
|    ep_rew_mean     | 2.79     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 137      |
|    time_elapsed    | 1595     |
|    total_timesteps | 280576   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26         |
|    ep_rew_mean          | 2.56       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 138        |
|    time_elapsed         | 1607       |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.07737914 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.676     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.001      |
|    loss                 | 0.11       |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.0367    |
|    value_loss           | 0.383      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 2.18       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 139        |
|    time_elapsed         | 1618       |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.07614212 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.851     |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.001      |
|    loss                 | 0.141      |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0461    |
|    value_loss           | 0.448      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 3.44       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 140        |
|    time_elapsed         | 1630       |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.10162905 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.701     |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0315     |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.0578    |
|    value_loss           | 0.318      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.5        |
|    ep_rew_mean          | 4.82        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 141         |
|    time_elapsed         | 1641        |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.086138934 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.649      |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0501     |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.0434     |
|    value_loss           | 0.175       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=290000, episode_reward=-14.99 +/- 16.85
Episode length: 94.80 +/- 67.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 94.8       |
|    mean_reward          | -15        |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.08249166 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.395     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0446    |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0409    |
|    value_loss           | 0.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.7     |
|    ep_rew_mean     | 4.22     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 142      |
|    time_elapsed    | 1654     |
|    total_timesteps | 290816   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 2.33       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 143        |
|    time_elapsed         | 1666       |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.05247709 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.522     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0842     |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0489    |
|    value_loss           | 0.431      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.5        |
|    ep_rew_mean          | 4.24        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 144         |
|    time_elapsed         | 1678        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.122190624 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.778      |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0497     |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0551     |
|    value_loss           | 0.343       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 3.95       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 145        |
|    time_elapsed         | 1689       |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.13630703 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.524     |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0367    |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0413    |
|    value_loss           | 0.249      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 4.23       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 146        |
|    time_elapsed         | 1701       |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.07074907 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.63      |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.001      |
|    loss                 | 0.11       |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.158      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=300000, episode_reward=-1.62 +/- 14.30
Episode length: 39.80 +/- 55.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39.8        |
|    mean_reward          | -1.62       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.059721272 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.518      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0574      |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 4.46     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 147      |
|    time_elapsed    | 1713     |
|    total_timesteps | 301056   |
---------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 3.76        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 148         |
|    time_elapsed         | 1725        |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.075951636 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.497      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0151     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0363     |
|    value_loss           | 0.2         |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 4.41       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 149        |
|    time_elapsed         | 1736       |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.08302106 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0251     |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.0386    |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 3.92       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 150        |
|    time_elapsed         | 1747       |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.06604585 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.476     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0291    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0312    |
|    value_loss           | 0.132      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 3.74       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 151        |
|    time_elapsed         | 1759       |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.09678312 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0511    |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.022     |
|    value_loss           | 0.118      |
----------------------------------------
reached max steps=300
Eval num_timesteps=310000, episode_reward=-2.42 +/- 13.87
Episode length: 39.60 +/- 55.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.6       |
|    mean_reward          | -2.42      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.07676061 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.57      |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0374    |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0351    |
|    value_loss           | 0.12       |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 3.65     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 152      |
|    time_elapsed    | 1770     |
|    total_timesteps | 311296   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.4      |
|    ep_rew_mean          | 3.97      |
| time/                   |           |
|    fps                  | 175       |
|    iterations           | 153       |
|    time_elapsed         | 1782      |
|    total_timesteps      | 313344    |
| train/                  |           |
|    approx_kl            | 0.2049465 |
|    clip_fraction        | 0.289     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.581    |
|    explained_variance   | 0.906     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0612   |
|    n_updates            | 1520      |
|    policy_gradient_loss | -0.0428   |
|    value_loss           | 0.101     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.4       |
|    ep_rew_mean          | 4.64       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 154        |
|    time_elapsed         | 1793       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.07531147 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.551     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0411    |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0195    |
|    value_loss           | 0.107      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.6        |
|    ep_rew_mean          | 4.94        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 155         |
|    time_elapsed         | 1805        |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.051441483 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.486      |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0389      |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0222     |
|    value_loss           | 0.11        |
-----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 3.47       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 156        |
|    time_elapsed         | 1816       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.05661851 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.432     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00432   |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.132      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=320000, episode_reward=-9.19 +/- 17.06
Episode length: 67.60 +/- 67.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 67.6       |
|    mean_reward          | -9.19      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.10438715 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.71      |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0418    |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.115      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 4.71     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 157      |
|    time_elapsed    | 1828     |
|    total_timesteps | 321536   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.1        |
|    ep_rew_mean          | 4.61        |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 158         |
|    time_elapsed         | 1839        |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.103721365 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.526      |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00606     |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0416     |
|    value_loss           | 0.114       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 4.49       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 159        |
|    time_elapsed         | 1851       |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.06833831 |
|    clip_fraction        | 0.223      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.491     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.062     |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.023     |
|    value_loss           | 0.138      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 3.66       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 160        |
|    time_elapsed         | 1862       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.07885791 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.591     |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.001      |
|    loss                 | 0.33       |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0296    |
|    value_loss           | 0.563      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.6       |
|    ep_rew_mean          | 4.91       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 161        |
|    time_elapsed         | 1874       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.09484629 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.652     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0237    |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0353    |
|    value_loss           | 0.208      |
----------------------------------------
Eval num_timesteps=330000, episode_reward=3.45 +/- 0.20
Episode length: 12.20 +/- 0.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.2        |
|    mean_reward          | 3.45        |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.083751924 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.467      |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.001       |
|    loss                 | 0.0252      |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.028      |
|    value_loss           | 0.213       |
-----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.6     |
|    ep_rew_mean     | 3.73     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 162      |
|    time_elapsed    | 1885     |
|    total_timesteps | 331776   |
---------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 2.81       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 163        |
|    time_elapsed         | 1896       |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.08985199 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.754     |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0549     |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0331    |
|    value_loss           | 0.105      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 4.28       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 164        |
|    time_elapsed         | 1908       |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.11414737 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.798     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0437    |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.0426    |
|    value_loss           | 0.135      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 4.05       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 165        |
|    time_elapsed         | 1920       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.07847113 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.568     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0992    |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0323    |
|    value_loss           | 0.159      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 4.37       |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 166        |
|    time_elapsed         | 1931       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.13002327 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.651     |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0128    |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0555    |
|    value_loss           | 0.256      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=7.34 +/- 4.01
Episode length: 12.80 +/- 1.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 12.8        |
|    mean_reward          | 7.34        |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.108302906 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.529      |
|    explained_variance   | 0.361       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00792     |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0568     |
|    value_loss           | 0.235       |
-----------------------------------------
New best mean reward!
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 5.32     |
| time/              |          |
|    fps             | 175      |
|    iterations      | 167      |
|    time_elapsed    | 1943     |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.3       |
|    ep_rew_mean          | 5.07       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 168        |
|    time_elapsed         | 1954       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.08349047 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.482     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0434    |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.0954     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 4.61       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 169        |
|    time_elapsed         | 1966       |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.06615854 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.38      |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0148    |
|    n_updates            | 1680       |
|    policy_gradient_loss | -0.0211    |
|    value_loss           | 0.137      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 4.65       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 170        |
|    time_elapsed         | 1977       |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.09227783 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.512     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00732   |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0377    |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=350000, episode_reward=5.62 +/- 1.84
Episode length: 13.20 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.2       |
|    mean_reward          | 5.62       |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.08791104 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.596     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0671     |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0406    |
|    value_loss           | 0.26       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 3.9      |
| time/              |          |
|    fps             | 176      |
|    iterations      | 171      |
|    time_elapsed    | 1989     |
|    total_timesteps | 350208   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 5.61       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 172        |
|    time_elapsed         | 2001       |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.09870267 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.686     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0299    |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0421    |
|    value_loss           | 0.123      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.71        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 173         |
|    time_elapsed         | 2012        |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.082747675 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.414      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0498     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0253     |
|    value_loss           | 0.149       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.7        |
|    ep_rew_mean          | 3.21        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 174         |
|    time_elapsed         | 2024        |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.077427834 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.001       |
|    loss                 | -0.00554    |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.031      |
|    value_loss           | 0.477       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 4.95       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 175        |
|    time_elapsed         | 2035       |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.16148114 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.552     |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.001      |
|    loss                 | 0.191      |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0456    |
|    value_loss           | 0.403      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=5.50 +/- 1.78
Episode length: 13.80 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.8       |
|    mean_reward          | 5.5        |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.11834182 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.478     |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00705    |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.039     |
|    value_loss           | 0.34       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.7     |
|    ep_rew_mean     | 4.94     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 176      |
|    time_elapsed    | 2047     |
|    total_timesteps | 360448   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 4.66       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 177        |
|    time_elapsed         | 2058       |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.11116824 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0323    |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.297      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 4.44       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 178        |
|    time_elapsed         | 2070       |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.11791859 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.561     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.001      |
|    loss                 | -0.058     |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0302    |
|    value_loss           | 0.21       |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.9        |
|    ep_rew_mean          | 4.03        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 179         |
|    time_elapsed         | 2081        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.104842864 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.611      |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0566     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 0.138       |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.1      |
|    ep_rew_mean          | 4.86      |
| time/                   |           |
|    fps                  | 176       |
|    iterations           | 180       |
|    time_elapsed         | 2092      |
|    total_timesteps      | 368640    |
| train/                  |           |
|    approx_kl            | 0.0984533 |
|    clip_fraction        | 0.305     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.589    |
|    explained_variance   | 0.862     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0631   |
|    n_updates            | 1790      |
|    policy_gradient_loss | -0.0415   |
|    value_loss           | 0.182     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=370000, episode_reward=-14.27 +/- 17.69
Episode length: 95.20 +/- 67.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 95.2        |
|    mean_reward          | -14.3       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.112909056 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.487      |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0588     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.147       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 5.37     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 181      |
|    time_elapsed    | 2105     |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.8       |
|    ep_rew_mean          | 5.62       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 182        |
|    time_elapsed         | 2116       |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.08317673 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.478     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0249    |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0423    |
|    value_loss           | 0.142      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 6.28       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 183        |
|    time_elapsed         | 2127       |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.07918116 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.314     |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0608     |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 0.182      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.8       |
|    ep_rew_mean          | 5.67       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 184        |
|    time_elapsed         | 2139       |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.12210716 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.33      |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0305    |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0576    |
|    value_loss           | 0.162      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.1       |
|    ep_rew_mean          | 5.88       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 185        |
|    time_elapsed         | 2150       |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.06647462 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.347     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0415    |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0221    |
|    value_loss           | 0.117      |
----------------------------------------
reached max steps=300
Eval num_timesteps=380000, episode_reward=-0.29 +/- 15.03
Episode length: 41.00 +/- 54.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 41         |
|    mean_reward          | -0.286     |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.09380019 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.355     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0252     |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0324    |
|    value_loss           | 0.15       |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 5.83     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 186      |
|    time_elapsed    | 2163     |
|    total_timesteps | 380928   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 5.4        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 187        |
|    time_elapsed         | 2174       |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.08708863 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.361     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0447    |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.0274    |
|    value_loss           | 0.178      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 4.78        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 188         |
|    time_elapsed         | 2185        |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.091384485 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.448      |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0432     |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.0252     |
|    value_loss           | 0.23        |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 5.95       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 189        |
|    time_elapsed         | 2197       |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.10816965 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.497     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0207     |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.0379    |
|    value_loss           | 0.178      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 5.8        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 190        |
|    time_elapsed         | 2209       |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.11448158 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.38      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0372    |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0356    |
|    value_loss           | 0.192      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=8.16 +/- 3.80
Episode length: 16.60 +/- 3.50
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 16.6      |
|    mean_reward          | 8.16      |
| time/                   |           |
|    total_timesteps      | 390000    |
| train/                  |           |
|    approx_kl            | 0.1164622 |
|    clip_fraction        | 0.279     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.367    |
|    explained_variance   | 0.714     |
|    learning_rate        | 0.001     |
|    loss                 | 0.00379   |
|    n_updates            | 1900      |
|    policy_gradient_loss | -0.0424   |
|    value_loss           | 0.277     |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 6.31     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 191      |
|    time_elapsed    | 2220     |
|    total_timesteps | 391168   |
---------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 4.99       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 192        |
|    time_elapsed         | 2232       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.11218522 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.344     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0102    |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.0289    |
|    value_loss           | 0.183      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.1       |
|    ep_rew_mean          | 6.52       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 193        |
|    time_elapsed         | 2243       |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.10234159 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.507     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.001      |
|    loss                 | 0.019      |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.0314    |
|    value_loss           | 0.299      |
----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.6      |
|    ep_rew_mean          | 6.05      |
| time/                   |           |
|    fps                  | 176       |
|    iterations           | 194       |
|    time_elapsed         | 2255      |
|    total_timesteps      | 397312    |
| train/                  |           |
|    approx_kl            | 0.0840206 |
|    clip_fraction        | 0.23      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.347    |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0938    |
|    n_updates            | 1930      |
|    policy_gradient_loss | -0.0407   |
|    value_loss           | 0.224     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 5.15        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 195         |
|    time_elapsed         | 2266        |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.098765865 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.46       |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0317     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0395     |
|    value_loss           | 0.178       |
-----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=400000, episode_reward=-1.82 +/- 14.37
Episode length: 40.60 +/- 54.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.6       |
|    mean_reward          | -1.82      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.12734154 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0438    |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0335    |
|    value_loss           | 0.156      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 5.33     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 196      |
|    time_elapsed    | 2278     |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 5.29       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 197        |
|    time_elapsed         | 2289       |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.14734526 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.49      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0517    |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.0483    |
|    value_loss           | 0.198      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 6.28       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 198        |
|    time_elapsed         | 2301       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.10595298 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.438     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0278    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0435    |
|    value_loss           | 0.182      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 5.2         |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 199         |
|    time_elapsed         | 2313        |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.092383996 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.341      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0377     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0206     |
|    value_loss           | 0.171       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 5.59       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 200        |
|    time_elapsed         | 2324       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.12514964 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.401     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0556    |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0501    |
|    value_loss           | 0.111      |
----------------------------------------
Eval num_timesteps=410000, episode_reward=7.81 +/- 2.73
Episode length: 14.40 +/- 2.73
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 14.4        |
|    mean_reward          | 7.81        |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.119019516 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.404      |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.001       |
|    loss                 | 0.147       |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0312     |
|    value_loss           | 0.197       |
-----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 5.87     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 201      |
|    time_elapsed    | 2336     |
|    total_timesteps | 411648   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 6.12       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 202        |
|    time_elapsed         | 2347       |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.07353164 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.339     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0343     |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.0364    |
|    value_loss           | 0.144      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 16.6        |
|    ep_rew_mean          | 6.21        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 203         |
|    time_elapsed         | 2358        |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.114496514 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.311      |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0231     |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0212     |
|    value_loss           | 0.185       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.8       |
|    ep_rew_mean          | 6.88       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 204        |
|    time_elapsed         | 2370       |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.09346831 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.307     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.001      |
|    loss                 | -0.000431  |
|    n_updates            | 2030       |
|    policy_gradient_loss | -0.0333    |
|    value_loss           | 0.0993     |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 5.21       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 205        |
|    time_elapsed         | 2382       |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.10550943 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.277     |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0502     |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0239    |
|    value_loss           | 0.155      |
----------------------------------------
reached max steps=300
Eval num_timesteps=420000, episode_reward=1.95 +/- 14.41
Episode length: 41.80 +/- 54.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 41.8       |
|    mean_reward          | 1.95       |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.21431012 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.468     |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.001      |
|    loss                 | -0.0379    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0597    |
|    value_loss           | 0.225      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 17.4     |
|    ep_rew_mean     | 5.77     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 206      |
|    time_elapsed    | 2393     |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 6.64       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 207        |
|    time_elapsed         | 2405       |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.09978217 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.339     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0292     |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0262    |
|    value_loss           | 0.223      |
----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 6.07        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 208         |
|    time_elapsed         | 2416        |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.095342696 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.29       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.001       |
|    loss                 | 0.254       |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0363     |
|    value_loss           | 0.292       |
-----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 5.99       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 209        |
|    time_elapsed         | 2428       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.11434913 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.375     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0143     |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0355    |
|    value_loss           | 0.312      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=430000, episode_reward=-8.96 +/- 15.60
Episode length: 66.60 +/- 68.10
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 66.6      |
|    mean_reward          | -8.96     |
| time/                   |           |
|    total_timesteps      | 430000    |
| train/                  |           |
|    approx_kl            | 0.1217955 |
|    clip_fraction        | 0.271     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.366    |
|    explained_variance   | 0.741     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0474    |
|    n_updates            | 2090      |
|    policy_gradient_loss | -0.0543   |
|    value_loss           | 0.281     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 5.99     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 210      |
|    time_elapsed    | 2440     |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.2       |
|    ep_rew_mean          | 6.54       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 211        |
|    time_elapsed         | 2451       |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.17376567 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.386     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0479    |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0329    |
|    value_loss           | 0.178      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 5.4        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 212        |
|    time_elapsed         | 2463       |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.12998398 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.332     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00779   |
|    n_updates            | 2110       |
|    policy_gradient_loss | -0.035     |
|    value_loss           | 0.133      |
----------------------------------------
reached max steps=300
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.5      |
|    ep_rew_mean          | 5.84      |
| time/                   |           |
|    fps                  | 176       |
|    iterations           | 213       |
|    time_elapsed         | 2474      |
|    total_timesteps      | 436224    |
| train/                  |           |
|    approx_kl            | 0.1244909 |
|    clip_fraction        | 0.201     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.398    |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0437   |
|    n_updates            | 2120      |
|    policy_gradient_loss | -0.0335   |
|    value_loss           | 0.0998    |
---------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 6.57       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 214        |
|    time_elapsed         | 2485       |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.14322616 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.437     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0502    |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0522    |
|    value_loss           | 0.1        |
----------------------------------------
reached max steps=300
Eval num_timesteps=440000, episode_reward=0.35 +/- 13.39
Episode length: 41.60 +/- 54.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.6        |
|    mean_reward          | 0.35        |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.101561666 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.246      |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0504     |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.109       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 14.9     |
|    ep_rew_mean     | 6.96     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 215      |
|    time_elapsed    | 2497     |
|    total_timesteps | 440320   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 5.58        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 216         |
|    time_elapsed         | 2509        |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.070901275 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.2        |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0327     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0187     |
|    value_loss           | 0.111       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 6.37       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 217        |
|    time_elapsed         | 2520       |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.19746384 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.418     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00455    |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0194    |
|    value_loss           | 0.203      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 5.51       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 218        |
|    time_elapsed         | 2531       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.10011175 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.293     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0558    |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.0266    |
|    value_loss           | 0.129      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 4.83       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 219        |
|    time_elapsed         | 2543       |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.10546319 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.56      |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0349    |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0337    |
|    value_loss           | 0.132      |
----------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=450000, episode_reward=-1.66 +/- 14.26
Episode length: 40.00 +/- 55.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40         |
|    mean_reward          | -1.66      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.14484967 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.579     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0275    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.038     |
|    value_loss           | 0.106      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.3     |
|    ep_rew_mean     | 5.53     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 220      |
|    time_elapsed    | 2555     |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.9       |
|    ep_rew_mean          | 6.49       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 221        |
|    time_elapsed         | 2566       |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.08582091 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0151     |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0268    |
|    value_loss           | 0.158      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 6.13       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 222        |
|    time_elapsed         | 2578       |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.08432104 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.329     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0513    |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0275    |
|    value_loss           | 0.102      |
----------------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 6.04       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 223        |
|    time_elapsed         | 2589       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.12536708 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.432     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0338     |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0311    |
|    value_loss           | 0.225      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 6.13       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 224        |
|    time_elapsed         | 2600       |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.12786782 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.46      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0594    |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0234    |
|    value_loss           | 0.199      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=460000, episode_reward=1.81 +/- 14.35
Episode length: 42.40 +/- 53.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 42.4       |
|    mean_reward          | 1.81       |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.10380103 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0534    |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0452    |
|    value_loss           | 0.125      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 5.7      |
| time/              |          |
|    fps             | 176      |
|    iterations      | 225      |
|    time_elapsed    | 2613     |
|    total_timesteps | 460800   |
---------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 5.84        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 226         |
|    time_elapsed         | 2624        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.081113055 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.496      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0383     |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0279     |
|    value_loss           | 0.134       |
-----------------------------------------
reached max steps=300
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.5      |
|    ep_rew_mean          | 5.73      |
| time/                   |           |
|    fps                  | 176       |
|    iterations           | 227       |
|    time_elapsed         | 2635      |
|    total_timesteps      | 464896    |
| train/                  |           |
|    approx_kl            | 0.1423428 |
|    clip_fraction        | 0.304     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.477    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.001     |
|    loss                 | 0.0209    |
|    n_updates            | 2260      |
|    policy_gradient_loss | -0.0212   |
|    value_loss           | 0.172     |
---------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 5.71       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 228        |
|    time_elapsed         | 2647       |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.10634034 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.428     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0827    |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0395    |
|    value_loss           | 0.116      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.1      |
|    ep_rew_mean          | 6.16      |
| time/                   |           |
|    fps                  | 176       |
|    iterations           | 229       |
|    time_elapsed         | 2658      |
|    total_timesteps      | 468992    |
| train/                  |           |
|    approx_kl            | 0.1027216 |
|    clip_fraction        | 0.235     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.509    |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0211   |
|    n_updates            | 2280      |
|    policy_gradient_loss | -0.0318   |
|    value_loss           | 0.135     |
---------------------------------------
reached max steps=300
reached max steps=300
reached max steps=300
Eval num_timesteps=470000, episode_reward=7.20 +/- 2.34
Episode length: 13.60 +/- 1.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 13.6       |
|    mean_reward          | 7.2        |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.09770056 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.388     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0243     |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0282    |
|    value_loss           | 0.157      |
----------------------------------------
reached max steps=300
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 4.36     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 230      |
|    time_elapsed    | 2670     |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 15.6       |
|    ep_rew_mean          | 6.14       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 231        |
|    time_elapsed         | 2681       |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.22711673 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.642     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0842     |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.0555    |
|    value_loss           | 0.101      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 17          |
|    ep_rew_mean          | 5.85        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 232         |
|    time_elapsed         | 2692        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.085113525 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.276      |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0559     |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0222     |
|    value_loss           | 0.0887      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.5       |
|    ep_rew_mean          | 6.6        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 233        |
|    time_elapsed         | 2704       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.13611586 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.33      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0462    |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0373    |
|    value_loss           | 0.173      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.5       |
|    ep_rew_mean          | 6.85       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 234        |
|    time_elapsed         | 2715       |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.08663829 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.261     |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00478    |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0272    |
|    value_loss           | 0.173      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=7.79 +/- 4.41
Episode length: 14.60 +/- 1.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 14.6       |
|    mean_reward          | 7.79       |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.12887065 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.272     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00991   |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.016     |
|    value_loss           | 0.116      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 6.18     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 235      |
|    time_elapsed    | 2727     |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.6       |
|    ep_rew_mean          | 6.3        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 236        |
|    time_elapsed         | 2738       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.16094624 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.338     |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0674    |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.0473    |
|    value_loss           | 0.182      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.9       |
|    ep_rew_mean          | 7.2        |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 237        |
|    time_elapsed         | 2750       |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.14365098 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.26      |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.001      |
|    loss                 | -0.000287  |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0287    |
|    value_loss           | 0.137      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 16.7       |
|    ep_rew_mean          | 6.67       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 238        |
|    time_elapsed         | 2761       |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.12825067 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.276     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0045     |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.03      |
|    value_loss           | 0.147      |
----------------------------------------
reached max steps=300
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 6.22       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 239        |
|    time_elapsed         | 2772       |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.11192559 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.243     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0853     |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 0.172      |
----------------------------------------
reached max steps=300
reached max steps=300
Eval num_timesteps=490000, episode_reward=-1.27 +/- 14.44
Episode length: 41.80 +/- 54.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 41.8       |
|    mean_reward          | -1.27      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.13435367 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.377     |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.001      |
|    loss                 | -0.0303    |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.0367     |
|    value_loss           | 0.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 5.68     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 240      |
|    time_elapsed    | 2784     |
|    total_timesteps | 491520   |
---------------------------------
reached max steps=300
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 6.42       |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 241        |
|    time_elapsed         | 2795       |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.11007281 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.391     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.001      |
|    loss                 | 0.00366    |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0135    |
|    value_loss           | 0.136      |
----------------------------------------
reached max steps=300
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 5.38        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 242         |
|    time_elapsed         | 2807        |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.099082775 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.279      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0566     |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0442     |
|    value_loss           | 0.155       |
-----------------------------------------
reached max steps=300
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 6.24        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 243         |
|    time_elapsed         | 2818        |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.078973204 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.289      |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0553     |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.044      |
|    value_loss           | 0.0906      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 15.5        |
|    ep_rew_mean          | 6.89        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 244         |
|    time_elapsed         | 2830        |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.118730515 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.37       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0363     |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0439     |
|    value_loss           | 0.0953      |
-----------------------------------------
reached max steps=300
Eval num_timesteps=500000, episode_reward=0.31 +/- 15.43
Episode length: 42.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 42         |
|    mean_reward          | 0.308      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.07318897 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.192     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0328    |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.00149    |
|    value_loss           | 0.105      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 16.4     |
|    ep_rew_mean     | 7.66     |
| time/              |          |
|    fps             | 176      |
|    iterations      | 245      |
|    time_elapsed    | 2841     |
|    total_timesteps | 501760   |
---------------------------------
